[
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "",
    "text": "Sobre mim\n \n\nMe chamo Prof.¬†Dr.¬†Pedro Rafael D. Marinho. Meu curr√≠culo Lattes poder√° ser acessado clicando aqui.\nSou docente do Departamento de Estat√≠stica da UFPB. üë®‚Äçüè´\nToda minha forma√ß√£o acad√™mica √© na √°rea de estat√≠stica (bacharelado ao doutorado).\nTenho entusiasmo por programa√ß√£o, ci√™ncia de dados e aprendizagem de m√°quina üíªüìà.\n Me acompanhe no GitHub: https://github.com/prdm0.\n Me acompanhe no Linkedin: https://www.linkedin.com/in/prdm0/."
  },
  {
    "objectID": "index.html#sobre-mim",
    "href": "index.html#sobre-mim",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Sobre mim",
    "text": "Sobre mim\n \n\nMe chamo Prof.¬†Dr.¬†Pedro Rafael D. Marinho. Meu curr√≠culo Lattes poder√° ser acessado clicando aqui.\nSou docente do Departamento de Estat√≠stica da UFPB. üë®‚Äçüè´\nToda minha forma√ß√£o acad√™mica √© na √°rea de estat√≠stica (bacharelado ao doutorado).\nTenho entusiasmo por programa√ß√£o, ci√™ncia de dados e aprendizagem de m√°quina üíªüìà.\n Me acompanhe no GitHub: https://github.com/prdm0.\n Me acompanhe no Linkedin: https://www.linkedin.com/in/prdm0/."
  },
  {
    "objectID": "index.html#meu-segundo-lar",
    "href": "index.html#meu-segundo-lar",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Meu segundo lar",
    "text": "Meu segundo lar\n\n\n\n\nDepartamento de Estat√≠stica da UFPB."
  },
  {
    "objectID": "index.html#que-linguagem-de-programa√ß√£o-utilizar",
    "href": "index.html#que-linguagem-de-programa√ß√£o-utilizar",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Que linguagem de programa√ß√£o utilizar?",
    "text": "Que linguagem de programa√ß√£o utilizar?\n\nNesse curso, ser√° abordado a linguagem de programa√ß√£o R, mas lembre-se que voc√™ poder√° utilizar qualquer linguagem de programa√ß√£o para fazer ci√™ncia de dados. Por√©m, R e Python s√£o as minhas sugest√µes, haja vista que, atualmente, elas s√£o as linguagens com maior quantidade de ferramentas e usu√°rios trabalhando na √°rea de ci√™ncia de dados.\n\nOutros motivos que me leva a lecionar a disciplina utilizando a linguagem R s√£o:\n\nPossui ferramentas muito bem pensadas para manipula√ß√£o e tratamento de dados;\nNormalmente, os frameworks de machine learning de R s√£o menos verbosos que os de Python;\nMatrizes e data frames s√£o estruturas de dados que j√° encontra-se definidas dentro da linguagem, n√£o precisando assim de importar bibliotecas.\n\nIsso √© meu gosto pessoal. √â um gosto que, talvez, faz mais sentido, em se tratando de algu√©m que vem da estat√≠stica. No mercado de trabalho e em seus estudos, ap√≥s cursar as disciplinas de R e Python, fornecidas pelo Bacharelado em Estat√≠stica da UFPB, voc√™ ter√° a capacidade de estudar os frameworks de machine learning, aos seus pr√≥prios passos e escolher o que melhor te agrada. A linguagem Julia tamb√©m poder√° ser uma √≥tima op√ß√£o."
  },
  {
    "objectID": "index.html#aprendizagem-de-m√°quina",
    "href": "index.html#aprendizagem-de-m√°quina",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Aprendizagem de m√°quina",
    "text": "Aprendizagem de m√°quina"
  },
  {
    "objectID": "index.html#aprendizagem-de-m√°quina-1",
    "href": "index.html#aprendizagem-de-m√°quina-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Aprendizagem de m√°quina",
    "text": "Aprendizagem de m√°quina\n \nAlguns pontos:\n\n\nA Aprendizagem de M√°quina (AM), tamb√©m chamada de Machine Learning (ML), no ingl√™s, nasceu na d√©cada de 60 como um campo da intelig√™nica artificial.\nEm sua origem, as aplica√ß√µes de AM tinha como objetivo aprender padr√µes com base nos dados.\nOriginalmente, as aplica√ß√µes de AM eram de cunho estritamente computacional. Todavia, desde o in√≠cio dos anos 90, a √°rea de aprendizagem de m√°quina expandiu seus horizontes e come√ßou a se estabelecer como um campo por sim mesma.\nEm particular, a √°rea de aprendizagem de m√°quina come√ßou a estabelecer muitas intersec√ß√µes com a estat√≠stica. Muitos de seus algoritmos s√£o constru√≠dos com base em metodologias que surgiram na estat√≠stica.\nAtualmente, a comunidade de AM √© bastante interdisciplinar e utiliza-se de ideias desenvolvidas em diversas √°reas, sendo a estat√≠stica uma delas."
  },
  {
    "objectID": "index.html#tipos-de-aprendizado",
    "href": "index.html#tipos-de-aprendizado",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tipos de Aprendizado",
    "text": "Tipos de Aprendizado\n\nAprendizado supervisionado\n\nNesse curso, inicialmente estudaremos problemas de aprendizado supervisionado, que consiste em aprender a fazer predi√ß√µes a partir de conjunto de dados em que r√≥tulos (valores da vari√°vel resposta Y) s√£o observados. Trataremos tanto de problemas de regress√£o (estimar um valor n√∫m√©rico) quanto problemas de classifica√ß√£o (classificar um cliente como aprovado ou reprovado, em um problema de concess√£o de cr√©dito). Por exemplo, os modelos de regress√£o s√£o exemplos de aprendizado supervisionado.\n\nAprendizado n√£o supervisionado\n\nNa segunda parte do curso, aprenderemos alguns m√©todos de aprendizado n√£o supervisionado, ou seja, algoritmos que n√£o utilizam-se de r√≥tulos, em que busca-se aprender mais sobre a estrutura dos dados. Por exemplo, os m√©todos de agrupamento (cluster), s√£o exempƒ∫os de m√©todos de aprendizado n√£o supervisionado."
  },
  {
    "objectID": "index.html#tipos-de-aprendizado-1",
    "href": "index.html#tipos-de-aprendizado-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tipos de Aprendizado",
    "text": "Tipos de Aprendizado\n\nMuito embora no nosso curso focaremos nas abordagens de aprendizagem supervisionada e n√£o-supervisionada, os tipos de aprendizagem, em geral, podem ser mais amplos, em que temos:\n\n\nAprendizagem supervisionada;\nAprendizagem n√£o-supervisionada;\nAprendizagem semi-supervisionada;\nAprendizagem por refor√ßo."
  },
  {
    "objectID": "index.html#o-que-√©-aprender",
    "href": "index.html#o-que-√©-aprender",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "O que √© aprender?",
    "text": "O que √© aprender?\n\nAntes de detalharmos os tipos de aprendizagem de m√°quina, uma d√∫vida que poder√° surgir √©: ‚ÄúO que √© aprender?‚Äù. ‚ÄúComo a m√°quina aprende?‚Äù."
  },
  {
    "objectID": "index.html#o-que-√©-aprender-1",
    "href": "index.html#o-que-√©-aprender-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "O que √© aprender?",
    "text": "O que √© aprender?\n\nDe forma simples, aprender √© ganhar conhecimento atrav√©s de estudo, experi√™ncias, por meio de ensinamentos.\n\nT√°, mais como √© que a m√°quina aprende?\n\n\nAprendizagem √© o processo em que se adquire conhecimento, isto √©, √© o processo em que utilizamos de algoritmos e fornecemos dados a esses algoritmos para que possamos extrair conhecimento. Nesse processo de aprendisagem, os algoritmos fazem uso de dados para a extress√£o de conhecimento, atrav√©s de procedimentos supervisionado, n√£o-supervisionado, semi-supervisionado ou por refor√ßo, a depender do algoritmo que voc√™ deseja utilizar.\n\n\n\nAprendizado √© o modelo ajustado, isto √©, √© o conhecimento adquirido ap√≥s o treinamamento obtido no processo de aprendizagem. Voc√™ poder√° entender como sendo o modelo ajustado e que utilizamores para a tomada de decis√µes."
  },
  {
    "objectID": "index.html#o-que-√©-aprender-2",
    "href": "index.html#o-que-√©-aprender-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "O que √© aprender?",
    "text": "O que √© aprender?\n\nPortanto, voc√™ poder√° entender, basiciamente, existe quatro tipos de aprendizagem, sendo os dois primeiros o que mais focaremos nesse curso e que de loge s√£o os mais utilizados:\n\n\nAprendizagem supervisionada;\nAprendizagem n√£o-supervisionada;\nAprendizagem semi-supervisionada;\nAprendizagem por refor√ßo."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada",
    "href": "index.html#aprendizagem-supervisionada",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\nNesse tipo de aprendizagem, o algoritmo ir√° receber um conjunto de dados em que conhecemos r√≥tulos para a vari√°vel de interesse. √â como se voc√™ soubesse onde um bom modelo deve chegar, para assim ser reconhecido como um bom modelo. Por exemplo,\n\n\nClassifica√ß√£o: precisamos determinar a classe de uma inst√¢ncia de dados, o seu atributo, i.e., \\widehat{y} = \\mathrm{argmax}_y\\,P(Y = y\\,|\\, X = \\bf{x}), em que y √© um atributo que desejamos prever (cahorro, gato, sapo), e \\bf{x} √© um vetor de caracter√≠sticas (peso, altura, comprimento, se tem rabo, etc).\n\n\n\nRegress√£o: precisamos estimar uma quantidade num√©rica, i.e., o valor da vari√°vel alvo por meio de uma inst√¢ncia de dados, ou seja, precisamos estimar Y = \\mathbb{E}(Y\\,|\\,X = \\bf{x}), i.e., devemos encontrar meios de obter \\widehat{Y}.\n\n\n\nAlgumas observa√ß√µes de nomenclaturas:\n\n√â comum chamar cada exemplo de dados, i.e., o vetor \\bf{x} que ser√° passado ao modelo de atributos ou features;\nTamb√©m √© comum chamarmos de r√≥tulo ou label a classe ou valor alvo, ou seja, estas s√£o as formas de nomearmos Y, sendo Y uma quantidade num√©rica (modelos de regress√£o) ou n√£o (modelos de classifica√ß√£o)."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-1",
    "href": "index.html#aprendizagem-supervisionada-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\nEm se tratando de m√©todos de classifica√ß√£o, podemos ter os m√©todos:\n\n\nGenerativos: s√£o os m√©todos que dada as vari√°veis X e Y, o objetivo √© encontrar a distribui√ß√£o de probabilidade conjunta P(X, Y), para ent√£o poder determinar P(Y\\, | \\, X = \\bf{x}). Alguns m√©todos s√£o:\n\nNaive Bayes;\nDescriminante linear.\n\n\n\n\nDescriminativos: s√£o os m√©todos que estimam diretamente a probabilidade condicional P(Y \\, | \\, X = \\bf{x}) ou que mesmo nem assumem modelos probabil√≠sticos. Podemos citar:\n\nRegress√£o logistica;\nPerceptron;\nSupport Vector Machine - SVM."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-2",
    "href": "index.html#aprendizagem-supervisionada-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\n\n\n\n\n Poder√≠amos estar interessados em classificar o tamanho de morangos:\n\n\nS (Slow): pequeno;\nM (Medium): m√©dio;\nL (Large): grande."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-3",
    "href": "index.html#aprendizagem-supervisionada-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n \n\nMais dois problemas de classifica√ß√£o (linear x n√£o-linear)."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-4",
    "href": "index.html#aprendizagem-supervisionada-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n \n\nUm exemplo de de um problema de regress√£o. Aqui, a ideia √© utilizar a equa√ß√£o da reta estimada, a reta que minimiza a soma dos quadrados entre a reta e os ponto seria a melhor, de modo a ter uma estimativa num√©rica atrav√©s de novos atributos passado ao modelo, i.e., por meio da equa√ß√£o da reta e de um novo valor de x."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-5",
    "href": "index.html#aprendizagem-supervisionada-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\nUm outro exemplo seria a classifica√ß√£o de imagem/v√≠deo, utilizando um algoritmo de rede neural, por exemplo, usando uma Convolutional Neural Network - CNN. Foram utilizados diversas imagens de pessoas ‚Äúcom‚Äù e ‚Äúsem‚Äù m√°scara. Em que ‚Äúcom‚Äù representa detec√ß√£o da m√°scara na face da pessoa e ‚Äúsem‚Äù a n√£o detec√ß√£o."
  },
  {
    "objectID": "index.html#aprendizagem-n√£o-supervisionada",
    "href": "index.html#aprendizagem-n√£o-supervisionada",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem n√£o-supervisionada",
    "text": "Aprendizagem n√£o-supervisionada\n\nNesse tipo de aprendizagem, os algoritmos trabalham sobre dados n√£o rotulados, por exemplo, em uma trarefa de agrupamento.\n\nOs algoritmos verificam se as inst√¢ncias observadas poder√£o ser arranjadas de alguma maneira, por exemplo, usando alguma m√©trica de dist√¢ncia, formando grupos (clusters).\n\nA ideia √© maximizar a dist√¢ncia entre os clusters e minimizar a dist√¢ncia entre os elementos no interrior do grupo. Em outras palavras, o que se quer √© tornar os grupos mais diferentes poss√≠veis e tornar os elementos dos grupos o mais parecido poss√≠vel.\n\nAqui, por n√£o haver r√≥tulos, um problema comum √© determinar a quantidade de grupos ideal que muitas vezes s√£o obtidos de forma subjetiva ou por heur√≠sticas. A quantidade de grupos √© um dilema!"
  },
  {
    "objectID": "index.html#aprendizagem-n√£o-supervisionada-1",
    "href": "index.html#aprendizagem-n√£o-supervisionada-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem n√£o-supervisionada",
    "text": "Aprendizagem n√£o-supervisionada\n\n\nAp√≥s a detec√ß√£o dos grupos, √© preciso analisar o resultado de modo a tentar extrair informa√ß√µes coerentes de modo a saber o que cada grupo representa no problema em quest√£o."
  },
  {
    "objectID": "index.html#aprendizagem-semi-supervisionada",
    "href": "index.html#aprendizagem-semi-supervisionada",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem semi-supervisionada",
    "text": "Aprendizagem semi-supervisionada\n\nA aprendizagem semi-supervisionada √© uma abordagem na √°rea de aprendizagem de m√°quina onde um algoritmo utiliza tanto dados rotulados quanto n√£o rotulados para treinamento. Por exemplo, algoritmos que propagam r√≥tulos, como o Label Propagation, em que r√≥tulos conhecidos s√£o propagados para dados n√£o rotulados com base em sua sua proximidade no espa√ßo de caracter√≠sticas.\n\nUma outra abordagem seria misturar modelos (Model Blending), em que diferentes modelos s√£o treinados em diferentes partes do conjunto de dados, por exemplo, um modelo para a parte roturada e um para a parte n√£o rotulada."
  },
  {
    "objectID": "index.html#aprendizagem-por-refor√ßo",
    "href": "index.html#aprendizagem-por-refor√ßo",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem por refor√ßo",
    "text": "Aprendizagem por refor√ßo\n\nNesse tipo de aprendizagem, n√£o h√° uma fonte externa de exemplos. O agente (modelo) aprende aprende com sua pr√≥pria experi√™ncia, por tentativas e erros, em que voc√™ dever√° definir uma medida de sucesso, e eventualmente recompensar os acertos. No v√≠deo abaixo, veja um joguinho que criei em R, onde o carrinho aprendeu a desviar de obst√°culos aleat√≥rios que aparecem em sua frente. Utilizou-se uma rede neural cuja a sa√≠da poderia ser (‚Äúparado‚Äù, ‚Äúpara cima‚Äù ou ‚Äúpara baixo‚Äù). Veja o c√≥digo clicando aqui."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamentom",
    "href": "index.html#dados-explora√ß√£o-e-tratamentom",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamentom",
    "text": "Dados: explora√ß√£o e tratamentom\n\nUm dos passos mais importante no fluxo de trabalho (workflow) de um modelo de aprendizagem de m√°quina, consiste na prepara√ß√£o dos dados, onde realizamos transforma√ß√µes, inputa√ß√µes de valores ausentes, identifica√ß√£o de outliers, remo√ß√£o de vari√°veis altamente correlacionadas, entre outros.\n\nFazer uma an√°lise explorat√≥ria dos dados √© um passo importante para que se possa entender e detecatar poss√≠veis inconsist√™ncias na base de dados. N√£o adianta fazer uso de modelos muito sofisticados quando se tem uma base de dados cheia de problemas.\n\nNormalmente trabalhamos com juntos de dados (tabelas) relacionais, em que cada linha √© uma observa√ß√£o e cada coluna representa um atributo do objeto/observa√ß√£o. A linha de uma base de dados relacional, sem sua a vari√°vel de interesse, lembre-se que denominamos Y de r√≥tulo ou label, fornece o vetor de caracter√≠sticas \\bf{x} que descreve uma dada observa√ß√£o."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento",
    "href": "index.html#dados-explora√ß√£o-e-tratamento",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\nNo artigo Tidy Data, 2014, publicado no Journal of Statistical Sofware, o Hadley Wickham discute que o princ√≠pio de dados organizados est√£o intimamente relacionados com banco de dados relacional e mais pr√≥ximo do recioc√≠nio que empregamos na √°lgebra. Nesse artigo, ele define o que √© Tidy Dados, sendo essa uma maneira de mapear um conjunto de dados.\n\nSegundo o artigo, um conjunto de dados √© bagun√ßado ou arrumado/tidy, dependendo de como as linhas, colunas e tabelas s√£o combinadas com as observa√ß√µes, vari√°veis e tipos. Em dados arrumados (dados tidy), temos que:\n\n\nCada vari√°vel forma uma coluna;\nCada observa√ß√£o forma uma linha;\nCada valor deve ter sua pr√≥pria c√©lula.\n\n\nEmbora existam situa√ß√µes em que j√° podemos come√ßar a analisar uma base de dados real, essa √© a exce√ß√£o e n√£o a regra. Normalmente, nos deparamos com bases de dados que violam uma ou mais dessas regras. Sempre, que poss√≠vel, procure utilizar dados no formato Tidy."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-1",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\n\nRepresenta√ß√£o de uma base de dados no formato tidy."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-2",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\n\n‚ÄúAs fam√≠lias felizes s√£o todas iguais; toda fam√≠lia infeliz √© infeliz √† sua maneira.‚Äù ‚Äì Leo Tolstoy\n\n\n‚ÄúConjuntos de dados organizados s√£o todos iguais, mas todo conjunto de dados confuso √© confuso √† sua maneira.‚Äù ‚Äì Hadley Wickham\n\n\n\nTrabalhar com a Tabela do lado esquerdo √© melhor que a Tabela do lado direito. Prefira, sempre que poss√≠vel, o formato tidy. N√£o permita-se ficar estressado t√£o facilmente."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-3",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\nA linguagem de programa√ß√£o R possue diversas ferramentas que permite manipular e explorar bases de dados. Enumero algumas:\n\ndplyr: biblioteca que implementa √© uma gram√°tica de manipula√ß√£o de dados, fornecendo um conjunto consistente de verbos que ajudam a resolver os desafios mais comuns de manipula√ß√£o de dados;\ntidyr: ferramentas para ajudar a criar dados organizados, onde cada coluna √© uma vari√°vel, cada linha √© uma observa√ß√£o e cada c√©lula cont√©m um √∫nico valor;\nggplot2: um sistema para criar gr√°ficos ‚Äòdeclarativamente‚Äô, baseado no livro The Grammar of Graphics, de Leland Wilkinson;\nvisdat: uma biblioteca √∫til para um visualiza√ß√£o explorat√≥ria preliminar de dados;\nexplore: biblioteca que apresenta algumas rotinas de an√°lise para realizar uma an√°lise explorat√≥ria nos dados.\n\nTodas essas bibliotecas est√£o muito bem documentadas. √â importante que voc√™s explorem as documentas dessas bibliotecas, pois eventualmente irei utizar alguma delas."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-4",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nNo Cap√≠tulo 12, do livro R for Data Science, o autor aborda mais sobre o formato Tidy e como trabalhar com a biblioteca tidyr. Aqui o autor aborda de forma b√°sica o pacote dplyr.\n\nDurante o curso, na medida da necessidade de utiliza√ß√£o dessas ferramentas, durante a exposi√ß√£o de exemplos, abordaremos alguns conceitos. Ok?"
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-5",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nMuitas vezes, no processo de tratamento dos dados, tamb√©m estamos preocupados em remover atributos que n√£o s√£o significativo para a modelagem, em que nesse momento a experi√™ncia dos especialistas s√£o fundamentais.\n\n√â comum enriquercermos a base de dados com informa√ß√µes de outras bases de dados, em um sistema de gerenciamento de banco de dados relacional, em que as bases de dados est√£o relacionadas por uma chave. Nesse caso, buscamos por novos atributos para um mesmo objeto (para uma mesma linha da base), em que atributos cruzados devem ter um √∫nico valor, para cada objeto, respeitando a regra tr√™s de conjuntos de dados tidy.\n\nAs vezes transformamos vari√°veis. Por exemplo, √© comum tomar o logaritmo de uma vari√°vel num√©rica que √© assim√©trica, se x &gt;= 1, em que x √© um atributo num√©rico qualquer.\n\nEm diveras situa√ß√µes, tamb√©m √© comum a base de dados apresentar informa√ß√µes faltantes. Nos data frames de R, a falta de informa√ß√£o na base, normlamente ser√£o representadas por NA."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-6",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nPoder√° ser que um dado atributo apresente informa√ß√£o faltante, e normalmente n√£o optaremos em remover a observa√ß√£o e precisaremos imputar a informa√ß√£o, por exemplo:\n\n\nTomando alguma medida de tend√™ncia central como m√©dia/moda/mediana dos valores que s√£o conhecidos para aquele atributo;\nCriar um novo valor que √© indica√ß√£o de valor faltante;\nUsar algoritmos como k-nearest neighbors - KNN (k vizinhos mais pr√≥ximos) para imputar valores coerentes;\nInterpolar os dados.\n\n\nEsses s√£o alguns exemplos de como podemos imputar observa√ß√µes faltantes. Muitas vezes n√£o podemos nos dar o luxo de percer observa√ß√µes de nossa base de dados."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-7",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\n√â comum ser necess√°rio transformar os dados:\n\nPode ser necess√°rio transformar os tipos ou os valores dos atributos para tentar obter um melhor ajuste do modelo;\nPode-se discretizar valores cont√≠nuos ou transform√°-los em intervalos;\n√â comum transformar atributos categ√≥ricos com p categorias, em p novos atributos bin√°rios.\n\nOne-hot encoding\nVari√°veis dummy\n\nOutra transforma√ß√£o muito comum √© a normaliza√ß√£o dos dados. Normalizar os dados √© muito √∫til quando os atributos num√©ricos possuem escalas muito diferentes.\n\n\n\nX_{novo} = \\frac{X - X_{min}}{X_{max} - X_{min}}, em que X_{novo} \\in [0, 1].\n\nX_{novo} = Z = \\frac{X - \\mu}{\\sigma^2}, em que \\mathbb{E}(X) = \\mu √© a m√©dia dos dados e \\mathrm{Var}(X) = \\sigma^2. Na pr√°tica, em um contexto de v.a., iids, usamos \\overline{x} como estimador de \\mu e S^2 (vari√¢ncia amostral) como estimador de \\sigma^2."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-8",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nLembre-se, como citado anteriormente, tomar o logaritmo natural, ou mesmo na base 10 de vari√°veis num√©ricas muito assim√©tricas, poder√° ajudar um pouco, desde que seja possivel tomar o \\log(\\cdot).\n\n\n\n\nset.seed(0)\nrgamma(1000, 2, 2) |&gt; \n  hist()\n\n\n\n\n\n\nset.seed(0)\nrgamma(1000, 2, 2) |&gt; \n  log() |&gt; hist()"
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-9",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-9",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nAnteriormente eu citei algumas bibliotecas √∫teis de R para explorar os dados, na fase de tratamento das observa√ß√µes. Por√©m, n√£o estranhe n√£o ter cidado bibliotecas do framework tidymodels, em especial o recipes que √© muito utilizado no workflow de aprendizagem de m√°quina na fase de pr√©-processamento dos dados. Muitas dessas transforma√ß√µes s√£o aplicadas como receitas de pr√©-processamento com o pacote recipes.\n\nO tidymodels ser√° muito √∫til para n√≥s, mas, aos poucos, seu uso e explica√ß√µes mais detalhadas ser√£o apresentadas, apesar que em algumas situa√ß√µes mais simples, poderei n√£o utiliz√°-lo, expor detalhes que eventualmente n√£o ser√° poss√≠vel ou estariam camuflados na utiliza√ß√£o do tidymodels."
  },
  {
    "objectID": "index.html#as-duas-culturas",
    "href": "index.html#as-duas-culturas",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "As duas culturas",
    "text": "As duas culturas\n\nEm Breiman, L. (2001a). Statistical modeling: The two cultures. Statistical Science, 16(3), 199‚Äì231, o Leo Breiman argumenta que existe duas culturas no uso de modelos estat√≠sticos, em especialmente na √°rea de modelos de regress√£o. Segundo eles, as culturas s√£o:\n\n\nData modeling culture: nela, em geral, se assume que o modelo de regress√£o utilizado r(x), por exemplo, r(x) = \\beta_0 + \\sum_{i = 1}^d \\beta_ix_i √© correto. O principal objetivo dessa abordagem √© a interpreta√ß√£o dos par√¢metros que indexam o modelo r(x). Nesse tipo de cultura, a ideia tamb√©m √© construir intervalos aleat√≥rios e testar hip√≥teses para os \\beta_i's. Sob essa √≥tica, muitas suposi√ß√µes sob o modelo s√£o realizadas, em que formas para checar essas suposi√ß√µes s√£o desenvolvidas, uma vez que elas s√£o fundamentais para esse tipo de modelagem.\n\n\n\nAlgorithmic modeling culture: essa √© a cultura que domina a comunidade de aprendizagem de m√°quina. Nessa abordagem, o principal objetivo s√£o as predi√ß√µes por meio de novas observa√ß√µes. N√£o se assume que o modelo utilizado √© o modelo correto. Nesse tipo de modelagem, muitas vezes os algoritmos n√£o envolve nenhuma estrutura probabil√≠stica. Muitas vezes, modelos n√£o bem especificado conduzem a boas predi√ß√µes."
  },
  {
    "objectID": "index.html#as-duas-culturas-1",
    "href": "index.html#as-duas-culturas-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "As duas culturas",
    "text": "As duas culturas\n\n\n\n\n\n\nBreiman, L. (2001a). Statistical modeling: The two cultures. Statistical Science, 16(3), 199‚Äì231.\n\n\n\n\n\n\nLeo como um probabilista jovem na Universidade da Calif√≥rina."
  },
  {
    "objectID": "index.html#as-duas-culturas-2",
    "href": "index.html#as-duas-culturas-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "As duas culturas",
    "text": "As duas culturas\n\nH√° diversos artigos interessantes que s√£o respostas ao artigo do Leo Breiman, como por exemplo, o artigo Statistical Modeling: The Two Cultures: Comment do David Cox e com coment√°rios do Brad Efron.\n\nSir David Cox."
  },
  {
    "objectID": "index.html#as-duas-culturas-3",
    "href": "index.html#as-duas-culturas-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "As duas culturas",
    "text": "As duas culturas\n\nMuito embora exista essa divis√£o entre as culturas, Breiman foi um estat√≠stico que desempenhou um grande trabalho para unir a √°rea de estat√≠stica com aprendizado de m√°quina. Por conta dessa grande import√¢ncia, um pr√™mio concedido em sua homenagem foi criado pela American Statistical Association.\n\nLeo Breiman trabalhando em sua resid√™ncia, em 1985."
  },
  {
    "objectID": "index.html#regress√£o",
    "href": "index.html#regress√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o",
    "text": "Regress√£o\n\nM√©todos de regress√£o surgiram h√° mais de dois s√©culos com Legendre (1805) e Gauss (1809), que exploraram o m√©todo dos m√≠nimos quadrados com o objetivo de prever √≥rbitas ao redor do Sol. Hoje em dia, o problema de estima√ß√£o de uma fun√ß√£o de regress√£o possui papel central em estat√≠stica.\n\n\nApesar de as primeiras t√©cnicas para solucionar esse problema datarem de ao menos 200 anos, os avan√ßos computacionais recentes permitiram que novas metodologias fossem exploradas. Em particular, com a capacidade cada vez maior de armazenamento de dados, m√©todos com menos suposi√ß√µes sobre o verdadeiro estado da natureza ganham cada vez mais espa√ßo. Com isso, v√°rios desafios surgiram: por exemplo, m√©todos tradicionais n√£o s√£o capazes de lidar de forma satisfat√≥ria com bancos de dados em que h√° mais covari√°veis que observa√ß√µes, uma situa√ß√£o muito comum nos dias de hoje. Similarmente, s√£o frequentes as aplica√ß√µes em que cada observa√ß√£o consiste em uma imagem ou um documento de texto, objetos complexos que levam a an√°lises que requerem metodologias mais elaboradas. ‚Äì Izbick et al."
  },
  {
    "objectID": "index.html#regress√£o-1",
    "href": "index.html#regress√£o-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o",
    "text": "Regress√£o\n\nDe forma geral, temos que o objetivo de um modelo de regress√£o √© determinar a rela√ß√£o entre uma vari√°vel aleat√≥ria (label) Y \\in \\mathbb{R} e um vetor de covari√°veis (features) \\mathbf{x} = (x_1, \\cdots, x_d) \\in \\mathbb{R}^d. Mais especificamente, busaca-se estimar\nr(\\bf{x}) := \\mathbb{E}(Y\\,|\\,\\bf{X} = \\bf{x}),\nsendo esta chamada de fun√ß√£o de regress√£o. Temos que:\n\n\nSe Y √© uma vari√°vel quantitativa, ent√£o estamos sob um problema de regress√£o;\nSe Y √© uma vari√°vel qualitativa, ent√£o teremos um problema de classifica√ß√£o.\n\nEm aprendizagem de m√°quina, assumimos que n√£o temos meios de calcular r({\\bf{x}}), i.e., n√£o conhecemos a distribui√ß√£o condicional de {\\bf{Y}\\,|\\,X}. Portanto, n√£o temos meios de calcular\n\\mathbb{E}({\\bf X}|Y = y) = \\int x\\,\\mathrm{d}F_{\\bf X}({\\bf x} | Y = y)."
  },
  {
    "objectID": "index.html#nota√ß√µes",
    "href": "index.html#nota√ß√µes",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nota√ß√µes",
    "text": "Nota√ß√µes\n\nA vari√°vel Y recebe frequentemente o nome de vari√°vel resposta, vari√°vel dependente, r√≥tulo ou label. J√° as observa√ß√µes contidas no vetor \\bf{x} = (x_1, \\cdots, x_d), s√£o, em geral, denominadas de vari√°veis explicativas, vari√°veis independentes, caracter√≠sticas, atributos, preditores, covari√°veis ou features.\n\nA ideia, nessa primeira parte do curso, √© descrever algumas t√©cnicas para estimar (treinar, como √© dito em aprendizagem de m√°quina) r(\\bf{x}).\n\nA menos quando dito o contr√°rio, assumiremos que nossa amostra s√£o i.i.d. (independentes e identicamente distribu√≠das), ou seja, (\\bf{X}_1, Y_1), \\cdots, (\\bf{X}_n, Y_n) s√£o i.i.d.\n\nDenota-se por x_{i,j} o valor da j-√©sima covari√°vel na i-√©sima amostra, com j = 1, \\cdots, d e i = 1, \\cdots, n."
  },
  {
    "objectID": "index.html#nota√ß√µes-1",
    "href": "index.html#nota√ß√µes-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nota√ß√µes",
    "text": "Nota√ß√µes\n\n\nNota√ß√£o utilizada nesse material para as vari√°veis envolvidas em um problema de regress√£o.\n\n\n\n\n\n\nLabel\nFeatures\n\n\n\n\nY_1\nX_{1,1},\\cdots, X_{1,d}\\,\\,\\, (= \\bf{X}_1)\n\n\n\\vdots\n\\,\\,\\,\\vdots\\,\\,\\,\\,\\, \\ddots\\,\\,\\ \\vdots\n\n\nY_n\nX_{n,1},\\cdots, X_{n,d}\\,\\,\\, (= \\bf{X}_n)"
  },
  {
    "objectID": "index.html#regress√£o-2",
    "href": "index.html#regress√£o-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o",
    "text": "Regress√£o\nNossa ideia √© construir uma boa estimativa g da fun√ß√£o de regress√£o r(\\bf{x}) := \\mathbb{E}(Y\\,|\\,\\bf{X} = \\bf{x}), para novas observa√ß√µes, i.e., queremos obter uma fun√ß√£o g, tal que:\ng: \\mathbb{R}^d \\rightarrow \\mathbb{R},\nde tal forma que g possua um bom poder preditivo. Em aprendizagem de m√°quina, s√≥ estaremos interessados em obter uma fun√ß√£o g que estime bem um n√∫mero real (em problemas de regress√£o), ou que classifique bem (em um problema de classifica√ß√£o), utilizando as d covari√°veis. Ou seja, para m novas observa√ß√µes, desejamos obter g, que\ng({\\bf{x}}_{n + 1}) \\approx y_{n + 1}, \\cdots, g({\\bf{x}}_{n + m}) \\approx y_{n + m}."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco",
    "href": "index.html#fun√ß√£o-de-risco",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nPara que possamos construir boas fun√ß√µes de predi√ß√£o, √© preciso que tenhamos um crit√©rio para medir o desempenho de uma dada fun√ß√£o g:\\mathbb{R}^d \\rightarrow \\mathbb{R}. Em contexto de regress√£o, usaremos o risco quadr√°tico, muito embora esta n√£o √© a √∫nica op√ß√£o. Denotaremos a fun√ß√£o de risco quadr√°tico por:\nR_{pred}(g) = \\mathbb{E}\\left[({\\bf Y} - g({\\bf X}))^2\\right], em que (\\bf X, Y) s√£o observa√ß√µes novas que n√£o foram utilizadas para treinar/estimar g. L√™-se R_{pred}(g) como ‚Äúrisco preditivo de g‚Äù. Note que, como \\bf X s√£o observa√ß√µes conhecidas e g(\\cdot) √© um modelo preditivo, portanto, g √© conhecido, ent√£o, \\widehat{\\bf Y} = g(\\bf X) √© um estimador dos labels, i.e., de \\bf Y.\n\nDiremos que L(g({\\bf X}); {\\bf Y}) = ({\\bf Y} - g({\\bf X}))^2 √© a fun√ß√£o de perda quadr√°tica, as vezes chamado de perda L_2. Outra fun√ß√µes como a fun√ß√£o de perda absoluta denotada por L(g({\\bf X}); {\\bf Y}) = |{\\bf Y} - g({\\bf X})|, as vezes chamada de perda L_1 poderiam ser consideradas."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-1",
    "href": "index.html#fun√ß√£o-de-risco-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nEm linhas gerais, seja L(\\cdot) uma fun√ß√£o qualquer, tal que \\forall \\, 0 &lt; u &lt; v, de modo que:\n\n\n0 = L(0) \\leq L(u) \\leq L(v);\n0 = L(0) \\leq L(-u) \\leq L(-v).\n\n\nQualquer fun√ß√£o L(\\cdot) que satisfaz as propriedades acima √© chamada de fun√ß√£o de perda. Em especial, temos que:\n\n\nFun√ß√£o de perda quadr√°tica: L(u) = u^2;\nFun√ß√£o de perda absoluta: L(u) = |u|;\nFun√ß√£o de perda degradu: L(0) = 0, se |u| &lt; \\delta e 1 caso contr√°rio, para algum \\delta &gt; 0;"
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-2",
    "href": "index.html#fun√ß√£o-de-risco-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nNormalmente considera-se a perda L_2, uma vez que em modelos de regress√£o, minimizar R_{pred}(g), em g, equivale a encontrar r({\\bf x}) = \\mathbb{E}({\\bf X}|{\\bf Y}), i.e., equivale a estimar a fun√ß√£o de regress√£o.\n\nTeorema: Suponha que definimos o risco de uma fun√ß√£o de predi√ß√£o g: \\mathbb{R}^d \\rightarrow \\mathbb{R} via fun√ß√£o perda quadr√°tica, i.e, R_{pred}(g) = \\mathbb{E}\\left[({\\bf Y} - g({\\bf X}))^2\\right], em que \\bf (X, Y) s√£o novas observa√ß√µes que n√£o foram utilizadas para estimar g. Suponha tamb√©m que estimaos o risco de um estimador de regress√£o r({\\bf X}) via fun√ß√£o perda quadr√°tica R_{reg}(g) = \\mathbb{E}\\left[(r({\\bf X}) - g({\\bf X}))^2\\right]. Ent√£o,\nR_{pred}(g) = R_{reg}(g) + \\mathbb{E}\\left[\\mathbb{V}[{\\bf Y} | {\\bf X}]\\right],\nem que \\mathbb{E}\\left[\\mathbb{V}[{\\bf Y} | {\\bf X}]\\right] √© a vari√¢ncia m√©dia do modelo que n√£o depende de g. Portanto, estimar bem r({\\bf x}) √© de fundamental import√¢ncia para criar uma boa fun√ß√£o de predi√ß√£o. Em especial, sob a √≥tica do risco quadr√°tico, a melhor fun√ß√£o de predi√ß√£o para \\bf Y √© a fun√ß√£o de regress√£o r({\\bf x}), de tal modo que:\n\\argmin_g R_{pred}(g) = \\argmin_g R_{reg}(g) = r({\\bf x})."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-3",
    "href": "index.html#fun√ß√£o-de-risco-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nLembre-se: r({\\bf x}) = \\mathbb{E}(Y | \\bf{X} = \\bf{x}) √© a nossa fun√ß√£o de regress√£o.\n\nA defini√ß√£o de risco preditivo R_{pred}, que tamb√©m denotaremos simplesmente por R, tem um apelo frequentista. Dessa forma, para um novo conjunto com m novas observa√ß√µs, ({\\bf X}_{n+1}, Y_{n+1}), \\cdots, ({\\bf X}_{n+m}, Y_{n+m}), temos que que essa nova amostra √© i.i.d √† amostra observada (utilizada no treinamento do modelo/na estima√ß√£o). Ent√£o, pela Lei dos Grandes N√∫meros, temos que um bom estimador para a fun√ß√£o para o risco preditivo √© dado por:\n\\frac{1}{m}\\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \\approx R(g) := \\mathbb{E}\\left[(Y - g({\\bf X}))^2\\right]. \\tag{1}\nChamaremos a quantidade acima de Erro Quadr√°tico M√©dio - EQM. Em aprendizagem de m√°quina, normalmente estaremos no contexto em que temos muitas observa√ß√µes, e que portanto, poderemos fazer esse apelo frequentista.\n\nDesejamos encontrar g (encontrar m√©todos) que minimize de forma satisfat√≥ria R, i.e., m√©todos que nos conduzam √† um risco baixo."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-4",
    "href": "index.html#fun√ß√£o-de-risco-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nSendo assim, se R(g) possui um valor baixo, ent√£o, temos que\ng({\\bf x}_{n+1}) \\approx y_{n+1}, \\cdots, g({\\bf x}_{n+m}) \\approx y_{n+m}."
  },
  {
    "objectID": "index.html#regress√£o-linear",
    "href": "index.html#regress√£o-linear",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear",
    "text": "Regress√£o linear\n\nNesse momento, vamos pensar um pouco em regress√£o linear. No caso mais simples, queremos prever o comportamento de uma vari√°vel de interesse Y condicional a uma vari√°vel explicativa X (regress√£o linear simples, i.e., d = 1). O melhor preditor de Y condicional em X √© aquele que minimiza a fun√ß√£o de perda esperada, ou seja, √© aquele que resolve:\n\\argmin_g \\mathbb{E}(L(Y - g)\\,|\\,X).\nPara o caso da fun√ß√£o perda quadr√°tica (fun√ß√£o L_2), o melhor preditor de Y condicional √† X √© a m√©dia condicional de Y dado X, i.e., r(X) = \\mathbb{E}(Y\\,|\\,X). J√°, na situa√ß√£o em que considera-se a perda absoluta (fun√ß√£o L_1), o melhor estimador √© a mediana condicional.\n\nOs modelos de regress√£o, em geral, fazem uso da fun√ß√£o de perda quadr√°tica."
  },
  {
    "objectID": "index.html#regress√£o-linear-simples",
    "href": "index.html#regress√£o-linear-simples",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear simples",
    "text": "Regress√£o linear simples\n\nNo caso da regress√£o linear simples (d = 1), temos que o modelo √© dado por:\ng(x) = \\beta_0 + \\beta_1 x_{i,1} + \\varepsilon_i, \\,\\, i = 1, \\cdots, n.\nAssumindo que a regress√£o linear simples √© o modelo g que iremos utilizar, ent√£o, desejamos minimizar:\n\\argmin_{\\beta} R(g_\\beta) = \\argmin_{\\beta} \\sum_{i = 1}^n(y_i - \\beta_0 - \\beta_1x_{i,1})^2. Derivando em rela√ß√£o √† \\beta e igualando a zero, ap√≥s algumas manipula√ß√µes alg√©bricas, temos que:\n\\widehat{\\beta} = \\frac{\\sum_{i = 1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n(x_i - \\overline{x})^2} = r_{xy}\\frac{s_y}{s_x}, em que s_x e s_y s√£o os desvio-padr√£o de x e y, respectivamente, e r_{xy} √© o coeficiente de correla√ß√£o da amostra."
  },
  {
    "objectID": "index.html#regress√£o-linear-simples-1",
    "href": "index.html#regress√£o-linear-simples-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear simples",
    "text": "Regress√£o linear simples\n\nr_{xy} = \\frac{\\overline{xy} - \\overline{x}\\,\\overline{y}}{\\sqrt{(\\overline{x^2} - \\overline{x}^2)(\\overline{y^2} - \\overline{y}^2)}}. O coeficiente de determina√ß√£o R^2 do modelo √© dado por r_{xy}^2, quando o modelo √© linear e possue uma √∫nica vari√°vel independente (feature).\n\nPortanto, temos que:\n\\widehat{\\beta_0} = \\overline{y} - \\widehat{\\beta}\\overline{x},\nNa data modeling culture (na estat√≠stica), normalmente assumimos que o \\varepsilon_i tem distribui√ß√£o normal e vari√¢ncia constante, \\forall\\, i = 1, \\cdots, n. Assume-se tamb√©m que \\mathbb{E}(\\varepsilon_i) = 0, \\, \\forall i."
  },
  {
    "objectID": "index.html#regress√£o-linear-simples-2",
    "href": "index.html#regress√£o-linear-simples-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear simples",
    "text": "Regress√£o linear simples\n\nAqui n√£o iremos nos preocupar com essas suposi√ß√µes, uma vez que em algorithmic modeling culture, n√£o estamos preocupados com suposi√ß√µes nem interpreta√ß√µes, ok!?"
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla",
    "href": "index.html#regress√£o-linear-multipla",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nA fun√ß√£o de perda quadr√°tica (fun√ß√£o L_2) tem algumas vantagens em rela√ß√£o a fun√ß√£o de perda absoluta. Listo algumas:\n\nA fun√ß√£o de perda quadr√°tica penaliza mais os erros maiores, devido ao vato dos erros serem levado ao quadrado;\nA fun√ß√£o de perda quadr√°tica √© mais sens√≠vel a presen√ßa de outlier, que em compensa√ß√£o s√£o menos penalizados ao se considerar a fun√ß√£o de perda absoluta (fun√ß√£o L_1);\nEm situa√ß√µes em que o erro tem distribui√ß√£o normal, a estimativa de m√≠nimos quadrados √© a solu√ß√£o de m√°xima verossimilhan√ßa e √© a estimativa linear n√£o viesada e com menor vari√¢ncia. Portanto, gozamos de um estimador com √≥timas propriedades, muito embora ele tamb√©m √© um bom estimador mesmo quando a suposi√ß√£o de normalidade n√£o √© verificada;\nA fun√ß√£o de perda quadr√°tica √© deferenci√°vel, j√° a fun√ß√£o de perda absoluta n√£o √©.\n\nPara o caso de regerss√£o linear m√∫ltipla, i.e., quando d &gt; 1, poderemos utilizar uma nota√ß√£o matricial para representar o modelo linear m√∫ltiplo de regress√£o."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-1",
    "href": "index.html#regress√£o-linear-multipla-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nConsiderando o modelo de regress√£o linear m√∫ltiplo, temos que:\nY = g({\\bf X}) = \\beta^{T}{\\bf X} + \\varepsilon,\nem que Y √© um vetor n \\times 1, {\\bf X} √© uma matriz fixa e conhecida com os atributos de dimens√£o n \\times d, em que a primeira coluna √© preenchida de 1, \\beta = (\\beta_0, \\cdots, \\beta_d). Na cultura de machine learning, iremos desconsiderar \\varepsilon, n√£o feremos suposi√ß√µes sobre \\varepsilon. Portanto, considere\ng({\\bf x}) = \\beta^{T}{\\bf X} = \\beta_{0}x_0 + \\beta_1x_{i,1} + \\cdots + \\beta_dx_{i,d}, em que x_0 \\equiv 1."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-2",
    "href": "index.html#regress√£o-linear-multipla-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nO m√©todo dos m√≠nimos quadrados, para o caso de regress√£o linear m√∫ltipla (d &gt; 1) √© dado por aquele que minimiza R(\\beta^{T}{\\bf X}), i.e., minimiza:\n\\argmin_\\beta \\sum_{i = 1}^n (Y_i - \\beta_0 - \\beta_1x_{i,1} - \\cdots - \\beta_dx_{i,d})^2. Temos que\n\\widehat{\\beta} = ({\\bf X}^{T}{\\bf X})^{-1}{\\bf X}^{T}Y.\nPortanto, a fun√ß√£o de regress√£o estimada √© dada por:\ng({\\bf x}) = \\widehat{\\beta}^{T}{\\bf x}."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-3",
    "href": "index.html#regress√£o-linear-multipla-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nGrande parte da literatura estat√≠stica √© voltada para justificar que o m√©todo de m√≠nimos quadrados sob um ponto de vista de um estimador de m√°xima verossimilhan√ßa, assim como tamb√©m para constru√ß√£o de testes de ader√™ncia, m√©todos para constru√ß√£o de intervalos de confian√ßa e teste de hip√≥tese para \\beta_i (par√¢metros que indexam o modelo), an√°lise de res√≠duos, entre outros.\n\nAssumir que a verdadeira regress√£o r({\\bf x}) = \\mathbb{E}({\\bf X}\\,|\\,Y) √© uma suposi√ß√£o muito forte. Contudo, existe, na literatura, justificativas para o uso de m√©todos de m√≠nimos quadrados para estimar os coeficientes, mesmo quando a regress√£o real r({\\bf x}) n√£o satisfaz a suposi√ß√£o de linearidade."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-4",
    "href": "index.html#regress√£o-linear-multipla-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nO estimador de m√≠nimos quadrados \\widehat{\\beta} = ({\\bf X}^{T}{\\bf X})^{-1}{\\bf X}^{T}Y √© bom, por alguns motivos:\n\n\n√â igual ao estimador de m√°xima verossimilhan√ßa sob normalidade, linearidade e homoscedasticidade, portanto, consistente sob essas condi√ß√µes\n√â best linear unbiased prediction - BLUE sob linearidade e homoscedasticidade;\nO m√©todo de m√≠nimos quadrados tem alguma garantia, mesmo sem assumir muitas suposi√ß√µes."
  },
  {
    "objectID": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade",
    "href": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√≠nimos quadrados sem suposi√ß√£o de linearidade",
    "text": "M√≠nimos quadrados sem suposi√ß√£o de linearidade\n\nQuando a suposi√ß√£o de linearidade falha, ou seja, quando a regress√£o verdadeira que desconhecemos r({\\bf x}) n√£o √© linear, frequentemente existe um vetor \\beta_{*}, tal que g_{\\beta_{*}}({\\bf x}) = \\beta_{*}^{T}{\\bf x} tem um bom poder preditivo. Nesses casos, o m√©trodo dos m√≠nimos quadrados \\widehat{\\beta} tende a produzir estimadores com baixo risco. Isso se deve ao fato que \\widehat{\\beta} converge para o melhor preditor linear (para o or√°culo \\beta_{*}) que √© dado por:\n\\beta_{*} = \\argmin_\\beta R(g_\\beta) =  \\argmin_\\beta \\mathbb{E}\\left[(Y - \\beta^{T}X)^2\\right], mesmo que a verdadeira regress√£o r({\\bf x}) n√£o seja linear, em que ({\\bf X}, Y) √© uma nova observa√ß√£o.\n\nTeorema: Seja \\beta_{*} o melhor estimador linear e \\widehat{\\beta} o estimador de m√≠nimos quadrados. Ent√£o,\n\\widehat{\\beta}\\overset{p}{\\longrightarrow}  \\beta_{*}\\,\\, \\mathrm{e}\\,\\, R(g_{\\widehat{\\beta}})\\overset{p}{\\longrightarrow} R(g_{\\beta_{*}}),  quando n \\longrightarrow \\infty. Para uma demonstra√ß√£o, veja http://www.rizbicki.ufscar.br/AME.pdf, p√°gina. 29."
  },
  {
    "objectID": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade-1",
    "href": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√≠nimos quadrados sem suposi√ß√£o de linearidade",
    "text": "M√≠nimos quadrados sem suposi√ß√£o de linearidade\n\nEm palavras, o que o Teorema anterior diz √© que mesmo quando a regress√£o verdadeira n√£o √© linear, o estimador de m√≠nimos quadrados √© consistente para nos conduzir a um bom estimador linear, ou seja, ao menos conseguiremos o melhor estimador linear como uma aproxima√ß√£o √† r({\\bf x}) que n√£o √© linear.\n\nIsso n√£o quer dizer que voc√™ ter√° boas estimativas em todas as situa√ß√µes, muito embora o or√°culo \\beta_{*}, em muitas situa√ß√µes, ter√° bom poder preditivo. Em outras palavras, em situa√ß√µes que um problema, em sua natureza, n√£o linear, poderemos alcan√ßar boas estimativas por uma aproxima√ß√£o linear pelo m√©todo dos m√≠nimos quadrados."
  },
  {
    "objectID": "index.html#predi√ß√£o-versus-infer√™ncia",
    "href": "index.html#predi√ß√£o-versus-infer√™ncia",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Predi√ß√£o versus Infer√™ncia",
    "text": "Predi√ß√£o versus Infer√™ncia\n\nInfer√™ncia: assume que o modelo linear √© correto. O principal objetivo consiste em interpretar os par√¢metros:\n\n\nQuais s√£o os par√¢metros significantes?\nQual o efeito do aumento da dose de um rem√©dio no paciente?\n\n\nPredi√ß√£o: queremos criar g({\\bf x}) com bom poder preditivo, mesmo que a especifica√ß√£o do modelo n√£o esteja correta. N√£o assume que a verdadeira regress√£o √© de fato linear! A interpreta√ß√£o aqui n√£o √© o foco. Tudo bem?"
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\nCaso voc√™ n√£o queira implementar o estimador de m√≠nimos quadrados \\widehat{\\beta} = ({\\bf X}^{T}{\\bf X})^{-1}{\\bf X}^{T}Y, voc√™ poder√° utilizar a famosa fun√ß√£o lm. Na verdade √© melhor que n√£o implemente o estimador \\widehat{\\beta}, uma vez que a fun√ß√£o lm, assim como a fun√ß√£o glmnet do pacote glmnet, utilizam-se de truques num√©ricos para um c√°lculo mais eficiente.\n\nFalaremos do pacote glmnet, um pouco mais a frente, quando abordarmos regress√£o penalizada. Certo!?"
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r-1",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\nConsidere o conjunto de dados de expectativa de vida versus PIB per Capita dispon√≠veis aqui. O comportamente entre as vari√°veis LifeExpectancy e GDPercapita, se fizermos um gr√°fico, n√£o √© linear.\n\nTodavia, isso n√£o impede que possamos ajustar um modelo de regerss√£o linear, muito embora o seu poder preditivo ser√° baixo.\n\nPor√©m, como j√° sabemos, ao menos conseguiremos o melhor or√°culo, denotado por \\beta_{*}, i.e., o melhor estimador dentre os poss√≠veis estimadores lineares, como mostrado em teoremas anteriores.\n\nE est√° tudo bem. Aqui n√£o estou querendo defender que voc√™ use uma aproxima√ß√£o linear para esse caso. Em breve, com um pequeno truque, poderemos ajustar uma regress√£o polinomial √† esses dados, e incorporaremos um pouco da tend√™ncia n√£o linar presente nos dados."
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r-2",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\n\n\nVeja o c√≥digo do gr√°fico\nlibrary(ggplot2)\n\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\n\n# Criando um arquivo tempor√°rio\narquivo_temp &lt;- tempfile()\n\n# Baixando um arquivo tempor√°rio\ndownload.file(url = url, destfile = arquivo_temp)\n\n# Carregando os dados\nload(arquivo_temp)\n\ndados_expectativa_renda |&gt; \n  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +\n  geom_point() +\n  labs(\n    title = \"PIB per Capita versus Expectativa de Vida\",\n    x = \"PIB per Capita\",\n    y = \"Expectativa de Vida\"\n  ) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )"
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r-3",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\nClaramente, a reta de regress√£o (linha azul) do gr√°fico anterior n√£o tem um bom poder preditivo. O ajuste foi feito diretamente usando o pacote ggplot2, utilizando a fun√ß√£o geom_smooth, em que foi escolhido o m√©todo \"lm\".\n\nPoder√≠amos ter utilizado a fun√ß√£o lm:\n\n\n\nVeja o c√≥digo do gr√°fico\nlibrary(ggplot2)\n\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\n\n# Criando um arquivo tempor√°rio\narquivo_temp &lt;- tempfile()\n\n# Baixando um arquivo tempor√°rio\ndownload.file(url = url, destfile = arquivo_temp)\n\n# Carregando os dados\nload(arquivo_temp)\n\n# Ajustando o modelo usando a fun√ß√£o lm\najuste &lt;- lm(LifeExpectancy ~ GDPercapita, data = dados_expectativa_renda)\n\nmodelo &lt;- function(x){\n  novos_dados &lt;- tibble::tibble(GDPercapita = x)\n  predict(ajuste, newdata = novos_dados)\n}\n\ndados_expectativa_renda |&gt; \n  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +\n  geom_point() +\n  labs(\n    title = \"PIB per Capita versus Expectativa de Vida\",\n    x = \"PIB per Capita\",\n    y = \"Expectativa de Vida\"\n  ) +\n  stat_function(fun = modelo, color = \"red\", size = 1.2) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )"
  },
  {
    "objectID": "index.html#matriz-esparsa",
    "href": "index.html#matriz-esparsa",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Matriz esparsa",
    "text": "Matriz esparsa\n\nPara grandes bases de dados, em um problema real que voc√™ venha trabalhar, e se o custo computacional voc√™ considera elevado, poder√° utilizar o pacote biglm.\n\nEm situa√ß√µes em que h√° muitos zeros na sua matriz, poder√° utilizar representa√ß√£o esparsa.\n\nMatrizes esparsas s√£o matrizes com muitas entradas iguais √† 0. Elas ocorrem naturalmente em diversas aplica√ß√µes, como por exemplo uma matriz de termos presentes em um documento, em que se o termo estiver no documento resebe 1, e zero, caso contr√°rio. Abaixo, {\\bf X} √© um exemplo de matriz esparsa.\n\n\n{\\bf X} =\n\\begin{bmatrix}\n1 & 0 & 0 & 0 & 0 \\\\\n0 & 2 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 3 & 0 & 0 \\\\\n0 & 0 & 0 & 4 & 0 \\\\\n\\end{bmatrix}"
  },
  {
    "objectID": "index.html#matriz-esparsa-1",
    "href": "index.html#matriz-esparsa-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Matriz esparsa",
    "text": "Matriz esparsa\n\nConsidere os textos:\n\nTexto 1: ‚ÄúEu amo essa disciplina.‚Äù\nTexto 2: ‚ÄúEu adoro meu professor.‚Äù\nTexto 3: ‚ÄúEu serei muito bom em aprendizagem de m√°quina.‚Äù\nTexto 4: ‚ÄúAdoro o departamento de estat√≠stica da UFPB.‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTextos\ndisciplina\namo\naprendizagem\nm√°quina\nestatistica\nadoro\nUFPB\n\n\n\n\nTexto 1\n1\n1\n0\n0\n0\n0\n0\n\n\nTexto 2\n0\n0\n0\n0\n0\n1\n0\n\n\nTexto 3\n0\n0\n1\n1\n0\n0\n0\n\n\nTexto 4\n0\n0\n0\n0\n1\n1\n1"
  },
  {
    "objectID": "index.html#matriz-esparsa-2",
    "href": "index.html#matriz-esparsa-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Matriz esparsa",
    "text": "Matriz esparsa\n\nA matriz com a ocorr√™ncia de determinados termos nos textos √© dada por:\n\n{\\bf X} =\n\\begin{bmatrix}\n1 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 1 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 1 \\\\\n\\end{bmatrix}\n\nA representa√ß√£o esparsa de {\\bf X}, aqui denotada por {\\bf X_*} √©:\n\n{\\bf X_*} =\n\\begin{bmatrix}\n1 & 1 & 1 \\\\\n2 & 6 & 1 \\\\\n3 & 3 & 1 \\\\\n3 & 4 & 1 \\\\\n4 & 5 & 1 \\\\\n4 & 6 & 1 \\\\\n4 & 7 & 1 \\\\\n\\end{bmatrix},\n em que as duas primeiras colunas, s√£o as linhas e colunas de {\\bf X} com valor diferente de 0. A √∫ltima coluna representa o valor."
  },
  {
    "objectID": "index.html#regress√£o-linear-com-matriz-esparsa",
    "href": "index.html#regress√£o-linear-com-matriz-esparsa",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear com matriz esparsa",
    "text": "Regress√£o linear com matriz esparsa\n\nExemplo: Ajuste de um modelo de regerss√£o linear m√∫ltiplo, em que {\\bf X} poder√° ter uma representa√ß√£o esparsa. Aqui n√£o estamos interessados em verificar qualidade de predi√ß√µes. Trata-se apenas de um exemplo de como utilizar uma representa√ß√£o esparsa para ajustar um modelo de regess√£o linear com algumas covari√°veis, em R.\n\n\n\nEstude o c√≥digo\nlibrary(glmnet)\nlibrary(Matrix)\n\n# Dados de exemplo\nx1 &lt;- c(1, 0, 2, 0, 0)\nx2 &lt;- c(0, 3, 0, 4, 0)\nx3 &lt;- c(5, 0, 6, 0, 7)\ny &lt;- c(1, 2, 3, 4, 5)\n\n# Criar data frame com as vari√°veis explicativas\ndados &lt;- data.frame(x1, x2, x3)\n\n# Converter o data frame para matriz esparsa\nX &lt;- sparse.model.matrix(~ ., data = dados)\n\n# Ajustar a regress√£o linear utilizando glmnet\nmodelo &lt;- glmnet(x = X, y = y, alpha = 0, lambda = 0)\n\n# Realizar previs√µes\npredicoes &lt;- predict(modelo, newx = X)"
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio",
    "href": "index.html#erro-quadr√°tico-m√©dio",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nComo exposto anteriormente, para avaliar o poder preditivo de uma modelo, i.e., a aprendizagem de um modelo, devemos avaliar a fun√ß√£o de risco, i.e., devemos avaliar R(g) := \\mathbb{E}\\left[L(g({\\bf X}); Y)\\right]. Em particular, considere L = L_2 (fun√ß√£o perda quadr√°tica). Ent√£o, poder√≠amos ser levados a acreditar que o melhor estimador de R(g), utilizando a Lei dos Grandes N√∫meros seria:\n\\frac{1}{n}\\sum_{i = 1}^n(Y_{i} - g({\\bf X_{i}}))^2 \\approx R(g) := \\mathbb{E}\\left[L_2(g({\\bf X}); Y)\\right].\n\nEssa quantidade √© chamada, de Erro Quadr√°tico M√©dio - EQM. Desejamos escolher o melhor mode, entre os modelos testados, que minimiza o EQM.\n\nO apelo frequentista em utilizar a Lei dos Grandes N√∫meros na forma acima n√£o √© correto, uma vez que usamos as n observa√ß√µes para treinar/ajustar o modelo g."
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio-1",
    "href": "index.html#erro-quadr√°tico-m√©dio-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nPor exemplo, no problema de PIB per Capita versus expectativa de vida, em que consideramos uma aproxima√ß√£o linear, n√£o poder√≠amos utilizar o EQM da forma acima, com as n observa√ß√µes utilizadas para treinar o modelo. √â um detalhe sutil, mas que muitas pessoas cometem esse erro.\n\nN√£o podemos utilizar as n observa√ß√µes para estimar o risco R(g) atrav√©s do EQM, uma vez que estamos utilizando o mesmo conjunto de dados para ajustar e avaliar g.\n\nQual o problema?\n\n\nN√£o vale a Lei dos Grandes N√∫meros;\nUsamos os mesmos valores de {\\bf x} e y para treinar e avaliar o modelo."
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio-2",
    "href": "index.html#erro-quadr√°tico-m√©dio-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nO que diz a Lei dos Grandes N√∫meros, em particular, a Lei Forte de Kolmogorov?\n\nTeorema (Lei Forte de Kolmogorov): Sejam X_1, \\cdots, X_n uma sequ√™ncia de veri√°veis aleat√≥rias - v.a. i.i.d. e integr√°veis, i.e., com valor esperado limitado, tal que \\mathbb{E}(X) = \\mu\\,\\, \\forall i. Ent√£o,\n\\frac{X_1 + X_2 + \\cdots + X_n}{n} \\rightarrow \\mu,\nquase certamente, i.e., com probabilidade 1.\n\nNote que se desejamos comparar diversos modelos, g_1({\\bf x}), g_2({\\bf x}), \\cdots, e se utilizarmos as mesmas n oberva√ß√µes para calularmos R(g_1({\\bf x})), R(g_2({\\bf x})), \\cdots, os termos de cada uma das somas n√£o s√£o independentes. Lembre-se que desejamos obter \\argmin_g R_{pred}(g)."
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio-3",
    "href": "index.html#erro-quadr√°tico-m√©dio-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nPortanto, nunca utilize as mesmas observa√ß√µes utilizadas para treinar o modelo, como aquelas que ser√£o utilizadas para se estimar R(g). Nunca! Isso √© um pecado mortal! Ok?!"
  },
  {
    "objectID": "index.html#data-splitting",
    "href": "index.html#data-splitting",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nCorrigir o problema de depend√™ncia que h√° ao estimarmos o risco usando o EQM √© f√°cil. Uma abordagem muito utilizada √© utilizar data splitting, tamb√©m chamado de m√©todo hold-out. Algo como a segunda linha da imagem abaixo:"
  },
  {
    "objectID": "index.html#data-splitting-1",
    "href": "index.html#data-splitting-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nEssa divis√£o √© feita de forma aleat√≥ria, algumas vezes estratificada de acordo com algumas vari√°v√°veis. A ideia de aleatorizar √© se livrar de problemas de conjunto de dados ordenados. Queremos que tanto no conjunto de treinamento Training quanto no conjunto de teste Testing, na imagem, contenham a mesma diversidade de observa√ß√µes.\n\nPor exemplo, ainda no exemplo de PIB per Capita versus Expectaitiva de Vida, n√£o quero correr o risco de ter no conjunto de treinamento apenas o pa√≠ses com maiores valores de PIB per Capita, caso o conjunto de dados tenha sido ordenado pela vari√°vel GDPercapita. Por isso aleatorizar o conjunto de treinamento e teste √© simple uma √≥tima ideia. Certo!?"
  },
  {
    "objectID": "index.html#data-splitting-2",
    "href": "index.html#data-splitting-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nO percentual de divis√£o dos dados normalmente √© emp√≠rico. Usa-se normalmente a propor√ß√£o de 70\\% para treinamento e 30\\% para teste (70\\%, 30\\%). Outros esquemas de divis√µes s√£o bastante utilizados, por exemplo, (80\\%, 20\\%), (99\\%, 1\\%), a depender da quantidade de observa√ß√µes (tamanho do conjunto de dados).\n\nPortanto, utilizar o EQM sob o conjunto de dados de teste para avaliar g_1({\\bf x}), g_2({\\bf x}), \\cdots,, √© uma boa estrat√©gia, uma vez que agora n√£o teremos mais uma depend√™ncia no numerador do c√°lculo do EQM. Em nota√ß√£o matem√°tica, poder√≠amos escrever como j√° apresentado anteriormente, em Equa√ß√£o¬†1, i.e,\n\\frac{1}{m}\\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \\approx R(g) := \\mathbb{E}\\left[(Y - g({\\bf X}))^2\\right].\n\nEsse resultado valeria para qualquer outra fun√ß√£o de perda."
  },
  {
    "objectID": "index.html#data-splitting-3",
    "href": "index.html#data-splitting-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\nReescrevendo, suponha que o conjunto de dados total possua n observa√ß√µes e que separamos aleatoriamente s &lt; n observa√ß√µes para o conjunto de treinamento. Assim, temos, algo como:\n\n\\overbrace{(X_1, Y_1), (X_2, Y_2), \\cdots, (X_s, Y_s)}^{70\\%}, \\,\\,\\, \\overbrace{(X_{s + 1}, Y_{s + 1}), (X_{s + 2}, Y_{s + 2}), \\cdots, (X_n, Y_n)}^{30\\%}.\n\nEnt√£o, temos que uma boa estimativa de R(g) √© dada pelo EQM calculado sobre o conjunto de dados de teste, que nesse caso considerei o conjunto com 30\\%, mas esse percentual poderia ser outro. Ent√£o, temos que um bom estimador √©:\n\\frac{1}{n - s}\\sum_{i = s + 1}^n (Y_{i} - g(X_{i}))^2 \\approx R(g) := \\mathbb{E}\\left[(Y - g({\\bf X}))^2\\right]."
  },
  {
    "objectID": "index.html#data-splitting-4",
    "href": "index.html#data-splitting-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nAgora voc√™ entende por que dividimos os dados em treinamento e teste?\n\n\n\nDividimos para obermos um bom estimador do risco utilizando o EQM. üéä"
  },
  {
    "objectID": "index.html#data-splitting-5",
    "href": "index.html#data-splitting-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nPodemos argumentar que o procedimento de data splitting, em que dividimos o nosso conjunto de dados em treinamento e teste far√° com que venhamos perder muitas observa√ß√µes que poderiam ter sido utilizadas para treinar o modelo. E de certa forma isso √© verdade, principalmente quando termos um conjunto n√£o muito grande de observa√ß√µes.\n\nPortanto, uma melhor abordagem, sendo esta uma varia√ß√£o do m√©todo de data splitting √© o procedimento de cross-validation - cv (valida√ß√£o cruzada). Uma vers√£o mais geral de uma valida√ß√£o cruzada √© o leave-one-out cross-validation.\n\nEm palavras, o procedimento consiste em tirar de fora uma √∫nica observa√ß√£o das n observa√ß√µes da base de dados para ser o nosso conjunto de teste e treinar o modelo com as observa√ß√µes que permaneceram. Da√≠, calcula-se o risco observado (EQM, sob o conjunto de teste). Na segunda itera√ß√£o, a observa√ß√£o que antes era de teste volta para perterncer ao conjunto de treinamento e uma nova observa√ß√£o √© removida para ser teste. Esse procedimento ocorre de forma iterativa at√© a retirada da √∫ltima observa√ß√£o como teste."
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation",
    "href": "index.html#leave-one-out-cross-validation",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nObserve a anima√ß√£o abaixo que ilustra o procedimento de leave-one-out cross-validation - LOOCV, em uma amostra de tamanho n = 8. Ao fim, teremos n modelos ajustados, em que calculamos as suas respectivas performances, i.e., com o risco observado, estimamos o risco de R(g)."
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation-1",
    "href": "index.html#leave-one-out-cross-validation-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nVejo muitas pessoas que usam uma valida√ß√£o cruzada, por exemplo, leave-one-out cross-validation - LOOCV comparando com o m√©todo Jackknife e algumas inclusive dizendo ser a mesma coisa. N√£o, n√£o s√£o!\n\nO algoritmo Jackknife √© um procedimento de estima√ß√£o e que por sua vez deve estar dentro do conjunto de treinamento. Para haver algum Jackknife, a estimativa com n-1 observa√ß√µes deve estar dentro do conjunto de treinamento, em que dentro do treinamento teria a remo√ß√£o de um observa√ß√£o por vez. Consegue perceber a diferen√ßa sutil?"
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation-2",
    "href": "index.html#leave-one-out-cross-validation-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nO m√©todo LOOCV foi proposto por Stones (1974), no artigo intitulado Cross-Validatory Choice and Assessment of Statistical Predictions, no Royal Statistical Society, S√©rie B. Clique aqui se tiver curiosidade em ler o artigo.\n\nEscrevendo o estimador do risco em um procedimento de LOOCV, temos que:\n\\widehat{R}(g) = \\frac{1}{n}\\sum_{i = 1}^n (Y_i - g_{-i}({\\bf X}_i))^2, em que g_{-i}(\\bf{X}_i), representa o ajuste do modelo no conjunto de dados sem a i-√©sima observa√ß√£o.\n\nN√£o √© dif√≠cil perceber que a depender do valor de n, o m√©todo LOOCV √© computacionalmente intensivo. O m√©todo requer que ajustemos n modelos. Em algumas situa√ß√µes isso n√£o √© um grande problema, por√©m, em diversas outras pode ser impeditivo utilizar o LOOCV. ü§Ø"
  },
  {
    "objectID": "index.html#k-fold-cross-validation",
    "href": "index.html#k-fold-cross-validation",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\nUma alternativa ao LOOCV √© utilizar o m√©todo k-fold cross-validation. Nessa abordagem, dividimos o conjunto de dados em k-folds (lotes) disjuntos e com aproximadamente o mesmo tamanho. Dessa forma, temos L_1, \\cdots, L_k \\subset \\{1, \\cdots, n\\} s√£o, cada um, um conjunto de indices aleat√≥rios associados a cada um dos lotes. A ideia aqui √© construir k estimadores da fun√ß√£o de regress√£o, denotados por \\widehat{g}_{-1}, \\cdots, \\widehat{g}_{-k}, em que \\widehat{g}_{-j} √© criado usando todas as observa√ß√µes do banco de dados, com exce√ß√£o daquelas do lote L_j, utilizado para valida√ß√£o. O estimador do risco √© dado por:\n\\widehat{R}(g) = \\frac{1}{n}\\sum_{j=1}^k \\sum_{i \\in L_j}(Y_i - g_{-j}({\\bf X}_i))^2. Perceba que, que o LOOCV √© um caso particular do k-fold cross-validation, quando fazemos k = n. Em outras palavras, L_1, \\cdots, L_k \\subset \\{1, \\cdots, n\\} representam os √≠ndices aleat√≥rios do conjunto de treinamento nos k lotes."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-1",
    "href": "index.html#k-fold-cross-validation-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\nA anima√ß√£o abaixo, ilustra o procedimento de 3-fold cross-validation (k = 3), para uma amostra de tamanho n = 12 observa√ß√µes. Note que os valores que pertencem a cada um dos lotes s√£o aleat√≥rios. Portanto, o procedimento LOOCV √© deterministico, j√° o procedimento de k-fold cross-validation √© randomizado.\n\n\nPerceba que teremos agora apenas 3 modelos. Para cada um desses lotes, calulamos o EQM com o conjunto de teste (parte azul) e treinamos o modelo com o conjunto de treinamento (parte vermelha)."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-2",
    "href": "index.html#k-fold-cross-validation-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\nMuitos modelos mais sofisticados apresentam hiperpar√¢metros (par√¢metros de sintoniza√ß√£o) que n√£o dependem dos dados. √â muito comum os algoritmos de aprendizagem de m√°quina se utilizarem do procedimento de valida√ß√£o cruzada, para al√©m da estima√ß√£o do risco R(g).\n\nAo estimar k modelos, normalmente faz-se um grid de poss√≠veis valores para esses hiperpar√¢metros em que ao final, escolhe-se como hiperpar√¢metro o modelo com menor EQM. Por fim, ajusta-se um modelo final, com todo o conjunto de treinamento usando o valor do hiperpar√¢metro que retornou o menor EQM no conjunto de valida√ß√£o."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-3",
    "href": "index.html#k-fold-cross-validation-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\nA imagem abaixo ilustra o procedimento k-fold cross-validation, em que uma 5-fold cross-validation √© realizada dentro do conjunto de treinamento. Em cada split, o conjunto verde de observa√ß√µes (fold verde) s√£o utilizados para treinar/ajustar o modelo e o conjunto azul, em cada um dos splits √© utilizado para avaliar o risco preditivo R(g) (atrav√©s, por exemplo do EQM).\n\n\n \n\nN√£o confunda os folds azuis com o conjunto de teste (Test data), este √∫ltimo utilizado por fim, depois do modelo pronto, para avaliar o desempenho do modelo treinado.\nNote tamb√©m que a valida√ß√£o cruzada tamb√©m √© utilizada para o ajuste de hiperpar√¢metros, que s√£o par√¢metros de sintoniza√ß√£o que n√£o dependem dos dados para serem equalizados. Por exemplo, em uma regress√£o lasso, que veremos adiante, h√° o hiperpar√¢metro \\lambda que precisamos obter, normalmente por meio de um grid search (sequ√™ncia finita), por exemplo, \\lambda \\in [0.5, 1, 1.5, 2, 2.5] de poss√≠veis valores. Cada split pode ser utilizado para avaliar um valor de \\lambda, dos poss√≠veis valores dispostos no grid. Aumentar√≠amos a quantidade de splits para mais valores de \\lambda na sequ√™ncia."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n\n\n\n\nO simples procedimento de dividir o conjunto de dados em dois, uma parte para treinar o modelo e a outra parte (conjunto de teste) para estimar o risco R(g) √© denominado de data splitting ou Hold-out Method. √â um procedimento mais simples, por√©m, pode n√£o ser √∫til em conjunto de dados n√£o muito grandes.\nA segunda linha da ilustra√ß√£o, demonstra o procedimento de cross-validation (valida√ß√£o cruzada), procedimento mais utilizado nos treinamentos de modelos de aprendizagem de m√°quina.\nA terceira linha √© uma abordagem tamb√©m utilizada, por√©m n√£o t√£o interessante quanto a valida√ß√£o cruzada. Nessa abordagem o banco de dados √© dividido aleatoriamente em tr√™s partes. Traina-se o modelo com a parte verde, estima-se o risco com o conjunto de valida√ß√£o amarelo e testa-se o modelo com o conjunto de teste."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-1",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n A abordagem do conjunto de valida√ß√£o envolve dividir o conjunto de treinamento em duas partes: uma parte √© usada para treinar o modelo e a outra parte √© usada para avaliar o desempenho do modelo. O conjunto de valida√ß√£o √© utilizado para ajustar os hiperpar√¢metros do modelo, como a taxa de aprendizado, o n√∫mero de camadas ocultas em uma rede neural, entre outros. Ap√≥s o ajuste dos hiperpar√¢metros, o modelo final √© treinado com o conjunto de treinamento completo e avaliado em um conjunto separado chamado conjunto de teste. Essa abordagem √© conhecida como divis√£o simples de treinamento/valida√ß√£o/teste.\n\nPor outro lado, a valida√ß√£o cruzada k-fold √© uma abordagem que visa obter uma estimativa mais robusta do desempenho do modelo. Nessa abordagem, o conjunto de treinamento √© dividido em k subconjuntos (folds) de tamanho aproximadamente igual. O modelo √© treinado k vezes, cada vez usando k-1 folds como conjunto de treinamento e 1 fold como conjunto de valida√ß√£o. O desempenho do modelo √© ent√£o calculado como a m√©dia dos resultados obtidos em cada itera√ß√£o. Isso permite avaliar o modelo de forma mais precisa, pois utiliza todos os dados para treinamento e valida√ß√£o, evitando a depend√™ncia de uma √∫nica divis√£o do conjunto de treinamento."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-2",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n\nA valida√ß√£o cruzada k-fold √© particularmente √∫til quando o conjunto de dados √© limitado, pois aproveita ao m√°ximo os dados dispon√≠veis. Al√©m disso, ela permite verificar se o modelo √© est√°vel e se seu desempenho varia significativamente com diferentes divis√µes dos dados. √â importante ressaltar que a valida√ß√£o cruzada k-fold pode ser computacionalmente mais cara do que a abordagem do conjunto de valida√ß√£o, uma vez que envolve treinar e avaliar o modelo v√°rias vezes.\n\n\n\n\n\nDepartamento de Estat√≠stica da UFPB"
  }
]