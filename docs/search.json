[
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "",
    "text": "Sobre mim\n \n\nMe chamo Prof.¬†Dr.¬†Pedro Rafael D. Marinho. Meu curr√≠culo Lattes poder√° ser acessado clicando aqui.\nSou docente do Departamento de Estat√≠stica da UFPB. üë®‚Äçüè´\nToda minha forma√ß√£o acad√™mica √© na √°rea de estat√≠stica (bacharelado ao doutorado).\nTenho entusiasmo por programa√ß√£o, ci√™ncia de dados e aprendizagem de m√°quina üíªüìà.\n Me acompanhe no GitHub: https://github.com/prdm0.\n Me acompanhe no Linkedin: https://www.linkedin.com/in/prdm0/."
  },
  {
    "objectID": "index.html#sobre-mim",
    "href": "index.html#sobre-mim",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Sobre mim",
    "text": "Sobre mim\n \n\nMe chamo Prof.¬†Dr.¬†Pedro Rafael D. Marinho. Meu curr√≠culo Lattes poder√° ser acessado clicando aqui.\nSou docente do Departamento de Estat√≠stica da UFPB. üë®‚Äçüè´\nToda minha forma√ß√£o acad√™mica √© na √°rea de estat√≠stica (bacharelado ao doutorado).\nTenho entusiasmo por programa√ß√£o, ci√™ncia de dados e aprendizagem de m√°quina üíªüìà.\n Me acompanhe no GitHub: https://github.com/prdm0.\n Me acompanhe no Linkedin: https://www.linkedin.com/in/prdm0/."
  },
  {
    "objectID": "index.html#meu-segundo-lar",
    "href": "index.html#meu-segundo-lar",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Meu segundo lar",
    "text": "Meu segundo lar\n\n\n\n\nDepartamento de Estat√≠stica da UFPB."
  },
  {
    "objectID": "index.html#que-linguagem-de-programa√ß√£o-utilizar",
    "href": "index.html#que-linguagem-de-programa√ß√£o-utilizar",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Que linguagem de programa√ß√£o utilizar?",
    "text": "Que linguagem de programa√ß√£o utilizar?\n\nNesse curso, ser√° abordado a linguagem de programa√ß√£o R, mas lembre-se que voc√™ poder√° utilizar qualquer linguagem de programa√ß√£o para fazer ci√™ncia de dados. Por√©m, R e Python s√£o as minhas sugest√µes, haja vista que, atualmente, elas s√£o as linguagens com maior quantidade de ferramentas e usu√°rios trabalhando na √°rea de ci√™ncia de dados.\n\nOutros motivos que me leva a lecionar a disciplina utilizando a linguagem R s√£o:\n\nPossui ferramentas muito bem pensadas para manipula√ß√£o e tratamento de dados;\nNormalmente, os frameworks de machine learning de R s√£o menos verbosos que os de Python;\nMatrizes e data frames s√£o estruturas de dados que j√° encontra-se definidas dentro da linguagem, n√£o precisando assim de importar bibliotecas.\n\nIsso √© meu gosto pessoal! √â um gosto que, talvez, faz mais sentido, em se tratando de algu√©m que vem da estat√≠stica. No mercado de trabalho e em seus estudos, ap√≥s cursar as disciplinas de R e Python, fornecidas pelo Bacharelado em Estat√≠stica da UFPB, voc√™ ter√° a capacidade de estudar os frameworks de machine learning, aos seus pr√≥prios passos e escolher o que melhor te agrada. A linguagem Julia tamb√©m poder√° ser uma √≥tima op√ß√£o."
  },
  {
    "objectID": "index.html#aprendizagem-de-m√°quina",
    "href": "index.html#aprendizagem-de-m√°quina",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Aprendizagem de m√°quina",
    "text": "Aprendizagem de m√°quina"
  },
  {
    "objectID": "index.html#aprendizagem-de-m√°quina-1",
    "href": "index.html#aprendizagem-de-m√°quina-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Aprendizagem de m√°quina",
    "text": "Aprendizagem de m√°quina\n \nAlguns pontos:\n\n\nA Aprendizagem de M√°quina (AM), tamb√©m chamada de Machine Learning (ML), no ingl√™s, nasceu na d√©cada de 60 como um campo da intelig√™nica artificial;\nEm sua origem, as aplica√ß√µes de AM tinha como objetivo aprender padr√µes com base nos dados;\nOriginalmente, as aplica√ß√µes de AM eram de cunho estritamente computacional. Todavia, desde o in√≠cio dos anos 90, a √°rea de aprendizagem de m√°quina expandiu seus horizontes e come√ßou a se estabelecer como um campo por sim mesma;\nEm particular, a √°rea de aprendizagem de m√°quina come√ßou a estabelecer muitas intersec√ß√µes com a estat√≠stica. Muitos de seus algoritmos s√£o constru√≠dos com base em metodologias que surgiram na estat√≠stica;\nAtualmente, a comunidade de AM √© bastante interdisciplinar e utiliza-se de ideias desenvolvidas em diversas √°reas, sendo a estat√≠stica uma delas."
  },
  {
    "objectID": "index.html#tipos-de-aprendizado",
    "href": "index.html#tipos-de-aprendizado",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tipos de Aprendizado",
    "text": "Tipos de Aprendizado\n\nAprendizado supervisionado\n\nNesse curso, inicialmente estudaremos problemas de aprendizado supervisionado, que consiste em aprender a fazer predi√ß√µes a partir de conjunto de dados em que r√≥tulos (valores da vari√°vel resposta Y) s√£o observados. Trataremos tanto de problemas de regress√£o (estimar um valor n√∫m√©rico) quanto problemas de classifica√ß√£o (classificar um cliente como aprovado ou reprovado, em um problema de concess√£o de cr√©dito). Por exemplo, os modelos de regress√£o s√£o exemplos de aprendizado supervisionado.\n\nAprendizado n√£o-supervisionado\n\nNa segunda parte do curso, aprenderemos alguns m√©todos de aprendizado n√£o-supervisionado, ou seja, algoritmos que n√£o utilizam-se de r√≥tulos, em que busca-se aprender mais sobre a estrutura dos dados. Por exemplo, os m√©todos de agrupamento (cluster), s√£o exempƒ∫os de m√©todos de aprendizado n√£o-supervisionado."
  },
  {
    "objectID": "index.html#tipos-de-aprendizado-1",
    "href": "index.html#tipos-de-aprendizado-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tipos de Aprendizado",
    "text": "Tipos de Aprendizado\n\nMuito embora no nosso curso focaremos nas abordagens de aprendizagem supervisionada e n√£o-supervisionada, os tipos de aprendizagem, em geral, podem ser mais amplos, em que temos:\n\n\nAprendizagem supervisionada;\nAprendizagem n√£o-supervisionada;\nAprendizagem semi-supervisionada;\nAprendizagem por refor√ßo."
  },
  {
    "objectID": "index.html#o-que-√©-aprender",
    "href": "index.html#o-que-√©-aprender",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "O que √© aprender?",
    "text": "O que √© aprender?\n\nAntes de detalharmos os tipos de aprendizagem de m√°quina, uma d√∫vida que poder√° surgir √©: ‚ÄúO que √© aprender?‚Äù. ‚ÄúComo a m√°quina aprende?‚Äù."
  },
  {
    "objectID": "index.html#o-que-√©-aprender-1",
    "href": "index.html#o-que-√©-aprender-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "O que √© aprender?",
    "text": "O que √© aprender?\n\nDe forma simples, aprender √© ganhar conhecimento atrav√©s de estudo, experi√™ncias, por meio de ensinamentos.\n\nT√°, mais como √© que a m√°quina aprende?\n\n\nAprendizagem √© o processo em que se adquire conhecimento, isto √©, √© o processo em que utilizamos de algoritmos e fornecemos dados a esses algoritmos para que possamos extrair conhecimento. Nesse processo de aprendizagem, os algoritmos fazem uso de dados para a extress√£o de conhecimento, atrav√©s de procedimentos supervisionado, n√£o-supervisionado, semi-supervisionado ou por refor√ßo, a depender do algoritmo que voc√™ deseja utilizar.\nAprendizado √© o modelo ajustado, isto √©, √© o conhecimento adquirido ap√≥s o treinamamento obtido no processo de aprendizagem. Voc√™ poder√° entender como sendo o modelo ajustado e que utilizamores para a tomada de decis√µes."
  },
  {
    "objectID": "index.html#o-que-√©-aprender-2",
    "href": "index.html#o-que-√©-aprender-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "O que √© aprender?",
    "text": "O que √© aprender?\n\nPortanto, voc√™ poder√° entender, basiciamente, existe quatro tipos de aprendizagem, sendo os dois primeiros o que mais focaremos nesse curso e que de longe s√£o os mais utilizados:\n\n\nAprendizagem supervisionada;\nAprendizagem n√£o-supervisionada;\nAprendizagem semi-supervisionada;\nAprendizagem por refor√ßo."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada",
    "href": "index.html#aprendizagem-supervisionada",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\nNesse tipo de aprendizagem, o algoritmo ir√° receber um conjunto de dados em que conhecemos r√≥tulos para a vari√°vel de interesse. √â como se voc√™ soubesse onde um bom modelo deve chegar, para assim ser reconhecido como um bom modelo. Por exemplo,\n\n\nClassifica√ß√£o: precisamos determinar a classe de uma inst√¢ncia de dados, o seu atributo, i.e., \\widehat{y} = \\mathrm{argmax}_y\\,P(Y = y\\,|\\, X = \\bf{x}), em que y √© um atributo que desejamos prever (cahorro, gato, sapo), e \\bf{x} √© um vetor de caracter√≠sticas (peso, altura, comprimento, se tem rabo, etc).\nRegress√£o: precisamos estimar uma quantidade num√©rica, i.e., o valor da vari√°vel alvo por meio de uma inst√¢ncia de dados, ou seja, precisamos estimar Y = \\mathbb{E}(Y|X = \\bf{x}), i.e., devemos encontrar meios de obter \\widehat{Y}.\n\n\n\n\nAlgumas observa√ß√µes de nomenclaturas:\n\n√â comum chamar cada exemplo de dados, i.e., o vetor \\bf{x} que ser√° passado ao modelo de atributos ou features;\nTamb√©m √© comum chamarmos de r√≥tulo ou label a classe ou valor alvo, ou seja, estas s√£o as formas de nomearmos Y, sendo Y uma quantidade num√©rica (modelos de regress√£o) ou n√£o (modelos de classifica√ß√£o)."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-1",
    "href": "index.html#aprendizagem-supervisionada-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\nEm se tratando de m√©todos de classifica√ß√£o, podemos ter os m√©todos:\n\n\nGenerativos: s√£o os m√©todos que dada as vari√°veis X e Y, o objetivo √© encontrar a distribui√ß√£o de probabilidade conjunta P(X, Y), para ent√£o poder determinar P(Y|X = \\bf{x}). Alguns m√©todos s√£o:\n\nNaive Bayes;\nDescriminante linear.\n\n\n\n\nDescriminativos: s√£o os m√©todos que estimam diretamente a probabilidade condicional P(Y|X = \\bf{x}) ou que mesmo nem assumem modelos probabil√≠sticos. Os modelos dessa classe s√£o projetados para aprender a fronteira de decis√£o que separa as classes diretamente com base nas caracter√≠sticas de entrada. Podemos citar:\n\nRegress√£o logistica;\nPerceptron;\nSupport Vector Machine - SVM."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-2",
    "href": "index.html#aprendizagem-supervisionada-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\n\n\n\n\n Poder√≠amos estar interessados em classificar o tamanho de morangos:\n\n\nS (Slow): pequeno;\nM (Medium): m√©dio;\nL (Large): grande."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-3",
    "href": "index.html#aprendizagem-supervisionada-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n \n\nMais dois problemas de classifica√ß√£o (linear x n√£o-linear)."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-4",
    "href": "index.html#aprendizagem-supervisionada-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n \n\nUm exemplo de de um problema de regress√£o. Aqui, a ideia √© utilizar a equa√ß√£o da reta estimada, a reta que minimiza a soma dos quadrados entre a reta e os ponto seria a melhor, de modo a ter uma estimativa num√©rica atrav√©s de novos atributos passado ao modelo, i.e., por meio da equa√ß√£o da reta e de um novo valor de x."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-5",
    "href": "index.html#aprendizagem-supervisionada-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\nUm outro exemplo seria a classifica√ß√£o de imagem/v√≠deo, utilizando um algoritmo de rede neural, por exemplo, usando uma Convolutional Neural Network - CNN. Foram utilizados diversas imagens de pessoas ‚Äúcom‚Äù e ‚Äúsem‚Äù m√°scara. Em que ‚Äúcom‚Äù representa detec√ß√£o da m√°scara na face da pessoa e ‚Äúsem‚Äù a n√£o detec√ß√£o."
  },
  {
    "objectID": "index.html#aprendizagem-n√£o-supervisionada",
    "href": "index.html#aprendizagem-n√£o-supervisionada",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem n√£o-supervisionada",
    "text": "Aprendizagem n√£o-supervisionada\n\nNesse tipo de aprendizagem, os algoritmos trabalham sobre dados n√£o rotulados, por exemplo, em uma trarefa de agrupamento.\n\nOs algoritmos verificam se as inst√¢ncias observadas poder√£o ser arranjadas de alguma maneira, por exemplo, usando alguma m√©trica de dist√¢ncia, formando grupos (clusters).\n\nA ideia √© maximizar a dist√¢ncia entre os clusters e minimizar a dist√¢ncia entre os elementos no interior do grupo. Em outras palavras, o que se quer √© tornar os grupos mais diferentes poss√≠veis e tornar os elementos dos grupos o mais parecido poss√≠vel.\n\nAqui, por n√£o haver r√≥tulos, um problema comum √© determinar a quantidade de grupos ideal que muitas vezes s√£o obtidos de forma subjetiva ou por heur√≠sticas. A quantidade de grupos √© um dilema!"
  },
  {
    "objectID": "index.html#aprendizagem-n√£o-supervisionada-1",
    "href": "index.html#aprendizagem-n√£o-supervisionada-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem n√£o-supervisionada",
    "text": "Aprendizagem n√£o-supervisionada\n\n\nAp√≥s a detec√ß√£o dos grupos, √© preciso analisar o resultado de modo a tentar extrair informa√ß√µes coerentes de modo a saber o que cada grupo representa no problema em quest√£o."
  },
  {
    "objectID": "index.html#aprendizagem-semi-supervisionada",
    "href": "index.html#aprendizagem-semi-supervisionada",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem semi-supervisionada",
    "text": "Aprendizagem semi-supervisionada\n\nA aprendizagem semi-supervisionada √© uma abordagem na √°rea de aprendizagem de m√°quina, em que um algoritmo utiliza tanto dados rotulados quanto n√£o rotulados para treinamento. Por exemplo, algoritmos que propagam r√≥tulos, como o Label Propagation, em que r√≥tulos conhecidos s√£o propagados para dados n√£o rotulados com base em sua sua proximidade no espa√ßo de caracter√≠sticas.\n\nUma outra abordagem seria misturar modelos (Model Blending), em que diferentes modelos s√£o treinados em diferentes partes do conjunto de dados, por exemplo, um modelo para a parte roturada e um para a parte n√£o rotulada."
  },
  {
    "objectID": "index.html#aprendizagem-por-refor√ßo",
    "href": "index.html#aprendizagem-por-refor√ßo",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem por refor√ßo",
    "text": "Aprendizagem por refor√ßo\n\nNesse tipo de aprendizagem, n√£o h√° uma fonte externa de exemplos. O agente (modelo) aprende aprende com sua pr√≥pria experi√™ncia, por tentativas e erros, em que voc√™ dever√° definir uma medida de sucesso, e eventualmente recompensar os acertos. No v√≠deo abaixo, veja um joguinho que criei em R, em que o carrinho aprendeu a desviar de obst√°culos aleat√≥rios que aparecem em sua frente. Utilizou-se uma rede neural cuja a sa√≠da poderia ser (‚Äúparado‚Äù, ‚Äúpara cima‚Äù ou ‚Äúpara baixo‚Äù). Veja o c√≥digo clicando aqui."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento",
    "href": "index.html#dados-explora√ß√£o-e-tratamento",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nUm dos passos mais importante no fluxo de trabalho (workflow) de um modelo de aprendizagem de m√°quina, consiste na prepara√ß√£o dos dados, em que realizamos transforma√ß√µes, inputa√ß√µes de valores ausentes, identifica√ß√£o de outliers, remo√ß√£o de vari√°veis altamente correlacionadas, entre outros.\n\nFazer uma an√°lise explorat√≥ria dos dados √© um passo importante para que se possa entender e detecatar poss√≠veis inconsist√™ncias na base de dados. N√£o adianta fazer uso de modelos muito sofisticados quando se tem uma base de dados cheia de problemas.\n\nNormalmente trabalhamos com juntos de dados (tabelas) relacionais, em que cada linha √© uma observa√ß√£o e cada coluna representa um atributo do objeto/observa√ß√£o. A linha de uma base de dados relacional, sem sua a vari√°vel de interesse, lembre-se que denominamos Y de r√≥tulo ou label, fornece o vetor de caracter√≠sticas \\bf{x} que descreve uma dada observa√ß√£o."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-1",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\nNo artigo Tidy Data, 2014, publicado no Journal of Statistical Sofware, o Hadley Wickham discute que o princ√≠pio de dados organizados est√£o intimamente relacionados com banco de dados relacional e mais pr√≥ximo do recioc√≠nio que empregamos na √°lgebra. Nesse artigo, ele define o que √© Tidy Data, sendo essa uma maneira de mapear um conjunto de dados.\n\nSegundo o artigo, um conjunto de dados √© bagun√ßado ou arrumado/tidy, dependendo de como as linhas, colunas e tabelas s√£o combinadas com as observa√ß√µes, vari√°veis e tipos. Em dados arrumados (dados tidy), temos que:\n\n\nCada vari√°vel forma uma coluna;\nCada observa√ß√£o forma uma linha;\nCada valor deve ter sua pr√≥pria c√©lula.\n\n\nEmbora existam situa√ß√µes em que j√° podemos come√ßar a analisar uma base de dados real, essa √© a exce√ß√£o e n√£o a regra. Normalmente, nos deparamos com bases de dados que violam uma ou mais dessas regras. Sempre, que poss√≠vel, procure utilizar dados no formato Tidy."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-2",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\n\nRepresenta√ß√£o de uma base de dados no formato tidy."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-3",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\n\n‚ÄúAs fam√≠lias felizes s√£o todas iguais; toda fam√≠lia infeliz √© infeliz √† sua maneira.‚Äù ‚Äì Leo Tolstoy\n\n\n‚ÄúConjuntos de dados organizados s√£o todos iguais, mas todo conjunto de dados confuso √© confuso √† sua maneira.‚Äù ‚Äì Hadley Wickham\n\n\n\nTrabalhar com a Tabela do lado esquerdo √© melhor que a Tabela do lado direito. Prefira, sempre que poss√≠vel, o formato tidy. N√£o permita-se ficar estressado t√£o facilmente. üòÉ"
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-4",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\nA linguagem de programa√ß√£o R possue diversas ferramentas que permite manipular e explorar bases de dados. Enumero algumas:\n\ndplyr: biblioteca que implementa √© uma gram√°tica de manipula√ß√£o de dados, fornecendo um conjunto consistente de verbos que ajudam a resolver os desafios mais comuns de manipula√ß√£o de dados;\ntidyr: ferramentas para ajudar a criar dados organizados, em que cada coluna √© uma vari√°vel, cada linha √© uma observa√ß√£o e cada c√©lula cont√©m um √∫nico valor;\nggplot2: um sistema para criar gr√°ficos ‚Äòdeclarativamente‚Äô, baseado no livro The Grammar of Graphics, de Leland Wilkinson;\nvisdat: uma biblioteca √∫til para um visualiza√ß√£o explorat√≥ria preliminar de dados;\nexplore: biblioteca que apresenta algumas rotinas de an√°lise para realizar uma an√°lise explorat√≥ria nos dados.\n\nTodas essas bibliotecas est√£o muito bem documentadas. √â importante que voc√™s explorem as documentas dessas bibliotecas, pois eventualmente irei utizar alguma delas."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-5",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nNo Cap√≠tulo 12, do livro R for Data Science, o autor aborda mais sobre o formato Tidy e como trabalhar com a biblioteca tidyr. Aqui o autor aborda de forma b√°sica o pacote dplyr.\n\nDurante o curso, na medida da necessidade de utiliza√ß√£o dessas ferramentas, durante a exposi√ß√£o de exemplos, abordaremos alguns conceitos. Voc√™ ter√° a oportunidade de tamb√©m explorar essas bibliotecas nos exerc√≠cios. Ok?!"
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-6",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nMuitas vezes, no processo de tratamento dos dados, tamb√©m estamos preocupados em remover atributos que n√£o s√£o significativo para a modelagem, em que nesse momento a experi√™ncia dos especialistas s√£o fundamentais.\n\n√â comum enriquercermos a base de dados com informa√ß√µes de outras bases de dados, em um sistema de gerenciamento de banco de dados relacional, em que as bases de dados est√£o relacionadas por uma chave. Nesse caso, buscamos por novos atributos para um mesmo objeto (para uma mesma linha da base), em que atributos cruzados devem ter um √∫nico valor, para cada objeto, respeitando a regra tr√™s de conjuntos de dados tidy.\n\nAs vezes transformamos vari√°veis. Por exemplo, √© comum tomar o logaritmo de uma vari√°vel num√©rica que √© assim√©trica, se x \\geq 1, em que x √© um atributo num√©rico qualquer.\n\nEm diveras situa√ß√µes, tamb√©m √© comum a base de dados apresentar informa√ß√µes faltantes. Nos data frames de R, a falta de informa√ß√£o na base, normlamente ser√£o representadas por NA."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-7",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nPoder√° ser que um dado atributo apresente informa√ß√£o faltante, e normalmente n√£o optaremos em remover a observa√ß√£o e precisaremos imputar a informa√ß√£o, por exemplo:\n\n\nTomando alguma medida de tend√™ncia central como m√©dia/moda/mediana dos valores que s√£o conhecidos para aquele atributo;\nCriar um novo valor que √© indica√ß√£o de valor faltante;\nUsar algoritmos como k-nearest neighbors - kNN (k vizinhos mais pr√≥ximos) para imputar valores coerentes;\nInterpolar os dados.\n\nEsses s√£o alguns exemplos de como podemos imputar observa√ß√µes faltantes. Muitas vezes n√£o podemos nos dar o luxo de percer observa√ß√µes de nossa base de dados."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-8",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\n√â comum ser necess√°rio transformar os dados:\n\nPode ser necess√°rio transformar os tipos ou os valores dos atributos para tentar obter um melhor ajuste do modelo;\nPode-se discretizar valores cont√≠nuos ou transform√°-los em intervalos;\n√â comum transformar atributos categ√≥ricos com p categorias, em p novos atributos bin√°rios.\n\nOne-hot encoding\nVari√°veis dummy\n\nOutra transforma√ß√£o muito comum √© a normaliza√ß√£o dos dados. Normalizar os dados √© muito √∫til quando os atributos num√©ricos possuem escalas muito diferentes.\n\n\n\nX_{novo} = \\frac{X - X_{min}}{X_{max} - X_{min}}, em que X_{novo} \\in [0, 1].\n\nX_{novo} = Z = \\frac{X - \\mu}{\\sigma^2}, em que \\mathbb{E}(X) = \\mu √© a m√©dia dos dados e \\mathrm{Var}(X) = \\sigma^2. Na pr√°tica, em um contexto de v.a., iids, usamos \\overline{x} como estimador de \\mu e S^2 (vari√¢ncia amostral) como estimador de \\sigma^2."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-9",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-9",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nLembre-se, como citado anteriormente, tomar o logaritmo natural, ou mesmo na base 10 de vari√°veis num√©ricas muito assim√©tricas, poder√° ajudar um pouco, desde que seja possivel tomar o \\log(\\cdot).\n\n\n\n\nset.seed(0)\nrgamma(1000, 2, 2) |&gt; \n  hist()\n\n\n\n\n\n\nset.seed(0)\nrgamma(1000, 2, 2) |&gt; \n  log() |&gt; hist()"
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-10",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-10",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nAnteriormente eu citei algumas bibliotecas √∫teis de R para explorar os dados, na fase de tratamento das observa√ß√µes. Por√©m, n√£o estranhe n√£o ter, at√© o momento, citado bibliotecas do framework tidymodels, em especial o recipes que √© muito utilizado no workflow de aprendizagem de m√°quina, na fase de pr√©-processamento dos dados. Muitas dessas transforma√ß√µes s√£o aplicadas como receitas de pr√©-processamento com o pacote recipes.\n\n\n\nO tidymodels ser√° muito √∫til para n√≥s, mas, aos poucos, seu uso e explica√ß√µes mais detalhadas ser√£o apresentadas, apesar que em algumas situa√ß√µes mais simples, poderei n√£o utiliz√°-lo, para expor detalhes que eventualmente n√£o ser√° poss√≠vel ou estariam camuflados (black box) na utiliza√ß√£o do tidymodels.\n\nPara n√£o deixar de valar sobre o tidymodels, explicarei, agora, a sua filosofia e como ele est√° dividido em outras bibliotecas que s√£o √∫teis em cada parte do processo de treinamento de um modelo de machine learning."
  },
  {
    "objectID": "index.html#tidymodels",
    "href": "index.html#tidymodels",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üíª Tidymodels",
    "text": "üíª Tidymodels\n\nDiversas bibliotecas na linguagem R s√£o preparadas para trabalharem na √°rea de aprendizagem de m√°quina. V√°rias dessas bibliotecas vem sendo desenvolvidas h√° anos. Por exemplo,as bibliotecas glmnet, ranger, kknn, xgboost, keras, rpart, randomForest, entre diversos outros.\n\n\n\nO n√∫mero de pacotes abaixo √© o mais recente. Obtido automaticamente por webscraping.\nlibrary(xml2)\nlibrary(httr)\nlibrary(stringr)\n\nnumero_pacotes_r &lt;- httr::GET(\"https://cloud.r-project.org/web/packages/index.html\") |&gt; \n  xml2::read_html() |&gt; \n  xml2::xml_find_all(\"//p[1]\") |&gt; \n  xml2::xml_text() |&gt; \n  stringr::str_extract(pattern = \"[0-9]+\")\n\n\n\nAtualmente, a linguagem R possui 19907, em que muitos deles s√£o preparados para para trabalharem em tarefas de aprendizagem de m√°quina, por√©m, cada com sua sintaxe espec√≠fica. Muitos implementam o mesmo modelo, uns com algumas varia√ß√µes, por√©m, o uso √© totalmente diferente, nomes de par√¢metros distintos, sa√≠das distintas, etc."
  },
  {
    "objectID": "index.html#tidymodels-1",
    "href": "index.html#tidymodels-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üíª Tidymodels",
    "text": "üíª Tidymodels\n\nEssas diferentes implementa√ß√µes torna confuso trabalhar e testar diferentes modelos ao mesmo tempo.\n\n\n\nUma das primeiras ideias mais conhecidas de unifica√ß√£o de sintaxe do workflow de machine learning, na linguagem R, foi idealizada pelo estat√≠stico Max Khun.\n\nEle criou a biblioteca caret - Classification And REgression Training de R que √© muito bem desenvolvida e abrangente. Voc√™ poder√° estudar o caret clicando aqui.\n\nN√£o foi um trabalho simples, veja uma tabela com a quantidade de modelos que o caret suporta, clicando aqui. Ent√£o, ‚Äúpor baixo dos panos‚Äù, a ideia era unificar a entrada e sa√≠da. A biblioteca caret continua sendo mantida, apesar da exist√™ncia do tidymodels."
  },
  {
    "objectID": "index.html#tidymodels-2",
    "href": "index.html#tidymodels-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üíª Tidymodels",
    "text": "üíª Tidymodels\n\n\n\n\n\n\n\n\n\nMax Kuhn, atualmente, no momento de escrita desse mateiral, √© funcion√°rio da Posit Ltda e foi contratado para estar a frente do desenvolvimento de uma vers√£o ‚Äúarrumada‚Äù (tidy) do caret, que √© o tidymodels."
  },
  {
    "objectID": "index.html#tidymodels-3",
    "href": "index.html#tidymodels-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üíª Tidymodels",
    "text": "üíª Tidymodels\n\n\nO workflow (pipeline) do treinamento de um modelo usando o framework tidymodels. Todos os pacotes (rsample, recipes, parsnip, tune, dails, yardstick) s√£o gerenciados pelo pacote tidymodels. Cada um desses pacotes fornece um conjunto de fun√ß√µes √∫teis em tarefas espec√≠ficas no workflow de machine learning."
  },
  {
    "objectID": "index.html#tidymodels-4",
    "href": "index.html#tidymodels-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üíª Tidymodels",
    "text": "üíª Tidymodels\n\n\nrsample: respons√°vel pela reamostragem dos dados, parte importante para que possamos treinar um modelo de aprendizagem de m√°quina. √â nele que encontra-se fun√ß√µes para realizar reamostragem como bootstrap, k-folds cross-validation, nested cross-validation, entre outras.\n\n\n\n\n\n\n\nrecipes: apresenta diversas fun√ß√µes para transforma√ß√µes de vari√°veis como cria√ß√£o de vari√°veis dummy, normaliza√ß√£o de vari√°veis, inputa√ß√£o de dados pela m√©dia, mediana, kNN, entre outras formas de imputa√ß√£o, transforma√ß√µes de vari√°veis categ√≥rias em num√©ricas, entre outras funcionalidades. Ele permite que possamos criar uma receita de transforma√ß√µes nos dados para que esses, ap√≥s transformados, possam entrar no modelo.\n\n\n\n\n\n\n\nparsnip: √© o pacote que unifica as entradas e sa√≠das de diversos pacotes de aprendizagem de m√°quina de R. Ele possui os motores (engines) que s√£o as comunica√ß√µes com os algoritmos implementados em diversos pacotes de R que trabalham com tarefas de regress√£o e classifica√ß√£o, em aprendizagem de m√°quina."
  },
  {
    "objectID": "index.html#tidymodels-5",
    "href": "index.html#tidymodels-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üíª Tidymodels",
    "text": "üíª Tidymodels\n\n\n\nOs pacotes tune, dails e yardstick tomar√° conta da parte de treino do modelo. Os pacote tune e dails s√£o respons√°veis pela ‚Äútunagem‚Äù dos eventuais hiperpar√¢metros, j√° o yardstick √© respons√°vel pelas m√©tricas de avalia√ß√£o do modelo.\n\nA biblioteca dails est√° mais relacionada a cria√ß√£o dos grids para os eventuais hiperpar√¢metros do modelo. J√° o pacote tune, utiliza-se da valida√ß√£o cruzada criada pelo pacote rsample para varrer as combina√ß√µes de hiperpar√¢metros criadas pelo dails, i.e., o tune est√° mais relacionado com a otimiza√ß√£o dos hiperpar√¢metros."
  },
  {
    "objectID": "index.html#tidymodels-6",
    "href": "index.html#tidymodels-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üíª Tidymodels",
    "text": "üíª Tidymodels\n\nTodo o fluxo de trabalho √© gerido pela biblioteca workflows de R. Em especial, as etapas de feature engineering e especifica√ß√£o do modelo."
  },
  {
    "objectID": "index.html#tidymodels-7",
    "href": "index.html#tidymodels-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üíª Tidymodels",
    "text": "üíª Tidymodels\n\n\nPerceba o papel da biblioteca workflows de R. Basicamente gostar√≠amos de ter uma automa√ß√£o da faze do tratamento das features realizada com o recipes com a modelagem."
  },
  {
    "objectID": "index.html#tidymodels-8",
    "href": "index.html#tidymodels-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üíª Tidymodels",
    "text": "üíª Tidymodels\n\nN√£o necessariamente iremos utilizar o tidymodels em todos os exemplos e exerc√≠cios. Por√©m, iremos explorar bastante, at√© o fim do curso, o treinamento de modelos usando o tidymodels. Por tanto, aos poucos, a medida em que exemplos s√£o apresentados e exerc√≠cios forem passados, o aprendizado do uso do tidymodels se dar√°.\n\n \n\nSempre que poss√≠vel, deveremos colocar as ‚Äúm√£os na massa‚Äù üçù para que possamos dominar e compreender uma ferramenta computacional. A pr√°tica √© importante!"
  },
  {
    "objectID": "index.html#as-duas-culturas",
    "href": "index.html#as-duas-culturas",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üé≠ As duas culturas",
    "text": "üé≠ As duas culturas\n\nEm Breiman, L. (2001a). Statistical modeling: The two cultures. Statistical Science, 16(3), 199‚Äì231, o Leo Breiman argumenta que existe duas culturas no uso de modelos estat√≠sticos, em especialmente na √°rea de modelos de regress√£o. Segundo eles, as culturas s√£o:\n\n\nData modeling culture: nela, em geral, se assume que o modelo de regress√£o utilizado r(x), por exemplo, r(x) = \\beta_0 + \\sum_{i = 1}^d \\beta_ix_i √© correto. O principal objetivo dessa abordagem √© a interpreta√ß√£o dos par√¢metros que indexam o modelo r(x). Nesse tipo de cultura, a ideia tamb√©m √© construir intervalos aleat√≥rios e testar hip√≥teses para os \\beta_i's. Sob essa √≥tica, muitas suposi√ß√µes sob o modelo s√£o realizadas, em que formas para checar essas suposi√ß√µes s√£o desenvolvidas, uma vez que elas s√£o fundamentais para esse tipo de modelagem.\n\n\n\nAlgorithmic modeling culture: essa √© a cultura que domina a comunidade de aprendizagem de m√°quina. Nessa abordagem, o principal objetivo s√£o as predi√ß√µes por meio de novas observa√ß√µes. N√£o se assume que o modelo utilizado √© o modelo correto. Nesse tipo de modelagem, muitas vezes os algoritmos n√£o envolve nenhuma estrutura probabil√≠stica. Muitas vezes, modelos n√£o bem especificado conduzem a boas predi√ß√µes."
  },
  {
    "objectID": "index.html#as-duas-culturas-1",
    "href": "index.html#as-duas-culturas-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üé≠ As duas culturas",
    "text": "üé≠ As duas culturas\n\n\n\n\n\n\nBreiman, L. (2001a). Statistical modeling: The two cultures. Statistical Science, 16(3), 199‚Äì231.\n\n\n\n\n\n\nLeo, na √©poca em que era um jovem probabilista na Universidade da Calif√≥rina."
  },
  {
    "objectID": "index.html#as-duas-culturas-2",
    "href": "index.html#as-duas-culturas-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üé≠ As duas culturas",
    "text": "üé≠ As duas culturas\n\nH√° diversos artigos interessantes que s√£o respostas ao artigo do Leo Breiman, como por exemplo, o artigo Statistical Modeling: The Two Cultures: Comment do David Cox e com coment√°rios do Brad Efron.\n\nSir David Cox."
  },
  {
    "objectID": "index.html#as-duas-culturas-3",
    "href": "index.html#as-duas-culturas-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üé≠ As duas culturas",
    "text": "üé≠ As duas culturas\n\nMuito embora exista essa divis√£o entre as culturas, Breiman foi um estat√≠stico que desempenhou um grande trabalho para unir a √°rea de estat√≠stica com aprendizado de m√°quina. Por conta dessa grande import√¢ncia, um pr√™mio concedido em sua homenagem foi criado pela American Statistical Association.\n\nLeo Breiman trabalhando em sua resid√™ncia, em 1985."
  },
  {
    "objectID": "index.html#as-duas-culturas-4",
    "href": "index.html#as-duas-culturas-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üé≠ As duas culturas",
    "text": "üé≠ As duas culturas\n\n\n\nLeo Breiman, renomado estat√≠stico, contribuiu significativamente para o campo de aprendizagem de m√°quina. Ele √© conhecido por ter criado m√©todos populares e influentes para a √°rea. Entre tais m√©todos famosos, cito dois:\n\n\nRandom forest (florestas aleat√≥rias): m√©todo que combina a previs√£o de v√°rios modelos de √°rvores de decis√£o (decision tree), que veremos mais a frente, por isso o termo ‚Äúfloresta‚Äù para problemas de regress√£o e classifica√ß√£o;\nBootstrap aggregating (bagging): t√©cnica de aprendizagem ensemble, em que cria-se multiplos conjuntos de dados obtidos com reposi√ß√£o da amostra de treinamento. O modelo de aprendizagem de m√°quina √© treinado em cada conjunto de dados e as previs√µes de cada um dos modelos s√£o combinadas por meio da m√©dia (em problemas de regress√£o), ou por voto majorit√°rio, em problemas de classifica√ß√£o. O bagging √© utilizado para reduzir a vari√¢ncia e melhorar a estabilidade do modelo."
  },
  {
    "objectID": "index.html#regress√£o",
    "href": "index.html#regress√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o",
    "text": "Regress√£o\n\nM√©todos de regress√£o surgiram h√° mais de dois s√©culos com Legendre (1805) e Gauss (1809), que exploraram o m√©todo dos m√≠nimos quadrados com o objetivo de prever √≥rbitas ao redor do Sol. Hoje em dia, o problema de estima√ß√£o de uma fun√ß√£o de regress√£o possui papel central em estat√≠stica.\n\n\nApesar de as primeiras t√©cnicas para solucionar esse problema datarem de ao menos 200 anos, os avan√ßos computacionais recentes permitiram que novas metodologias fossem exploradas. Em particular, com a capacidade cada vez maior de armazenamento de dados, m√©todos com menos suposi√ß√µes sobre o verdadeiro estado da natureza ganham cada vez mais espa√ßo. Com isso, v√°rios desafios surgiram: por exemplo, m√©todos tradicionais n√£o s√£o capazes de lidar de forma satisfat√≥ria com bancos de dados em que h√° mais covari√°veis que observa√ß√µes, uma situa√ß√£o muito comum nos dias de hoje. Similarmente, s√£o frequentes as aplica√ß√µes em que cada observa√ß√£o consiste em uma imagem ou um documento de texto, objetos complexos que levam a an√°lises que requerem metodologias mais elaboradas. ‚Äì Izbick et al."
  },
  {
    "objectID": "index.html#regress√£o-1",
    "href": "index.html#regress√£o-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o",
    "text": "Regress√£o\n\nDe forma geral, temos que o objetivo de um modelo de regress√£o √© determinar a rela√ß√£o entre uma vari√°vel aleat√≥ria (label) Y \\in \\mathbb{R} e um vetor de covari√°veis (features) \\mathbf{x} = (x_1, \\cdots, x_d) \\in \\mathbb{R}^d. Mais especificamente, busaca-se estimar\nr(\\bf{x}) := \\mathbb{E}(Y|\\bf{X} = \\bf{x}),\nsendo esta chamada de fun√ß√£o de regress√£o. Temos que:\n\n\nSe Y √© uma vari√°vel quantitativa, ent√£o estamos sob um problema de regress√£o;\nSe Y √© uma vari√°vel qualitativa, ent√£o teremos um problema de classifica√ß√£o.\n\nEm aprendizagem de m√°quina, assumimos que n√£o temos meios de calcular r({\\bf{x}}), i.e., n√£o conhecemos a distribui√ß√£o condicional de {\\bf{Y}\\,|\\,X}. Portanto, n√£o temos meios de calcular\n\\mathbb{E}({\\bf X}|Y = y) = \\int x\\,\\mathrm{d}F_{\\bf X}({\\bf x} | Y = y)."
  },
  {
    "objectID": "index.html#nota√ß√µes",
    "href": "index.html#nota√ß√µes",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nota√ß√µes",
    "text": "Nota√ß√µes\n\nA vari√°vel Y recebe frequentemente o nome de vari√°vel resposta, vari√°vel dependente, r√≥tulo ou label. J√° as observa√ß√µes contidas no vetor \\bf{x} = (x_1, \\cdots, x_d), s√£o, em geral, denominadas de vari√°veis explicativas, vari√°veis independentes, caracter√≠sticas, atributos, preditores, covari√°veis ou features.\n\nA ideia, nessa primeira parte do curso, √© descrever algumas t√©cnicas para estimar (treinar, como √© dito em aprendizagem de m√°quina) r(\\bf{x}).\n\nA menos quando dito o contr√°rio, assumiremos que nossa amostra s√£o i.i.d. (independentes e identicamente distribu√≠das), ou seja, (\\bf{X}_1, Y_1), \\cdots, (\\bf{X}_n, Y_n) s√£o i.i.d.\n\nDenota-se por x_{i,j} o valor da j-√©sima covari√°vel na i-√©sima amostra, com j = 1, \\cdots, d e i = 1, \\cdots, n."
  },
  {
    "objectID": "index.html#nota√ß√µes-1",
    "href": "index.html#nota√ß√µes-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nota√ß√µes",
    "text": "Nota√ß√µes\n\n\nNota√ß√£o utilizada nesse material para as vari√°veis envolvidas em um problema de regress√£o.\n\n\n\n\n\n\nLabel\nFeatures\n\n\n\n\nY_1\nX_{1,1},\\cdots, X_{1,d}\\,\\,\\, (= \\bf{X}_1)\n\n\n\\vdots\n\\,\\,\\,\\vdots\\,\\,\\,\\,\\, \\ddots\\,\\,\\ \\vdots\n\n\nY_n\nX_{n,1},\\cdots, X_{n,d}\\,\\,\\, (= \\bf{X}_n)"
  },
  {
    "objectID": "index.html#regress√£o-2",
    "href": "index.html#regress√£o-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o",
    "text": "Regress√£o\nNossa ideia √© construir uma boa estimativa g da fun√ß√£o de regress√£o r(\\bf{x}) := \\mathbb{E}(Y\\,|\\,\\bf{X} = \\bf{x}), para novas observa√ß√µes, i.e., queremos obter uma fun√ß√£o g, tal que:\ng: \\mathbb{R}^d \\rightarrow \\mathbb{R},\nde tal forma que g possua um bom poder preditivo. Em aprendizagem de m√°quina, s√≥ estaremos interessados em obter uma fun√ß√£o g que estime bem um n√∫mero real (em problemas de regress√£o), ou que classifique bem (em um problema de classifica√ß√£o), utilizando as d covari√°veis. Ou seja, para m novas observa√ß√µes, desejamos obter g, que\ng({\\bf{x}}_{n + 1}) \\approx y_{n + 1}, \\cdots, g({\\bf{x}}_{n + m}) \\approx y_{n + m}."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco",
    "href": "index.html#fun√ß√£o-de-risco",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nPara que possamos construir boas fun√ß√µes de predi√ß√£o, √© preciso que tenhamos um crit√©rio para medir o desempenho de uma dada fun√ß√£o g:\\mathbb{R}^d \\rightarrow \\mathbb{R}. Em contexto de regress√£o, usaremos o risco quadr√°tico, muito embora esta n√£o √© a √∫nica op√ß√£o. Denotaremos a fun√ß√£o de risco quadr√°tico por:\nR_{pred}(g) = \\mathbb{E}\\left[({\\bf Y} - g({\\bf X}))^2\\right], em que (\\bf X, Y) s√£o observa√ß√µes novas que n√£o foram utilizadas para treinar/estimar g. L√™-se R_{pred}(g) como ‚Äúrisco preditivo de g‚Äù. Note que, como \\bf X s√£o observa√ß√µes conhecidas e g(\\cdot) √© um modelo preditivo, portanto, g √© conhecido, ent√£o, \\widehat{\\bf Y} = g(\\bf X) √© um estimador dos labels, i.e., de \\bf Y.\n\nDiremos que L(g({\\bf X}); {\\bf Y}) = ({\\bf Y} - g({\\bf X}))^2 √© a fun√ß√£o de perda quadr√°tica, as vezes chamado de perda L_2. Outra fun√ß√µes como a fun√ß√£o de perda absoluta denotada por L(g({\\bf X}); {\\bf Y}) = |{\\bf Y} - g({\\bf X})|, as vezes chamada de perda L_1 poderiam ser consideradas."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-1",
    "href": "index.html#fun√ß√£o-de-risco-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nEm linhas gerais, seja L(\\cdot) uma fun√ß√£o qualquer, tal que \\forall \\, 0 &lt; u &lt; v, de modo que:\n\n\n0 = L(0) \\leq L(u) \\leq L(v);\n0 = L(0) \\leq L(-u) \\leq L(-v).\n\n\nQualquer fun√ß√£o L(\\cdot) que satisfaz as propriedades acima √© chamada de fun√ß√£o de perda. Em especial, temos que:\n\n\nFun√ß√£o de perda quadr√°tica: L(u) = u^2;\nFun√ß√£o de perda absoluta: L(u) = |u|;\nFun√ß√£o de perda degrau: L(0) = 0, se |u| &lt; \\delta e 1 caso contr√°rio, para algum \\delta &gt; 0;"
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-2",
    "href": "index.html#fun√ß√£o-de-risco-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nNormalmente considera-se a perda L_2, uma vez que em modelos de regress√£o, minimizar R_{pred}(g), em g, equivale a encontrar r({\\bf x}) = \\mathbb{E}({\\bf X}|{\\bf Y}), i.e., equivale a estimar a fun√ß√£o de regress√£o.\n\nTeorema: Suponha que definimos o risco de uma fun√ß√£o de predi√ß√£o g: \\mathbb{R}^d \\rightarrow \\mathbb{R} via fun√ß√£o perda quadr√°tica, i.e, R_{pred}(g) = \\mathbb{E}\\left[({\\bf Y} - g({\\bf X}))^2\\right], em que \\bf (X, Y) s√£o novas observa√ß√µes que n√£o foram utilizadas para estimar g. Suponha tamb√©m que estimamos o risco de um estimador de regress√£o r({\\bf X}) via fun√ß√£o perda quadr√°tica R_{reg}(g) = \\mathbb{E}\\left[(r({\\bf X}) - g({\\bf X}))^2\\right]. Ent√£o,\nR_{pred}(g) = R_{reg}(g) + \\mathbb{E}\\left[\\mathbb{V}[{\\bf Y} | {\\bf X}]\\right],\nem que \\mathbb{E}\\left[\\mathbb{V}[{\\bf Y} | {\\bf X}]\\right] √© a vari√¢ncia m√©dia do modelo que n√£o depende de g. Portanto, estimar bem r({\\bf x}) √© de fundamental import√¢ncia para criar uma boa fun√ß√£o de predi√ß√£o. Em especial, sob a √≥tica do risco quadr√°tico, a melhor fun√ß√£o de predi√ß√£o para \\bf Y √© a fun√ß√£o de regress√£o r({\\bf x}), de tal modo que:\n\\argmin_g R_{pred}(g) = \\argmin_g R_{reg}(g) = r({\\bf x})."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-3",
    "href": "index.html#fun√ß√£o-de-risco-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nLembre-se: r({\\bf x}) = \\mathbb{E}(Y | \\bf{X} = \\bf{x}) √© a nossa fun√ß√£o de regress√£o.\n\nA defini√ß√£o de risco preditivo R_{pred}, que tamb√©m denotaremos simplesmente por R, tem um apelo frequentista. Dessa forma, para um novo conjunto com m novas observa√ß√µs, ({\\bf X}_{n+1}, Y_{n+1}), \\cdots, ({\\bf X}_{n+m}, Y_{n+m}), temos que essa nova amostra √© i.i.d. √† amostra observada (utilizada no treinamento do modelo/na estima√ß√£o). Ent√£o, pela Lei dos Grandes N√∫meros, temos que um bom estimador para a fun√ß√£o para o risco preditivo √© dado por:\n\\frac{1}{m}\\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \\approx R(g) := \\mathbb{E}\\left[(Y - g({\\bf X}))^2\\right]. \\tag{1}\nChamaremos a quantidade acima de Erro Quadr√°tico M√©dio - EQM. Em aprendizagem de m√°quina, normalmente estaremos no contexto em que temos muitas observa√ß√µes, e que portanto, poderemos fazer esse apelo frequentista.\n\nDesejamos encontrar g (encontrar m√©todos) que minimize de forma satisfat√≥ria R, i.e., m√©todos que nos conduzam √† um risco baixo."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-4",
    "href": "index.html#fun√ß√£o-de-risco-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nSendo assim, se R(g) possui um valor baixo, ent√£o, temos que\ng({\\bf x}_{n+1}) \\approx y_{n+1}, \\cdots, g({\\bf x}_{n+m}) \\approx y_{n+m}."
  },
  {
    "objectID": "index.html#regress√£o-linear",
    "href": "index.html#regress√£o-linear",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear",
    "text": "Regress√£o linear\n\nNesse momento, vamos pensar um pouco em regress√£o linear. No caso mais simples, queremos prever o comportamento de uma vari√°vel de interesse Y condicional a uma vari√°vel explicativa X (regress√£o linear simples, i.e., d = 1). O melhor preditor de Y condicional em X √© aquele que minimiza a fun√ß√£o de perda esperada, ou seja, √© aquele que resolve:\n\\argmin_g \\mathbb{E}(L(Y - g)|X).\nPara o caso da fun√ß√£o perda quadr√°tica (fun√ß√£o L_2), o melhor preditor de Y condicional √† X √© a m√©dia condicional de Y dado X, i.e., r(X) = \\mathbb{E}(Y|X). J√°, na situa√ß√£o em que considera-se a perda absoluta (fun√ß√£o L_1), o melhor estimador √© a mediana condicional.\n\nOs modelos de regress√£o, em geral, fazem uso da fun√ß√£o de perda quadr√°tica."
  },
  {
    "objectID": "index.html#regress√£o-linear-simples",
    "href": "index.html#regress√£o-linear-simples",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear simples",
    "text": "Regress√£o linear simples\n\nNo caso da regress√£o linear simples (d = 1), temos que o modelo √© dado por:\ng(x) = \\beta_0 + \\beta_1 x_{i,1} + \\varepsilon_i, \\,\\, i = 1, \\cdots, n, em que \\varepsilon_i √© um erro aleat√≥rio. Na abordagem data modeling culture, v√°rias suposi√ß√µes poderem ser feitas para \\varepsilon_i.\nAssumindo que a regress√£o linear simples √© o modelo g que iremos utilizar, ent√£o, desejamos minimizar:\n\\argmin_{\\beta} R(g_\\beta) = \\argmin_{\\beta} \\sum_{i = 1}^n(y_i - \\beta_0 - \\beta_1x_{i,1})^2. Derivando em rela√ß√£o √† \\beta e igualando a zero, ap√≥s algumas manipula√ß√µes alg√©bricas, temos que:\n\\widehat{\\beta} = \\frac{\\sum_{i = 1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n(x_i - \\overline{x})^2} = r_{xy}\\frac{s_y}{s_x}, em que s_x e s_y s√£o os desvio-padr√£o de x e y, respectivamente, e r_{xy} √© o coeficiente de correla√ß√£o da amostra, em que -1 \\leq r_{xy} \\leq 1."
  },
  {
    "objectID": "index.html#regress√£o-linear-simples-1",
    "href": "index.html#regress√£o-linear-simples-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear simples",
    "text": "Regress√£o linear simples\n\nr_{xy} = \\frac{\\overline{xy} - \\overline{x}\\,\\overline{y}}{\\sqrt{(\\overline{x^2} - \\overline{x}^2)(\\overline{y^2} - \\overline{y}^2)}}. O coeficiente de determina√ß√£o R^2 do modelo √© dado por r_{xy}^2, quando o modelo √© linear e possue uma √∫nica vari√°vel independente (feature).\n\nPortanto, temos que:\n\\widehat{\\beta_0} = \\overline{y} - \\widehat{\\beta}\\overline{x},\nNa data modeling culture (na estat√≠stica), normalmente assumimos que o \\varepsilon_i tem distribui√ß√£o normal e vari√¢ncia constante, \\forall\\, i = 1, \\cdots, n. Assume-se tamb√©m que \\mathbb{E}(\\varepsilon_i) = 0, \\, \\forall i."
  },
  {
    "objectID": "index.html#regress√£o-linear-simples-2",
    "href": "index.html#regress√£o-linear-simples-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear simples",
    "text": "Regress√£o linear simples\n\nAqui n√£o iremos nos preocupar com essas suposi√ß√µes, uma vez que em algorithmic modeling culture, n√£o estamos preocupados com suposi√ß√µes nem interpreta√ß√µes, ok!?"
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla",
    "href": "index.html#regress√£o-linear-multipla",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nA fun√ß√£o de perda quadr√°tica (fun√ß√£o L_2) tem algumas vantagens em rela√ß√£o a fun√ß√£o de perda absoluta. Listo algumas:\n\nA fun√ß√£o de perda quadr√°tica penaliza mais os erros maiores, devido ao fato dos erros serem levado ao quadrado;\nA fun√ß√£o de perda quadr√°tica √© mais sens√≠vel a presen√ßa de outlier, que em compensa√ß√£o s√£o menos penalizados ao se considerar a fun√ß√£o de perda absoluta (fun√ß√£o L_1);\nEm situa√ß√µes em que o erro tem distribui√ß√£o normal, a estimativa de m√≠nimos quadrados √© a solu√ß√£o de m√°xima verossimilhan√ßa e √© a estimativa linear n√£o viesada e com menor vari√¢ncia. Portanto, gozamos de um estimador com √≥timas propriedades, muito embora ele tamb√©m √© um bom estimador mesmo quando a suposi√ß√£o de normalidade n√£o √© verificada;\nA fun√ß√£o de perda quadr√°tica √© deferenci√°vel, j√° a fun√ß√£o de perda absoluta n√£o √©.\n\nPara o caso de regress√£o linear m√∫ltipla, i.e., quando d &gt; 1, poderemos utilizar uma nota√ß√£o matricial para representar o modelo linear m√∫ltiplo de regress√£o."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-1",
    "href": "index.html#regress√£o-linear-multipla-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nConsiderando o modelo de regress√£o linear m√∫ltiplo, temos que:\nY = g({\\bf X}) = \\beta^{T}{\\bf X} + \\varepsilon,\nem que Y √© um vetor n \\times 1, {\\bf X} √© uma matriz fixa e conhecida com os atributos de dimens√£o n \\times d, em que a primeira coluna √© preenchida de 1, \\beta = (\\beta_0, \\cdots, \\beta_d). Na cultura de machine learning, iremos desconsiderar \\varepsilon, i.e., n√£o feremos suposi√ß√µes sobre \\varepsilon. Portanto, considere\ng({\\bf x}) = \\beta^{T}{\\bf X} = \\beta_{0}x_0 + \\beta_1x_{i,1} + \\cdots + \\beta_dx_{i,d}, em que x_0 \\equiv 1."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-2",
    "href": "index.html#regress√£o-linear-multipla-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nO m√©todo dos m√≠nimos quadrados, para o caso de regress√£o linear m√∫ltipla (d &gt; 1) √© dado por aquele que minimiza R(\\beta^{T}{\\bf X}), i.e., minimiza:\n\\argmin_\\beta \\sum_{i = 1}^n (Y_i - \\beta_0 - \\beta_1x_{i,1} - \\cdots - \\beta_dx_{i,d})^2. Temos que\n\\widehat{\\beta} = ({\\bf X}^{T}{\\bf X})^{-1}{\\bf X}^{T}Y.\nPortanto, a fun√ß√£o de regress√£o estimada √© dada por:\ng({\\bf x}) = \\widehat{\\beta}^{T}{\\bf x}."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-3",
    "href": "index.html#regress√£o-linear-multipla-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nGrande parte da literatura estat√≠stica √© voltada para justificar que o m√©todo de m√≠nimos quadrados sob um ponto de vista de um estimador de m√°xima verossimilhan√ßa, assim como tamb√©m para constru√ß√£o de testes de ader√™ncia, m√©todos para constru√ß√£o de intervalos de confian√ßa e teste de hip√≥tese para \\beta_i (par√¢metros que indexam o modelo), an√°lise de res√≠duos, entre outros.\n\nAssumir que a verdadeira regress√£o r({\\bf x}) = \\mathbb{E}({\\bf X}\\,|\\,Y) √© uma suposi√ß√£o muito forte. Contudo, existe, na literatura, justificativas para o uso de m√©todos de m√≠nimos quadrados para estimar os coeficientes, mesmo quando a regress√£o real r({\\bf x}) n√£o satisfaz a suposi√ß√£o de linearidade."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-4",
    "href": "index.html#regress√£o-linear-multipla-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nO estimador de m√≠nimos quadrados \\widehat{\\beta} = ({\\bf X}^{T}{\\bf X})^{-1}{\\bf X}^{T}Y √© bom, por alguns motivos:\n\n\n√â igual ao estimador de m√°xima verossimilhan√ßa sob normalidade, linearidade e homoscedasticidade, portanto, consistente sob essas condi√ß√µes\n√â best linear unbiased prediction - BLUE sob linearidade e homoscedasticidade;\nO m√©todo de m√≠nimos quadrados tem alguma garantia, mesmo sem assumir muitas suposi√ß√µes."
  },
  {
    "objectID": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade",
    "href": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√≠nimos quadrados sem suposi√ß√£o de linearidade",
    "text": "M√≠nimos quadrados sem suposi√ß√£o de linearidade\n\nQuando a suposi√ß√£o de linearidade falha, ou seja, quando a regress√£o verdadeira que desconhecemos r({\\bf x}) n√£o √© linear, frequentemente existe um vetor \\beta_{*}, tal que g_{\\beta_{*}}({\\bf x}) = \\beta_{*}^{T}{\\bf x} tem um bom poder preditivo. Nesses casos, o m√©trodo dos m√≠nimos quadrados \\widehat{\\beta} tende a produzir estimadores com baixo risco. Isso se deve ao fato que \\widehat{\\beta} converge para o melhor preditor linear (para o or√°culo \\beta_{*}) que √© dado por:\n\\beta_{*} = \\argmin_\\beta R(g_\\beta) =  \\argmin_\\beta \\mathbb{E}\\left[(Y - \\beta^{T}X)^2\\right], mesmo que a verdadeira regress√£o r({\\bf x}) n√£o seja linear, em que ({\\bf X}, Y) √© uma nova observa√ß√£o.\n\nTeorema: Seja \\beta_{*} o melhor estimador linear e \\widehat{\\beta} o estimador de m√≠nimos quadrados. Ent√£o,\n\\widehat{\\beta}\\overset{p}{\\longrightarrow}  \\beta_{*}\\,\\, \\mathrm{e}\\,\\, R(g_{\\widehat{\\beta}})\\overset{p}{\\longrightarrow} R(g_{\\beta_{*}}),  quando n \\longrightarrow \\infty. Para uma demonstra√ß√£o, veja http://www.rizbicki.ufscar.br/AME.pdf, p√°gina. 29."
  },
  {
    "objectID": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade-1",
    "href": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√≠nimos quadrados sem suposi√ß√£o de linearidade",
    "text": "M√≠nimos quadrados sem suposi√ß√£o de linearidade\n\nEm palavras, o que o Teorema anterior diz √© que mesmo quando a regress√£o verdadeira n√£o √© linear, o estimador de m√≠nimos quadrados √© consistente para nos conduzir a um bom estimador linear, ou seja, ao menos conseguiremos o melhor estimador linear como uma aproxima√ß√£o √† r({\\bf x}) que n√£o √© linear.\n\nIsso n√£o quer dizer que voc√™ ter√° boas estimativas em todas as situa√ß√µes, muito embora o or√°culo \\beta_{*}, em muitas situa√ß√µes, ter√° bom poder preditivo. Em outras palavras, em situa√ß√µes que um problema, em sua natureza, n√£o linear, poderemos alcan√ßar boas estimativas por uma aproxima√ß√£o linear pelo m√©todo dos m√≠nimos quadrados."
  },
  {
    "objectID": "index.html#leia-mais-sobre-regress√£o-linear",
    "href": "index.html#leia-mais-sobre-regress√£o-linear",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leia mais sobre regress√£o linear",
    "text": "Leia mais sobre regress√£o linear\n\nCaso voc√™ deseje ler um pouco mais sobre regress√£o linear sob homocedasticidade e sob heteroscedasticidades, leia o segundo Cap√≠tulo de minha disserta√ß√£o de mestrado intitulada Estimadores Intervalares sob Heteroscedasticidade de Forma Desconhecida via Bootstrap Duplo. Apesar do t√≠tulo, o segundo cap√≠tulo √© uma revis√£o do conceito de regress√£o linear √© apresentado de forma did√°tica. Clique aqui para ler."
  },
  {
    "objectID": "index.html#predi√ß√£o-versus-infer√™ncia",
    "href": "index.html#predi√ß√£o-versus-infer√™ncia",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Predi√ß√£o versus Infer√™ncia",
    "text": "Predi√ß√£o versus Infer√™ncia\n\nInfer√™ncia: assume que o modelo linear √© correto. O principal objetivo consiste em interpretar os par√¢metros:\n\n\nQuais s√£o os par√¢metros significantes?\nQual o efeito do aumento da dose de um rem√©dio no paciente?\n\n\nPredi√ß√£o: queremos criar g({\\bf x}) com bom poder preditivo, mesmo que a especifica√ß√£o do modelo n√£o esteja correta. N√£o assume que a verdadeira regress√£o √© de fato linear! A interpreta√ß√£o aqui n√£o √© o foco. Tudo bem?!"
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\nCaso voc√™ n√£o queira implementar o estimador de m√≠nimos quadrados \\widehat{\\beta} = ({\\bf X}^{T}{\\bf X})^{-1}{\\bf X}^{T}Y, voc√™ poder√° utilizar a famosa fun√ß√£o lm. Na verdade √© melhor que n√£o implemente o estimador \\widehat{\\beta}, uma vez que a fun√ß√£o lm, assim como a fun√ß√£o glmnet do pacote glmnet, utilizam-se de truques num√©ricos para um c√°lculo mais eficiente.\n\nFalaremos do pacote glmnet, um pouco mais a frente, quando abordarmos regress√£o penalizada. Certo!?"
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r-1",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\nConsidere o conjunto de dados de expectativa de vida versus PIB per Capita dispon√≠veis aqui. O comportamente entre as vari√°veis LifeExpectancy e GDPercapita, se fizermos um gr√°fico, n√£o √© linear.\n\nTodavia, isso n√£o impede que possamos ajustar um modelo de regress√£o linear, muito embora o seu poder preditivo ser√° baixo.\n\nPor√©m, como j√° sabemos, ao menos conseguiremos o melhor or√°culo, denotado por \\beta_{*}, i.e., o melhor estimador dentre os poss√≠veis estimadores lineares, como mostrado em teoremas anteriores.\n\nE est√° tudo bem. Aqui n√£o estou querendo defender que voc√™ use uma aproxima√ß√£o linear para esse caso. Em breve, com um pequeno truque, poderemos ajustar uma regress√£o polinomial √† esses dados, e incorporaremos um pouco da tend√™ncia n√£o linar presente nos dados."
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r-2",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\n\n\nVeja o c√≥digo do gr√°fico\nlibrary(ggplot2)\n\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\n\n# Criando um arquivo tempor√°rio\narquivo_temp &lt;- tempfile()\n\n# Baixando um arquivo tempor√°rio\ndownload.file(url = url, destfile = arquivo_temp)\n\n# Carregando os dados\nload(arquivo_temp)\n\ndados_expectativa_renda |&gt; \n  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +\n  geom_point() +\n  labs(\n    title = \"PIB per Capita versus Expectativa de Vida\",\n    x = \"PIB per Capita\",\n    y = \"Expectativa de Vida\"\n  ) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )"
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r-3",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\nClaramente, a reta de regress√£o (linha azul) do gr√°fico anterior n√£o tem um bom poder preditivo. O ajuste foi feito diretamente usando o pacote ggplot2, utilizando a fun√ß√£o geom_smooth, em que foi escolhido o m√©todo \"lm\".\n\nPoder√≠amos ter utilizado a fun√ß√£o lm:\n\n\n\nVeja o c√≥digo do gr√°fico\nlibrary(ggplot2)\n\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\n\n# Criando um arquivo tempor√°rio\narquivo_temp &lt;- tempfile()\n\n# Baixando um arquivo tempor√°rio\ndownload.file(url = url, destfile = arquivo_temp)\n\n# Carregando os dados\nload(arquivo_temp)\n\n# Ajustando o modelo usando a fun√ß√£o lm\najuste &lt;- lm(LifeExpectancy ~ GDPercapita, data = dados_expectativa_renda)\n\nmodelo &lt;- function(x){\n  novos_dados &lt;- tibble::tibble(GDPercapita = x)\n  predict(ajuste, newdata = novos_dados)\n}\n\ndados_expectativa_renda |&gt; \n  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +\n  geom_point() +\n  labs(\n    title = \"PIB per Capita versus Expectativa de Vida\",\n    x = \"PIB per Capita\",\n    y = \"Expectativa de Vida\"\n  ) +\n  stat_function(fun = modelo, color = \"red\", size = 1.2) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )"
  },
  {
    "objectID": "index.html#matriz-esparsa",
    "href": "index.html#matriz-esparsa",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Matriz esparsa",
    "text": "Matriz esparsa\n\nPara grandes bases de dados, em um problema real que voc√™ venha trabalhar, e se o custo computacional voc√™ considera elevado, poder√° utilizar o pacote biglm.\n\nEm situa√ß√µes em que h√° muitos zeros na sua matriz, poder√° utilizar representa√ß√£o esparsa.\n\nMatrizes esparsas s√£o matrizes com muitas entradas iguais √† 0. Elas ocorrem naturalmente em diversas aplica√ß√µes, como por exemplo uma matriz de termos presentes em um documento, em que se o termo estiver no documento resebe 1, e zero, caso contr√°rio. Abaixo, {\\bf X} √© um exemplo de matriz esparsa.\n\n\n{\\bf X} =\n\\begin{bmatrix}\n1 & 0 & 0 & 0 & 0 \\\\\n0 & 2 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 3 & 0 & 0 \\\\\n0 & 0 & 0 & 4 & 0 \\\\\n\\end{bmatrix}"
  },
  {
    "objectID": "index.html#matriz-esparsa-1",
    "href": "index.html#matriz-esparsa-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Matriz esparsa",
    "text": "Matriz esparsa\n\nConsidere os textos:\n\nTexto 1: ‚ÄúEu amo essa disciplina.‚Äù\nTexto 2: ‚ÄúEu adoro meu professor.‚Äù\nTexto 3: ‚ÄúEu serei muito bom em aprendizagem de m√°quina.‚Äù\nTexto 4: ‚ÄúAdoro o departamento de estat√≠stica da UFPB.‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTextos\ndisciplina\namo\naprendizagem\nm√°quina\nestatistica\nadoro\nUFPB\n\n\n\n\nTexto 1\n1\n1\n0\n0\n0\n0\n0\n\n\nTexto 2\n0\n0\n0\n0\n0\n1\n0\n\n\nTexto 3\n0\n0\n1\n1\n0\n0\n0\n\n\nTexto 4\n0\n0\n0\n0\n1\n1\n1"
  },
  {
    "objectID": "index.html#matriz-esparsa-2",
    "href": "index.html#matriz-esparsa-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Matriz esparsa",
    "text": "Matriz esparsa\n\nA matriz com a ocorr√™ncia de determinados termos nos textos √© dada por:\n\n{\\bf X} =\n\\begin{bmatrix}\n1 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 1 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 1 \\\\\n\\end{bmatrix}\n\nA representa√ß√£o esparsa de {\\bf X}, aqui denotada por {\\bf X_*} √©:\n\n{\\bf X_*} =\n\\begin{bmatrix}\n1 & 1 & 1 \\\\\n2 & 6 & 1 \\\\\n3 & 3 & 1 \\\\\n3 & 4 & 1 \\\\\n4 & 5 & 1 \\\\\n4 & 6 & 1 \\\\\n4 & 7 & 1 \\\\\n\\end{bmatrix},\n em que as duas primeiras colunas, s√£o as linhas e colunas de {\\bf X} com valor diferente de 0. A √∫ltima coluna representa o valor."
  },
  {
    "objectID": "index.html#regress√£o-linear-com-matriz-esparsa",
    "href": "index.html#regress√£o-linear-com-matriz-esparsa",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear com matriz esparsa",
    "text": "Regress√£o linear com matriz esparsa\n\nExemplo: Ajuste de um modelo de regerss√£o linear m√∫ltiplo, em que {\\bf X} poder√° ter uma representa√ß√£o esparsa. Aqui n√£o estamos interessados em verificar qualidade de predi√ß√µes. Trata-se apenas de um exemplo de como utilizar uma representa√ß√£o esparsa para ajustar um modelo de regess√£o linear com algumas covari√°veis, em R.\n\n\n\nEstude o c√≥digo\nlibrary(glmnet)\nlibrary(Matrix)\n\n# Dados de exemplo\nx1 &lt;- c(1, 0, 2, 0, 0)\nx2 &lt;- c(0, 3, 0, 4, 0)\nx3 &lt;- c(5, 0, 6, 0, 7)\ny &lt;- c(1, 2, 3, 4, 5)\n\n# Criar data frame com as vari√°veis explicativas\ndados &lt;- data.frame(x1, x2, x3)\n\n# Converter o data frame para matriz esparsa\nX &lt;- sparse.model.matrix(~ ., data = dados)\n\n# Ajustar a regress√£o linear utilizando glmnet\nmodelo &lt;- glmnet(x = X, y = y, alpha = 0, lambda = 0)\n\n# Realizar previs√µes\npredicoes &lt;- predict(modelo, newx = X)"
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio",
    "href": "index.html#erro-quadr√°tico-m√©dio",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nComo exposto anteriormente, para avaliar o poder preditivo de uma modelo, i.e., a aprendizagem de um modelo, devemos avaliar a fun√ß√£o de risco, i.e., devemos avaliar R(g) := \\mathbb{E}\\left[L(g({\\bf X}); Y)\\right]. Em particular, considere L = L_2 (fun√ß√£o perda quadr√°tica). Ent√£o, poder√≠amos ser levados a acreditar que o melhor estimador de R(g), utilizando a Lei dos Grandes N√∫meros seria:\n\\frac{1}{n}\\sum_{i = 1}^n(Y_{i} - g({\\bf X_{i}}))^2 \\approx R(g) := \\mathbb{E}\\left[L_2(g({\\bf X}); Y)\\right].\n\nEssa quantidade √© chamada, de Erro Quadr√°tico M√©dio - EQM. Desejamos escolher o melhor mode, entre os modelos testados, que minimiza o EQM.\n\nO apelo frequentista em utilizar a Lei dos Grandes N√∫meros na forma acima n√£o √© correto, uma vez que usamos as n observa√ß√µes para treinar/ajustar o modelo g."
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio-1",
    "href": "index.html#erro-quadr√°tico-m√©dio-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nPor exemplo, no problema de PIB per Capita versus expectativa de vida, em que consideramos uma aproxima√ß√£o linear, n√£o poder√≠amos utilizar o EQM da forma acima, com as n observa√ß√µes utilizadas para treinar o modelo. √â um detalhe sutil, mas que muitas pessoas cometem esse erro.\n\nN√£o podemos utilizar as n observa√ß√µes para estimar o risco R(g) atrav√©s do EQM, uma vez que estamos utilizando o mesmo conjunto de dados para ajustar e avaliar g.\n\nQual o problema?\n\n\nN√£o vale a Lei dos Grandes N√∫meros;\nUsamos os mesmos valores de {\\bf x} e y para treinar e avaliar o modelo."
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio-2",
    "href": "index.html#erro-quadr√°tico-m√©dio-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nO que diz a Lei dos Grandes N√∫meros, em particular, a Lei Forte de Kolmogorov?\n\nTeorema (Lei Forte de Kolmogorov): Sejam X_1, \\cdots, X_n uma sequ√™ncia de veri√°veis aleat√≥rias - v.a. i.i.d. e integr√°veis, i.e., com valor esperado limitado, tal que \\mathbb{E}(X) = \\mu\\,\\, \\forall i. Ent√£o,\n\\frac{X_1 + X_2 + \\cdots + X_n}{n} \\rightarrow \\mu,\nquase certamente, i.e., com probabilidade 1.\n\nNote que se desejamos comparar diversos modelos, g_1({\\bf x}), g_2({\\bf x}), \\cdots, e se utilizarmos as mesmas n oberva√ß√µes para calularmos R(g_1({\\bf x})), R(g_2({\\bf x})), \\cdots, os termos de cada uma das somas n√£o s√£o independentes. Lembre-se que desejamos obter \\argmin_g R_{pred}(g)."
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio-3",
    "href": "index.html#erro-quadr√°tico-m√©dio-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nPortanto, nunca utilize as mesmas observa√ß√µes utilizadas para treinar o modelo, como aquelas que ser√£o utilizadas para se estimar R(g). Nunca! Isso √© um pecado mortal! Ok?!"
  },
  {
    "objectID": "index.html#data-splitting",
    "href": "index.html#data-splitting",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nCorrigir o problema de depend√™ncia que h√° ao estimarmos o risco usando o EQM √© f√°cil. Uma abordagem muito utilizada √© utilizar data splitting, tamb√©m chamado de m√©todo hold-out. Algo como a segunda linha da imagem abaixo:"
  },
  {
    "objectID": "index.html#data-splitting-1",
    "href": "index.html#data-splitting-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nEssa divis√£o √© feita de forma aleat√≥ria, algumas vezes estratificada de acordo com algumas vari√°v√°veis. A ideia de aleatorizar √© se livrar de problemas de conjunto de dados ordenados. Queremos que tanto no conjunto de treinamento Training quanto no conjunto Testing, na imagem, contenham a mesma diversidade de observa√ß√µes.\n\nAinda no exemplo de PIB per Capita versus Expectaitiva de Vida, n√£o quero correr o risco de ter no conjunto de treinamento apenas o pa√≠ses com maiores valores de PIB per Capita, caso o conjunto de dados tenha sido ordenado pela vari√°vel GDPercapita. Por isso, aleatorizar o conjunto de treinamento e teste √© sempre uma √≥tima ideia. Certo!?"
  },
  {
    "objectID": "index.html#data-splitting-2",
    "href": "index.html#data-splitting-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nO percentual de divis√£o dos dados normalmente √© emp√≠rico. Usa-se normalmente a propor√ß√£o de 70\\% para treinamento e 30\\% para teste (70\\%, 30\\%). Outros esquemas de divis√µes s√£o bastante utilizados, por exemplo, (80\\%, 20\\%), (99\\%, 1\\%), a depender da quantidade de observa√ß√µes (tamanho do conjunto de dados).\n\nPortanto, utilizar o EQM sob o conjunto de dados de teste para avaliar g_1({\\bf x}), g_2({\\bf x}), \\cdots,, √© uma boa estrat√©gia, uma vez que agora n√£o teremos mais uma depend√™ncia no numerador do c√°lculo do EQM. Em nota√ß√£o matem√°tica, poder√≠amos escrever como j√° apresentado anteriormente, em Equa√ß√£o¬†1, i.e.,\n\\frac{1}{m}\\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \\approx R(g) := \\mathbb{E}\\left[(Y - g({\\bf X}))^2\\right].\n\nEsse resultado valeria para qualquer outra fun√ß√£o de perda."
  },
  {
    "objectID": "index.html#data-splitting-3",
    "href": "index.html#data-splitting-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\nReescrevendo, suponha que o conjunto de dados total possua n observa√ß√µes e que separamos aleatoriamente s &lt; n observa√ß√µes para o conjunto de treinamento. Assim, temos, algo como:\n\n\\overbrace{(X_1, Y_1), (X_2, Y_2), \\cdots, (X_s, Y_s)}^{70\\%}, \\,\\,\\, \\overbrace{(X_{s + 1}, Y_{s + 1}), (X_{s + 2}, Y_{s + 2}), \\cdots, (X_n, Y_n)}^{30\\%}.\n\nEnt√£o, temos que uma boa estimativa de R(g) √© dada pelo EQM calculado sobre o conjunto de dados de teste, que nesse caso considerei o conjunto com 30\\%, mas esse percentual poderia ser outro. Ent√£o, temos que um bom estimador √©:\n\\frac{1}{n - s}\\sum_{i = s + 1}^n (Y_{i} - g(X_{i}))^2 \\approx R(g) := \\mathbb{E}\\left[(Y - g({\\bf X}))^2\\right]."
  },
  {
    "objectID": "index.html#data-splitting-4",
    "href": "index.html#data-splitting-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nAgora voc√™ entende por que dividimos os dados em treinamento e teste?\n\n\n\nDividimos para obermos um bom estimador do risco utilizando o EQM. üéÅ"
  },
  {
    "objectID": "index.html#data-splitting-5",
    "href": "index.html#data-splitting-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nPodemos argumentar que o procedimento de data splitting, em que dividimos o nosso conjunto de dados em treinamento e teste far√° com que venhamos perder muitas observa√ß√µes que poderiam ter sido utilizadas para treinar o modelo. E de certa forma isso √© verdade, principalmente quando termos um conjunto n√£o muito grande de observa√ß√µes.\n\nPortanto, uma melhor abordagem, sendo esta uma varia√ß√£o do m√©todo de data splitting √© o procedimento de cross-validation - cv (valida√ß√£o cruzada). Uma vers√£o mais geral de uma valida√ß√£o cruzada √© o leave-one-out cross-validation.\n\nEm palavras, o procedimento consiste em tirar de fora uma √∫nica observa√ß√£o das n observa√ß√µes da base de dados para ser o nosso conjunto de teste e treinar o modelo com as observa√ß√µes que permaneceram. Da√≠, calcula-se o risco observado (EQM, sob o conjunto de teste/valida√ß√£o). Na segunda itera√ß√£o, a observa√ß√£o que antes era de teste volta para perterncer ao conjunto de treinamento e uma nova observa√ß√£o √© removida para ser teste. Esse procedimento ocorre de forma iterativa at√© a retirada da √∫ltima observa√ß√£o como teste."
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation",
    "href": "index.html#leave-one-out-cross-validation",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nObserve a anima√ß√£o abaixo que ilustra o procedimento de leave-one-out cross-validation - LOOCV, em uma amostra de tamanho n = 8. Ao fim, teremos n modelos ajustados, em que calculamos as suas respectivas performances, i.e., com o risco observado, estimamos o risco de R(g)."
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation-1",
    "href": "index.html#leave-one-out-cross-validation-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nVejo muitas pessoas que usam uma valida√ß√£o cruzada, por exemplo, leave-one-out cross-validation - LOOCV comparando com o m√©todo Jackknife e algumas inclusive dizendo ser a mesma coisa. N√£o, n√£o s√£o!\n\nO algoritmo Jackknife √© um procedimento de estima√ß√£o, e que, por sua vez, deve estar dentro do conjunto de treinamento. Para haver algum Jackknife, a estimativa com n-1 observa√ß√µes deve estar dentro do conjunto de treinamento, em que dentro do treinamento teria a remo√ß√£o de um observa√ß√£o por vez. Consegue perceber a diferen√ßa sutil?"
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation-2",
    "href": "index.html#leave-one-out-cross-validation-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nO m√©todo LOOCV foi proposto por Stones (1974), no artigo intitulado Cross-Validatory Choice and Assessment of Statistical Predictions, no Royal Statistical Society, S√©rie B. Clique aqui se tiver curiosidade em ler o artigo.\n\nEscrevendo o estimador do risco em um procedimento de LOOCV, temos que:\n\\widehat{R}(g) = \\frac{1}{n}\\sum_{i = 1}^n (Y_i - g_{-i}({\\bf X}_i))^2, em que g_{-i}(\\bf{X}_i), representa o ajuste do modelo no conjunto de dados sem a i-√©sima observa√ß√£o.\n\nN√£o √© dif√≠cil perceber que a depender do valor de n, o m√©todo LOOCV √© computacionalmente intensivo. O m√©todo requer que ajustemos n modelos. Em algumas situa√ß√µes isso n√£o √© um grande problema, por√©m, em diversas outras pode ser impeditivo utilizar o LOOCV. ü§Ø"
  },
  {
    "objectID": "index.html#k-fold-cross-validation",
    "href": "index.html#k-fold-cross-validation",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\nUma alternativa ao LOOCV √© utilizar o m√©todo k-fold cross-validation. Nessa abordagem, dividimos o conjunto de dados em k-folds (lotes) disjuntos e com aproximadamente o mesmo tamanho. Dessa forma, temos L_1, \\cdots, L_k \\subset \\{1, \\cdots, n\\} s√£o, cada um, um conjunto de √≠ndices aleat√≥rios associados a cada um dos lotes. A ideia aqui √© construir k estimadores da fun√ß√£o de regress√£o, denotados por \\widehat{g}_{-1}, \\cdots, \\widehat{g}_{-k}, em que \\widehat{g}_{-j} √© criado usando todas as observa√ß√µes do banco de dados, com exce√ß√£o daquelas do lote L_j, utilizado para valida√ß√£o. O estimador do risco √© dado por:\n\\widehat{R}(g) = \\frac{1}{n}\\sum_{j=1}^k \\sum_{i \\in L_j}(Y_i - g_{-j}({\\bf X}_i))^2. Perceba que, que o LOOCV √© um caso particular do k-fold cross-validation, quando fazemos k = n. Em outras palavras, L_1, \\cdots, L_k \\subset \\{1, \\cdots, n\\} representam os √≠ndices aleat√≥rios do conjunto de treinamento nos k lotes."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-1",
    "href": "index.html#k-fold-cross-validation-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\nA anima√ß√£o abaixo, ilustra o procedimento de 3-fold cross-validation (k = 3), para uma amostra de tamanho n = 12 observa√ß√µes. Note que os valores que pertencem a cada um dos lotes s√£o aleat√≥rios. Portanto, o procedimento LOOCV √© deterministico, j√° o procedimento de k-fold cross-validation √© randomizado.\n\n\nPerceba que teremos agora apenas 3 modelos. Para cada um desses lotes, calulamos o EQM com o conjunto de teste (parte azul) e treinamos o modelo com o conjunto de treinamento (parte vermelha)."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-2",
    "href": "index.html#k-fold-cross-validation-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\nMuitos modelos mais sofisticados apresentam hiperpar√¢metros (par√¢metros de sintoniza√ß√£o) que n√£o dependem dos dados. √â muito comum os algoritmos de aprendizagem de m√°quina se utilizarem do procedimento de valida√ß√£o cruzada, para al√©m da estima√ß√£o do risco R(g) no conjunto de valida√ß√£o.\n\nAo estimar k modelos, normalmente faz-se um grid de poss√≠veis valores para esses hiperpar√¢metros em que ao final, escolhe-se como hiperpar√¢metro o modelo com menor EQM. Por fim, ajusta-se um modelo final, com todo o conjunto de treinamento usando o valor do hiperpar√¢metro que retornou o menor EQM no conjunto de valida√ß√£o.\n\nAlias, utilizamos um procedimento de valida√ß√£o para selecionar a melhor combina√ß√£o de hiperpar√¢metros e √© ser√° risco preditivo observado sob o conjunto de teste que realmente ir√° nos fornecer uma estimativa v√°lida do risco preditivo R(g)."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-3",
    "href": "index.html#k-fold-cross-validation-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\n\n\nO termo valida√ß√£o refere-se √† parcela do conjunto de treinamento incial que dividimos em valida√ß√£o e treinamento, dentro de uma valida√ß√£o cruzada.\n\nO conjunto Testing na segunda hierarquia da √°rvore ao lado, s√≥ usamos no final para avaliar o desempenho do modelo nesse conjunto. Isto √©, usamos o Testing para o c√°lculo do risco observado.\n\nPerceba que o conjunto de treinamento (Not Testing) √© particionado em treinamento e valida√ß√£o. Poder√≠amos fazer uma √∫nica parti√ß√£o, mas o procedimento comumente utilizado √© particionar entre Training e Validation uzando algum procedimento de valida√ß√£o cruzada."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-4",
    "href": "index.html#k-fold-cross-validation-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\nEm alguns livros o conjunto de treinamento √© denominado de not-testing (n√£o-teste). Isso, porqu√™ eles querem enfatizar o fato de que o conjunto not-testing √© utilizado para treinar/ensinar o modelo e jamais dever√° ser utilizado para avaliar o risco preditivo R(g).\n\nAo usar essa terminologia, os autores dos livros tentam enfatizar que o conjunto de treinamento √© usado exclusivamente para ensinar o modelo a aprender os padr√µes nos dados, enquanto o conjunto de teste √© usado para medir qu√£o bem o modelo generaliza esses padr√µes para dados n√£o vistos anteriormente."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n\n\n\n\nO simples procedimento de dividir o conjunto de dados em dois, uma parte para treinar o modelo e a outra parte (conjunto de teste) para estimar o risco R(g) √© denominado de data splitting ou hold-out method. √â um procedimento mais simples, por√©m, pode n√£o ser √∫til em conjunto de dados n√£o muito grandes.\nA segunda linha da ilustra√ß√£o, demonstra o procedimento de cross-validation (valida√ß√£o cruzada), procedimento mais utilizado nos treinamentos de modelos de aprendizagem de m√°quina.\nA terceira linha √© uma abordagem tamb√©m utilizada, por√©m n√£o t√£o interessante quanto a valida√ß√£o cruzada. Nessa abordagem o banco de dados √© dividido aleatoriamente em tr√™s partes. Treina-se o modelo com a parte verde, estima-se o risco com o conjunto de valida√ß√£o amarelo e testa-se o modelo com o conjunto de teste."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-1",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n A abordagem do conjunto de valida√ß√£o envolve dividir o conjunto de treinamento em duas partes: uma parte √© usada para treinar o modelo e a outra parte √© usada para avaliar o desempenho do modelo para uma dada combina√ß√£o. de hiperpar√¢metros. O conjunto de valida√ß√£o √© utilizado para avaliar os hiperpar√¢metros do modelo, como a taxa de aprendizado, o n√∫mero de camadas ocultas em uma rede neural, entre outros. Ap√≥s o ajuste dos hiperpar√¢metros, o modelo final √© treinado com o conjunto de treinamento completo e avaliado em um conjunto separado chamado conjunto de teste. Essa abordagem √© conhecida como divis√£o simples de treinamento/valida√ß√£o/teste.\n\nPor outro lado, a valida√ß√£o cruzada k-fold √© uma abordagem que visa obter uma estimativa mais robusta do desempenho do modelo. Nessa abordagem, o conjunto de treinamento √© dividido em k subconjuntos (folds) de tamanho aproximadamente igual. O modelo √© treinado k vezes, cada vez usando k-1 folds como conjunto de treinamento e 1 fold como conjunto de valida√ß√£o. O desempenho do modelo √© ent√£o calculado como a m√©dia dos resultados obtidos em cada itera√ß√£o. Isso permite avaliar o modelo, em diferentes combina√ß√µes dos hiperpar√¢metros, de forma mais precisa, pois utiliza todos os dados para treinamento e valida√ß√£o, evitando a depend√™ncia de uma √∫nica divis√£o do conjunto de treinamento."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-2",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n\nA valida√ß√£o cruzada k-fold √© particularmente √∫til quando o conjunto de dados √© limitado, pois aproveita ao m√°ximo os dados dispon√≠veis. Al√©m disso, ela permite verificar se o modelo √© est√°vel e se seu desempenho varia significativamente com diferentes divis√µes dos dados. √â importante ressaltar que a valida√ß√£o cruzada k-fold pode ser computacionalmente mais cara do que a abordagem do conjunto de valida√ß√£o, uma vez que envolve treinar e avaliar o modelo v√°rias vezes."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-3",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n\nUm outro detalhe que muitas vezes n√£o √© falado √© que apesar de temos duas tarefas de estima√ß√£o, uma envolvendo o conjunto de treinamento, em que treinamos o modelo e outra envolvendo o conjunto de teste, em que queremos estimar o risco R(g), de modo a poder selecionar o melhor modelo, a segunda tarefa √© bem mais f√°cil. √â por isso que o conjunto de treinamento tende a ser menor que o conjunto de teste."
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia",
    "text": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia\n\nA ideia de precis√£o e exatid√£o est√£o ligadas ao vi√©s e vari√¢ncia do modelo g, em que precis√£o est√° ligado a ideia de vari√¢ncia pequena e exatid√£o est√° ligada a ideia de baixo vi√©s. A ideia √© termos um estimador pr√≥ximo o que ilustra o item d. Muitas vezes temos um estimador nas situa√ß√µes b e c. O ideal √© o balan√ßo de vi√©s e vari√¢ncia, que seria o estimador ilustrado pelo item d."
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-1",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia",
    "text": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia\n\nUm grande apelo para o uso do risco quadr√°tico, i.e., risco que utiliza a fun√ß√£o de perda L_2 √© sua interpretabilidade. Temos que o risco quadr√°tico R(g) condicional a um novo {\\bf x} poder√° ser decomposto por:\n\\mathbb{E}\\left[(Y - \\widehat{g}({\\bf X}))^2| {\\bf X} = {\\bf x}\\right] = \\underbrace{\\mathbb{V}[Y | {\\bf X = x}]}_{\\mathrm{i - Vari√¢ncia\\,\\, intr√≠nseca}} + \\overbrace{(r({\\bf x}) - \\mathbb{E}[\\widehat{g}({\\bf x})])^2}^{\\mathrm{ii - Vi√©s\\, ao\\, quadrado\\, do\\, modelo}} + \\underbrace{\\mathbb{V}[\\widehat{g}({\\bf x})]}_{\\mathrm{iii - Vari√¢ncia\\, do\\, modelo}}. \\tag{2} Temos que:\n\ni - √â a vari√¢ncia intr√≠nseca da vair√°vel resposta (label), que n√£o depende da fun√ß√£o \\widehat{g} escolhida e, assim, n√£o poder√° ser reduzida. Na verdade, poderemos reduzir i, se incluirmos mais features (covari√°veis/vari√°veis explicativas) ao nosso modelo;\nii - √â o vi√©s ao quadrado do estimador \\widehat{g} (vi√©s ao quadrado do modelo);\niii - √â a vari√¢ncia do estimador \\widehat{g}."
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-2",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia",
    "text": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia\n\nAssim, lembre-se que uma escolha adequada de \\widehat{g} nos garante que conseguiremos reduzir o risco preditivo R(g), pois a escolha apropriada implica em escolhermos um estimador de \\widehat{g} com balan√ßo entre v√≠es e vari√¢ncia.\n\nModelos com muitos par√¢metros possuem vi√©s relativamente baixo, por√©m, tendem a ter vari√¢ncia muito alta, em geral, uma vez que precisamos estimar muitos par√¢metros. J√° modelos com poucos par√¢metros, normalmente tendem a ter vari√¢ncia baixa, acompanhados normalmente de um alto vi√©s.\n\nGeralmente, modelos com muitos par√¢metros nos levam a termos overffiting (super-ajuste), o que n√£o √© bom pois s√£o acompanhados de alta vari√¢ncia. J√° modelos muito simplistas nos conduzem √† um ajuste muito ruim (underffiting ou sub-ajuste). Entendeu!?"
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-3",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia",
    "text": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia\n\n\n\nEstude o c√≥digo\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Fun√ß√£o de regress√£o verdadeira. Na pr√°tica √© desconhecida.\nregressao_verdadeira &lt;- function(x)\n  45 * tanh(x/1.9 - 7) + 57\n\nobservacoes_regressao_real &lt;- function(n, desvio_padrao = 0.2) {\n  # Permitindo que o mesmo x possa ter dois pontos de y, como ocorre na \n  # pratica\n  seq_x &lt;- sample(seq(0, 17.5, length.out = n), size = n, replace = TRUE)\n  \n  step &lt;- function(x)\n    regressao_verdadeira(x) + rnorm(n = 1L, mean = 0, sd = desvio_padrao)\n  \n  tibble::tibble(y = purrr::map_vec(.x = seq_x, .f = step), x = seq_x)\n}\n\n# Usaremos uma regress√£o polinomial para tentar ajustar √† regress√£o -------\nregressao_polinomial &lt;- function(n = 30L, desvio_padrao = 4, grau = 1L) {\n  \n  dados &lt;- observacoes_regressao_real(n = n, desvio_padrao = desvio_padrao)\n    \n  iteracoes &lt;- function(tibble_data, grau) {\n      x &lt;- tibble_data$x\n      iteracoes &lt;- lapply(X = 2L:grau, FUN = function(i) x^i)\n      \n      result &lt;- cbind(tibble_data, do.call(cbind, iteracoes))\n      colnames(result)[(ncol(tibble_data) + 1):ncol(result)] &lt;- paste0(\"x\", 2L:grau)\n      \n      as_tibble(result)\n  }  \n  \n  if(grau &gt;= 2L)\n    dados &lt;- iteracoes(dados, grau = grau)\n  \n  ajuste &lt;- lm(formula = y ~ ., data = dados)\n  dados$y_chapeu &lt;- predict(ajuste, new.data = dados)\n  \n  dados |&gt; \n    dplyr::relocate(y_chapeu, .before = x)\n}\n\nplotando &lt;- function(dados){\n  dados |&gt;  \n    ggplot(aes(x = x, y = y_chapeu)) +\n    geom_point()\n}\n\nmc_ajustes &lt;- function(mc = 100L, n = 50L, desvio_padrao = 5, grau = 1L){\n\n  p &lt;- \n    ggplot(data = NULL) +\n      coord_cartesian(xlim = c(0, 17.5), ylim = c(0, 110)) +      \n      ylab(\"Valores estimados\")\n  \n  df &lt;- NULL\n  for(i in 1L:mc){\n    df &lt;- regressao_polinomial(n = n, desvio_padrao = desvio_padrao, grau = grau)\n    p &lt;- p + geom_line(data = df, aes(x = x, y = y_chapeu))\n  }\n  p + \n    stat_function(fun = regressao_verdadeira, col = \"red\", size= 1.4) +\n    labs(\n      title = \"Regress√£o Polinomial\",\n      subtitle = paste(\"Grau: \", grau)\n    ) +\n    theme(\n      plot.title = element_text(face = \"bold\"),\n      axis.title = element_text(face = \"bold\")\n    )\n}\n\n# Fixando uma semente\nset.seed(0)\n\np1 &lt;- mc_ajustes(grau = 1, n = 100, desvio_padrao = 10)\np2 &lt;- mc_ajustes(grau = 7, n = 100, desvio_padrao = 10)\np3 &lt;- mc_ajustes(grau = 70, n = 100, desvio_padrao = 10)\np4 &lt;- mc_ajustes(grau = 200, n = 100, desvio_padrao = 10)\n\np &lt;- ((p1 | p2) / (p3 | p4)) + plot_annotation(tag_levels = \"A\")\n\nggsave(p, file = \"imgs/vies_variancia.png\", device = \"png\", width = 40, height = 30, units = \"cm\")"
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-4",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia",
    "text": "‚öñÔ∏è Balan√ßo vi√©s e vari√¢ncia\n\nExperimente de forma interativa altera a complefixade do modelo.\n\n \n\nPara ampliar a aplica√ß√£o, clique aqui."
  },
  {
    "objectID": "index.html#tuning-parameters",
    "href": "index.html#tuning-parameters",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üéõ Tuning Parameters",
    "text": "üéõ Tuning Parameters\n\nNo exemplo anterior, note que os par√¢metros dos modelos s√£o os coeficientes \\beta‚Äôs que indexam a regress√£o polinomial. Por√©m, perceba que √° um par√¢metro de sintoniza√ß√£o (tuning parameter) que √© o valor de p, isto √©, qual o grau do polin√¥mio que iremos utilizar.\n\nNormalmente a escolha √© feita realizando um grid search por meio de um cross-validation.\n\nNo exemplo anterior, fizemos uma simula√ß√£o e observamos que ao considerar graus nem muito grandes nem muito pequenos, aparentemente teremos escolhas razo√°veis."
  },
  {
    "objectID": "index.html#tuning-parameters-1",
    "href": "index.html#tuning-parameters-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üéõ Tuning Parameters",
    "text": "üéõ Tuning Parameters\n\nExemplo: Consedere os dados de expectativa de vida versus PIB per Capita, dispon√≠veis aqui. Selecione o melhor estimador g da classe \\mathbb{G}, em que\n\\mathbb{G} = \\left\\{g(x)\\,\\,:\\,\\, \\beta_0 + \\sum_{i = 1}^p \\beta_i x^i\\,\\, \\text{para } p \\in \\{1, 2, \\cdots,11\\} \\right\\}. Note que selecionar o melhor polin√¥mio √© uma busca em p. Devemos utilizar o erro quadr√°tico m√©dio - EQM sob o conjunto de valida√ß√£o, uma vez que sabemos que apenas em um conjunto de valida√ß√£o ou em novas observa√ß√µes o estimador do risco pelo EQM √© consistente, pela Lei dos Grandes N√∫meros.\n\nVamos utilizar a biblioteca rsample para a tarefa de valida√ß√£o cruzada. Leia a documenta√ß√£o da biblioteca, em especial, a da fun√ß√£o vfold_cv, respons√°vel por construir a valida√ß√£o cruzada. Na verdade ela faz a divis√£o da base de dados em v splits de tamanho aproximadamente iguais. Por padr√£o, v = 10. Esse √© o procedimento de k-fold cross-validation que apresentamos aqui, em que v = k."
  },
  {
    "objectID": "index.html#tuning-parameters-2",
    "href": "index.html#tuning-parameters-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üéõ Tuning Parameters",
    "text": "üéõ Tuning Parameters\n\nAlgumas observa√ß√µes gerais a respetio da biblioteca rsample, que s√£o √∫teis para resolver esse problema:\n\n\nPara realizar uma primeira divis√£o do conjunto de dados (data splitting/hold-out), utiliza-se a fun√ß√£o initial_split;\nPara acessar o conjunto de treinamento dos dados, usamos a fun√ß√£o training;\nPara acessar o conjunto de teste, usamos a fun√ß√£o testing;\nPara constuir todas as divis√µes da valida√ß√£o cruzada, entre treinamento e valida√ß√£o, no conjunto de treinamento inicial, usamos a fun√ß√£o vfold_cv j√° mencionada;\nPara acessar o conjunto de treinamento de um split da valida√ß√£o cruzada, usamos a fun√ß√£o analysis;\nPara acessar o conjunto de valida√ß√£o, utilizamos a fun√ß√£o assessment."
  },
  {
    "objectID": "index.html#tuning-parameters-3",
    "href": "index.html#tuning-parameters-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üéõ Tuning Parameters",
    "text": "üéõ Tuning Parameters\n\n Note que realizar uma valida√ß√£o cruzada √© importante para podemos selecionar o melhor polin√¥mio, i.e., o melhor valor de p. Caso venhamos negligenciar esse aspecto da an√°lise, iremos cair na fal√°cia de acreditarmos que quanto maior o grau do polin√¥mio, maior ser√° o poder preditivo do modelo. Isso n√£o √© verdade e voc√™ dever√° selecionar o melhor modelo dentro de um esquema de valida√ß√£o cruzada.\n\nNo mundo de aprendizagem de m√°quina, muitos chamam o processo de encontrar o melhor hiperpar√¢metro de ‚Äútunagem‚Äù. Em v√°rios modelos, podemos ter mais de um."
  },
  {
    "objectID": "index.html#tuning-parameters-4",
    "href": "index.html#tuning-parameters-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üéõ Tuning Parameters",
    "text": "üéõ Tuning Parameters\n\nAs Figuras abaixo, mostram a avalia√ß√£o dos polin√¥mios da classe \\mathbb{G}, usando o risco estimado \\widehat{R}(g) pelo erro quadr√°tico m√©dio - EQM. Por√©m, a Figura A aprenseta a avalia√ß√£o dos modelos, usando simplesmente o conjunto de treinamento e a Figura B aprensenta a avalia√ß√£o do grau do polin√¥mio considerando uma valida√ß√£o cruzada dentro do conjunto de treinamento.\n \n\nA mensagem equivocada passada pela Figura A √© que supostamente aumentar a complexidade do modelo seria uma uma boa alternativa e nos conduzir√≠amos √† bons modelos preditivos. Mas sempre se lembre do equil√≠brio que temos que ter entre vi√©s e vari√¢ncia. A Figura B mostra que um polin√¥mio com grau pr√≥ximo √† p = 8 √© a melhor alternativa."
  },
  {
    "objectID": "index.html#tuning-parameters-5",
    "href": "index.html#tuning-parameters-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üéõ Tuning Parameters",
    "text": "üéõ Tuning Parameters\n\nObserve o dashboard interativo! Sabemos que para que tenhamos uma boa estimativa do risco preditivo, devemos utilizar novas observa√ß√µes. No dashboard, √© poss√≠vel observar que a forma errada (usando o conjunto de treinamento para avaliar o risco), sugere que sempre ser√° bom adicionar mais par√¢metros ao modelo, levando a overfitting. Perceba que usando a forma correta (usando valida√ß√£o cruzada), o EQM (risco estimado) sugere que n√£o podemos aumentar muito a quantidade de par√¢metros."
  },
  {
    "objectID": "index.html#tuning-parameters-6",
    "href": "index.html#tuning-parameters-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üéõ Tuning Parameters",
    "text": "üéõ Tuning Parameters\n\nAbaixo voc√™ poder√° acessar o c√≥digo que soluciona o problema. O par√¢metro errado = FALSE da fun√ß√£o valida√ß√£o no c√≥digo que segue, conduz a solu√ß√£o correta (usando a valida√ß√£o cruzada), que sempre voc√™ dever√° considerar na pr√°tica.\n\n\n\nEstude o c√≥digo da solu√ß√£o de exemplo\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Lendo dados\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados &lt;- \n  dados_expectativa_renda |&gt; \n  dplyr::select(-CountryName) |&gt; \n  dplyr::rename(y = LifeExpectancy, x = GDPercapita)\n  \niteracoes &lt;- function(tibble_data, grau) {\n  x &lt;- tibble_data$x\n  iteracoes &lt;- lapply(X = 2L:grau, FUN = function(i) x^i)\n  \n  result &lt;- cbind(tibble_data, do.call(cbind, iteracoes))\n  colnames(result)[(ncol(tibble_data) + 1):ncol(result)] &lt;- paste0(\"x\", 2L:grau)\n  \n  as_tibble(result)\n}  \n\nregressao_polinomial &lt;- function(dados, grau = 1L) {\n  if(grau &gt;= 2L)\n    dados &lt;- iteracoes(dados, grau = grau)\n  \n  lm(formula = y ~ ., data = dados)\n}\n\n# Divis√£o dos dados\ndivisao_inicial &lt;- rsample::initial_split(dados)\ntreinamento &lt;- rsample::training(divisao_inicial)\nteste &lt;- rsample::testing(divisao_inicial) # Teste final\n\n# v-folds cross-validation\nvalidacao &lt;- function(dados, grau = 1L, errado = FALSE, ...){\n  \n  # Todas as divis√µes da validacao cruzada\n  cv &lt;- rsample::vfold_cv(dados, ...)\n  \n  hiper &lt;- function(i){\n    treino &lt;- rsample::analysis(cv$splits[[i]]) # Treinamento\n    validacao &lt;- rsample::assessment(cv$splits[[i]]) # Validaca√ß√£o\n    ajuste &lt;- regressao_polinomial(dados = treino, grau = grau)\n    \n    if(errado){\n      df_treino &lt;- iteracoes(treino, grau = grau)\n      df_treino &lt;- df_treino |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_treino))\n      yardstick::rmse(data = df_treino, truth = y, estimate = y_chapeu)$.estimate\n    } else {\n      df_validacao &lt;- iteracoes(validacao, grau = grau)\n      df_validacao &lt;- df_validacao |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_validacao))\n      yardstick::rmse(data = df_validacao, truth = y, estimate = y_chapeu)$.estimate\n    }\n  }\n  purrr::map_dbl(.x = seq_along(cv$splits), .f = hiper) |&gt; \n    mean()\n}\n\nplot_avaliacao &lt;- function(dados, errado = FALSE){\n  # Testando iterativamente, v√°rios valores de p:\n  p &lt;- seq(1L:11L)\n  risco &lt;- purrr::map_dbl(.x = p, .f = \\(p) validacao(dados = dados, grau = p, errado = errado))\n  df_risco &lt;- tibble::tibble(p = p, risco = risco)\n  \n  # Plotando\n  df_risco |&gt; \n    ggplot(aes(x = p, y = risco, color = risco)) +\n    geom_point(size = 5) +\n    scale_x_continuous(breaks = p) +\n    scale_y_continuous(breaks = p) +\n    labs(\n      title = \"Valiando o risco estimado para diversos graus do polin√¥mio\",\n      subtitle = \"EQM no conjunto de valida√ß√£o\"\n    ) +\n    theme(\n      plot.title = element_text(size = 18, face = \"bold\"),\n      plot.subtitle = element_text(size = 16),\n      axis.text = element_text(size = 10), \n      axis.title = element_text(size = 14, face = \"bold\")\n    )\n}\n\n# Avaliac√£o errada versus correta\nset.seed(0)\ngrafico &lt;- \n  plot_avaliacao(dados, errado = TRUE) + \n  plot_avaliacao(dados, errado = FALSE) +\n  plot_annotation(tag_levels = c(\"A\", \"B\"))\n\nggsave(grafico, file = \"imgs/avaliacao_risco.png\", device = \"png\", width = 50, height = 20, units = \"cm\", limitsize = F)\n\nplot_bar &lt;- function(grau){\n  ruim &lt;- validacao(dados, errado = TRUE, grau = grau)\n  bom &lt;- validacao(dados, errado = FALSE, grau = grau)\n  df &lt;- tibble::tibble(x = c(\"Errado\", \"Certo\"), y = c(log(ruim), log(bom)))\n  \n  df |&gt; \n    ggplot(aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = y), vjust = 0)\n}"
  },
  {
    "objectID": "index.html#exerc√≠cios",
    "href": "index.html#exerc√≠cios",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Explique resumidamente o que √© aprendizagem supervisionada e n√£o-supervisionada. Cite um problema de aprendizagem supervisionada e um outro de aprendizagem n√£o-supervisionada.\n\nExerc√≠cio: Considere o conjunto de dados de Expectativa de vida versus PIB per Capita, dispon√≠vel aqui. Considere a fun√ß√£o g, da seguinte forma:\ng(x) = \\beta_0 + \\sum_{i = 1}^p \\beta_i x^i, com p \\in \\{1, 2, ..., 50\\}. Utilizando o erro quadr√°tico m√©dio observado, sem fazer nenhuma estrat√©gia de divis√£o dos dados, implemente um c√≥digo em R para checar qual o melhor modelo.\n\nExerc√≠cio: Explique qual o motivo que faz com que o Erro Quadr√°tico M√©dio - EQM para avaliar o desempenho de um modelo √© ruim quando n√£o adotamos nenhuma estrat√©gia de divis√£o do conjunto de dados em treinamento e teste."
  },
  {
    "objectID": "index.html#exerc√≠cios-1",
    "href": "index.html#exerc√≠cios-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Com suas palavras, explique o dilema de balan√ßo entre v√≠es e vari√¢ncia.\n\nExerc√≠cio: Refa√ßa o exerc√≠cio do polin√¥mio, utilizando a estrat√©gia de data splitting, em que divide-se o conjunto de dados em treinamento e teste. Utilize o conjunto de teste para calcular a estimativa do risco, usando o EQM.\n\nExerc√≠cio: Ainda considerando o exerc√≠cio do polin√¥mio, implemente uma estrat√©gia de leave-one-out cross-validation e selecione o melhor modelo minimizando a fun√ß√£o de risco.\n\nExerc√≠cio: Por fim, considerando o exerc√≠cio do polin√¥mio, rafa√ßa-o utilizando um procedimento de k-fold cross-validation. Considere k = 5. Dica: considere utiliza a biblioteca rsample."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis",
    "href": "index.html#melhor-subconjunto-de-covari√°veis",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nO estimador de m√≠nimos quadrados - EMQ, na presen√ßa de muitas features (covari√°veis), i.e., quando temos d grande, possui um baixo poder preditivo devido a possibilidade de overfitting (super-ajuste). Isso, porqu√™ haver√° muitos par√¢metros a serem estimados, e portanto, a fun√ß√£o de regress√£o estimada \\widehat{r}({\\bf x}) ter√° baixo poder preditivo.\n\nIsso se deve ao fato do balan√ßo de vi√©s e vari√¢ncia. Havendo muitos par√¢metros, como j√° tinhamos visto, a vari√¢ncia do modelo poder√° ser muito alta.\n\nPortanto, deveremos buscar meios de encontrar o melhor (ao menos um bom) conjunto de covari√°veis. Queremos diminuir a vari√¢ncia do Estimador de M√≠nimos Quadrados!"
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-1",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nA ideia para resolver esse problema √© retirar algumas covari√°veis do modelo de regress√£o, com o objetivo de diminuir a vari√¢ncia de \\widehat{g}.\n\nVoc√™ poder√° entender que estamos em busca de um estimador \\widehat{g} de g um pouco mais viesado. Trata-se de uma troca em que desejamos reduzir substancialmente a variabilidade do estimador do modelo em troca de um pouco mais de vi√©s."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-2",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nMatematicamente, uma maneira de fazer isso, √© buscar a estimativa para\n\\widehat{\\beta}_{L_0} = \\argmin_{\\beta_0 \\in \\mathbb{R}, \\beta \\in \\mathbb{R}^d}\\sum_{k = 1}^n\\overbrace{\\left(y_k - \\beta_0 - \\sum_{i = 1}^d \\beta_i x_{k,i}\\right)^2}^{n \\times EQM} + \\lambda \\,\\,\\underbrace{\\sum_{i = 1}^d \\mathbb{I}(\\beta_i \\neq 0)}_{\\text{Penaliza√ß√£o}}. \\tag{3}\nNote que a penaliza√ß√£o \\sum_{i = 1}^d \\mathbb{I}(\\beta_i \\neq 0) nos conduz na dire√ß√£o de modelos com poucas covari√°veis, quando \\lambda √© um valor alto. Em particualr, quando \\lambda \\to \\infty, for√ßamos a retirada de todas as covari√°veis \\beta_i‚Äôs, i.e., a solu√ß√£o para o problema seria \\widehat{\\beta}_{L_0} \\equiv (\\overline{y}, {\\bf 0}). Note que n√£o h√° penaliza√ß√£o para o intercepto \\beta_0.\n No outro extremo, para \\lambda = 0, temos o estimador de m√≠nimos quadrados, em que nenhuma penaliza√ß√£o ser√° considerada.\n N√£o h√° uma forma f√°cil de minimizar \\widehat{\\beta}_{L_0}. ü§Ø"
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-3",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nPoder√≠amos, ingenuamente, pensar em ajustar todas as combina√ß√µes poss√≠veis de par√¢metros e utilizar algum crit√©rio, por exemplo, o EQM em novas observa√ß√µes para escolher o melhor modelo entre todas as combina√ß√µes poss√≠veis. Isto √©, escolher o melhor modelo entre todas as 2^d combina√ß√µes poss√≠veis de modelos em \\mathbb{G}.\n\nSe \\widehat{\\lambda} = \\frac{2}{n}\\widehat{\\sigma}^2, estimar \\widehat{\\beta}_{L_0} equivale uma busca entre 2^d modelos da classe \\mathbb{G}:\n\n\\begin{align*}\n\\mathbb{G} = \\{\n&g({\\bf x}) = \\widehat{\\beta}_0, \\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_2x_2,\\\\\n&\\cdots\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_dx_d,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_2x_2,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_3x_3,\\\\\n&\\cdots\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_dx_d,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_2x_2 + \\widehat{\\beta}_3x_3,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_2x_2 + \\widehat{\\beta}_dx_d,\\\\\n&\\cdots\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_2x_2 + \\widehat{\\beta}_3x_3 + \\cdots + &\\widehat{\\beta}_dx_d\n\\}.\n\\end{align*}"
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-4",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nUtilizar \\lambda = \\frac{2}{n}\\widehat{\\sigma}^2 √© o mesmo que utilizar o crit√©rio AIC para determinar o melhor modelo, em que dado\n\\widehat{R}(g) = \\frac{1}{m}\\sum_{k = 1}^m \\underbrace{(\\widetilde{Y}_k - g({\\bf \\widetilde{X}}_k))^2}_{W_k}, em que (\\widetilde{{\\bf X}}_1, \\widetilde{Y}_1), \\cdots, (\\widetilde{{\\bf X}}_m, \\widetilde{Y}_m), representa o conjunto de teste, i.e., calculado com base em m observa√ß√µes em um conjundo de dados n√£o utilizados para treinar o modelo, independentemente da estrat√©gia de divis√£o utilizada, em que\n\\widehat{\\sigma}^2 = \\frac{1}{m}\\sum_{k = 1}^m (W_k - \\overline{W})^2, com \\overline{W} = \\frac{1}{m}\\sum_{k=1}^m W_k."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-5",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nTemos que \\widehat{R}(g), calculado em novas observa√ß√µes (observa√ß√µes n√£o utilizadas no treinamento), pode se valer do Teorema Central do Limite, uma vez que \\widehat{R}(g) √© calculado em uma sequ√™ncia de vari√°veis aleat√≥rias i.i.d.‚Äôs. Ent√£o:\n\\widehat{R}(g) \\sim \\text{Normal}\\left(R(g), \\frac{1}{m}\\mathbb{V}[W_1]\\right).\nPortanto, um intervalo aleat√≥rio de aproximadamente 95\\% de confian√ßa para o erro preditivo R(g) poder√° ser calculado como:\n\\widehat{R}(g) \\pm 1,645 \\sqrt{\\frac{1}{m}\\widehat{\\sigma}^2}.\nO c√°lculo de um intervalo de confian√ßa poder√° ser √∫til para entendermos como est√° variando o risco preditivo do nosso modelo. Gostamos de ter modelos com intervalo de amplitude pequena. O intervalo poder√° ser utilizado para fornecer insight de como escolher a divis√£o de treinamento e teste. Por exemplo, pode-se escolher o menor valor de m de modo que a amplitude seja a menor poss√≠vel. üí≠üí°"
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-6",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nPor que essa seria uma escolha ing√™nua? Pense na situa√ß√£o em que temos d = 30, i.e., trinta covari√°veis. Ter√≠amos portanto 2^{30} modelos para ajustar, ou seja, um bilh√£o e setenta e tr√™s milh√µes, setecentos e quarenta e um mil, oitocentos e vinte e quatro modelos para ajustar. √â um a quantidade absurda de modelos para serem estimados!\n\nSe d = 100, ter√≠amos que estimar uma quantidade de modelos que a quantidade estimada de estrelas no universo. A depender do n√∫mero de covari√°veis, esque√ßa a ideia de estimar 2^d modelos! N√£o permita se frustrar facilmente. üòè"
  },
  {
    "objectID": "index.html#regress√£o-stepwise",
    "href": "index.html#regress√£o-stepwise",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o Stepwise",
    "text": "Regress√£o Stepwise\n Devido a impossibilidade de experimentar uma grande quantidade de modelos (2^d), existe uma s√©rie de algoritmos (heur√≠sticas), que visam reduzir a quantidade de modelos avaliados. Um dos mais conhecidos √© o forward stepwise. Trata-se de um algoritmo sequencial, que em cada passo, apenas uma vari√°vel √© adicionada:\n\n1 - Para j = 1, \\cdots, d, ajuste a regress√£o de Y na j-√©sima vari√°vel X_j. Seja \\widehat{R}(g_j) o risco estimado desta fun√ß√£o. Ent√£o,\n\\widehat{j} = \\argmin_j \\widehat{R}(g_j)\\,\\,\\,\\,\\,\\, \\text{e}\\,\\,\\,\\,\\,\\, S = \\{\\widehat{j}\\}. 2 - Para cada j \\in S^c, ajuste a regress√£o Y = \\beta_jX_j + \\sum_{s \\in S}\\beta_sX_S, em que \\widehat{R}(g_j) √© o risco estimado desta fun√ß√£o. Defina\n\\widehat{j} = \\argmin_{j \\in S^c} \\widehat{R}(g_j)\\,\\,\\,\\,\\,\\, \\text{e atualize}\\,\\,\\,\\,\\,\\, S \\leftarrow \\{S \\cup \\widehat{j}\\}.\n3 - Repita os passos anteriores at√© que todas as vari√°veis estejam em S ou at√© quando n√£o seja mais poss√≠vel ajustar o modelo de regress√£o.\n4 - Selecione o modelo com menor risco estimado."
  },
  {
    "objectID": "index.html#regress√£o-stepwise-1",
    "href": "index.html#regress√£o-stepwise-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o Stepwise",
    "text": "Regress√£o Stepwise\n\nUtilizar o algoritmo de sele√ß√£o de vari√°veis foward stepwise, ao inv√©s de buscarmos o melhor ajuste entre 2^d poss√≠veis modelos, que muitas vezes √© imposs√≠vel, precisaremos investigar apenas 1 + d(d + 1)/2 modelos. Reduzimos a complexidade da sele√ß√£o que antes era um problema exponencial. Melhor, n√£o?!"
  },
  {
    "objectID": "index.html#penaliza√ß√£o",
    "href": "index.html#penaliza√ß√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Penaliza√ß√£o",
    "text": "Penaliza√ß√£o\n\nQuando temos modelos que envolve d par√¢metros e que temos controle sobre eles (conhecemos muito bem cada um deles), acrescentar algum tipo de penaliza√ß√£o √† fun√ß√£o objetivo poder√° ser √∫til. A penaliza√ß√£o √© uma medida de complexidade, em que √© √∫til para equilibrar o modelo, de modo a tentar buscar um equilibrio entre vi√©s e vari√¢ncia, discutidos anteriormente. Assim, sob novas observa√ß√µes, desejamos estimar o risco R(g), por\n\nR(g) \\approx EQM(g) + \\mathcal{P}(g).\n\nDesejamos minimiar R(g), mas n√£o a custa de muitos par√¢metros, pois assim ter√≠amos overfitting. Portanto, para muitos par√¢metros temos que ter EQM baixo, por√©m, \\mathcal{P}(g) deve ser alto. J√° em modelos viesados, quando temos poucos par√¢metros, o EQM normalmente √© alto, mas a complexidade \\mathcal{P}(g) deve ser baixo, pois temos um modelo mais simplista."
  },
  {
    "objectID": "index.html#aic-e-bic",
    "href": "index.html#aic-e-bic",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "AIC e BIC",
    "text": "AIC e BIC\n\nExistem diversas penaliza√ß√µes, em que o AIC (Akaike Information Criterion) e BIC (Bayesian Information Criterion) s√£o as mais conhecidas. Com base nesses crit√©rios, temos que\n\n\n\n\nAIC: EQM + \\frac{2}{n\\,d\\, \\widehat{\\sigma}^2}.\nBIC: EQM + \\frac{\\log(n)}{n\\, d\\, \\widehat{\\sigma}^2}.\n\n\n\n\\widehat{\\sigma}^2 = \\frac{1}{m}\\sum_{k = 1}^m (W_k - \\overline{W})^2.\n\n\n\nAqui, d √© a quantidade de par√¢metros no modelo e \\widehat{\\sigma}^2 √© uma estimativa da vari√¢ncia do erro, que para um conjunto de teste suficientemente grande, poder√° ser considerado o estimador de \\widehat{\\sigma}^2 conforme descrito anteriormente. Segundo James, Gareth, et al.¬†An introduction to statistical learning. Ed. 2, p. 233, assume-se o modelo com todos os preditores para o c√°lculo de \\widehat{\\sigma}^2."
  },
  {
    "objectID": "index.html#lasso",
    "href": "index.html#lasso",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n\n\n\nO lasso foi desenvolvido pelo Robert Tibshirani, em um artigo publicado no artigo Regression Shrinkage and Selection via the Lasso."
  },
  {
    "objectID": "index.html#lasso-1",
    "href": "index.html#lasso-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n\nO lasso tem como objetivo encontrar um estimador de uma regress√£o linear que possui risco menor que o de m√≠nimos quadrados, possuindo duas grandes vantagens, em rela√ß√£o ao stepwise:\n\n\nSua solu√ß√£o √© mais r√°pida, ainda que stepwise seja consideravalmente mais r√°pido do que avaliar 2^d modelos;\nO lasso √© capaz de selecionar automaticamente as vari√°veis mais relevantes para o modelo, reduzindo a dimensionalidade dos dados.\n\n\nA segunda vantagem ocorre, uma vez que ele realiza uma penaliza√ß√£o que leva √† estimativas de alguns coeficientes \\beta_i igual a zero, eliminando as vari√°veis menos importantes. Normalmente o vetor \\beta √© esparso!"
  },
  {
    "objectID": "index.html#lasso-2",
    "href": "index.html#lasso-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n\nNo lasso, ao inv√©s de reduzir a vari√¢ncia do estimador de m√≠nimos quadrados usando a complexidade (L_0 = \\sum_{i = 1}^d\\mathbb{I}(\\beta_i) \\neq 0) em Equa√ß√£o¬†3, usa-se a penaliza√ß√£o L_1 = \\sum_{i = 1}^d|\\beta_i|. No lasso, buscamos:\n\\widehat{\\beta}_{L_1,\\lambda} = \\argmin_{\\beta_0 \\in \\mathbb{R}, \\beta \\in \\mathbb{R}^d}\\sum_{k = 1}^n\\overbrace{\\left(y_k - \\beta_0 - \\sum_{i = 1}^d \\beta_i x_{x,i}\\right)^2}^{n \\times EQM} + \\overbrace{\\lambda \\,\\,\\underbrace{\\sum_{j = 1}^d|\\beta_j|}_{\\text{Penaliza√ß√£o}}}^{\\text{A magnitude do coeficiente importa!}}, em que \\lambda √© um tuning parameter üéõ. Perceba que quando \\lambda = 0, ca√≠mos no caso do modelo de regress√£o por m√≠nimos quadrados sem penaliza√ß√£o. J√°, quando \\lambda \\rightarrow \\infty, temos um modelo em que todas as vari√°veis s√£o removidas, uma vez que a primeira parte do modelo torna-se insignificante."
  },
  {
    "objectID": "index.html#lasso-3",
    "href": "index.html#lasso-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n \nQuando \\lambda √© grande, temos que\n\\sum_{k = 1}^n \\left(y_k - \\beta_0 - \\sum_{j = 1}^d \\beta_j x_{k,j}\\right)^2 + \\lambda \\sum_{j = 1}^d |\\beta_j| \\approx \\lambda \\sum_{j = 1}^d |\\beta_j|, e portanto, \\widehat{\\beta}_1 = 0, \\cdots, \\widehat{\\beta}_d = 0.\n\nA escolha de \\lambda, em geral, √© feita utilizado algum m√©todo de valida√ß√£o cruzada. üîç"
  },
  {
    "objectID": "index.html#lasso-4",
    "href": "index.html#lasso-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n\nO lasso √© extremamente r√°pido, e nos √∫ltimos anos, diversos algoritmos foram constru√≠dos para fazer essa tar√©fa de forma eficiente. O LARS foi um dos primeiros algoritmos desenvolvidos em 2010. Para detalhes, ler Friedman, J. H. (2001). Greedy function approximation: a gradient boosting machine. Annals of statistics, 1189‚Äì1232.\n\nNo R, a regress√£o lasso poder√° ser feita usando a biblioteca glmnet, assim:\n\n\nlibrary(glmnet)\najuste &lt;- cv.glmnet(x, y, alpha = 1)"
  },
  {
    "objectID": "index.html#ridge",
    "href": "index.html#ridge",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ridge",
    "text": "Ridge\n\nUma alternativa que surgiu antes do lasso √© a regress√£o ridge. Ela foi proposta no artigo Hoerl, A. E. & Kennard, R. W. (1970). Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1), 55‚Äì67. Aqui, utiliza-se como medida de complexidade a norma L_2, em que, o estimador √© dado por:\n\\widehat{\\beta}_{L_2,\\lambda} = \\argmin_{\\beta_0 \\in \\mathbb{R}, \\beta \\in \\mathbb{R}^d}\\sum_{k = 1}^n\\overbrace{\\left(y_k - \\beta_0 - \\sum_{i = 1}^d \\beta_i x_{x,i}\\right)^2}^{n \\times EQM} + \\lambda \\,\\,\\underbrace{\\sum_{j = 1}^d\\beta_j^2}_{\\text{Penaliza√ß√£o}}. Diferentemente do lasso, a regress√£o ridge possui solu√ß√£o anal√≠tica, dada por:\n\\widehat{\\beta}_{L_2,\\lambda} = ({\\bf X}^{T}{\\bf X} + \\lambda\\mathbb{\\bf I}_0)^{-1}{\\bf X}^{T}Y, em que \\mathbb{\\bf I}_0 √© a matriz identidade (d + 1) \\times (d + 1) com \\mathbb{\\bf I}_0(1,1) = 0."
  },
  {
    "objectID": "index.html#ridge-1",
    "href": "index.html#ridge-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ridge",
    "text": "Ridge\n\nA regress√£o ridge poder√° ter uma vari√¢ncia menor que a regress√£o lasso, por√©m seu vi√©s poder√° ser maior. Outra caracter√≠stica da regress√£o ridge √© que ela possue uma √∫nica solu√ß√£o, enquanto a regress√£o lasso poder√° ter multiplas solu√ß√µes. Os autores tamb√©m demonstram que a regress√£o ridge lida melhor com multicolinearidade.\n\nNo R, tamb√©m poderemos utilizar a biblioteca glmnet:\n\n\nlibrary(glmnet)\najuste &lt;- cv.glmnet(x, y, alpha = 0)"
  },
  {
    "objectID": "index.html#elastic-net",
    "href": "index.html#elastic-net",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Elastic Net",
    "text": "Elastic Net\n\nNesse tipo de modelo de gress√£o, combina-se as penaliza√ß√µes da regress√£o ridge com a utilizada na regress√£o lasso, herdando os benef√≠cios do uso de cada um dos m√©todos isoladamente, melhorando a estabilidade das estimativas do lasso, em situa√ß√µes de multicolinearidade entre as vari√°veis e tamb√©m permitindo a sele√ß√£o autom√°tica de vari√°veis.\n(1-\\alpha)\\widehat{\\beta}_{L_2,\\lambda} + \\alpha\\widehat{\\beta}_{L_1,\\lambda}, em que 0 \\leq \\alpha \\leq1. Em R, basta especificar para a fun√ß√£o glmnet um valor de \\alpha diferente de 0 e 1."
  },
  {
    "objectID": "index.html#exemplo-emq-ridge-lasso-e-elastic-net",
    "href": "index.html#exemplo-emq-ridge-lasso-e-elastic-net",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Exemplo: EMQ, Ridge, Lasso e Elastic Net",
    "text": "Exemplo: EMQ, Ridge, Lasso e Elastic Net\n\nExemplo: Considere uma base de dados simulada, com n = 500 observa√ß√µes, de tal forma que\nY = 3X_{1} - 2X_2 + X_3 + -3X_4 + X_5 + \\sum_{i = 6}^{20}0X_i + \\varepsilon, em que \\varepsilon \\sim \\text{Normal}(0, 0.5^2) e X_i \\sim \\text{Normal}(0, 1), independentes, com i = 1, \\cdots, 20. Desejamos ajustar quatro modelos de regress√£o. Para o caso do Estimador de M√≠nimos Quadrados - EMQ e do modelo Ridge, que n√£o tem sele√ß√£o autom√°tica de vari√°veis, usaremos todas as vari√°veis. Desejamos avaliar o risco estimado de cada uma das regress√µes."
  },
  {
    "objectID": "index.html#exemplo-emq-ridge-lasso-e-elastic-net-1",
    "href": "index.html#exemplo-emq-ridge-lasso-e-elastic-net-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Exemplo: EMQ, Ridge, Lasso e Elastic Net",
    "text": "Exemplo: EMQ, Ridge, Lasso e Elastic Net\n\n\n\nSolu√ß√£o utilizando o tidymodels\nlibrary(tidymodels)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Removendo poss√≠veis conflitos de pacotes --------------------------------\ntidymodels::tidymodels_prefer()\n\n# Fun√ß√£o para gerar os dados ----------------------------------------------\ngerando_dados &lt;- function(n = 300L){\n  regressao &lt;- function(i){\n    x &lt;- rnorm(n = 5L)\n    y &lt;- 3*x[1L] - 2*x[2L] + x[3L] - 3*x[4L] + x[5L] + rnorm(1L, 0, 0.5)\n    tibble(\n      y = y,\n      x1 = x[1L],\n      x2 = x[2L],\n      x3 = x[3L],\n      x4 = x[4L],\n      x5 = x[5L]\n    )\n  }\n  dados &lt;- purrr::map(.x = 1L:n, .f = regressao) |&gt; \n    purrr::list_rbind()\n  \n  parte_esparsa &lt;- matrix(0, n, 15)\n  \n  dados &lt;- cbind(dados, parte_esparsa)\n  colnames(dados) &lt;- c(\"y\", paste0(\"x\", 2L:ncol(dados)))\n  as_tibble(dados)\n}\n\ndados &lt;- gerando_dados(n = 500)\n\n# Divis√£o inicial da base -------------------------------------------------\nhod_out &lt;- initial_split(dados, prop = 0.7)\ntreinamento &lt;- training(hod_out)\nteste &lt;- testing(hod_out)\n\n# Setando o modelo (set engine) -------------------------------------------\nmodelo_eqm &lt;- \n  linear_reg(penalty = 0, mixture = 0) |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine(\"glmnet\")\n  \nmodelo_ridge &lt;- \n  linear_reg(penalty = tune::tune(), mixture = 0) |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine(\"glmnet\")\n\nmodelo_lasso &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) |&gt; \n  set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"glmnet\")\n  \nmodelo_elastic &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) |&gt; \n  set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"glmnet\")\n\n# Criando workflows -------------------------------------------------------\nall_wf &lt;- \n  workflow_set(\n    preproc = list(y ~ . ),\n    models = list(eqm = modelo_eqm, ridge = modelo_ridge, lasso = modelo_lasso, elastic = modelo_elastic), \n    cross = TRUE\n  )\n\n# Valida√ß√£o cruzada -------------------------------------------------------\nset.seed(0)\ncv &lt;- rsample::vfold_cv(treinamento, v = 5L)\n\n# Setando a m√©trica -------------------------------------------------------\nmetrica &lt;- yardstick::metric_set(rmse)\n\n# Tunagem dos hiperpar√¢metros ---------------------------------------------\n# A semente (seed = 0) faz com que dentro da valida√ß√£o cruzada para cada modelo\n# a semente seja sempre a mesma.\ntunagem &lt;- \n  all_wf |&gt; \n  workflow_map(\n    seed = 0, \n    verbose = TRUE,\n    resamples = cv,\n    grid = 50,\n    metrics = metrica\n  )\n\n# Rank dos melhores modelos -----------------------------------------------\nmodelos_rank &lt;- tunagem |&gt; rank_results()\n\nmelhor_eqm &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"formula_eqm\") |&gt; \n  select_best(\"rmse\")\n\nmelhor_ridge &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"formula_ridge\") |&gt; \n  select_best(\"rmse\")\n\nmelhor_lasso &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"formula_lasso\") |&gt; \n  select_best(\"rmse\")\n\nmelhor_elastic &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"formula_elastic\") |&gt; \n  select_best(\"rmse\")\n\nfinalizando_eqm &lt;- \n  tunagem |&gt; \n  extract_workflow(\"formula_eqm\") |&gt; \n  finalize_workflow(melhor_eqm) |&gt; \n  last_fit(split = hod_out)\n\nfinalizando_ridge &lt;- \n  tunagem |&gt; \n  extract_workflow(\"formula_ridge\") |&gt; \n  finalize_workflow(melhor_ridge) |&gt; \n  last_fit(split = hod_out)\n\nfinalizando_lasso &lt;- \n  tunagem |&gt; \n  extract_workflow(\"formula_lasso\") |&gt; \n  finalize_workflow(melhor_lasso) |&gt; \n  last_fit(split = hod_out)\n\nfinalizando_elastic &lt;- \n  tunagem |&gt; \n  extract_workflow(\"formula_elastic\") |&gt; \n  finalize_workflow(melhor_elastic) |&gt; \n  last_fit(split = hod_out)\n\n# Visualizando as m√©tricas\nfinalizando_eqm |&gt; collect_metrics()\nfinalizando_ridge |&gt; collect_metrics()\nfinalizando_lasso |&gt; collect_metrics()\nfinalizando_elastic |&gt; collect_metrics()\n\n# Visualizando predi√ß√µes:\nfinalizando_eqm |&gt; collect_predictions()\nfinalizando_ridge |&gt; collect_predictions()\nfinalizando_lasso |&gt; collect_predictions()\nfinalizando_elastic |&gt; collect_predictions()"
  },
  {
    "objectID": "index.html#exerc√≠cios-2",
    "href": "index.html#exerc√≠cios-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n Exerc√≠cio: Utilizando os dados de vinho vermelhoüç∑, dispon√≠veis aqui, fa√ßa uma pequena an√°lise explorat√≥ria dos dados. No link do Kaggle voc√™ consegue uma explica√ß√£o sobre o que significa cada uma das vari√°veis."
  },
  {
    "objectID": "index.html#exerc√≠cios-3",
    "href": "index.html#exerc√≠cios-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Utilizando os dados de vinho vermelhoüç∑, dispon√≠veis aqui, obtenha o melhor modelo de regress√£o linar para modelar a qualidade do vinho, considerando:\n\n\ng_1 - M√©todo dos m√≠nimos quadrados;\ng_2 - Regress√£o ridge;\ng_3 - Regressao lasso;\ng_4 - Elastic Net.\n\n\nVoc√™ dever√° selecionar o melhor modelo de cada uma das classes de modelos de regress√£o e construir uma tabela com o risco estimado \\widehat{R}(g_i),\\,\\, i = 1, \\cdots, 4, em que aqui g_i representa o modelo geral n√£o estimado. Ao fim, construa quatro gr√°ficos mostrando o ajuste de cada um dos modelos.\n\nExerc√≠cio: Se voc√™ utilizou o tidymodels para resolver o exerc√≠cio anterior, rafa√ßa usando a biblioteca glmnet. Caso contr√°rio, resolva-o utilizando o tidymodels."
  },
  {
    "objectID": "index.html#exerc√≠cios-4",
    "href": "index.html#exerc√≠cios-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Considere agora o conjunto de dados de despesas m√©dicas, dispon√≠vel aqui, refa√ßa o mesmo exerc√≠cio dos dados de vinho vermelho, em que aqui, o objetivo √© prever a vari√°vel charges. Perceba que algumas vari√°veis s√£o qualitativas, e port√£o, voc√™ dever√° transform√°-las em dummy. Indique os melhores cen√°rios dos quatro modelos e informe qual modelo voc√™ utilizaria. Explique!"
  },
  {
    "objectID": "index.html#m√©todos-n√£o-param√©tricos",
    "href": "index.html#m√©todos-n√£o-param√©tricos",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√©todos n√£o-param√©tricos",
    "text": "M√©todos n√£o-param√©tricos\n\nM√©todos param√©tricos podem impor muitas limita√ß√µes na solu√ß√£o de um problema de regress√£o, i.e., em problemas que desejamos estimar a fun√ß√£o de regress√£o r({\\bf x}). Por exemplo, nem sempre o melhor estimador linear √© um bom estimador para r({\\bf x}).\n\nM√©todos param√©tricos s√£o muitas vezes simplistas e restritivos, em que normalmente abrimos m√£os para se ter um estimador um pouco mais viesado, em detrimento da diminui√ß√£o da vari√¢ncia do modelo. Por exemplo, nas regress√µes penalizadas que vimos anteriormente (ridge, lasso e elastic-net), penalizamos modelos com muitas covari√°veis o que naturalmente aumentar√° o vi√©s, na maioria das vezes."
  },
  {
    "objectID": "index.html#m√©todos-n√£o-param√©tricos-1",
    "href": "index.html#m√©todos-n√£o-param√©tricos-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√©todos n√£o-param√©tricos",
    "text": "M√©todos n√£o-param√©tricos\n\nEm situa√ß√µes em que temos muitos dados (n grande), os modelos n√£o-param√©tricos possuem, em geral, boa peformance, uma vez que apesar de que nessa classe de modelos existir um aumento da vari√¢ncia, por√©m, seguida de uma redu√ß√£o de vi√©s, a vari√¢ncia do modelo n√£o aumenta muito.\n\nDe um lado, nos modelos de regress√£o que vimos at√© o momento, introduzimos uma penaliza√ß√£o para diminuir a vari√¢ncia do modelo frente ao m√©todo dos m√≠nimos quadrados (quando n√£o usamos penaliza√ß√£o) em troca de um aumento no v√≠es. Aqui, em modelos n√£o param√©tricos, desejamos fazer a troca oposta, i.e., diminuir o vi√©s, em troca de um ganho na vari√¢ncia no modelo.\n\nQualquer abordagem param√©trica tr√°s consigo a possibilidade de que a forma funcional g para estimar f seja muito diferente da verdadeira, claro, se o modelo resultante n√£o se ajustar bem aos dados, isto √© \\widehat{g} n√£o tem boa capacidade preditiva, muito embora, tamb√©m √© poss√≠vel que tenhamos \\widehat{g} com boa capacidade preditiva, por√©m, n√£o represente a estrutura real de f (sempre desconhecida)."
  },
  {
    "objectID": "index.html#m√©todos-n√£o-param√©tricos-2",
    "href": "index.html#m√©todos-n√£o-param√©tricos-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√©todos n√£o-param√©tricos",
    "text": "M√©todos n√£o-param√©tricos\n \nIsso n√£o √© regra, por√©m ajuda a entender um pouco o dilema entre essas classes de modelos (param√©tricos e n√£o-param√©tricos)."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nTamb√©m chamado de k-nearest neighbours - kNN, o kNN √© um dos m√©todos mais populares na comunidade de aprendizagem de m√°quina. O m√©todo foi formulado em uma sequ√™ncia de dois artigos:\n\n1 - Benedetti, J. K. (1977). On the nonparametric estimation of regression functions. Journal of the Royal Statistical Society. Series B (Methodological), 248‚Äì253;\n\n2 - Stone, C. J. (1977). Consistent nonparametric regression. The Annals of Statistics, 595‚Äì 620.\n\nA ideia do m√©todo √© estimar a fun√ß√£o de regress√£o r({\\bf x}), para um dado {\\bf x} com base nas respostas Y dos k-vizinhos mais pr√≥ximos de {\\bf x}."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-1",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nFormalmente, temos que\ng({\\bf x^*}) = \\frac{1}{k}\\sum_{i \\in \\mathcal{N}_{\\bf x^*}}y_i, em que \\mathcal{N}_{\\bf x} √© o conjunto √≠ndices das k observa√ß√µes mais pr√≥ximas de {\\bf x}, i.e,\n\\mathcal{N}_{\\bf x^*} = \\{i \\in \\{1, \\cdots, n\\}\\, : \\, d({\\bf x}_i, {\\bf x^*}) \\leq d_{\\bf x^*}^k\\}, em que d_{\\bf x^*}^k √© a dist√¢ncia do k-√©simo vizinho mais pr√≥ximo de \\bf{x^*} em \\bf{x}. Portanto, o valor da regress√£o no ponto {\\bf x^*}, i.e., o valor de r({\\bf x^*}) = \\mathbb{E}(Y|{\\bf X} = {\\bf x^*}) √© estimado pela m√©dia de Y_{N_{\\bf x^*}}. Ou seja, estimamos por:\n\\overline{Y}_{N_{\\bf x^*}} = \\frac{1}{k} \\sum_{i \\in \\mathcal{N}_{\\bf x^*}}y_i."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-2",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n  Para determinar d_{\\bf x^*}^k, poderemos utilizar alguma m√©trica de dist√¢ncia e assim mensurarmos a proximidade. Entre elas:\n\n\nDist√¢ncia Euclidiana ou dist√¢ncia L_2: d(x^a, x^b) = \\sqrt{(x_1^a - x_1^b)^2 + \\cdots + (x_d^a - x_d^b)^2};\n\n\n\nDist√¢ncia de Manhattan, City Block ou dist√¢ncia L_1: d(x^a, x^b) = \\sqrt{|x_1^a - x_1^b| + \\cdots + |x_d^a - x_d^b|};\n\n\n\nDist√¢ncia de Mahalanobis: d(x^a, x^b) = \\sqrt{(x^a - x^b)^{T}S^{-1}(x^a - x^b)}, em que S √© a matriz de covari√¢ncia, em que na diagonal princial temos as vari√¢ncias e fora dela as covari√¢ncias entre os pontos. Lembre-se que se x e y s√£o vetores de dados quaisquer, a interdepend√™ncia linear entre eles poder√° ser estimada como:\n\n\n\\mathrm{cov}(x, y) = \\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\overline{x})(y_i - \\overline{y})."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-3",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nVoc√™ poder√° utilizar qualquer outra medida de dist√¢ncia al√©m das que foram citadas acima.\n\n√â importante perceber que o m√©todo kNN n√£o faz uma ‚Äúcompress√£o‚Äù dos dados como a regress√£o linear que estudamos. L√°, temos uma equa√ß√£o que utilizamos para estimar o valor de Y, ap√≥s as estima√ß√£o dos coeficientes do modelo de regress√£o, ou seja, n√£o precisamos mais dos dados para estimar novas observa√ß√µes. J√° no kNN, precisamos sempre nos recorrer aos dados para fazer novas predi√ß√µes, ou seja, sempre que desejarmos calcular r({\\bf x}) = \\mathbb{E}(Y|{\\bf X} = {\\bf x}) deveremos sempre fazer uma nova consulta aos dados para calcular a m√©dia dos vizinhos mais pr√≥ximos. O kNN n√£o possui coeficientes para interpretar. Diferentemente da regress√£o linear, o kNN √© um pouco mais ‚Äúblack box‚Äù."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-4",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n O valor da constante k √© um hiperpar√¢metro do kNN e dever√° ser obtido por valida√ß√£o cruzada. Perceba que se k = n temos um modelo muito viesado, por√©m com vari√¢ncia pequena. Isso, porqu√™ para k = n basicamente iremos tirar uma m√©dia dos dados. Para k = 1, teremos um overfitting, uma vez que o estimador ir√° interpolar os dados.\n Exemplo: Considere novamente o conjunto de dados de expectativa de vida versus PIB per Capita dispon√≠veis aqui. Utilizando o tidymodels, vamos construir uma fu√ß√£o que retorne um gr√°fico com as estimativas do kNN. A fun√ß√£o receber√° como argumentos o conjunto de dados e o valor de k. Voc√™ tamb√©m poderia utilizar outras bibliotecas, como por exemplo a FNN, ou a KKNN, esta √∫tlima √© a que √© utilizada internamente na biblioteca parsnip do tidymodels."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-5",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nAbrindo apenas um par√™ntese, o tidymodels refere-se a um conjunto de pacotes que s√£o √∫teis para o tratamento, treinamento, tunagem e avalia√ß√£o de modelos de aprendizagem de m√°quina, em que o parsnip implementa as engines (algoritmos/motores) que iremos utilizar para treinar um modelo. Na verdade, os algoritmos est√£o implementados em pacotes de terceiros e n√£o precisamente no parsnip. Por√©m, o parsnip unifica a sintaxe de diversos algoritmos implementados em pacotes separados."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-6",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nObserve que na imagem abaixo, a Figura A, quando k=1, percebemos initidamente que houve overfitting, i.e., h√° uma interpola√ß√£o dos dados. J√° na Figura D temos um modelo com vari√¢ncia menor, por√©m, este √© muito simplista, o que sugere um alto vi√©s."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-7",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nEstude o c√≥digo! Ele fornece a solu√ß√£o para o exemplo.\n\n\n\nSolu√ß√£o pelo m√©todo knn do exemplo anterior\nlibrary(tidymodels)\nlibrary(glue)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\ntidymodels::tidymodels_prefer()\n\n# Lendo dados\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados &lt;- \n  dados_expectativa_renda |&gt; \n  dplyr::select(-CountryName) |&gt; \n  dplyr::rename(y = LifeExpectancy, x = GDPercapita)\n\nknn_exp_pip &lt;- function(dados, k = 1L){\n  # Criando receita\n  receita &lt;- recipe(y ~ x, data = dados)\n  \n  # Definindo o modelo\n  modelo_knn &lt;- nearest_neighbor(neighbors = k) |&gt; \n    set_mode(\"regression\") |&gt; \n    set_engine(\"kknn\")\n  \n  # Workflow\n  ajuste_final &lt;- \n    workflow() |&gt; \n    add_model(modelo_knn) |&gt; \n    add_recipe(receita) |&gt; \n    fit(data = dados)\n  \n  # Retornando previsoes\n  y_chapeu &lt;- predict(ajuste_final, new_data = dados)\n  \n  dados &lt;- \n    dados |&gt; \n    mutate(y_chapeu = y_chapeu$.pred)\n  \n  dados |&gt; \n    ggplot() +\n    geom_point(aes(x = x, y = y), size = 3) +\n    geom_line(aes(x = x, y = y_chapeu), col = \"red\", alpha = 0.6, size = 2) +\n    labs(title = \"k-nearest neighbours\", subtitle = glue(\"k = {k}\")) +\n    theme(\n      title = element_text(face = \"bold\")\n    )\n}\n\np1 &lt;- knn_exp_pip(dados, k = 1L)\np2 &lt;- knn_exp_pip(dados, k = 7L)\np3 &lt;- knn_exp_pip(dados, k = 10L)\np4 &lt;- knn_exp_pip(dados, k = 200L)\n\np &lt;- p1 + p2 + p3 + p4 + plot_annotation(tag_levels = \"A\")\n\nggsave(p, file = \"imgs/knn_plot.png\", width = 50, height = 30, units = \"cm\")"
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-8",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nAlgumas limita√ß√µes do kNN s√£o:\n\n\n√â totalmente dependente do conjunto de dados para fazer novas predi√ß√µes;\nPara novas observa√ß√µes que s√£o fora dos limites dos dados de treinamento, as predi√ß√µes do kNN tendem a serem imprecisas;\nPode ser custoso para uma grande base de dados;\nO c√°lculo de dist√¢ncias pode sofrer com a chamada ‚Äúmaldi√ß√£o da dimensionalidade‚Äù, em que a depender da m√©trica de dist√¢ncia utilizada, tudo fica muito distante.\n\n\nAlgumas vantagens s√£o:\n\n\n√â um m√©todo simples de ser implementado;\n√â muito utilizado para imputa√ß√£o de observa√ß√µes faltantes;\n√â comumente utilizado, por conta de sua simplicidade, em explora√ß√µes iniciais."
  },
  {
    "objectID": "index.html#nadaraya-watson",
    "href": "index.html#nadaraya-watson",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nUma varia√ß√£o do m√©todo kNN que √© bastante difundida na comunidade estat√≠stica √© o m√©todo de Nadaraya-Watson, propostos nos artigos:\n\n\nNadaraya, E. A. (1964). On estimating regression. Theory of Probability & Its Applications, 9(1), 141‚Äì142;\nWatson, G. S. (1964). Smooth regression analysis. Sankhya: The Indian Journal of Statistics, Series A, 359‚Äì372.\n\n\nEsse m√©todo tamb√©m √© chamado de estimador k-vizinhos ponderados (kNN ponderado), uma vez que a estima√ß√£o da fun√ß√£o de regress√£o em um dado ponto {\\bf x} utiliza de m√©dias ponderadas das observa√ß√µes do conjunto de treinamento:\ng({\\bf x}) = \\sum_{i = 1}^n w_i({\\bf x})y_i, em que w_i({\\bf x}) √© o peso atribu√≠do √† i-√©sima observa√ß√£o, medindo a similaridade de {\\bf x}_i √† {\\bf x}."
  },
  {
    "objectID": "index.html#nadaraya-watson-1",
    "href": "index.html#nadaraya-watson-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nTemos que w_i({\\bf x}) √© definido por:\nw_i({\\bf x}) = \\frac{K({\\bf x}, {\\bf x}_i)}{\\sum_{j = 1}^n K({\\bf x}, {\\bf x}_j)}, em que K({\\bf x}, {\\bf x}_j) √© um kernel de suaviza√ß√£o usado para medir a similaridade entre as observa√ß√µes. Escolhas que s√£o populares para K({\\bf x}, {\\bf x}_j), s√£o:\n\n\nKernel uniforme: K({\\bf x}, {\\bf x}_i) = \\mathbb{I}(d({\\bf x}, {\\bf x}_i) \\leq h);\nKernel gaussiano: K({\\bf x}, {\\bf x}_i) = (\\sqrt{2\\pi h^2})^{-1}\\exp\\left\\{ -\\frac{d^2({\\bf x}, {\\bf x}_i)}{2h^2}\\right\\};\nKernel triangular: K({\\bf x}, {\\bf x}_i) = (1 - d({\\bf x}, {\\bf x}_i)/h)\\mathbb{I}(d({\\bf x}, {\\bf x}_i) \\leq h);\nKernel de Epanechnikov: K({\\bf x}, {\\bf x}_i) = (1 - d^2({\\bf x}, {\\bf x}_i)/h^2)\\mathbb{I}(d({\\bf x}, {\\bf x}_i) \\leq h)."
  },
  {
    "objectID": "index.html#nadaraya-watson-2",
    "href": "index.html#nadaraya-watson-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nEnquanto no kernel uniforme, os pesos s√£o iguais para as observa√ß√µes a uma dist√¢ncia menor que h de {\\bf x} e atribui peso zero para observa√ß√µes maiores que h, os kernels triangular e de Epanechnikov atribui pesos maiores para observa√ß√µes mais pr√≥ximas de {\\bf x}. A quantidade h √© um tuning parameter, e na pr√°tica, deve ser estimada por um procedimento de valida√ß√£o cruzada.\n\nAlgumas propriedades de uma fun√ß√£o kernel s√£o:\n\n\nSimetria: K(x,y) = K(y,x), permitindo que a fun√ß√£o de similaridade seja invariante em rela√ß√£o a ordem dos argumentos;\nPositiva definida: Para qualquer vetor c, em que seja poss√≠vel fazer c^{T}K(x,y), temos que c^{T}K(x,y)c &gt; 0.\n\n\nVoc√™ poder√° encontrar outras fun√ß√µes kernel aqui."
  },
  {
    "objectID": "index.html#nadaraya-watson-3",
    "href": "index.html#nadaraya-watson-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nExemplo: Novamente, considerando o conjunto de dados de expectativa de vida versus PIB per Capita dispon√≠veis aqui. Utilizando o tidymodels, vamos construir uma fu√ß√£o que retorne um gr√°fico com as estimativas. A fun√ß√£o receber√° como argumentos o conjunto de dados e o valor de h. Observe a documenta√ß√£o da fun√ß√£o nearest_neighbor do pacote parsnip. Perceba que o argumento weight_func permite que possamos escolher entre algumas fun√ß√µes kernel. Por√©m, como m√©trica de dist√¢ncias, apenas poderemos utilizar a de Minkowski. Seja x = (x_1, \\cdots, x_n) e y = (y_1, \\cdots, y_n), ambos vetores do \\mathbb{R}^n. Ent√£o, a dist√¢ncia de Minkowski √© dada por:\nd(x,y) = \\left(\\sum_{i = 1}^n |x_i - y_i|^p\\right)^{\\frac{1}{p}}, com p \\geq 1. Note que se p = 1 temos a dist√¢ncia euclidiana (dist√¢ncia L_1) e se p = 2 teremos a distancia de Manhattan (dist√¢ncia L_2)."
  },
  {
    "objectID": "index.html#nadaraya-watson-4",
    "href": "index.html#nadaraya-watson-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nPortanto, com o argumento dist_power da fun√ß√£o nearest_neighbor, do pacote parsnip, voc√™ poder√° especificar o valor de p, que inclusive poder√° ser um hiperpar√¢metro, podendo ser obtido por meio de uma valida√ß√£o cruzada.\n\n\n\nNo exemplo n√£o iremos fazer a valida√ß√£o cruzada, pois apenas queremos implementar uma fun√ß√£o em que seja poss√≠vel experimentar o m√©todo para diferentes valores de h e diferentes fun√ß√µes de kernel."
  },
  {
    "objectID": "index.html#nadaraya-watson-5",
    "href": "index.html#nadaraya-watson-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n A imagem abaixo utiliza o kernel gaussiano:"
  },
  {
    "objectID": "index.html#nadaraya-watson-6",
    "href": "index.html#nadaraya-watson-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\n\n\nSolu√ß√£o do exempƒ∫o de Nadaraya-Watson\nlibrary(tidymodels)\nlibrary(glue)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\ntidymodels::tidymodels_prefer()\n\n\n# Lendo dados\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados &lt;- \n  dados_expectativa_renda |&gt; \n  dplyr::select(-CountryName) |&gt; \n  dplyr::rename(y = LifeExpectancy, x = GDPercapita)\n\nnadaraya_watson_exp_pip &lt;- function(dados, h = 1, ...){\n  # Criando receita\n  receita &lt;- \n    recipe(y ~ x, data = dados) |&gt; \n    step_normalize()\n  \n  # Definindo o modelo\n  modelo_knn &lt;- nearest_neighbor(dist_power = h, ...) |&gt; \n    set_mode(\"regression\") |&gt; \n    set_engine(\"kknn\")\n  \n  # Workflow\n  ajuste_final &lt;- \n    workflow() |&gt; \n    add_model(modelo_knn) |&gt; \n    add_recipe(receita) |&gt; \n    fit(data = dados)\n  \n  # Retornando previsoes\n  y_chapeu &lt;- predict(ajuste_final, new_data = dados)\n  \n  dados &lt;- \n    dados |&gt; \n    mutate(y_chapeu = y_chapeu$.pred)\n  \n  dados |&gt; \n    ggplot() +\n    geom_point(aes(x = x, y = y), size = 3) +\n    geom_line(aes(x = x, y = y_chapeu), col = \"red\", alpha = 0.6, size = 2) +\n    labs(title = \"Nadaraya-Watson\", subtitle = glue(\"h = {h}\")) +\n    theme(\n      title = element_text(face = \"bold\")\n    )\n}\n\np1 &lt;- nadaraya_watson_exp_pip(dados, h = 1, weight_func = \"gaussian\")\np2 &lt;- nadaraya_watson_exp_pip(dados, h = 1000, weight_func = \"gaussian\")\n\np &lt;- p1 + p2 + plot_annotation(tag_levels = \"A\")\n\nggsave(p, file = \"imgs/nadaraya_watson.png\", width = 30, height = 15, units = \"cm\")"
  },
  {
    "objectID": "index.html#tidymodels-knn-e-nadaraya-watson",
    "href": "index.html#tidymodels-knn-e-nadaraya-watson",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels kNN e Nadaraya-Watson",
    "text": "Tidymodels kNN e Nadaraya-Watson\n\nPara que possamos experimentar o tidymodels seguindo todo o fluxo de ‚Äúpadr√£o‚Äù de aprendizagem de m√°quina, com divis√£o do conjunto de dados, valida√ß√£o cruzada e busca pelos melhores hiperpar√¢metros (‚Äútunagem‚Äù). Iremos reproduir dois exemplos com os dados de expectativa de vida e PIB per Capita.\n\nExemplo: Nesse exemplo estamos realizando o kNN, em que estamos obtendo um candidato para o valor de k, por meio de um procedimento de cross-validation (10-folds cross-validation). Aqui, a busca do hiperpar√¢metro k far√° uso de um grid search. Perceba, no c√≥digo que segue o exemplo, que no processo de ‚Äútunagem‚Äù, alterei o grid de valores usando a fun√ß√£o grid_max_entropy do pacote dails. Uma observa√ß√£o √© que voc√™ poderia criar uma tibble com valores do seu interesse. O argumento grid da fun√ß√£o tune_grid do pacote tune deve ser um data frame/tibble ou um n√∫mero inteiro. Esse objeto conter√° todas as poss√≠veis combina√ß√µes de hiperpar√¢metros que ser√£o testadas na valida√ß√£o cruzada, no nosso caso, temos apenas um hiperpar√¢metro. Foi utilizado um grid de tamanho 60. Foi utilizado uma divis√£o de 80\\% para treinamento e 20\\% para teste."
  },
  {
    "objectID": "index.html#tidymodels-knn-e-nadaraya-watson-1",
    "href": "index.html#tidymodels-knn-e-nadaraya-watson-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels kNN e Nadaraya-Watson",
    "text": "Tidymodels kNN e Nadaraya-Watson\n\n\n\nWorkflow completo do treimanento de um modelo KNN.\nlibrary(tidymodels)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Resolvendo eventuais conflitos entre tidymodels e outros pacotes eventualmente\n# carregados:\ntidymodels::tidymodels_prefer()\n\n# Lendo a base de dados:\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados_expectativa_renda &lt;-\n  dados_expectativa_renda |&gt;\n  dplyr::select(-CountryName)\n\n# Setando uma semente\nset.seed(0)\n\n# Divis√£o da base de dados ------------------------------------------------\n# Divis√£o inicial (treino e teste)\nsplits &lt;- \n  rsample::initial_split(\n    dados_expectativa_renda,\n    strata = \"LifeExpectancy\", \n    prop = 0.8 \n  )\n\n# O conjunto de dados de treinamento ser√° utilizado para ajustar/treinar o\n# modelo:\ntreinamento &lt;- rsample::training(splits)\n\n# O conjunto de teste ser√° utilizado apenas no fim, para avaliar o desempenho\n# preditivo final do modelo:\nteste &lt;- rsample::testing(splits) \n\n# Criando uma receita para os dados ---------------------------------------\n\n# Poderia ter passado o conjunto treinamento ou posso passar o conjunto \"splits\".\n# O comando recipes j√° entende que dever√° utilizar o conjunto de treinamento.\nreceita &lt;- \n  recipes::recipe(formula = LifeExpectancy ~ ., data = treinamento) |&gt; \n  step_YeoJohnson(all_predictors()) |&gt; # Ajuda na normaliza√ß√£o dos dados. Pode ser bom!\n  step_normalize(all_predictors()) # Normalizando vari√°veis num√©ricas.\n\n# Construindo modelo kNN --------------------------------------------------\nmodelo_knn &lt;- \n  parsnip::nearest_neighbor(neighbors = tune()) |&gt; \n  parsnip::set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"kknn\")\n\n# Construindo um workflow (pipeline) --------------------------------------\nwf_knn &lt;-\n  workflows::workflow() |&gt;\n  workflows::add_recipe(receita) |&gt;\n  workflows::add_model(modelo_knn)\n\n# Cross-validation --------------------------------------------------------\ncv &lt;- \n  treinamento |&gt; \n  rsample::vfold_cv(v = 10L, strata = \"LifeExpectancy\")\n\n# Busca do hiperpar√¢metro k -----------------------------------------------\nmetrica &lt;- metric_set(rmse)\n\n# Extraindo e atualizando range do par√¢metro ------------------------------\nupdate_parametros &lt;-\n  wf_knn |&gt; \n  extract_parameter_set_dials() |&gt;\n  update(\"neighbors\" = neighbors(c(1, 50)))\n\n# Tunagem -----------------------------------------------------------------\nmeu_grid &lt;- dials::grid_max_entropy(update_parametros, size = 60)\n\ntunagem &lt;-\n  tune::tune_grid(\n    wf_knn,\n    resamples = cv,\n    grid = meu_grid,\n    metrics = metrica,\n    control = control_grid(save_pred = TRUE, verbose = TRUE)\n  )\n\np_hiper &lt;- autoplot(tunagem) +\n  labs(title = \"KNN - Sele√ß√£o do n√∫mero k (vizinhos)\", subtitle = \"Sintoniza√ß√£o do hiperpar√¢metro (valor de k)\") +\n  theme(\n    title = element_text(face = \"bold\")\n  )\n\n# Atualizando workflow ----------------------------------------------------\nwf_knn &lt;- \n  wf_knn |&gt; \n  finalize_workflow(select_best(tunagem))\n\n# Ajustar o modelo ao conjunto de treinamento e avaliar no teste --------\najuste_final &lt;- last_fit(wf_knn, splits)\n\n# Ajuste final com toda a base de dados -----------------------------------\nmodelo_final &lt;- fit(wf_knn, data = dados_expectativa_renda)\n\n# Visualizando as predi√ß√µes na base de treino\np_ajuste &lt;- ajuste_final$.predictions[[1L]] |&gt; \n  ggplot(aes(x = LifeExpectancy, y = .pred)) + \n  geom_point(size = 3, alpha = 0.7, col = \"red\") +\n  labs(\n    title = \"Predi√ß√µes versus Real\", \n    subtitle = \"Usando apenas os dados de teste\"\n  ) +\n  xlab(\"LifeExpectancy\") + \n  xlab(\"LifeExpectancy predito\") + \n  theme(\n    title = element_text(face = \"bold\")\n  )\n\n# Unindo os dois plots\np &lt;- p_hiper + p_ajuste + plot_annotation(tag_levels = \"A\")\n\n# Salvando gr√°ficos\nggsave(p, file = \"imgs/plot_hiper_ajuste_tidymodels_knn_whatson.png\", width = 30,\n       height = 15, units = \"cm\")\n\n\nO pacote dials fornece tr√™s fun√ß√µes o grid de par√¢metros. S√£o apenas fun√ß√µes que criam grids para os hiperpar√¢metros, segundo algumas metodologias, mas que na pr√°tica n√£o h√° garantias de qual ir√° funcionar melhor. A ideia √© experimentar e, por meio de uma valida√ß√£o cruzada, decidir por qual utilizar. Normalmente, a grid_max_entropy, utilizada no c√≥digo acima, funciona bem.\n\n\n\ngrid_max_entropy\ngrid_latin_hypercube\ngrid_regular\ngrid_random"
  },
  {
    "objectID": "index.html#tidymodels-knn-e-nadaraya-watson-2",
    "href": "index.html#tidymodels-knn-e-nadaraya-watson-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels kNN e Nadaraya-Watson",
    "text": "Tidymodels kNN e Nadaraya-Watson\n\nPara demonstar que podemos realizar transforma√ß√µes (receitas) na base de dados, entre do processo de treinamento, foi realizado duas transforma√ß√µes na vari√°vel GDPercapita. A primeira foi a Yeo‚ÄìJohnson transformation e a segunda foi uma simples normaliza√ß√£o dos dados (subitrair da m√©dia e dividir pelo desvio padr√£o). A transforma√ß√£o de Yeo‚ÄìJohnson √© uma transforma√ß√£o semelhante a de Box-Cox. A transforma√ß√£o de Yeo‚ÄìJohnson trata de situa√ß√µes que a transforma√ß√£o de Box-Cox n√£o trata. Por exemplo, ela trata de valores negativos e zero.\n\nA ideia do steps utilizados na faze de pr√©-processamento dos dados, em que utilizamos o pacote recipes do R, √© que para novas observa√ß√µes, depois do modelo ajustado, essas transforma√ß√µes ser√£o automaticamente aplicadas aos novos dados."
  },
  {
    "objectID": "index.html#tidymodels-knn-e-nadaraya-watson-3",
    "href": "index.html#tidymodels-knn-e-nadaraya-watson-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels kNN e Nadaraya-Watson",
    "text": "Tidymodels kNN e Nadaraya-Watson"
  },
  {
    "objectID": "index.html#tidymodels-knn-e-nadaraya-watson-4",
    "href": "index.html#tidymodels-knn-e-nadaraya-watson-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels kNN e Nadaraya-Watson",
    "text": "Tidymodels kNN e Nadaraya-Watson\n\nExemplo: Vamos reproduzir todo o fluxo de treinamento que fizemos com o m√©todo kNN no exemplo anterior, agora, utilizando o modelo Nadaraya-Watson. Note que uma vez que entendemos o tidymodels, fica f√°cil adaptar um c√≥digo j√° existente para o treinamento de um outro modelo. Na verdade, o m√©todo de Nadaraya-Watson implementado no tidymodels √© um pouco diferente. Ainda utilizamos a informa√ß√£o de k, em que o valor de h √© deverminado pela m√©dia dos vizinhos mais pr√≥ximos de {\\bf x}_i √† {\\bf x}. Al√©m de k, temos o valor de p para a dist√¢ncia de Minkowski como hiperpar√¢metro. Portanto, aqui, teremos dois hiperpar√¢metros (par√¢metros de sintoniza√ß√£o).\n\n\n\nWorkflow completo do treimanento de um modelo Nadaraya-Watson.\nlibrary(tidymodels)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(doMC)\n\n# Paralelizando o c√≥digo em sistemas Unix\nregisterDoMC(cores = parallel::detectCores())\n\n# Resolvendo eventuais conflitos entre tidymodels e outros pacotes eventualmente\n# carregados:\ntidymodels::tidymodels_prefer()\n\n# Lendo a base de dados:\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados_expectativa_renda &lt;-\n  dados_expectativa_renda |&gt;\n  dplyr::select(-CountryName)\n\n# Setando uma semente\nset.seed(0)\n\n# Divis√£o da base de dados ------------------------------------------------\n# Divis√£o inicial (treino e teste)\nsplits &lt;- \n  rsample::initial_split(\n    dados_expectativa_renda,\n    strata = \"LifeExpectancy\", \n    prop = 0.8 \n  )\n\n# O conjunto de dados de treinamento ser√° utilizado para ajustar/treinar o\n# modelo:\ntreinamento &lt;- rsample::training(splits)\n\n# O conjunto de teste ser√° utilizado apenas no fim, para avaliar o desempenho\n# preditivo final do modelo:\nteste &lt;- rsample::testing(splits) \n\n# Criando uma receita para os dados ---------------------------------------\n\n# Poderia ter passado o conjunto treinamento ou posso passar o conjunto \"splits\".\n# O comando recipes j√° entende que dever√° utilizar o conjunto de treinamento.\nreceita &lt;- \n  recipes::recipe(formula = LifeExpectancy ~ ., data = treinamento) |&gt; \n  step_YeoJohnson(all_predictors()) |&gt; # Ajuda na normaliza√ß√£o dos dados. Pode ser bom!\n  step_normalize(all_predictors()) # Normalizando vari√°veis num√©ricas.\n\n# Construindo modelo Nadaraya ---------------------------------------------\nmodelo_nadaraya &lt;- \n  parsnip::nearest_neighbor(dist_power = tune(), weight_func = \"gaussian\") |&gt; \n  parsnip::set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"kknn\")\n\n# Construindo um workflow (pipeline) --------------------------------------\nwf_nadaraya &lt;-\n  workflows::workflow() |&gt;\n  workflows::add_recipe(receita) |&gt;\n  workflows::add_model(modelo_nadaraya)\n\n# Cross-validation --------------------------------------------------------\ncv &lt;- \n  treinamento |&gt; \n  rsample::vfold_cv(v = 10L, strata = \"LifeExpectancy\")\n\n# Busca do hiperpar√¢metro k -----------------------------------------------\nmetrica &lt;- metric_set(rmse)\n\n# Extraindo e atualizando range do par√¢metro ------------------------------\nupdate_parametros &lt;-\n  wf_nadaraya |&gt; \n  extract_parameter_set_dials() |&gt;\n  update(\"dist_power\" = dist_power(c(2, 50)))\n\n# Tunagem -----------------------------------------------------------------\nmeu_grid &lt;- dials::grid_max_entropy(update_parametros, size = 100L)\n\ntunagem &lt;-\n  tune::tune_grid(\n    wf_knn,\n    resamples = cv,\n    grid = meu_grid,\n    metrics = metrica,\n    control = control_grid(save_pred = TRUE, verbose = TRUE)\n  )\n\np_hiper &lt;- autoplot(tunagem) +\n  labs(title = \"Nadaraya-Watson - Sele√ß√£o do par√¢metro p\", subtitle = \"Sintoniza√ß√£o do hiperpar√¢metro (dist√¢ncia p)\") +\n  theme(\n    title = element_text(face = \"bold\")\n  )\n\n# Atualizando workflow ----------------------------------------------------\nwf_nadaraya &lt;- \n  wf_nadaraya |&gt; \n  finalize_workflow(select_best(tunagem))\n\n# Ajustar o modelo ao conjunto de treinamento e avaliar no teste --------\najuste_final &lt;- last_fit(wf_nadaraya, splits)\n\n# Ajuste final com toda a base de dados -----------------------------------\nmodelo_final &lt;- fit(wf_nadaraya, data = dados_expectativa_renda)\n\n# Visualizando as predi√ß√µes na base de treino\np_ajuste &lt;- ajuste_final$.predictions[[1L]] |&gt; \n  ggplot(aes(x = LifeExpectancy, y = .pred)) + \n  geom_point(size = 3, alpha = 0.7, col = \"red\") +\n  labs(\n    title = \"Predi√ß√µes versus Real\", \n    subtitle = \"Usando apenas os dados de teste\"\n  ) +\n  xlab(\"LifeExpectancy\") + \n  xlab(\"LifeExpectancy predito\") + \n  theme(\n    title = element_text(face = \"bold\")\n  )\n\n# Unindo os dois plots\np &lt;- p_hiper + p_ajuste + plot_annotation(tag_levels = \"A\")\n\n# Salvando gr√°ficos\nggsave(p, file = \"imgs/plot_hiper_ajuste_tidymodels_nadaraya.png\", width = 30,\n       height = 15, units = \"cm\")"
  },
  {
    "objectID": "index.html#tidymodels-knn-e-nadaraya-watson-5",
    "href": "index.html#tidymodels-knn-e-nadaraya-watson-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels kNN e Nadaraya-Watson",
    "text": "Tidymodels kNN e Nadaraya-Watson\n\n ## Tidymodels kNN e Nadaraya-Watson\n\nPodemos visualizar a melhor combina√ß√£o de hiperpar√¢metros, segundo \\widehat{R}(g) usando fazendo:\n\n# As cinco melhores combina√ß√µes\ntunagem |&gt; \n  show_best()"
  },
  {
    "objectID": "index.html#comparando-dois-ou-mais-modelos",
    "href": "index.html#comparando-dois-ou-mais-modelos",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Comparando dois ou mais modelos",
    "text": "Comparando dois ou mais modelos\n\nVoc√™ poderia perguntar: ‚ÄúCerto, mais tenho como comparar dois ou mais modelos de uma √∫nica vez?‚Äù\n\n\n\n\n\n\nA resposta √© Sim!"
  },
  {
    "objectID": "index.html#comparando-dois-ou-mais-modelos-1",
    "href": "index.html#comparando-dois-ou-mais-modelos-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Comparando dois ou mais modelos",
    "text": "Comparando dois ou mais modelos\n\nNa verdade, √© bem mais interessante comparar conjuntamente, visto que para poder compararmos devemos garantir que as mesmas amostras de treinamento e teste est√£o sendo utilizadas, i.e., para termos uma compara√ß√£o mais justa. Claro que d√° para fazer de forma separada, fixando a semente dos geradores de n√∫meros pseudo-aleat√≥rios, para que a biblioteca rsample possa reproduzir a mesma divis√£o para ambos os modelos. Por√©m, a estrat√©gia do exemplo abaixo √© mais consistente.\n\nExemplo: Estude o c√≥digo que segue! Ele compara os modelos de kNN com o m√©todo de Nadaraya-Watson.\n\n\n\nWorkflow completo do treimanento e compara√ß√£o de dois modelos (KNN e Nadaraya-Whatson).\nlibrary(tidymodels)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Resolvendo eventuais conflitos entre tidymodels e outros pacotes eventualmente\n# carregados:\ntidymodels::tidymodels_prefer()\n\n# Lendo a base de dados:\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados_expectativa_renda &lt;-\n  dados_expectativa_renda |&gt;\n  dplyr::select(-CountryName)\n\n# Setando uma semente\nset.seed(0)\n\n# Divis√£o da base de dados ------------------------------------------------\n# Divis√£o inicial (treino e teste)\nsplits &lt;- \n  rsample::initial_split(\n    dados_expectativa_renda,\n    strata = \"LifeExpectancy\", \n    prop = 0.8 \n  )\n\n# O conjunto de dados de treinamento ser√° utilizado para ajustar/treinar o\n# modelo:\ntreinamento &lt;- rsample::training(splits)\n\n# O conjunto de teste ser√° utilizado apenas no fim, para avaliar o desempenho\n# preditivo final do modelo:\nteste &lt;- rsample::testing(splits) \n\n# Criando uma receita para os dados ---------------------------------------\n\n# Poderia ter passado o conjunto treinamento ou posso passar o conjunto \"splits\".\n# O comando recipes j√° entende que dever√° utilizar o conjunto de treinamento.\nreceita_knn &lt;- \n  recipes::recipe(formula = LifeExpectancy ~ ., data = treinamento) |&gt; \n  step_YeoJohnson(all_predictors()) |&gt; # Ajuda na normaliza√ß√£o dos dados. Pode ser bom!\n  step_normalize(all_predictors()) # Normalizando vari√°veis num√©ricas.\n\nreceita_nadaraya &lt;- receita_knn\n\n# Construindo modelo kNN --------------------------------------------------\nmodelo_knn &lt;- \n  parsnip::nearest_neighbor(neighbors = tune()) |&gt; \n  parsnip::set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"kknn\")\n\n# Construindo modelo Nadaraya ---------------------------------------------\nmodelo_nadaraya &lt;- \n  parsnip::nearest_neighbor(dist_power = tune(), neighbors = tune(),\n                            weight_func = \"gaussian\") |&gt; \n  parsnip::set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"kknn\")\n\n# Valida√ß√£o cruzada -------------------------------------------------------\nset.seed(0)\ncv &lt;- rsample::vfold_cv(treinamento, v = 5L)\n\n# Criando workflow conjunto -----------------------------------------------\nall_wf &lt;- \n  workflow_set(\n    preproc = list(receita_knn, receita_nadaraya),\n    models = list(modelo_knn = modelo_knn, modelo_nadaraya = modelo_nadaraya)\n  )\n\n# Tunando ambos os modelos ------------------------------------------------\ntunagem &lt;- \n  all_wf |&gt; \n  workflow_map(\n    seed = 0, \n    verbose = TRUE,\n    resamples = cv,\n    grid = 50,\n    metrics = metric_set(rmse)\n  )\n\n# Selecionando o melhor de cada um dos modelos ----------------------------\nmelhor_knn &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"recipe_1_modelo_knn\") |&gt; \n  select_best(\"rmse\")\n\nmelhor_nadaraya &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"recipe_1_modelo_nadaraya\") |&gt; \n  select_best(\"rmse\")\n\n# Avaliando o desempenho no conjunto de teste\nteste_knn &lt;- \n  tunagem |&gt; \n  extract_workflow(\"recipe_1_modelo_knn\") |&gt; \n  finalize_workflow(melhor_knn) |&gt; \n  last_fit(split = splits)\n\nteste_nadaraya &lt;- \n  tunagem |&gt; \n  extract_workflow(\"recipe_1_modelo_nadaraya\") |&gt; \n  finalize_workflow(melhor_nadaraya) |&gt; \n  last_fit(split = splits)\n\n# Visualizando as m√©tricas de cada um\ncollect_metrics(teste_knn)\ncollect_metrics(teste_nadaraya)\n\n# Ajustando o modelo com todos os dados. Aqui escolhemos o Nadaraya-Watson\nmodelo_final &lt;- \n  teste_nadaraya |&gt; \n  extract_workflow(\"recipe_1_modelo_nadaraya\") |&gt; \n  fit(data = dados_expectativa_renda)\n\n# Fazendo previs√µes com novos dados. Aqui usarei os mesmos dados\npredict(modelo_final, new_data = dados_expectativa_renda)\n\n# Salvando o modelo em um arquivo. Aqui estou supondo que salvei em\n# \"~/Downloads/modelo_final.rds\":\n# saveRDS(modelo_final, file = \"~/Downloads/modelo_final.rds\")\n\n# Lendo um modelo salvo para depois fazer predi√ß√µes. Aqui estou supondo que \n# o modelo encontra-se salvo em \"~/Downloads/modelo_final.rds\":\n# readRDS(\"~/Downloads/modelo_final.rds\")\n![](gifs/bom.gif)"
  },
  {
    "objectID": "index.html#suport-vector-regression-machine",
    "href": "index.html#suport-vector-regression-machine",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nM√©todos de estima√ß√£o da fun√ß√£o de regress√£o r({\\bf x}) com base em Reproducing Kernel Hilbert Spaces - RKHs s√£o fam√≠lias de metodologias bastante gerais. A ideia desses m√©todos envolvem definir uma fun√ß√£o objetivo para a quantifica√ß√£o da qualidade das predi√ß√µes e, porteriormente, busca-se uma fun√ß√£o que melhor se ajuste ao espa√ßo de fun√ß√µes \\mathcal{H}. Busca-se uma solu√ß√£o para\n\\argmin_{g \\in \\mathcal{H}} \\sum_{k = 1}^n L(g({\\bf x}_k, y_k)) + \\mathcal{P}(g), \\tag{4} em que L √© uma fun√ß√£o de perda arbitr√°ria, \\mathcal{P} uma medida de complexidade de g e \\mathcal{H} um subespa√ßo de fun√ß√µes.\n\n\n\nOcorre que para um espa√ßo de fun√ß√µes arbitr√°rio, a solu√ß√£o para o problema seria bastante dif√≠cil. A ideia √© poder uma grande fam√≠lia de espa√ßos \\mathcal{H} (RKHs) de modo que a solu√ß√£o do problema seja relativamente simples de ser implementada."
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-1",
    "href": "index.html#suport-vector-regression-machine-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nM√©todos de regress√£o que se baseiam em panaliza√ß√£o em RKHS s√£o uma generaliza√ß√£o da Equa√ß√£o¬†4, em que a fun√ß√£o objetivo nesse caso √© dada por:\n\\argmin_{g \\in \\mathcal{H}_k} \\sum_{k = 1}^n L(g({\\bf x}_k, y_k)) + \\lambda||g||_{\\mathcal{H}_k}^2, \\tag{5} em que \\mathcal{H}_{k} √© um RKHS e L √© uma fun√ß√£o adequada para o problema em quest√£o. Calma que vai ser relativamente simples definir \\mathcal{H}_{k}, uma vez que isso √© feito utilizando fun√ß√µes kernel, em particular, o kernel de Mercer."
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-2",
    "href": "index.html#suport-vector-regression-machine-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nO termo ||g||_{\\mathcal{H}_k}^2 na Equa√ß√£o¬†5 reflete a suavidade das fun√ß√µes em \\mathcal{H}_k e cada espa√ßo poder√° conter uma no√ß√£o de suavidade diferente, a depender da fun√ß√£o de kernel escolhida. Sim, a fun√ß√£o ed kernel e fun√ß√£o de perda L s√£o escolhidas pelo usu√°rio da metodologia.\n\n√â claro que para diferen√ßas kernel (kernel de Mercer), poderemos ter diferentes resultados que pode ser avaliado em um procedimento de valida√ß√£o-cruzada (cross-validation). O par√¢metro \\lambda √© um hiperpar√¢metro que podemos obter dentro de uma valida√ß√£o-cruzada, testando, por exemplo, um grid de par√¢metros, para selecionarmos um \\lambda que forne√ßa o melhor risco estimado \\widehat{R}(g).\n\nA parcela ||g||_{\\mathcal{H}_k}^2 mensura a suavidade das fun√ß√µes em \\mathcal{H}_k. Assim como g, ||g||_{\\mathcal{H}_k}^2 ser√° definidas em termos da fun√ß√£o de kernel, e essa √© a grande sacada!"
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-3",
    "href": "index.html#suport-vector-regression-machine-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nDefini√ß√£o (Kernel de Mercer): Seja K({\\bf x}_a, {\\bf x}_b) uma fun√ß√£o com dom√≠nio em \\mathcal{X} \\times \\mathcal{X} (dom√≠nio das features/covari√°veis/espa√ßo de caracter√≠sticas) que poder√° ser mais geral que \\mathbb{R}^d. Diremos que uma fun√ß√£o K, tal que K:{\\mathcal{X}\\times\\mathcal{X}}\\longrightarrow \\mathbb{R} √© um Kernel de Mercer se ele satisfaz √†s condi√ß√µes que seguem:\n\n\nSimetria: K({\\bf x}_a, {\\bf x}_b) = K({\\bf x}_b, {\\bf x}_a), para todo {\\bf x}_a,{\\bf x}_b \\in \\mathcal{X};\nPositivo semi-definido: a matriz \\big[K({\\bf x}_a,{\\bf x}_b)\\big]_{i,j = 1}^n √© positiva semi-definida para todo n \\in \\mathbb{N} e para todo {\\bf x}_1,\\cdots, {\\bf x}_n \\in \\mathcal{X}.\n\n\nSer positiva semi-definida, significa que para qualquer sequ√™ncia c_r \\in \\mathbb{R}\\,, \\forall r = 1, \\cdots, n, temos que\n\\sum_{i = 1}^n\\sum_{k = 1}^n c_i c_k K({\\bf x}_i,{\\bf x}_k)\\geq 0,\\, \\forall n \\geq 2."
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-4",
    "href": "index.html#suport-vector-regression-machine-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nAlguns kernels de Mercer comuns s√£o:\n\n\nKernel Linear: K({\\bf x}_i, {\\bf x}_l) = {\\bf x}_i^T{\\bf x}_l;\nKernel Polinomial de grau p: K({\\bf x}_i, {\\bf x}_l) = (1 + \\langle{\\bf x}_i, {\\bf x}_l\\rangle)^p, \\gamma &gt; 0, \\theta \\geq 0, p \\in \\mathbb{N};\nKernel Gaussiano: K({\\bf x}_i, {\\bf x}_l) = \\exp\\left\\{-\\frac{d^2({\\bf x}_i, {\\bf x}_l)}{2h^2}\\right\\},\\, h &gt; 0;\nKernel Laplaciano: K({\\bf x}_i, {\\bf x}_l) = \\mathrm{e}^{-\\gamma d({\\bf x}_i, {\\bf x}_l)}\\,, \\gamma &gt; 0;\nKernel Sigm√≥ide: K({\\bf x}_i, {\\bf x}_l) = \\tanh(\\gamma {\\bf x}_i^T{\\bf x}_l + \\theta), \\, \\gamma&gt;0, \\theta&gt;0.\n\n\nem que \\gamma, h, \\theta e p, s√£o par√¢metros do kernel."
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-5",
    "href": "index.html#suport-vector-regression-machine-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nA ideia principal por tr√°s dos m√©todos que fazem uso de kernel √© fazer o uso de um mapeamento n√£o-linear arbitr√°rio \\phi do espa√ßo original dos padr√µes de entrada para um espa√ßo de mais alta dimens√£o, \\mathcal{X} \\times \\mathcal{X} chamado de espa√ßo de caracter√≠sticas.\n\nUm conjunto de padr√µes que entrada, em um problema de classifica√ß√£o, por exemplo, que n√£o √© linearmente separ√°vel poder√° se tornar linearmente separ√°vel atrav√©s desse mapeamento n√£o linear.\n\nEm um espa√ßo vetorial, o produto interno, \\langle{\\bf x}_i,{\\bf x}_j\\rangle = {\\bf x}_i^{T}{\\bf x}_j, normalmente √© utilizado como medida de similaridade entre vetores. Por√©m, como n√£o conhecemos \\phi(\\cdot), n√£o √© poss√≠vel realizar \\phi({\\bf x}_i)^T\\phi({\\bf x}_j) em \\mathcal{X}\\times\\mathcal{X}. Aparentemente √© bem complicado calcular \\langle\\phi({\\bf x}_i),\\phi({\\bf x}_j)\\rangle, sem conhecer \\phi(\\cdot), n√£o √© verdade?!"
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-6",
    "href": "index.html#suport-vector-regression-machine-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nA ess√™ncia dos m√©todos m√©todos baseado em kernel, √© que n√£o precisamos conhecer \\phi(\\cdot). Os produtos internos no espa√ßo de caracter√≠sticas poder√° ser calculado utilizando um kernel de Mercer.\n\nTeorema de Mercer: Todo kernel de Mercer K pode ser decomposto como\nK({\\bf x}_a,{\\bf x}_b) = \\sum_{i \\geq 0} \\gamma_i \\phi_i({\\bf x}_a)\\phi_i({\\bf x}_b), \\tag{6} em que \\sum_{i \\geq 0} \\gamma_i^2 &lt; \\infty e \\phi_0, \\phi_1, \\cdots √© uma sequ√™ncia de fun√ß√µes. Essa propriedade dos em que o kernel de Mercer poder√° ser decomposto na forma acima e que n√£o precisamos conhecer \\phi(\\cdot) para o c√°lculo de produtos internos no espa√ßo de caracter√≠sticas √© comumente denominada de kernel trick/truque kernel. Ver detalhes em aqui."
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-7",
    "href": "index.html#suport-vector-regression-machine-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nDefini√ß√£o: Seja K um kernel de Mercer, e sejam \\phi_i e \\gamma_i,\\, i \\geq 0, da forma do teorema acima. Ent√£o,\n\n\\mathcal{H}_K = \\left\\{g \\in L^2(\\mathcal{X}):\\,\\, existem\\,\\, (c_i)_{i\\geq0}\\,\\, com\\,\\,\\sum_{i\\geq1}\\frac{c_i^2}{\\gamma_i} &lt; \\infty\\,\\,,\\, tais\\,\\, que\\,\\, g({\\bf x}) = \\sum_{i\\geq1} c_i\\phi_i({\\bf x}) \\right\\}.\n\nDiremos que \\mathcal{H}_k √© o Reproducing Kernel Hilbert Space - RKHS associado ao kernel K, em que a norma de uma fun√ß√£o g({\\bf x}) = \\sum_{i\\geq0}c_i\\phi({\\bf x}) √© definda por\n||g||_{\\mathcal{H}_k}^2 := \\sum_{i \\geq 0} c_i^2/\\gamma_i.\n\nAl√©m disso, tem-se que \\mathcal{H}_K √© √∫nica para um dado K, muito embora a decomposi√ß√£o dada pela Equa√ß√£o¬†6 n√£o seja √∫nica."
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-8",
    "href": "index.html#suport-vector-regression-machine-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n O Teorema que segue, frequentemente atribu√≠do a ao artigo Kimeldorf, G. S. & Wahba, G. (1970). A correspondence between Bayesian estimation on stochastic processes and smoothing by splines. The Annals of Mathematical Statistics, 495‚Äì502, simplifica o problema de otimizar a fun√ß√£o objetivo dada na Equa√ß√£o¬†5.\n\nTeorema da Representa√ß√£o: Seja K um kernel de Mercer correspondente ap RKHS \\mathcal{H}_K. Considere o conjunto de treinamento ({\\bf x}_1, y_1), \\cdots, ({\\bf x}_n, y_n) e uma fun√ß√£o de perda arbitr√°ria L. Ent√£o, a solu√ß√£o de\n\n\\argmin_{g \\in \\mathcal{H}_K} \\sum_{k = 1}^n L(g({\\bf x}_k), y_k) + \\lambda||g||_{\\mathcal{H}_K^2}, \\tag{7} existe, e √© √∫nica, em que\n\ng({\\bf x}) = \\sum_{k=1}^n \\alpha_k K({\\bf x}_k, {\\bf x}), em que \\alpha_1, \\cdots, \\alpha_n √© uma sequ√™ncia de valores reais."
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-9",
    "href": "index.html#suport-vector-regression-machine-9",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\n√â poss√≠vel desmontrar que a otimiza√ß√£o da Equa√ß√£o¬†7 poder√° se dar pela otimiza√ß√£o de\n\n\\argmin_{\\alpha_1, \\cdots, \\alpha_n}\\sum_{k = 1}^n L\\left(\\overbrace{\\sum_{i=1}^n\\alpha_iK({\\bf x}_i, {\\bf x})}^{g({\\bf x})}, y_k \\right) + \\lambda\\underbrace{\\sum_{1 \\leq j,k \\leq n}\\alpha_i\\alpha_k K({\\bf x}_j, {\\bf x}_k)}_{||g||_{\\mathcal{H}_K}^2}.\n\nPortanto, o problema de otimizar a fun√ß√£o objetivo dada na Equa√ß√£o¬†5 se reduz a encontrar os valores de \\alpha_1, \\cdots, \\alpha_n que minimiza a Equa√ß√£o¬†7. Portanto, ir√° especificar o kernel K e a fun√ß√£o de perda L, em que \\lambda √© um par√¢metro de sintoniza√ß√£o (hiperpar√¢metro) que poder√° ser obtido por uma valida√ß√£o cruzada."
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-10",
    "href": "index.html#suport-vector-regression-machine-10",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nEm se tratando de estimadores de regress√£o, Support Vector Regression Machines, utiliza-se uma fun√ß√£o de perda diferente da quadr√°tica, como definido em Drucker, H., Burges, C. J., Kaufman, L., Smola, A. J. & Vapnik, V. (1997). Support vector regression machines em Advances in neural information processing systems.\n\nEles definem a seguinte fun√ß√£o de perda L(g({\\bf x}_k, y_k)) = (|y_k - g({\\bf x}_k)| - \\varepsilon)_{+}, que assume o valor 0 se |y_k - g({\\bf x}_k)| &lt; \\varepsilon e assumir√° |y_k - g({\\bf x}_k)| - \\varepsilon, caso contr√°rio."
  },
  {
    "objectID": "index.html#suport-vector-regression-machine-11",
    "href": "index.html#suport-vector-regression-machine-11",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Suport Vector Regression Machine",
    "text": "Suport Vector Regression Machine\n\nExemplo: Vamos consirar a base de dados de vinho vermelhoüç∑, dispon√≠veis aqui, fa√ßa uma pequena an√°lise explorat√≥ria dos dados. No link do Kaggle voc√™ consegue uma explica√ß√£o sobre o que significa cada uma das vari√°veis."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o",
    "href": "index.html#√°rvores-de-regress√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nEm aprendizagem de m√°quina, uma arvore de regress√£o consiste em uma metodologia n√£o-param√©trica que nos leva a resultados que s√£o facilmente interpret√°veis. A √°rvore √© construirda por meio de particionamentos recursivos no espa√ßo das covari√°veis. Cada parti√ß√£o recebe o nome de n√≥ e o resultado final (valor da regress√£o) √© denominado de folha üçÉ.\n\nExemplo: Construindo uma √°rvore de regress√£o, usando a biblioteca rpart para constru√ß√£o da √°rvore e a biblioteca rpart.plot para a plotagem da √°rvore estimada.\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ndados &lt;- readr::read_csv(file = \"dados/winequality-red.csv\", show_col_types = FALSE)\narvore &lt;-  rpart::rpart(formula = quality ~ ., data = dados)\nrpart.plot(arvore, type = 4, extra = 1)\n\n\nPerceba que h√° um particionamento bin√°rio em cada n√≥ da √°rvore üå≥ e que poderemos sequir para a aresta da esquerda quando a condi√ß√£o no n√≥ for verdadeira e para direita caso contr√°rio. Dada uma nova observa√ß√£o {\\bf x}_i, poderemos seguir as condi√ß√µes da √°rvore at√© chegar a uma folha üçÉ dessa √°rvore. Nesse caso, a folha üçÉ cont√©m uma estimativa da qualidade do vinho.\n\nPor exemplo, na √°rvore acima podemos perceber que vinhos com teor alco√≥lico inferior √† 11 nos conduzem a vinhos üç∑ de qualidade inferior. Temos que vinhos com teor alco√≥lico maior que 11 e com sulfato maior que 0.65 nos levam √† √≥timos vinhos, segundo o conjunto de dados utilizado.\n\nPerceba que dado {\\bf x}_i, poderemos percorrer a √°rvore a m√£o."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-1",
    "href": "index.html#√°rvores-de-regress√£o-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nFormalmente, temos que a metodologia de estima√ß√£o de uma √°rvore de regress√£o cria uma parti√ß√£o no espa√ßo das covari√°veis em regi√µes distintas e disjuntas, que denotaremos de R_1, R_2, \\cdots, R_j, com R_a \\cap R_b, \\forall a,b \\in 1, \\cdots, j. A predi√ß√£o √© dada por:\ng({\\bf x}) = \\frac{1}{|\\{i:{\\bf x}_i \\in R_k\\}|}\\sum_{i:{\\bf x}_i \\in R_k} y_i.\n\nA constru√ß√£o de uma √°rvore de regress√£o envolve dois passos principais:\n\n\nA cria√ß√£o de uma √°rvore complexa que nos leve a parti√ß√µes ‚Äúpuras‚Äù, i.e., a parti√ß√µes nas observa√ß√µes do conjunto de covari√°veis que nos leve a valores de Y, no conjunto de treinamento em cada uma das folhas sejam homog√™neas;\nPodar a √°rvore, com a finalidade de evitarmos super-ajuste (overffiting), e portanto, termos uma alta vari√¢ncia do modelo."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-2",
    "href": "index.html#√°rvores-de-regress√£o-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nA ideia de uma √°rvore üå≥ pura √© de que ‚Äútodo mundo‚Äù que cai em uma dada folha √© muito homog√™neo em rela√ß√£o a vari√°vel resposta (ao r√≥tulo/label).\n\nEm uma √°rvore de regress√£o, a maneira mais simples de definir pureza √© utilizar o EQM."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "",
    "text": "Aprendizagem de M√°quina\nBacharelado em Estat√≠stica\nUFPB"
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-3",
    "href": "index.html#√°rvores-de-regress√£o-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nNo passo 1, para avaliarmos o qu√£o razo√°vel √© uma √°rvore T, utilizamos o Erro Quadr√°tico M√©dio - EQM, em que\n\\mathcal{P}(T) = \\sum_{R}\\sum_{i:{\\bf x}_i \\in R} \\frac{(y_i - \\widehat{y}_R)^2}{n}, em que \\widehat{y}_R √© o valor predito de y para a resposta de uma observa√ß√£o pertencente √† regi√£o R. No gr√°fico de uma √°rvore de regress√£o, o R √© dado por todos os indiv√≠duos na base de dados que est√£o em uma dada folha üçÉ.\n\nEncontrar uma √°rvore T que minimize \\mathcal{P}(T) √© uma tarefa computacionalmente cara. Por isso, que os algoritmos de estima√ß√£o de T normalmente utilizam parti√ß√µes bin√°rias, como no exemplo anterior.\n\nExistem diversos algoritmos utilizados para estima√ß√£o de T, em que o Classification And Regression Tree - CART √© o mais conhecido. O algoritmo foi estabelecido no livro Breiman L., Friedman J. H., Olshen R. A., and Stone, C. J. (1984) Classification and Regression Trees. Wadsworth."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-4",
    "href": "index.html#√°rvores-de-regress√£o-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nO algoritmo particiona o espa√ßo de covari√°veis em duas regi√µes disjuntas. Para a escolha dessa parti√ß√£o, busca-se, dentre todas as covari√°veis x_i e cortes t_1, a combina√ß√£o que conduz a uma parti√ß√£o (R_1, R_2) com menor predi√ß√µes de erro quadr√°tico, i.e., dado um n√≥, a parti√ß√£o √© constru√≠da de modo a minimizar:\n\\overbrace{SSE}^{\\text{sum of squares error}} = \\sum_{i:{\\bf x}_i \\in R_1}^n (y_i - \\widehat{y}_{R_1})^2 + \\sum_{i:{\\bf x}_i \\in R_2}^n (y_i - \\widehat{y}_{R_2})^2, \\tag{8} em que \\widehat{y}_{R_k} √© a predi√ß√£o de y fornecida pela regi√£o R_k e SSE √© denominado Sum of Squares of Errors - SSE.\n\nAssim, tem-se que o algoritmo ir√° fornecer:\n\nR_1 = \\{{\\bf x} : {\\bf x}_i &lt; t_1\\}\\, \\mathrm{e}\\, R_2 = \\{{\\bf x} : {\\bf x}_i \\geq t_1\\}, em que x_i √© a vari√°vel escolhida e t_1 √© o corte definido."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-5",
    "href": "index.html#√°rvores-de-regress√£o-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nUma vez que estabelecemos um n√≥ raiz, este √© fixado. No passo seguinte, o algoritmo ir√° particionar as regi√µes R_1 e R_2 em regi√µes menores, seguindo o mesmo crit√©rio,tanto para R_1 quanto para R_2. O algoritmo continua de forma recursiva at√© que tenhamos uma √°rvore com poucas observa√ß√µes em uma das folhas üçÉ.\n\nPor exemplo, podemos decidir em parar de tornar a √°rvore profunda quando em cada folha tivermos menos de 5 observa√ß√µes. Por√©m, essa √°rvore criada ir√° produzir boas predi√ß√µes para o conjunto de treinamento, por√©m, n√£o ir√° performar bem em novas observa√ß√µes. Isso, por conta, do trade off entre vi√©s e vari√¢ncia. Em outras palavas, haver√° overfitting.\n Na etapa do processo de poda, cada n√≥ √© retirado, um por vez, e observa-se como o erro de predi√ß√£o varia no conjunto de valida√ß√£o. Com base nisso, decide-se quais n√≥s permanecem na √°rvore. O processo de poda reduz o overffiting do modelo."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-6",
    "href": "index.html#√°rvores-de-regress√£o-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nUma observa√ß√£o importante √© que sempre √© bom crescer a √°rvore ao m√°ximo poss√≠vel e depois proceder com a etapa de ‚Äúpoda‚Äù, em que removemos os ramos mais profundos e reavaliamos o poder preditivo da √°rvore üå≥ T. Isso porqu√™ a melhoria do poder preditivo da √°rvore n√£o √© linear, i.e., as vezes podemos ter uma divis√£o que piore um pouco a capacidade preditiva da √°rvore, por√©m, a divis√£o seguinte poder√° dar um grande salto de melhoria. Dessa forma, √© mais conveniente deixar a √°rvore ‚Äúprofunda‚Äù para depois sairmos ‚Äúpodando‚Äù ‚úÇÔ∏è a √°rvore üå≥."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-7",
    "href": "index.html#√°rvores-de-regress√£o-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nPara limitar a profundidade da arvore T a ser estimada, um par√¢metro de penaliza√ß√£o/complexidade poder√° ser introduzido na Equa√ß√£o¬†8. Assim, o problema consistem em obter regi√µes e pontos de cortes que minimize:\nSSE + \\alpha|T|, em que \\alpha &gt; 0 √© o hiperpar√¢metro de complexidade do modelo e |T| √© um valor inteiro que define a profundidade m√°xima da √°rvore. Por exemplo, |T| na biblioteca rpart √© definido pelo par√¢metro tree_depth em 30. Normalmente nos concentramos em em tunar o par√¢metro cost_complexity que √© o \\alpha."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-8",
    "href": "index.html#√°rvores-de-regress√£o-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nExemplo: Poderemos podar a √°rvore usando a fun√ß√£o prune do pacote rpart. Considerando o exemplo anterior, tornando a √°rvore menos comple√ßa, poder√≠amos decidir em podar alterando o seu par√¢metro de complexidade.\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ndados &lt;- readr::read_csv(file = \"dados/winequality-red.csv\")\n\narvore &lt;- dados |&gt; \n  rpart::rpart(formula = quality ~ ., data = _) \n\n# O melhor par√¢metro de custo\nmelhor_grau &lt;- arvore$cptable[nrow(arvore$cptable),][1L]\n\n# Aumentando o par√¢metro de custo de 0.01 para 0.04\narvore_podada &lt;- rpart::prune(tree = arvore, cp = 0.04)\n\n# Plotando a √°rvore podada\nrpart.plot::rpart.plot(arvore_podada)"
  },
  {
    "objectID": "reports_code/tufte_svm_regressao.html",
    "href": "reports_code/tufte_svm_regressao.html",
    "title": "Suport Vector Regression Machine - SVRM",
    "section": "",
    "text": "library(tidymodels)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels 1.1.0 ‚îÄ‚îÄ\n\n\n‚úî broom        1.0.5     ‚úî recipes      1.0.6\n‚úî dials        1.2.0     ‚úî rsample      1.1.1\n‚úî dplyr        1.1.2     ‚úî tibble       3.2.1\n‚úî ggplot2      3.4.2     ‚úî tidyr        1.3.0\n‚úî infer        1.0.4     ‚úî tune         1.1.1\n‚úî modeldata    1.1.0     ‚úî workflows    1.1.3\n‚úî parsnip      1.1.0     ‚úî workflowsets 1.0.1\n‚úî purrr        1.0.1     ‚úî yardstick    1.2.0\n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels_conflicts() ‚îÄ‚îÄ\n‚úñ purrr::discard() masks scales::discard()\n‚úñ dplyr::filter()  masks stats::filter()\n‚úñ dplyr::lag()     masks stats::lag()\n‚úñ recipes::step()  masks stats::step()\n‚Ä¢ Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî forcats   1.0.0     ‚úî readr     2.1.4\n‚úî lubridate 1.9.2     ‚úî stringr   1.5.0\n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ readr::col_factor() masks scales::col_factor()\n‚úñ purrr::discard()    masks scales::discard()\n‚úñ dplyr::filter()     masks stats::filter()\n‚úñ stringr::fixed()    masks recipes::fixed()\n‚úñ dplyr::lag()        masks stats::lag()\n‚úñ readr::spec()       masks yardstick::spec()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(skimr)\n\n# Resolvendo poss√≠veis conflitos entre o tidymodels e outras bibliotecas\ntidymodels::tidymodels_prefer()"
  },
  {
    "objectID": "reports_code/tufte_svm_regressao.html#carregando-bibliotecas-necess√°rias",
    "href": "reports_code/tufte_svm_regressao.html#carregando-bibliotecas-necess√°rias",
    "title": "Suport Vector Regression Machine - SVRM",
    "section": "",
    "text": "library(tidymodels)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels 1.1.0 ‚îÄ‚îÄ\n\n\n‚úî broom        1.0.5     ‚úî recipes      1.0.6\n‚úî dials        1.2.0     ‚úî rsample      1.1.1\n‚úî dplyr        1.1.2     ‚úî tibble       3.2.1\n‚úî ggplot2      3.4.2     ‚úî tidyr        1.3.0\n‚úî infer        1.0.4     ‚úî tune         1.1.1\n‚úî modeldata    1.1.0     ‚úî workflows    1.1.3\n‚úî parsnip      1.1.0     ‚úî workflowsets 1.0.1\n‚úî purrr        1.0.1     ‚úî yardstick    1.2.0\n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels_conflicts() ‚îÄ‚îÄ\n‚úñ purrr::discard() masks scales::discard()\n‚úñ dplyr::filter()  masks stats::filter()\n‚úñ dplyr::lag()     masks stats::lag()\n‚úñ recipes::step()  masks stats::step()\n‚Ä¢ Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî forcats   1.0.0     ‚úî readr     2.1.4\n‚úî lubridate 1.9.2     ‚úî stringr   1.5.0\n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ readr::col_factor() masks scales::col_factor()\n‚úñ purrr::discard()    masks scales::discard()\n‚úñ dplyr::filter()     masks stats::filter()\n‚úñ stringr::fixed()    masks recipes::fixed()\n‚úñ dplyr::lag()        masks stats::lag()\n‚úñ readr::spec()       masks yardstick::spec()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(skimr)\n\n# Resolvendo poss√≠veis conflitos entre o tidymodels e outras bibliotecas\ntidymodels::tidymodels_prefer()"
  },
  {
    "objectID": "reports_code/tufte_svm_regressao.html#importando-a-base-de-dados",
    "href": "reports_code/tufte_svm_regressao.html#importando-a-base-de-dados",
    "title": "Suport Vector Regression Machine - SVRM",
    "section": "2 Importando a base de dados",
    "text": "2 Importando a base de dados\nUtilizando os dados de vinho vermelhoüç∑, dispon√≠veis aqui, fa√ßa uma pequena an√°lise explorat√≥ria dos dados. No link do Kaggle voc√™ consegue uma explica√ß√£o sobre o que significa cada uma das vari√°veis.\nOs dados, no meu caso, est√£o no diret√≥rio \"../dados/winequality-red.csv\". Voc√™ dever√° alterar o path para o diret√≥rio encontra-se a base que dever√° ser obtida no link acima.\n\ndados &lt;- readr::read_csv(file = \"../dados/winequality-red.csv\")\n\nRows: 1599 Columns: 12\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\ndbl (12): fixed acidity, volatile acidity, citric acid, residual sugar, chlo...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "reports_code/tufte_svm_regressao.html#uma-explora√ß√£o-r√°pida-dos-dados",
    "href": "reports_code/tufte_svm_regressao.html#uma-explora√ß√£o-r√°pida-dos-dados",
    "title": "Suport Vector Regression Machine - SVRM",
    "section": "3 Uma explora√ß√£o r√°pida dos dados",
    "text": "3 Uma explora√ß√£o r√°pida dos dados\n√â sempre importante olhar os dados antes de tentar modelar. Uma an√°lise explorat√≥ria sempre ser√° √∫til para identificarmos poss√≠veis inconsist√™ncias.\n\nvisdat::vis_dat(dados)\n\n\n\n\nO gr√°fico acima mostra que temos uma base de dados sem informa√ß√µes faltantes e todas as features presentes na base s√£o num√©ricas. √â uma situa√ß√£o confort√°vel, haja vista que, aqui, n√£o precisaremos nos preocupar com imputa√ß√£o de dados faltantes.\nUm resumo dos dados poder√° ser obtido utilizando a fun√ß√£o glimpse do pacote dplyr que √© carregado com a biblioteca tidyverse de R.\n\ndados |&gt; \n  dplyr::glimpse()\n\nRows: 1,599\nColumns: 12\n$ `fixed acidity`        &lt;dbl&gt; 7.4, 7.8, 7.8, 11.2, 7.4, 7.4, 7.9, 7.3, 7.8, 7‚Ä¶\n$ `volatile acidity`     &lt;dbl&gt; 0.700, 0.880, 0.760, 0.280, 0.700, 0.660, 0.600‚Ä¶\n$ `citric acid`          &lt;dbl&gt; 0.00, 0.00, 0.04, 0.56, 0.00, 0.00, 0.06, 0.00,‚Ä¶\n$ `residual sugar`       &lt;dbl&gt; 1.9, 2.6, 2.3, 1.9, 1.9, 1.8, 1.6, 1.2, 2.0, 6.‚Ä¶\n$ chlorides              &lt;dbl&gt; 0.076, 0.098, 0.092, 0.075, 0.076, 0.075, 0.069‚Ä¶\n$ `free sulfur dioxide`  &lt;dbl&gt; 11, 25, 15, 17, 11, 13, 15, 15, 9, 17, 15, 17, ‚Ä¶\n$ `total sulfur dioxide` &lt;dbl&gt; 34, 67, 54, 60, 34, 40, 59, 21, 18, 102, 65, 10‚Ä¶\n$ density                &lt;dbl&gt; 0.9978, 0.9968, 0.9970, 0.9980, 0.9978, 0.9978,‚Ä¶\n$ pH                     &lt;dbl&gt; 3.51, 3.20, 3.26, 3.16, 3.51, 3.51, 3.30, 3.39,‚Ä¶\n$ sulphates              &lt;dbl&gt; 0.56, 0.68, 0.65, 0.58, 0.56, 0.56, 0.46, 0.47,‚Ä¶\n$ alcohol                &lt;dbl&gt; 9.4, 9.8, 9.8, 9.8, 9.4, 9.4, 9.4, 10.0, 9.5, 1‚Ä¶\n$ quality                &lt;dbl&gt; 5, 5, 5, 6, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5,‚Ä¶\n\n\n√â poss√≠vel todas as correla√ß√µes entre todas as vari√°veis da base, com a fun√ß√£o data_vis_cor. Um gr√°fico √∫til com as correla√ß√µes poder√° ser obtido usando a fun√ß√£o vis_cor, conforme abaixo:\n\nvisdat::data_vis_cor(dados)\n\n# A tibble: 144 √ó 3\n   row_1         row_2                  value\n   &lt;chr&gt;         &lt;chr&gt;                  &lt;dbl&gt;\n 1 fixed acidity fixed acidity         1     \n 2 fixed acidity volatile acidity     -0.256 \n 3 fixed acidity citric acid           0.672 \n 4 fixed acidity residual sugar        0.115 \n 5 fixed acidity chlorides             0.0937\n 6 fixed acidity free sulfur dioxide  -0.154 \n 7 fixed acidity total sulfur dioxide -0.113 \n 8 fixed acidity density               0.668 \n 9 fixed acidity pH                   -0.683 \n10 fixed acidity sulphates             0.183 \n# ‚Ñπ 134 more rows\n\nvisdat::vis_cor(dados)\n\n\n\n\nUm gr√°fico de scatterplot para as vari√°veis num√©ricas poder√° ser √∫til. Voc√™ poder√° fazer isso, usando a fun√ß√£o ggcatmat do pacote GGally.\n\ndados |&gt; \n  GGally::ggscatmat()\n\nWarning: The dot-dot notation (`..scaled..`) was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `after_stat(scaled)` instead.\n‚Ñπ The deprecated feature was likely used in the GGally package.\n  Please report the issue at &lt;https://github.com/ggobi/ggally/issues&gt;.\n\n\n\n\n\nAs bibliotecas GGally e skimr tamb√©m possuem fun√ß√µes √∫teis que podem nos auxiliar no processo de explora√ß√£o dos dados.\n\ndados |&gt; \n  GGally::ggpairs()\n\n\n\ndados |&gt; \n  skimr::skim()\n\n\nData summary\n\n\nName\ndados\n\n\nNumber of rows\n1599\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n12\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nfixed acidity\n0\n1\n8.32\n1.74\n4.60\n7.10\n7.90\n9.20\n15.90\n‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\nvolatile acidity\n0\n1\n0.53\n0.18\n0.12\n0.39\n0.52\n0.64\n1.58\n‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\ncitric acid\n0\n1\n0.27\n0.19\n0.00\n0.09\n0.26\n0.42\n1.00\n‚ñá‚ñÜ‚ñÖ‚ñÅ‚ñÅ\n\n\nresidual sugar\n0\n1\n2.54\n1.41\n0.90\n1.90\n2.20\n2.60\n15.50\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nchlorides\n0\n1\n0.09\n0.05\n0.01\n0.07\n0.08\n0.09\n0.61\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nfree sulfur dioxide\n0\n1\n15.87\n10.46\n1.00\n7.00\n14.00\n21.00\n72.00\n‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n\n\ntotal sulfur dioxide\n0\n1\n46.47\n32.90\n6.00\n22.00\n38.00\n62.00\n289.00\n‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\n\ndensity\n0\n1\n1.00\n0.00\n0.99\n1.00\n1.00\n1.00\n1.00\n‚ñÅ‚ñÉ‚ñá‚ñÇ‚ñÅ\n\n\npH\n0\n1\n3.31\n0.15\n2.74\n3.21\n3.31\n3.40\n4.01\n‚ñÅ‚ñÖ‚ñá‚ñÇ‚ñÅ\n\n\nsulphates\n0\n1\n0.66\n0.17\n0.33\n0.55\n0.62\n0.73\n2.00\n‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n\n\nalcohol\n0\n1\n10.42\n1.07\n8.40\n9.50\n10.20\n11.10\n14.90\n‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ\n\n\nquality\n0\n1\n5.64\n0.81\n3.00\n5.00\n6.00\n6.00\n8.00\n‚ñÅ‚ñá‚ñá‚ñÇ‚ñÅ"
  },
  {
    "objectID": "reports_code/tufte_svm_regressao.html#construindo-os-workflows-dos-modelos",
    "href": "reports_code/tufte_svm_regressao.html#construindo-os-workflows-dos-modelos",
    "title": "Suport Vector Regression Machine - SVRM",
    "section": "4 Construindo os workflows dos modelos",
    "text": "4 Construindo os workflows dos modelos\nIremos comparar os modelos de regress√£o linar utilizando elastic net, com o m√©todo kNN e suport vector regression machine - SVRM. Buscaremos pelo melhor modelo de cada uma das metodologias consideradas. Posteriormente iremos escolher o melhor modelo entre os melhores de cada uma das classes. A ideia √© escolher o melhor modelo que consiga prever melhor a qualidade do vinho, i.e., prever a vari√°vel quality.\n\n4.1 Divis√£o dos dados\nAqui usaremos as fun√ß√µes initial_split, training e testing para realizar o m√©todo hold-out (divis√£o inicial dos dados) em treino e teste. Vamos considerar 80\\% para treino e 20\\% para teste. A fun√ß√£o initial_split ir√° realizar a divis√£o, por√©m, as fun√ß√µes training e testing s√£o respons√°veis para obtermos as tibbles da base de treino e teste, respectivamente.\nAqui, os dados est√° sendo estratificado pelo label, i.e., pela vari√°vel quality que desejamos prever:\n\nset.seed(0) # Fixando uma semente\ndivisao_inicial &lt;- rsample::initial_split(dados, prop = 0.8, strata = \"quality\")\ntreinamento &lt;- rsample::training(divisao_inicial) # Conjunto de treinamento\nteste &lt;- rsample::testing(divisao_inicial) # Conjunto de teste\n\n\n\n4.2 Tratamento dos dados (pr√©-processamento)\nApesar de n√£o haver muito o que fazer nos dados que estamos utilizando nesse exemplo, em que nosso objetivo aqui √© ter uma an√°lise explicativa de como comparar modelos usando o tidymodels, iremos utilizar a biblioteca recipes. Os dados cont√©m apenas vari√°veis num√©ricas com todas informa√ß√µes presentes, tornando o problema um pouco mais simples.\nNa receita, iremos colocar as seguintes etapas:\n\nTomaremos o logar√≠tmo de todas as vari√°veis peditoras (features);\nRemover vari√°veis preditoras (features) que eventualmente est√£o altamente correlacionadas (usando a fun√ß√£o step_corr);\nRemover vari√°veis que possam ter vari√¢ncia pr√≥xima √† zero, i.e., que sejam aproximadamente constantes (usando step_zv);\nNormalizar os dados utilizando a fun√ß√£o step_normalize.\n\nPara que iremos remover vari√°veis altamente correlacionadas apenas nas vari√°veis preditoras, utilizamos a fun√ß√£o all_predictors como argumentod a fun√ß√£o step_corr. J√° no passo de normaliza√ß√£o dos dados, quando consideramos todas as vari√°veis num√©ricas, passamos para a fun√ß√£o step_normalize a fun√ß√£o all_numeric que especifica que dever√° ser normalizado todas as vari√°veis num√©ricas. Na verdade, a normaliza√ß√£o se d√° em todas as vari√°veis num√©ricas, e portanto, esse argumento poderia ser omitido. Al√©m disso, toda nossa base √© formada por vari√°veis num√©ricas, o que torna redundante o uso, mas irei deixar expl√≠cito que todas as vari√°veis num√©ricas est√£o sendo normalizadas.\n\nreceita_1 &lt;- \n  treinamento |&gt; \n    recipe(formula = quality ~ .) |&gt;\n    step_YeoJohnson(all_predictors()) |&gt;\n    step_normalize(all_predictors()) |&gt;\n    step_zv(all_predictors()) |&gt;\n    step_corr(all_predictors())\n\nreceita_2 &lt;- \n  treinamento |&gt; \n    recipe(formula = quality ~ .) |&gt;\n    step_YeoJohnson(all_predictors()) |&gt;\n    step_normalize(all_predictors())\n\nComo fazemos para observar se nosso pr√©-processamento funcionou?\n\nF√°cil, assim:\n\nreceita_1 |&gt; \n  prep() |&gt; \n  juice()\n\n# A tibble: 1,278 √ó 12\n   `fixed acidity` `volatile acidity` `citric acid` `residual sugar` chlorides\n             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1         -0.446              1.00          -1.52            -0.602   -0.245 \n 2         -0.162              1.77          -1.52             0.559    0.198 \n 3         -0.162              1.28          -1.25             0.154    0.0774\n 4         -0.446              1.00          -1.52            -0.602   -0.245 \n 5         -0.446              0.813         -1.52            -0.845   -0.265 \n 6         -0.0949             0.508         -1.12            -1.42    -0.386 \n 7         -0.373             -0.0496         0.527            2.10    -0.346 \n 8         -1.01               0.402         -0.994           -0.845    0.178 \n 9         -0.373             -0.0496         0.527            2.10    -0.346 \n10         -0.162              0.560          0.186           -1.42     0.521 \n# ‚Ñπ 1,268 more rows\n# ‚Ñπ 7 more variables: `free sulfur dioxide` &lt;dbl&gt;,\n#   `total sulfur dioxide` &lt;dbl&gt;, density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;,\n#   alcohol &lt;dbl&gt;, quality &lt;dbl&gt;\n\n\nA fun√ß√£o prep estima uma receita de pr√©-processamento. Algumas fun√ß√µes step_* pode conter par√¢metros que devem ser estimados. Inclusive, poderemos tunar esses par√¢metros com a fun√ß√£o tune do pacote tune. Por exemplo, se tivessemos interesse em interpolar uma feature usando a fun√ß√£o step_ns, o argumento deg_free que refere-se ao grau do polin√¥mio poderia ser ‚Äútunado‚Äù.\nTodas as etapas de pr√©-processamento s√£o estimadas em cima do conjunto de dados de treinamento. Por exemplo, na etapa em que realiza-se a normaliza√ß√£o dos dados, a m√©dia a vari√¢ncia dos dados s√£o estimadas uma √∫nica vez na base de dados completa, e sempre que essa refeita for aplicada a novos dados, ser√° utilizado essa mesma m√©dia e vari√¢ncia, ou seja, n√£o ser√° recalculada com base no novo conjunto de dados.\nPoder√≠amos utilizar a fun√ß√£o bake ao inv√©s da juice. A diferen√ßa de uma para a outra √© que a fun√ß√£o bake utiliza uma receita j√° estimada com prep e poder√° ser aplicada √† novos dados. J√° a juice retorna a tibble com a receita preparada para o conjunto de dados de treinamento, ou ao conjunto de dados ao qual uma receita foi preparada com prep. Usando bake para o conjunto de dados de treinamento, poder√≠amos fazer:\n\nreceita_1 |&gt; \n  prep() |&gt; \n  bake(new_data = treinamento)\n\n# A tibble: 1,278 √ó 12\n   `fixed acidity` `volatile acidity` `citric acid` `residual sugar` chlorides\n             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1         -0.446              1.00          -1.52            -0.602   -0.245 \n 2         -0.162              1.77          -1.52             0.559    0.198 \n 3         -0.162              1.28          -1.25             0.154    0.0774\n 4         -0.446              1.00          -1.52            -0.602   -0.245 \n 5         -0.446              0.813         -1.52            -0.845   -0.265 \n 6         -0.0949             0.508         -1.12            -1.42    -0.386 \n 7         -0.373             -0.0496         0.527            2.10    -0.346 \n 8         -1.01               0.402         -0.994           -0.845    0.178 \n 9         -0.373             -0.0496         0.527            2.10    -0.346 \n10         -0.162              0.560          0.186           -1.42     0.521 \n# ‚Ñπ 1,268 more rows\n# ‚Ñπ 7 more variables: `free sulfur dioxide` &lt;dbl&gt;,\n#   `total sulfur dioxide` &lt;dbl&gt;, density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;,\n#   alcohol &lt;dbl&gt;, quality &lt;dbl&gt;\n\n\n\n\n4.3 Definindo os modelos\nO c√≥digo que segue faz a configura√ß√£o realiza a configura√ß√£o dos modelos que ser√£o comparados. O c√≥digo tune::tune() especifica que o respectivo par√¢metro de sintoniza√ß√£o ser√° obtido no processo de valida√ß√£o cruzada, particularmente, um grid search.\n\nmodelo_elastic &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) |&gt; \n  parsnip::set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"glmnet\")\n\nmodelo_knn &lt;-\n  parsnip::nearest_neighbor(\n    neighbors = tune::tune(),\n    dist_power = tune::tune(), \n    weight_func = \"gaussian\" \n  ) |&gt; \n  parsnip::set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"kknn\")\n\nmodelo_svm &lt;- \n  parsnip::svm_rbf(\n    cost = tune::tune(),\n    rbf_sigma = tune::tune(),\n    margin = tune::tune()\n  ) |&gt; \n  parsnip::set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"kernlab\")\n\n\n\n4.4 Criando o conjunto de valida√ß√£o\nUma vez que temos a divis√£o dos dados em conjunto de treinamento e conjunto de teste, precisamos construir o conjunto de valida√ß√£o, que necesse caso utilizaremos um k-fold cross-validation. Lembre-se que a valida√ß√£o cruzada ocorrer√° sob a amostra de treinamento e necesso processo, a base de dados de treinamento ser√° dividida em k partes aproximadamente iguais em que trainamos o modelo em k-1 e validanos no fold restante, em que isso √© feito k vezes. Utilizando o conjunto k-1 em cada uma das divis√µes da valida√ß√£o cruzada em que diferentes combina√ß√µes de hiperpar√¢metros s√£o experimentadas e avaliada no conjunto de valida√ß√£o em cada divis√£o da valida√ß√£o cruzada.\nO c√≥digo que segue, em que utiliza a fun√ß√£o vfold_cv da biblioteca rsample apenas cria a valida√ß√£o cruzada. Nesse caso, a valida√ß√£o ser√° estratificada considerando a o label quality (qualidade do vinho), assim como foi feito na divis√£o inicial no hold-out (divis√£o inicial dos dados).\nUtilizaremos k=8:\n\nvalidacao_cruzada &lt;- \n  treinamento |&gt; \n  rsample::vfold_cv(v = 8L, strata = quality)\n\n\n\n4.5 Criando um workflow completo\nAqui criaremos um workflow completo com todos modelos a serem comparados. Chamaremos ele de wf_todos:\n\nwf_todos &lt;-\n  workflow_set(\n    preproc = list(receita_1, receita_2),\n    models = list(\n      knn_fit = modelo_knn,\n      elastic_fit = modelo_elastic,\n      svm_fit = modelo_svm\n    ),\n    cross = TRUE\n  )\n\nPodemos manipular alguns argumentos que controlam aspectos da pesquisa em grade (grid search).. Fazemos isso com o uso da fun√ß√£o control_grid da biblioteca parsnip. Por exemplo, podemos informar que desejamos paralelizar essa pesquisa, passando o argumento parallel_over = \"resamples\". Podemos tamb√©m salvar as predi√ß√µes para cada um dos modelos especificando o argumento save_pred = TRUE. Se desejarmos anexar √† sa√≠da o workflow, fazemos save_workflow = TRUE.\nAssim, criaremos o objeto controle_grid, para que possamos passar a fun√ß√£o workflow_map posteriormente. Tem-se:\n\ncontrole_grid &lt;- control_grid(\n  save_pred = TRUE,\n  save_workflow = TRUE,\n  parallel_over = \"resamples\"\n)\n\n\n\n4.6 Trainando o modelo\nNessa etapa iremos treinar o modelo usando a fun√ß√£o workflow_map do pacote workflow. Temos ent√£o:\n\ntreino &lt;-\n  wf_todos |&gt; \n  workflow_map(\n    resamples = validacao_cruzada,\n    grid = 20L,\n    control = controle_grid\n  )\n\nA fun√ß√£o autoplot do pacote ggplot2 √© √∫til para que possamos visualizar o desempenho de cada um dos modelos considerando a m√©trica do EQM. Isso √© feito da seguinte forma:\n\nautoplot(treino, metric = \"rmse\") + \n  labs(\n    title = \"Avalia√ß√£o dos modelos de regress√£o\",\n    subtitle = \"Utilizando a m√©trica do EQM\"\n  ) + \n  xlab(\"Rank dos Workflows\") +\n  ylab(\"Erro Quadr√°tico M√©dio - EQM\")\n\n\n\n\nPerceba que no gr√°fico acima, temos os 8 modelos avaliados no 8-folds cross-validation. Portanto, para cada um dos modelos comparados, temos 8 avalia√ß√µes. Caso deseje avaliar as m√©tricas do melhor cen√°rio de cada um dos modelos, fazemos:\n\nmelhores &lt;- \n  treino |&gt; \n  rank_results(select_best = TRUE, rank_metric = \"rmse\")\n\nautoplot(treino, select_best = TRUE)\n\n\n\n\nVamos agora selecionar o melhor modelo dentre os modelos comparados. Isso n√£o quer dizer que o modelo seja bom para resolver o problema em quest√£o. Para ver um rank e saber qual modelo e receita foram as melhores, fazemos:\n\ntreino |&gt; \n  rank_results()\n\n# A tibble: 240 √ó 9\n   wflow_id         .config .metric  mean std_err     n preprocessor model  rank\n   &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n 1 recipe_2_knn_fit Prepro‚Ä¶ rmse    0.632  0.0168     8 recipe       near‚Ä¶     1\n 2 recipe_2_knn_fit Prepro‚Ä¶ rsq     0.392  0.0182     8 recipe       near‚Ä¶     1\n 3 recipe_1_knn_fit Prepro‚Ä¶ rmse    0.632  0.0168     8 recipe       near‚Ä¶     2\n 4 recipe_1_knn_fit Prepro‚Ä¶ rsq     0.392  0.0182     8 recipe       near‚Ä¶     2\n 5 recipe_1_knn_fit Prepro‚Ä¶ rmse    0.633  0.0165     8 recipe       near‚Ä¶     3\n 6 recipe_1_knn_fit Prepro‚Ä¶ rsq     0.391  0.0174     8 recipe       near‚Ä¶     3\n 7 recipe_2_knn_fit Prepro‚Ä¶ rmse    0.633  0.0165     8 recipe       near‚Ä¶     4\n 8 recipe_2_knn_fit Prepro‚Ä¶ rsq     0.391  0.0174     8 recipe       near‚Ä¶     4\n 9 recipe_2_knn_fit Prepro‚Ä¶ rmse    0.633  0.0169     8 recipe       near‚Ä¶     5\n10 recipe_2_knn_fit Prepro‚Ä¶ rsq     0.390  0.0188     8 recipe       near‚Ä¶     5\n# ‚Ñπ 230 more rows\n\n\nAssim, podemos perceber que a receita_1 combinada com o modelo kNN √© o melhor escolha entre os modelos e receitas comparadas. Portanto:\n\nmelhor_modelo &lt;- \n  treino |&gt; \n  extract_workflow_set_result(id = \"recipe_1_knn_fit\") |&gt; \n  select_best(metric = \"rmse\")\n\nmelhor_modelo\n\n# A tibble: 1 √ó 3\n  neighbors dist_power .config              \n      &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;                \n1        12       1.47 Preprocessor1_Model15\n\n\n\n\n4.7 Avalia√ß√£o final do melhor modelo\nAp√≥s a escolha do melhor modelo e da estima√ß√£o de seus hiperpar√¢metros, nesse caso, o modelo kNN com k = 12 e dist_power \\approx 1.47, precisamos testar o desempenho do modelo final segundo a base de dados de teste. Para tanto, utilizamos a fun√ß√£o last_fit do pacote tune. Temos que:\n\nwf_final &lt;- \n  treino |&gt; \n  extract_workflow(id = \"recipe_1_knn_fit\") |&gt; \n  finalize_workflow(melhor_modelo)\n\nteste &lt;- \n  wf_final |&gt; \n  last_fit(split = divisao_inicial)\n\nteste$.metrics\n\n[[1]]\n# A tibble: 2 √ó 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.629 Preprocessor1_Model1\n2 rsq     standard       0.405 Preprocessor1_Model1\n\n\nAgora que temos os hiperpar√¢metros estimados e temos uma boa estimativa do risco preditivo real do modelo final selecionado, poderemos preceder com um ajuste final, com toda a base de dados (treinamento + teste).\n\nmodelo_final &lt;- \n  wf_final |&gt; \n  fit(dados)\n\n\n\n4.8 Salvando o modelo\nDepois que temos o modelo finalizado, podemos ter alguns interesses de como utilizar o resultado, i.e., o modelo treinado. Entre alguns motivos, posso citar:\n\nSalvar o modelo para uso no futuro, sem ter que retreinar;\nDistribuir o modelo para que outras pessoas possam experimentar, sem terem que executar seu script R e retreinar o modelo;\nIntroduzir seu modelo treinado em uma API que ir√° consumir os resultados, i.e., consumir as previs√µes do modelo.\n\nNessas situa√ß√µes, √© conveniente salvar o modelo em um arquivo serializado (R Data Serialization). Tais arquivos possuem a extens√£o .rds. Devemos fazer:\n\n# Salvando o modelo em um arquivo serializado\nsaveRDS(modelo_final, file = \"modelo_final.rds\")\n\n# Lendo o arquivo serializado com o modelo final\nload(file = \"modelo_final.rds\")\n\n# Fazendo novas previs√µes\npredict(modelo_final, new_data = novos_dados)"
  },
  {
    "objectID": "shiny_apps/index.html",
    "href": "shiny_apps/index.html",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "",
    "text": ".shiny-output-area {\n  margin: 0;\n}\n\n.full-width-image {\n    width: 100vw; /* Define a largura igual √† largura da janela do navegador */\n    height: auto; /* Mant√©m a propor√ß√£o original da imagem */\n}\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(shiny)\nlibrary(shinyWidgets)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(fontawesome)\nlibrary(purrr)\nlibrary(leaflet)\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(rpart)\nlibrary(evaluate)\nlibrary(tibble)\nlibrary(ranger)\n\n# Fun√ß√£o de regress√£o verdadeira. Na pr√°tica √© desconhecida.\nregressao_verdadeira &lt;- function(x)\n  45 * tanh(x/1.9 - 7) + 57\n\nobservacoes_regressao_real &lt;- function(n, desvio_padrao = 0.2) {\n  # Permitindo que o mesmo x possa ter dois pontos de y, como ocorre na \n  # pratica\n  seq_x &lt;- sample(seq(0, 17.5, length.out = n), size = n, replace = TRUE)\n  \n  step &lt;- function(x)\n    regressao_verdadeira(x) + rnorm(n = 1L, mean = 0, sd = desvio_padrao)\n  \n  tibble::tibble(y = purrr::map_vec(.x = seq_x, .f = step), x = seq_x)\n}\n\n# Usaremos uma regress√£o polinomial para tentar ajustar √† regress√£o -------\nregressao_polinomial &lt;- function(n = 30L, desvio_padrao = 4, grau = 1L) {\n  \n  dados &lt;- observacoes_regressao_real(n = n, desvio_padrao = desvio_padrao)\n    \n  iteracoes &lt;- function(tibble_data, grau) {\n      x &lt;- tibble_data$x\n      iteracoes &lt;- lapply(X = 2L:grau, FUN = function(i) x^i)\n      \n      result &lt;- cbind(tibble_data, do.call(cbind, iteracoes))\n      colnames(result)[(ncol(tibble_data) + 1):ncol(result)] &lt;- paste0(\"x\", 2L:grau)\n      \n      as_tibble(result)\n  }  \n  \n  if(grau &gt;= 2L)\n    dados &lt;- iteracoes(dados, grau = grau)\n  \n  ajuste &lt;- lm(formula = y ~ ., data = dados)\n  dados$y_chapeu &lt;- predict(ajuste, new.data = dados)\n  \n  dados |&gt; \n    dplyr::relocate(y_chapeu, .before = x)\n}\n\nplotando &lt;- function(dados){\n  dados |&gt;  \n    ggplot(aes(x = x, y = y_chapeu)) +\n    geom_point()\n}\n\nmc_ajustes &lt;- function(mc = 100L, n = 50L, desvio_padrao = 5, grau = 1L){\n\n  p &lt;- \n    ggplot(data = NULL) +\n      coord_cartesian(xlim = c(0, 17.5), ylim = c(0, 110)) +      \n      ylab(\"Valores estimados\")\n  \n  df &lt;- NULL\n  for(i in 1L:mc){\n    df &lt;- regressao_polinomial(n = n, desvio_padrao = desvio_padrao, grau = grau)\n    p &lt;- p + geom_line(data = df, aes(x = x, y = y_chapeu))\n  }\n  p + \n    stat_function(fun = regressao_verdadeira, col = \"red\", linewidth = 1.4) +\n    labs(\n      title = \"Regress√£o Polinomial\",\n      subtitle = paste(\"Grau: \", grau)\n    ) +\n    theme(\n      plot.title = element_text(face = \"bold\"),\n      axis.title = element_text(face = \"bold\")\n    )\n}"
  },
  {
    "objectID": "shiny_apps/index.html#rows",
    "href": "shiny_apps/index.html#rows",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Rows",
    "text": "Rows\n\n\n\n\n\n\nEssa aplica√ß√£o foi constru√≠da para conter alguns exempos da disciplina de Aprendizagem de M√°quina, lecionada aos dicentes do curso de bacharelado em estat√≠stica da UFPB."
  },
  {
    "objectID": "shiny_apps/index.html#column",
    "href": "shiny_apps/index.html#column",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEntrada de informa√ß√µes\n\nsliderInput(\"numeromodelos\", \"N√∫mero de modelos:\",\n    min = 1, max = 100, value = 50\n)\n\n\nN√∫mero de modelos:\n\n\n\nsliderInput(\"tamanhoamostral\", \"Tamanho amostral:\",\n    min = 100, max = 250, value = 100\n)\n\n\nTamanho amostral:\n\n\n\nsliderInput(\"grau\", \"Grau do polin√¥mio:\",\n    min = 1, max = 200, value = 1\n)\n\n\nGrau do polin√¥mio:"
  },
  {
    "objectID": "shiny_apps/index.html#column-1",
    "href": "shiny_apps/index.html#column-1",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nResultado gr√°fico das simula√ß√µes\n\nrenderPlot({\n  mc_ajustes(mc = input$numeromodelos, n = input$tamanhoamostral, desvio_padrao = 5, grau = input$grau)\n})"
  },
  {
    "objectID": "shiny_apps/index.html#column-2",
    "href": "shiny_apps/index.html#column-2",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEntrada de informa√ß√µes\n\nsliderInput(\"grau_polinomio\", \"Grau do polin√¥mio:\",\n    min = 1L, max = 40L,\n    value = 1L,\n    step = 1L\n)\n\n\nGrau do polin√¥mio:\n\n\n\n# Lendo dados\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados &lt;-\n  dados_expectativa_renda |&gt;\n  dplyr::select(-CountryName) |&gt;\n  dplyr::rename(y = LifeExpectancy, x = GDPercapita)\n\niteracoes &lt;- function(tibble_data, grau) {\n  x &lt;- tibble_data$x\n  iteracoes &lt;- lapply(X = 2L:grau, FUN = function(i) x^i)\n\n  result &lt;- cbind(tibble_data, do.call(cbind, iteracoes))\n  colnames(result)[(ncol(tibble_data) + 1):ncol(result)] &lt;- paste0(\"x\", 2L:grau)\n\n  as_tibble(result)\n}\n\nreg_polinomial &lt;- function(dados, grau = 1L) {\n  if(grau &gt;= 2L)\n    dados &lt;- iteracoes(dados, grau = grau)\n\n  lm(formula = y ~ ., data = dados)\n}\n\n# Divis√£o dos dados\ndivisao_inicial &lt;- rsample::initial_split(dados)\ntreinamento &lt;- rsample::training(divisao_inicial)\nteste &lt;- rsample::testing(divisao_inicial) # Teste final\n\n# v-folds cross-validation\nvalidacao &lt;- function(dados, grau = 1L, errado = FALSE, ...){\n\n  # Todas as divis√µes da validacao cruzada\n  cv &lt;- rsample::vfold_cv(dados, ...)\n\n  hiper &lt;- function(i){\n    treino &lt;- rsample::analysis(cv$splits[[i]]) # Treinamento\n    validacao &lt;- rsample::assessment(cv$splits[[i]]) # Validaca√ß√£o\n    ajuste &lt;- reg_polinomial(dados = treino, grau = grau)\n\n    if(errado){\n      df_treino &lt;- iteracoes(treino, grau = grau)\n      df_treino &lt;- df_treino |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_treino))\n      yardstick::rmse(data = df_treino, truth = y, estimate = y_chapeu)$.estimate\n    } else {\n      df_validacao &lt;- iteracoes(validacao, grau = grau)\n      df_validacao &lt;- df_validacao |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_validacao))\n      yardstick::rmse(data = df_validacao, truth = y, estimate = y_chapeu)$.estimate\n    }\n  }\n  purrr::map_dbl(.x = seq_along(cv$splits), .f = hiper) |&gt;\n    mean()\n}\n\nplot_bar &lt;- function(grau){\n  ruim &lt;- validacao(dados, errado = TRUE, grau = grau)\n  bom &lt;- validacao(dados, errado = FALSE, grau = grau)\n  df &lt;- tibble::tibble(x = c(\"Errado\", \"Certo\"), y = c(log(ruim), log(bom)))\n\n  df |&gt;\n    ggplot(aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\", fill = \"#0f385d\") +\n    geom_text(aes(label = round(y, digits = 2L)), vjust = -0.5, size = 10) +\n    labs(x = \"Estrat√©gia\", y = \"EQM estimado\") +\n    theme(\n      plot.title = element_text(size = 18, face = \"bold\"),\n      plot.subtitle = element_text(size = 16),\n      axis.text = element_text(size = 20),\n      axis.title = element_text(size = 14, face = \"bold\")\n    )\n}"
  },
  {
    "objectID": "shiny_apps/index.html#column-3",
    "href": "shiny_apps/index.html#column-3",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nAvalia√ß√£o do risco estimado\n\nrenderPlot({\n  plot_bar(input$grau_polinomio)\n})"
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-9",
    "href": "index.html#√°rvores-de-regress√£o-9",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n O par√¢metro de complexidade/custo √© um hiperpar√¢metro, e dever√° ser estimado dentro de um procedimento de valida√ß√£o cruzada."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-10",
    "href": "index.html#√°rvores-de-regress√£o-10",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n Algumas observa√ß√µes sobre a √°rvore üå≥ de regress√£o:\n\n\n√â um m√©todo n√£o-param√©trico;\nPode ser representado graficamente;\n√â √∫til na an√°lise explorat√≥ria dos dados do problema em quest√£o;\nPode ser utilizada para selecionar vari√°veis. Aparentemente, as vari√°veis que pertence √† √°rvore tem uma maior import√¢ncia para o problema em quest√£o;\nPoder√° trabalhar com vari√°veis num√©ricas, mas tamb√©m poder√° trabalhar com vari√°veis categ√≥ricas;\nA √°rvore √© robusta na presen√ßa de vari√°veis irrelevantes."
  },
  {
    "objectID": "shiny_apps/index.html#column-4",
    "href": "shiny_apps/index.html#column-4",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEntrada de informa√ß√µes\n\nsliderInput(\"complexidade\", \"Valor de complexidade:\",\n    min = 0.0001, max = 0.4, value = 0.001\n)\n\n\nValor de complexidade:\n\n\n\nrandom_y &lt;- function(n = 250L, sigma = 0.1){\n  x &lt;- runif(n = n, min = 0, max = 10)\n  tibble(x = x, y = rnorm(n = n, mean = sin(x), sd = sigma))\n}\n\nset.seed(0)\n\narvore &lt;- function(dados, complexidade = 0.5, graph = TRUE, ...){\n\n  dados &lt;- random_y(...)\n\n  arvore &lt;- rpart::rpart(formula = y ~ ., data = dados)\n  arvore &lt;- rpart::prune(arvore, cp = complexidade) # Realizando poda\n\n  dados$y_chapeu &lt;- predict(arvore, newdata = dados)\n\n  # Plotando x versus y -----------------------------------------------------\n  dados |&gt;\n    ggplot(aes(x, y)) +\n    geom_point() +\n    geom_line(aes(x, y_chapeu), linewidth = 1.5, col = \"red\") +\n    labs(\n      title = \"√Årvore de regress√£o\",\n      subtitle = glue::glue(\"Par√¢metro de coplexidade = {complexidade}\")\n    )\n}\n\nrenderPlot({\n  arvore(complexidade = input$complexidade)\n})"
  },
  {
    "objectID": "index.html#exerc√≠cios-5",
    "href": "index.html#exerc√≠cios-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Considere o problema em que o objetivo √© prever a pontua√ß√£o (score) / (item 2) do aluno com base em algumas vari√°veis. S√£o elas:\n\n\nHoras estudadas: o n√∫mero total de horas gastas estudando por cada aluno;\nPontua√ß√£o: As notas obtidas pelos alunos em testes anteriores;\nAtividades extracurriculares: Se o aluno participa de atividades extracurriculares (Sim ou N√£o);\nHoras de sono: o n√∫mero m√©dio de horas de sono que o aluno teve por dia;\nAmostras de perguntas praticadas: O n√∫mero de amostras de perguntas que o aluno praticou.\n\n\nVoc√™ poder√° baixar e ter uma descri√ß√£o maior da base de dados clicando aqui. Avalie o poder preditivo do modelo lasso com o do kNN. Sua an√°lise deve conter uma an√°lise explorat√≥ria dos dados, dever√° utilizar um esquema de k-folds cross-validation, com k = 20 e considerar um esquema de data splitting na propor√ß√£o 90\\% para treino e 10\\% para teste. Sua an√°lise dever√° estar em um notebook de quarto, em que voc√™ dever√° comentar cada passo da an√°lise."
  },
  {
    "objectID": "index.html#exerc√≠cios-6",
    "href": "index.html#exerc√≠cios-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Considere o problema em que o objetivo √© prever a pontua√ß√£o (score) / (item 2) do aluno com base em algumas vari√°veis. S√£o elas:\n\n\nHoras estudadas: o n√∫mero total de horas gastas estudando por cada aluno;\nPontua√ß√£o: As notas obtidas pelos alunos em testes anteriores;\nAtividades Extracurriculares: Se o aluno participa de atividades extracurriculares (Sim ou N√£o);\nHoras de sono: o n√∫mero m√©dio de horas de sono que o aluno teve por dia;\nAmostras de perguntas praticadas: O n√∫mero de amostras de perguntas que o aluno praticou.\n\n\nVoc√™ poder√° baixar e ter uma descri√ß√£o maior da base de dados clicando aqui. Avalie o poder preditivo do modelo lasso com o do SVRM. Sua an√°lise deve conter uma an√°lise explorat√≥ria dos dados, dever√° utilizar um esquema de k-folds cross-validation, com k = 20 e considerar um esquema de data splitting na propor√ß√£o 90\\% para treino e 10\\% para teste. Sua an√°lise dever√° estar em um notebook de quarto, em que voc√™ dever√° comentar cada passo da an√°lise."
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation-3",
    "href": "index.html#leave-one-out-cross-validation-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nO m√©todo LOOCV converge assintotivamente para o AIC, por√©m, este, muitas vezes n√£o poderemos calcular diretamente, uma vez que n√£o conhecemos a distribui√ß√£o conjunta dos dados, i.e., n√£o conhecemos a estrutura probabil√≠stica."
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation-4",
    "href": "index.html#leave-one-out-cross-validation-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nEssa rela√ß√£o entre o LOOCV e o Akaike Information Criterion - AIC foi provada no paper Stone (1977) intitulado An Asymptotic Equivalence of Choice of Model by Cross-Validation and Akaike‚Äôs Criterion e publicado no Journal of the Royal Statistical Society, Series B. Clique aqui, se quiser ler o artigo."
  },
  {
    "objectID": "index.html#exerc√≠cios-7",
    "href": "index.html#exerc√≠cios-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Refa√ßa o exerc√≠cio anterior considerando a base de dados de dados pessoais de custos m√©dicos dispon√≠vel aqui. As informa√ß√µes contidas na base s√£o:\n\n\nIdade (age): idade do benefici√°rio principal;\nSexo (sex): sexo do benefici√°rio;\n√çndice de massa corporal - IMC (bmi): IMC = \\frac{Peso}{altura^2}, com peso em Kg e altura em m (metro);\nN√∫mero de filhos (children): n√∫mero de filhos cobertos pelo plano de sa√∫de;\nFumante (smoker): vari√°vel dummy que informa se o benefici√°rio √© ou n√£o fumante;\nRegi√£o (region): regi√£o dos EUA em que o benefici√°rio reside (northeast, southeast, southwest ou northwest);\nCusto (charges): custos m√©dicos cobrados, em d√≥lares.\n\n\nO objetivo √© prever o custo (charges) com base nas demais informa√ß√µes. Dica: utilizando a biblioteca recipes, utilize a fun√ß√£o step_dummy especificando o argumento one_hot = TRUE para realizar um one hot encoding com a vari√°vel region. Dessa forma, region deixar√° ser ser uma vari√°vel nominal e se tornar√° uma vari√°vel num√©rica."
  },
  {
    "objectID": "index.html#exerc√≠cios-8",
    "href": "index.html#exerc√≠cios-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Considere a vari√°vel aleat√≥ria Y_i \\sim \\mathcal{N}(\\sin(X_i), \\sigma^2), com X_i \\in \\mathcal{U}(0, 10)\\,, \\forall i. Utilizando a biblioteca rpart, implemente a fun√ß√£o arvore(n = 250L, complexidade, sigma = 0.1) que devolve o gr√°fico scatterplot com os pontos X_i e Y_i e por cima deles o gr√°fico de linha com os valores preditos. A fun√ß√£o dever√° ter tr√™s argumentos, n, complexidade e sigma, que s√£o o tamanho da amostra, o grau de complexidade do modelo, e o desvio padr√£o, respectivamente. Aqui n√£o se preocupe com divis√£o entre treino e teste nem valida√ß√£o cruzada. A solu√ß√£o desse exerc√≠cio n√£o tem como objetivo encontrar o melhor hiperpar√¢metro, i.e., n√£o √© necess√°rio ‚Äútunar‚Äù o par√¢metro complexidade. A fun√ß√£o dever√° retornar algo como:"
  },
  {
    "objectID": "index.html#exerc√≠cios-9",
    "href": "index.html#exerc√≠cios-9",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Ainda com base no exerc√≠cio anterior, construa uma fun√ß√£o que retorne v√°rias estimativas obtidas por √°rvores de regress√£o, com base em v√°rias amostra de X_i e Y_i. O gr√°fico dever√° mostrar as estimativas das diversas √°rvores de regress√£o, sem mostrar os pontos. Perceba a flutua√ß√£o das estimativas em diferentes valores de complexidade, dado n e sigma fixos.\n\nExerc√≠cio: Sem utilizar a biblioteca tidymodels, apenas as bibliotecas rsample e rpart, treine um modelo com 10 mil observa√ß√µes geradas. No procedimento k-folds cross-validation, para k = 20, encontre um bom valor para o grau de complexidade considerando um grid de poss√≠veis valores. Dica: experimente testar um par√¢metro dentro do conjunto de treino no procedimento de cross-validation. Por exemplo, experimente criar um grid com valores entre 0.001 e 0.4. Aprensente o gr√°fico com a estimativa do melhor modelo. N√£o esque√ßa de fixar um valor de semente, para que os resultados possam ser reproduzidos.\n\nExerc√≠cio: Refa√ßa o exerc√≠cio anterior utilizando a biblioteca tidymodels. Fique livre para tunar o hiperpar√¢metro que achar necess√°rio, da engine que utilizar com a biblioteca parsnip. Compare o risco preditivo do exerc√≠cio anterior com o que voc√™ obteve utilizando o tidymodels."
  },
  {
    "objectID": "index.html#bagging-e-√°rvores-de-regress√£o",
    "href": "index.html#bagging-e-√°rvores-de-regress√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Bagging e √°rvores de regress√£o üå≥",
    "text": "Bagging e √°rvores de regress√£o üå≥\n\nAs √°rvores üå≥ de regress√£o tem a caracter√≠stica de ser facilmente interpret√°vel, por√©m, costumam ser uma capacidade preditiva baixa\n\n\n\nDepartamento de Estat√≠stica da UFPB"
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-11",
    "href": "index.html#√°rvores-de-regress√£o-11",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nO n√≠vel de complexidade √© obtido via cross-validation de modo a encontrar a menor sub√°rvore que generaliza melhor o problema para dados n√£o visto.\n\nAssim como nos modelos de regress√£o com penalidade que vimos anteriormente, aqui, para valores menores de \\alpha tende a produzir modelos mais complexos. Consequentemente, √† medida que uma √°rvore cresce, a redu√ß√£o no SSE deve ser maior do que a penalidade de complexidade de custo."
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging",
    "href": "index.html#combinando-predi√ß√µes---bagging",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nAs √°rvores üå≥ de regress√£o tem a caracter√≠stica de ser facilmente interpret√°vel, por√©m, costumam ser uma capacidade preditiva baixa.\n\nUma das ideias de melhorar a capacidade preditiva √© combinar √°rvores usando a metodologia de reamostragem bootstrap. As t√©cnicas de reamostragem via bootstrap n√£o-param√©trico s√£o bastante difundidas na estat√≠stica e consiste reamostrar da amostra original com reposi√ß√£o.\n\nNa estat√≠stica, a ideia de bootstrap √© muito comum para corre√ß√£o de v√≠es de um estimador, c√°lculo do erro-padr√£o de um estimador, constru√ß√£o de intervalos de confian√ßas e teste de hip√≥teses.\n\nEm aprendizagem de m√°quina, o conceito de bagging consiste em reaplicar uma metodologia, nesse caso a de √°rvore üå≥ de regress√£o em diferentes amostras obtidas da amostra original com reposi√ß√£o."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-12",
    "href": "index.html#√°rvores-de-regress√£o-12",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nExperimente alterar o par√¢metro de complexidade e perceba como ele influencia nas regi√ß√µes da √°rvore de regress√£o. Quando maior o valor, maior a penalidade, e portanto, mais simples ser√° a √°rvore de regress√£o que ir√° estimar os valores de Y_i com base em X_i."
  },
  {
    "objectID": "index.html#√°rvores-de-regress√£o-13",
    "href": "index.html#√°rvores-de-regress√£o-13",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≥ √Årvores de regress√£o",
    "text": "üå≥ √Årvores de regress√£o\n\nAlgumas outras caracter√≠sticas das üå≥ √°rvores de regress√£o s√£o:\n\n\nA fun√ß√£o de regress√£o estimada \\widehat{r}({\\bf x}) √© constante por partes, i.e., em uma folha üçÉ tendemos predizer que v√°rios indiv√≠duos distintos tem o mesmo valor de \\widehat{r}({\\bf x});\nEm uma √°rvore üå≥ de regress√£o as intera√ß√µes entre vari√°veis s√£o consideradas de forma autom√°tica, enquanto em uma regress√£o as intera√ß√µes s√£o introduzidas como os produtos entre covari√°veis;\nElas s√£o uma esp√©cie de ‚Äúsamambaias‚Äù, em que crescem para baixo;\n√â f√°cil introduzir vari√°veis categ√≥ricas üéâ;\nUma pessoa sem muito conhecimento poder√° estimar \\widehat{r}({\\bf x}), dada uma √°rvore, para cada nova observa√ß√£o {\\bf x}."
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-1",
    "href": "index.html#combinando-predi√ß√µes---bagging-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n Caso voc√™ tenha interesse e entender o m√©todo de bootstrap, no contexto mais difundido na estat√≠stica como mencionado no slide anterior, assista a v√≠deo aula sobre bootstrap do Prof.¬†Pedro Rafael do Departamento de Estat√≠stica da Universidade Federal da Para√≠ba - UFPB."
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-2",
    "href": "index.html#combinando-predi√ß√µes---bagging-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nPortanto, √© importante ficar claro que o bagging √© uma metodologia gen√©rica que poder√° ser aplicada em situa√ß√µes ao qual desejamos combinar modelos. Por exemplo, o m√©todo ramdom forest que veremos mais a frente √© uma pequena modifica√ß√£o de um bagging de √°rvores de regress√£o que vimos anteriormente. Na verdade o ramdom forest, assim como as √°rvores de decis√µes podem ser utilizadas tamb√©m para problemas de classifica√ß√£o, como veremos mais adiante no curso."
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-3",
    "href": "index.html#combinando-predi√ß√µes---bagging-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nA ideia de combinar √°rvores de regress√£o √© interessante, uma vez que o risco preditivo da m√©dia das previs√µes das √°rvores √© menor que o risco individual de cada uma das √°rvores.\n\nLembre-se que quando fal√°vamos em momentos anteriores do curso sobre o balan√ßo entre vi√©s e vari√¢ncia, apresentamos uma decomposi√ß√£o do risco quadr√°tico R(g) condicional a um novo {\\bf x} dada na Equa√ß√£o¬†2. Para que n√£o seja necess√°rio necess√°rio voltar um grande n√∫mero de slides, recoloco a decomposi√ß√£o abaixo:\n\n\\mathbb{E}\\left[(Y - \\widehat{g}({\\bf X}))^2| {\\bf X} = {\\bf x}\\right] = \\underbrace{\\mathbb{V}[Y | {\\bf X = x}]}_{\\mathrm{i - Vari√¢ncia\\,\\, intr√≠nseca}} + \\overbrace{(r({\\bf x}) - \\mathbb{E}[\\widehat{g}({\\bf x})])^2}^{\\mathrm{ii - Vi√©s\\, ao\\, quadrado\\, do\\, modelo}} + \\underbrace{\\mathbb{V}[\\widehat{g}({\\bf x})]}_{\\mathrm{iii - Vari√¢ncia\\, do\\, modelo}}."
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-4",
    "href": "index.html#combinando-predi√ß√µes---bagging-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nAinda no caso de √°rvores üå≥ de regress√£o, suponha um caso mais simples, em que temos dois modelos de √°rvores de regress√£o, sejam eles g_1 e g_2, respectivamente, em que a previs√£o combinada √© dada por:\n\\widehat{g}({\\bf x}) = \\frac{\\widehat{g_1}({\\bf x})  + \\widehat{g_2}({\\bf x})}{2}, em que \\widehat{g_1}({\\bf x}) e \\widehat{g_2}({\\bf x}) s√£o as estimativas da fun√ß√£o de regress√£o r({\\bf x}) fornecidades pelas √°rvores g_1 e g_2, respectivamente.\n\nSupondo que \\widehat{g_1}({\\bf x}) e \\widehat{g_2}({\\bf x}) s√£o n√£o-viesados e possuem a mesma vari√¢ncia, e al√©m disso s√£o n√£o correlacionados ent√£o:\n\\begin{align*}\n\\mathbb{E}[(Y - g({\\bf x}))^2|{\\bf x}] &= \\mathbb{V}[Y|{\\bf x}] + \\frac{1}{4}(\\mathbb{V}[\\widehat{g}_1({\\bf x}) + \\widehat{g}_2({\\bf x})|{\\bf x}]) \\\\\n&\\quad + \\left(\\mathbb{E}[Y|{\\bf x}] - \\frac{\\mathbb{E}[\\widehat{g}_1({\\bf x})|{\\bf x}]+\\mathbb{E}[\\widehat{g}_2({\\bf x})|{\\bf x}]}{2} \\right)^2\n\\end{align*}"
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-5",
    "href": "index.html#combinando-predi√ß√µes---bagging-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nNote que se \\widehat{g_1}({\\bf x}) e \\widehat{g_2}({\\bf x}) ent√£o \\mathbb{E}(\\widehat{g}_1({\\bf x})|{\\bf x}) = \\mathbb{E}(\\widehat{g}_2({\\bf x})|{\\bf x}) = r({\\bf x}). Isso faz com que a √∫ltima parcela da equa√ß√£o anterior seja zero. Se al√©m disso, se os estimadores possuem a mesma vari√¢ncia, ent√£o a decomposi√ß√£o do risco preditivo combinado √© simplificada e dada por:\n\\overbrace{\\mathbb{E}[(Y - \\widehat{g}({\\bf x}))^2|{\\bf x}]}^{\\text{Risco preditivo combinado}} = \\mathbb{V}[Y|{\\bf x}] + \\frac{1}{2}\\mathbb{V}[\\widehat{g}_i({\\bf x})| {\\bf x}] \\leq \\underbrace{\\mathbb{E}[(Y - \\widehat{g}_i({\\bf x}))^2 | {\\bf x}]}_{\\text{Risco preditivo individual}}, \\tag{9} para um dado i, com i = 1, 2. Dado as suposi√ß√µes de estimadores n√£o-viesados, vari√¢ncia iguais e que os estimadores s√£o n√£o-correlacionados, a Equa√ß√£o¬†9 poderia ser generalizada para o caso de mais de dois estimadores, no nosso caso, para mais de duas √°rvores de regress√£o üå≥. Basta utilizar indu√ß√£o matem√°tica!"
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-6",
    "href": "index.html#combinando-predi√ß√µes---bagging-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nDevemos notar, contudo que, para que tenhamos √°rvores üå≥ aproximadamente n√£o-viesadas, n√£o devemos ‚Äúpodar‚Äù as √°rvoresÔ∏è üå≥. Muito embora elas possam aprensenta overfitting quando consideradas individualmente o risco preditivo combinado ir√° diminuir.\n\nPortanto, seja B o n√∫mero de pseudo-amostras bootstrap, i.e., amostras obtidas da amostra original com reposi√ß√£o. Ent√£o, o estimador combinado em um procedimento de bagging √© dado por:\n\\widehat{g}({\\bf x}) = \\frac{1}{B}\\sum_{b = 1}^B \\widehat{g}_b({\\bf x})."
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-7",
    "href": "index.html#combinando-predi√ß√µes---bagging-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nUma observa√ß√£o importante √© que o bagging pode ser ruim em modelos quando utilizado em modelos intrinsecamente est√°veis, como √© o caso de modelos lineares de regress√£o, kNN, regress√£o log√≠stica, entre outros. O procedimento de bagging costuma ser eficaz quando s√£o utilizados em modelos que possuem uma alta vari√¢ncia e que tendem a ter overfitting, como o caso da √°rvore de decis√£o profunda (√°rvores de regress√£o e de classifica√ß√£o)."
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-8",
    "href": "index.html#combinando-predi√ß√µes---bagging-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nUma forma de perceber a estabilidade de um modelo de aprendizagem de m√°quina √© avaliar as predi√ß√µes do modelo em diferentes parti√ß√µes do conjunto de dados, por exemplo, em um procedimento de valida√ß√£o cruzada repetida. A fun√ß√£o rsample::vfold_cv(), permite a possibilidade de retepir uma valida√ß√£o cruzada por meio do argumento repeats, que por default √© igual √† 1.\n\nUma outra forma seria utilizar um procedimento de bootstrap n√£o-param√©trico (reamostrar da amostra com reposi√ß√£o) e treinar o modelo em cada pseudo-amostra bootstrap e avaliar a variabilidade das estimativas no conjunto de valida√ß√£o.\n\nUma outra forma seria avaliar a curva de aprendizado do modelo. Essa curva poder√° ser obtida treinando o modelo em diferentes tamanhos de conjunto de treinamento, em que observa-se como varia a peformance do modelo nos diferentes tamanhos do conjunto de treinamento."
  },
  {
    "objectID": "index.html#random-forest",
    "href": "index.html#random-forest",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≤üêûüå≥üêùüå≤ü¶ãüå≥ Random Forest",
    "text": "üå≤üêûüå≥üêùüå≤ü¶ãüå≥ Random Forest\n\n\n\nO random forest (floresta aleat√≥ria) √© um procedimento de bagging em que introduz um n√≠veo de aleatoriedade maior no processo de sela√ß√£o das vari√°veis, visando reduzir ainda mais a corre√ß√£o entre as √°rvores de regress√£o. Isso √© feito sorteando m &lt; d covari√°veis em cada particionamento, i.e., essa randomiza√ß√£o √© feita em toda divis√£o de todas as B √°rvores do procedimento de bagging, em que d √© o total de covari√°veis consideradas.\n\nO valor de m poder√° ser obtido via algum procedimento de cross-validation, i.e., √© um hiperpar√¢metro que poder√° ser ‚Äútunado‚Äù."
  },
  {
    "objectID": "index.html#random-forest-1",
    "href": "index.html#random-forest-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≤üêûüå≥üêùüå≤ü¶ãüå≥ Random Forest",
    "text": "üå≤üêûüå≥üêùüå≤ü¶ãüå≥ Random Forest\n\nA ideia de construir √°rvores que sejam menos correlacionadas uma com as outras nos aproxima melhor do crit√©rio de n√£o correla√ß√£o que utilizamos para mostrar que o risco preditivo combinado √© menor que o risco preditivo ao considerar uma √∫nica √°rvore, como mostra a Equa√ß√£o¬†9.\n\nO algoritmo random forest consegue produzir um estimador com menor vari√¢ncia que o bagging. Al√©m disso, assim como no bagging, podemos calcular a import√¢ncia de cada vari√°vel usando o mesmo procedimento apresentado anteriormente.\n\nMuito embora o bagging √© um procedimento √∫til para diminuir a vari√¢ncia de um modelo utilizando predi√ß√µes combinadas, o procedimento de random forest para o caso de √°rvores de regress√£o ou de classifica√ß√£o nos conduz a um estimador com menor vari√¢ncia.\n\nUm valor de m frequentemente considerado √© o valor inteiro que aproxima \\sqrt{d}."
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-9",
    "href": "index.html#combinando-predi√ß√µes---bagging-9",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nMuito embora a combina√ß√£o preditiva usando bagging de um conjunto de √°rvores de regress√£o n√£o s√£o t√£o f√°ceis de interpretar quando comparada com uma √∫nica √°rvore de regress√£o, ele permite que possamos criar uma medida de import√¢ncia para cada vari√°vel. Essa medida baseia-se na redu√ß√£o da Residual Sum of squares - RSS de cada divis√£o.\n\n\nUma simples divis√£o bin√°ria em qualquer ponto de uma dada √°rvore üå≥ de regress√£o. Desejamos encontrar a import√¢ncia da vari√°vel ‚Äúpai‚Äù que poder√° aparecer em diversas divis√µes em uma mesma √°rvore.\nDevemos computar a redu√ß√£o da soma dos quadrados dos res√≠duos em cada n√≥ em que a vari√°vel do n√≥ ‚Äúpai‚Äù aparece em todas as √°rvores obtidas pelo procedimento de bagging, em que calculamos a soma dos quadrados no n√≥ ‚Äúpai‚Äù e subtra√≠mos da soma dos quadrados do n√≥ esquerdo e do n√≥ direito."
  },
  {
    "objectID": "index.html#combinando-predi√ß√µes---bagging-10",
    "href": "index.html#combinando-predi√ß√µes---bagging-10",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Combinando predi√ß√µes - bagging",
    "text": "Combinando predi√ß√µes - bagging\n\nAssim, a import√¢ncia da vari√°vel no n√≥ ‚Äúpai‚Äù, em uma dada divis√£o bin√°ria em uma dada √°rvore üå≥ do procedimento de bagging √© dada por:\n\n\\begin{align*}\n\\text{Import√¢ncia local} &= RSS_{pai} - RSS_{esq} - RSS_{dir} = \\\\\n& \\sum_{i \\in pai} (y_i - \\overline{y}_{pai})^2 - \\sum_{i \\in esq} (y_i - \\overline{y}_{esq})^2 - \\sum_{i \\in dir} (y_i - \\overline{y}_{dir})^2.\n\\end{align*}\n\nFoi denominado de ‚ÄúImport√¢ncia local‚Äù, uma vez que o n√≥ ‚Äúpai‚Äù (vari√°vel de interesse) poder√° aparecer nas diversas B √°rvores de regress√£o do procedimento bagging, e mais, poder√° aparecer v√°rias vezes em uma mesma √°rvore. Portanto, em todas as B e em todas as ocorr√™ncias da vari√°vel ‚Äúpai‚Äù em qualquer ponto de uma √°rvore a ‚ÄúImport√¢ncia local‚Äù dever√° ser calculada. Ao fim, dever√° somar todas as import√¢ncias locais para se ter a import√¢ncia global da vari√°vel no n√≥ ‚Äúpai‚Äù."
  },
  {
    "objectID": "index.html#exerc√≠cios-10",
    "href": "index.html#exerc√≠cios-10",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nConsidere a vari√°vel aleat√≥ria Y_i \\sim \\mathcal{N}(\\sin(X_i), \\sigma^2), com X_i \\in \\mathcal{U}(0, 10)\\,, \\forall i.\n\nExerc√≠cio: Avalie a estabilidade de uma √°rvore de regress√£o usando um valida√ß√£o cruzada repetida. Construa um gr√°fico com os riscos observados na valida√ß√£o para um \\sigma^2 fixo.\n\nExerc√≠cio: Avalie a estibilidade usando um procedimento de bootstrap. Construa um gr√°fico com os riscos observados na valida√ß√£o para um \\sigma^2 fixo.\n\nExerc√≠cio: Por fim, avalie a estabilidade utilizando avaliando a curva de aprendizado do modelo."
  },
  {
    "objectID": "shiny_apps/index.html#column-5",
    "href": "shiny_apps/index.html#column-5",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEntrada de informa√ß√µes\n\nselectInput(\"modelo_bagging_floresta\", label = \"Estrat√©gia:\",\n            choices = c(\"Bagging\" = \"bagging\", \"Random Forest\" = \"floresta\"))\n\n\nEstrat√©gia:\n\nBagging\nRandom Forest\n\n\n\n\nsliderInput(\"n_bagging_floresta\", \"n:\",\n    min = 10, max = 250, value = 50\n)\n\n\nn:\n\n\n\nsliderInput(\"sd_bagging_floresta\", \"Desvio Padr√£o:\",\n    min = 0.001, max = 0.7, value = 0.2\n)\n\n\nDesvio Padr√£o:\n\n\n\nsliderInput(\"replicas_bagging_floresta\", \"N√∫mero de modelos:\",\n    min = 1, max = 100, value = 50, step = 1\n)\n\n\nN√∫mero de modelos:\n\n\n\nmc &lt;- function(m = 10L, n = 10, sigma = 0.1, modelo = \"floresta\"){\n\n  cenarios &lt;- function(n, sigma){\n    dados &lt;- random_y(n = n, sigma = sigma)\n    if(modelo == \"bagging\"){\n      dados &lt;- \n        dados[rsample::bootstraps(dados, times = 1L) |&gt; \n        _$splits[[1L]]$in_id,]\n    }\n    \n    # Modelos\n    arvore &lt;- \n      rpart::rpart(formula = y ~ ., data = dados) |&gt; \n      predict(new.data = dados)\n    \n    floresta &lt;- \n      ranger::ranger(formula = y ~ ., data = dados) |&gt; \n      predict(data = dados, type = \"response\") |&gt; \n      _$predictions\n    \n    dados$y_arvore &lt;- arvore\n    dados$y_floresta &lt;- floresta\n    \n    dados\n  }\n  \n  step_arvore &lt;- function(i){\n    resultados &lt;- cenarios(n = n, sigma)\n    tibble(\n      x = resultados$x,\n      y = resultados$y,\n      arvore = resultados$y_arvore,\n      floresta = resultados$y_floresta\n    )\n  }\n  \n  resultados_mc &lt;- purrr::map(.x = 1L:m, .f = step_arvore)\n  resultados_mc &lt;- purrr::list_rbind(resultados_mc)\n  resultados_mc$modelos &lt;- rep(1L:(nrow(resultados_mc)/n), each = n) \n\n  # Plotando\n  \n  if(modelo == \"floresta\"){\n    resultados_mc |&gt;\n      ggplot(aes(x = x, y = y)) +\n      geom_line(aes(x = x, y = floresta, color = modelos)) +\n      geom_smooth(se = FALSE, color = \"red\")\n  } else if(modelo == \"bagging\") {\n    resultados_mc |&gt;\n      ggplot(aes(x = x, y = y)) +\n      geom_line(aes(x = x, y = arvore, color = modelos)) +\n      geom_smooth(se = FALSE, color = \"red\")\n  }\n}"
  },
  {
    "objectID": "shiny_apps/index.html#column-6",
    "href": "shiny_apps/index.html#column-6",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\nConsidere a vari√°vel aleat√≥ria \\(Y_i \\sim \\mathcal{N}(\\sin(X_i), \\sigma^2)\\), com \\(X_i \\in \\mathcal{U}(0, 10)\\,, \\forall i.\\)\n\nrenderPlot({\n  mc(\n    m = round(input$replicas_bagging_floresta,0),\n    n = input$n_bagging_floresta,\n    sigma = input$sd_bagging_floresta,\n    modelo = input$modelo_bagging_floresta\n  )\n})"
  },
  {
    "objectID": "index.html#random-forest-2",
    "href": "index.html#random-forest-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üå≤üêûüå≥üêùüå≤ü¶ãüå≥ Random Forest",
    "text": "üå≤üêûüå≥üêùüå≤ü¶ãüå≥ Random Forest\n\nA aplica√ß√£o abaixo permite que voc√™ possa comparar as estrat√©gias de bagging com o random forest, sendo este um bagging de √°rvores de regress√£o com o pequeno ajuste mencionado anteriormente, permitindo termos √°rvores menos correlacionadas. Perceba que o random forest consegue diminuir ainda mais a vari√¢ncia das previs√µes de Y. A linha vermelha √© a distribui√ß√£o verdadeira.\n\n \n\nSe desejar ver de forma ampliada, acesse a aplica√ß√£o clicando aqui."
  },
  {
    "objectID": "shiny_apps/index.html#column-7",
    "href": "shiny_apps/index.html#column-7",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEntrada de informa√ß√µes\n\nsliderInput(\"n_boosting\", \"Tamanho da amostra:\",\n    min = 50, max = 1000, value = 500, step = 50\n)\n\n\nTamanho da amostra:"
  },
  {
    "objectID": "shiny_apps/index.html#column-8",
    "href": "shiny_apps/index.html#column-8",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEstimativa"
  },
  {
    "objectID": "index.html#k-fold-cross-validation-5",
    "href": "index.html#k-fold-cross-validation-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\nA imagem abaixo ilustra o procedimento k-fold cross-validation, em que uma 5-fold cross-validation √© realizada dentro do conjunto de treinamento. Em cada split, o conjunto verde de observa√ß√µes (fold verde) s√£o utilizados para treinar/ajustar o modelo e o conjunto azul, em cada um dos splits √© utilizado para avaliar o risco preditivo R(g) (atrav√©s, por exemplo do EQM).\n\n\n \n\nN√£o confunda os folds azuis com o conjunto de teste (Test data), este √∫ltimo utilizado por fim, depois do modelo pronto, para avaliar o desempenho do modelo treinado.\nNote tamb√©m que a valida√ß√£o cruzada tamb√©m √© utilizada para o ajuste de hiperpar√¢metros, que s√£o par√¢metros de sintoniza√ß√£o que n√£o dependem dos dados para serem equalizados. Por exemplo, em uma regress√£o lasso, que veremos adiante, h√° o hiperpar√¢metro \\lambda que precisamos obter, normalmente por meio de um grid search (sequ√™ncia finita), por exemplo, \\lambda \\in [0.5, 1, 1.5, 2, 2.5] de poss√≠veis valores. Cada split pode ser utilizado para avaliar um valor de \\lambda, dos poss√≠veis valores dispostos no grid. Aumentar√≠amos a quantidade de splits para mais valores de \\lambda na sequ√™ncia."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-4",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n\nNo tidymodels, utilizamos a biblioteca rsample para realizar procedimentos de valida√ß√£o cruzada:\n\n\ninitial_split(): √∫til para uma divis√£o inicial dos dados, i.e., para aplica√ß√£o do hold-out;\nloo_cv(): se desejar realizar um procedimento de leave-one-out cross-validation;\nvfold_cv(): para um procedimento de k-folds cross-validation. Podemos inclusive realizar v√°rias repeti√ß√µes de valida√ß√£o cruzada o que poder√° remelhorar ainda mais a sele√ß√£o da melhor combina√ß√£o de hiperpar√¢metros. O n√∫mero de repeti√ß√µes de valida√ß√£o cruzada poder√° ser especificado no argumento repeats que por padr√£o √© 1L;\nbootstraps(): se for desejado utilizar um procedimento de bootstrap n√£o-param√©trico ao inv√©s de uma valida√ß√£o cruzada. O papel do bootstrap √© o mesmo da valida√ß√£o cruzada, por√©m, a sele√ß√£o das amostras de treinamento √© de mesmo tamanho da amostra de treinamento original e o procedimento √© feito com reposi√ß√£o, i.e., os mesmos dados podem aparecer nas amostras. O conjunto de avalia√ß√£o √© definido como as linhas dos dados originais que n√£o foram inclu√≠dos na amostra bootstrap. Isso geralmente √© chamado de amostra out-of-bag - OOB. Podemos alterar o n√∫mero de amostras bootstrap modificando o argumento times que por padr√£o √© 25L.\n\n\nLembre-se que qualquer procedimento de valida√ß√£o cruzada que voc√™ escolher deve ser realizado no conjunto de treinamento! üìå"
  },
  {
    "objectID": "index.html#boosting",
    "href": "index.html#boosting",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üöÄ Boosting",
    "text": "üöÄ Boosting\n\nDa mesma forma que m√©todos como bagging e random forest, os m√©todos de boosting tamb√©m tem como objetivo agregar diferentes estimadores da fun√ß√£o de regre√ß√£o r({\\bf x}). A ideia desses m√©todos que combinam diferentes estimadores da fun√ß√£o de regress√£o √© melhora a precis√£o e a performance preditiva dos modelos de m√°quina, convertendo v√°rios aprendizes fracos em um √∫nico modelo de aprendizado forte.\n\nO boosting üöÄ funciona construindo os modelos de forma sequencial, dando mais peso √†s inst√¢ncias que foram classificadas incorretamente nos modelos anteriores. O funcionamento do boosting √© semelhante ao bagging e random forest, exceto pelo fato de que a √°rvore ir√° crescendo sequencialmente: cada √°rvore √© ‚Äúcultivada‚Äù üå±üöøüå≥ usando informa√ß√µes de √°rvores crescidas. Boosting n√£o envolve amostragem bootstrap; em vez de cada √°rvore √© ajustada em uma vers√£o modificada do conjunto de dados original."
  },
  {
    "objectID": "index.html#boosting-1",
    "href": "index.html#boosting-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üöÄ Boosting",
    "text": "üöÄ Boosting\n\nExistem diversas varia√ß√µes e implementa√ß√µes de boosting com diversas implementa√ß√µes distintas em diferentes frameworks de aprendizagem de m√°quina. Aqui, ser√° descrito o conceito geral, sendo este a forma mais usual do boosting.\n\nNo boosting, como mencionado anteriormente, o estimador \\widehat{g}({\\bf x}) √© constur√≠do incrementalmente, i.e., de forma sequencial, melhorando a cada passo. Inicialmente considera-se \\widehat{g}({\\bf x}) \\equiv 0. Fazer \\widehat{g}({\\bf x}) \\equiv 0 estamos iniciando um estimador com alto vi√©s, por√©m, com vari√¢ncia muito baixa, a saber, vari√¢ncia zero.\n\nA cada passo do algoritmo, procuramos obter uma √°rvore menos viesada, por√©m, como mencionado em anteriormente, quadando falamos sobre o trade off entre vi√©s e vari√¢ncia, obtemos uma √°rvore atualizada com uma vari√¢ncia um pouco maior. Por isso √© importante partir de uma √°rvore inicial com vari√¢ncia muito baixa."
  },
  {
    "objectID": "index.html#boosting-2",
    "href": "index.html#boosting-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üöÄ Boosting",
    "text": "üöÄ Boosting\n\nA ideia √© construir um estimador para r_i, em que na primeira itera√ß√£o, considera-se r_i = y_i. A cada passo subsequente, atualizamos r_i para r_i = y_i - \\widehat{g}({\\bf x}_i), em que r_i denominados de res√≠duo. Portanto, a ideia do boosting √© prever o res√≠duo que inicia-se no r√≥tulo/label y_i.\n\nUma observa√ß√£o importante √© que as √°rvores tenham profundida pequena de modo a evitar overfitting.\n\nAl√©m disso, considera-se uma taxa de aprendizagem (learning rate) que denotaremos por \\lambda \\in [0, 1] que tem como objetivo controlar o super-ajuste. Trata-se de um hiperpar√¢metro que dever√° ser obtido via algum procedimento de cross-validation. Portanto, deveremos ‚Äútunar‚Äù üéõ o valor de \\lambda de modo a encontrar um valor adequado que maximize nosso risco observado, i.e., que maximize a previs√£o de R(g)."
  },
  {
    "objectID": "index.html#boosting-3",
    "href": "index.html#boosting-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üöÄ Boosting",
    "text": "üöÄ Boosting\n\nOs passos para conseguir boas estimativas de usando o boosting s√£o:\n\n\nDefinimos \\widehat{g}({\\bf x}) \\equiv 0 e r_i = y_i, \\, \\forall i = 1, \\cdots, n;\nPara cada b = 1, \\cdots, B, fazemos:\n\n\nAjustamos uma √°rvore com p folhas para ({\\bf x}_1, r_1), \\cdots, ({\\bf x}_n, r_n), em que denotamos essa fun√ß√£o de predi√ß√£o por \\widehat{g}^b({\\bf x}). Lembre-se que estamos estimando r_i com base em {\\bf x}_i;\nAtualizamos g e os res√≠duos: \\widehat{g}({\\bf x}) \\leftarrow \\widehat{g}({\\bf x}) + \\lambda \\widehat{g}^b({\\bf x}) e r_i \\leftarrow Y_i - \\widehat{g}({\\bf x}).\n\n\nRetorna-se o modelo final \\widehat{g}({\\bf x}).\n\nNo boosting, os valores de \\lambda, p e B s√£o hiperpar√¢metros e devem ser obtidos por meio de algum procedimento de valida√ß√£o cruzada, i.e., voc√™ dever√° ‚Äútunar‚Äù üéõ. √â comum que \\lambda seja pequeno, por exemplo, 0,01 ou 0,001, B \\approx 1000 e p de ordem pr√≥xima √† 2 ou 4."
  },
  {
    "objectID": "index.html#boosting-4",
    "href": "index.html#boosting-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üöÄ Boosting",
    "text": "üöÄ Boosting\n\nConsidere a vari√°vel aleat√≥ria Y_i \\sim \\mathcal{N}(\\sin(X_i), \\sigma^2), com X_i \\in \\mathcal{U}(0, 10)\\,, \\forall i. Experimente na aplica√ß√£o web que segue o m√©todo boosting. Observe o comportamento do estimador variando os par√¢metros do algoritmo boosting. Perceba que para \\lambda = 0 n√£o h√° aprendizado algum! Se desejar visualizar a aplica√ß√£o abaixo de forma ampliada, clique aqui."
  },
  {
    "objectID": "index.html#boosting-5",
    "href": "index.html#boosting-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üöÄ Boosting",
    "text": "üöÄ Boosting\n\nEm geral, as abordagens de aprendizagem estat√≠stica que aprendem lentamente tendem a executar bem. Observe que no boosting, ao contr√°rio do ensacamento, a constru√ß√£o de cada √°rvore depende fortemente das √°rvores que j√° foram ‚Äúcultivadas‚Äù üå±üöøüå≥. Portanto, diferentemente do bagging que √© um algoritmo em que as √°rvores em cada itera√ß√£o s√£o mutuamente independentes e, portanto, facilmente paraleliz√°vel, no boosting as √°rvores s√£o dependentes umas das outras.\n\nNa literatura de machine learning h√° diversos algoritmos que implementam o boosting. Uma implementa√ß√£o bastante popular, por conta de seu desempenho, √© denominada XGBoost, proposto em CHEN, Tianqi; GUESTRIN, Carlos. Xgboost: A scalable tree boosting system. In: Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. 2016. p.¬†785-794.\n\nNo R, o algoritmo est√° implementado na biblioteca xgboost. Caso deseje utilizar a biblioteca tidymodels em sua modelagem, √© poss√≠vel utilizar o XGBoost usando a fun√ß√£o boost_tree da biblioteca parsnip que faz parte do tidymodels. Por padr√£o, essa fun√ß√£o j√° utiliza o algoritmo XGBoost."
  },
  {
    "objectID": "index.html#boosting-6",
    "href": "index.html#boosting-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üöÄ Boosting",
    "text": "üöÄ Boosting\n\nUma outra forma de obter um valor adequado de B √© parar de adicionar itera√ß√µes quando o risco observado come√ßa a aumentar. Lembre-se que h√° um trade off entre vi√©s e vari√¢ncia, em que as itera√ß√µes come√ßam por um estimador \\widehat{g} com vari√¢ncia nula e na medida que as itera√ß√µes progridem, \\widehat{g} aumenta sua vari√¢ncia em troca da diminui√ß√£o do vi√©s. Para algum valor de B o estimador poder√° perder um pouco de performance. A ideia √© escolher um valor de B antes de atingir uma piora de \\widehat{R}(g) (risco observado). Essa estrat√©gia √© denominada de early stopping ‚åõ.\n\nMuito embora aqui apresentamos o algoritmo boostring em um contexto de √°rvores de regress√£o, esse algoritmo √© gen√©rico e poder√° ser utilizado como estat√©gia para combinar modelos que s√£o individualmente fracos."
  },
  {
    "objectID": "index.html#exerc√≠cios-11",
    "href": "index.html#exerc√≠cios-11",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Considere a vari√°vel aleat√≥ria Y_i \\sim \\mathcal{N}(\\sin(X_i), \\sigma^2), com X_i \\in \\mathcal{U}(0, 10)\\,, \\forall i. Implemente uma fun√ß√£o em R que construi o gr√°fico da aplica√ß√£o anterior. Essa fun√ß√£o dever√° ter os argumentos do algoritmo boosting, al√©m de outros argumentos para controle do tamanho da amostra e da vari√¢ncia \\sigma^2.\n\nExerc√≠cio: Construa um gr√°fico com a avalia√ß√£o do risco observado do m√©todo de boosting para diferentes valores de B. Considere B = 1, \\cdots, 10000. Comente o resultado.\n\nExerc√≠cio: Utilizando um procedimento de valida√ß√£o cruzada, e o tidymodels, obtenha uma estimativa para os hiperpar√¢metros da fun√ß√£o boost_tree(), a saber, os argumentos trees (n√∫mero de √°rvores), tree_depth (profundidade da √°rvore) e learn_rate (taxa de aprendizado). Avalie o risco preditivo do modelo, i.e., estime \\widehat{R}(g).\n\nExerc√≠cio: Compare o bagging de √°rvores de regress√£o, com o m√©todo random forest e o boosting de √°rvores de regress√£o. Qual o risco preditivo de cada um deles para prever Y_i? Construa um gr√°fico com as previs√µes, no conjunto de teste, de cada um dos modelos."
  },
  {
    "objectID": "index.html#exerc√≠cios-12",
    "href": "index.html#exerc√≠cios-12",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Considere o problema em que o objetivo √© prever a pontua√ß√£o (score) / (item 2) do aluno com base em algumas vari√°veis. S√£o elas:\n\n\nHoras estudadas: o n√∫mero total de horas gastas estudando por cada aluno;\nPontua√ß√£o: As notas obtidas pelos alunos em testes anteriores;\nAtividades extracurriculares: Se o aluno participa de atividades extracurriculares (Sim ou N√£o);\nHoras de sono: o n√∫mero m√©dio de horas de sono que o aluno teve por dia;\nAmostras de perguntas praticadas: O n√∫mero de amostras de perguntas que o aluno praticou.\n\n\nVoc√™ poder√° baixar e ter uma descri√ß√£o maior da base de dados clicando aqui. Avalie o poder preditivo do random forest comparando com o boosting e kNN. Construa uma an√°lise usando um notebook de quarto, comentando os passos.\n\nExerc√≠cio: Refa√ßa o exerc√≠cio anterior usando os dados de vermelho üçáüç∑, dispon√≠veis aqui."
  },
  {
    "objectID": "index.html#exerc√≠cios-13",
    "href": "index.html#exerc√≠cios-13",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Considere os dados reais de im√≥veis anunciados para venda na cidade de Jo√£o Pessoa - PB. S√£o mais de 27 mil observa√ß√µes obtidas via web scraping de sites de an√∫ncios imobili√°rios e referem-se √† an√∫ncios do primeiro semestre de 2023. O interesse consiste em prever o valor de um novo im√≥vel com base nas features. Clique aqui üóÉÔ∏è para acessar a base. Nessa base encontra-se diversas o label (valor dos im√≥veis) e features num√©ricas como √°rea, n√∫mero de quartos, n√∫mero de banheiros, coordenadas geogr√°ficas (latitude e longitude), quantidade de vagas de estacionamento, al√©m de diversas outras features em forma de vari√°veis dummy com valores TRUEe FALSE, como por exemplo, elevador (se tem TRUE ou n√£o FALSE), piscina (se tem TRUE ou n√£o FALSE), salao_de_festa (se tem TRUE ou n√£o FALSE), entre outras. Crie um notebook em quarto comparando todos os modelos de regress√£o apresentados at√© aqui. Realize uma an√°lise explorat√≥ria dos dados e comente todos os resultados intermedi√°rios de sua an√°lise. Conclua sua an√°lise realizando um rank da performance preditiva de cada modelo apresentando o risco preditivo R(g) estimado. Algumas sugest√µes:\n\nNote que a feature tipo apresenta os tipos de im√≥veis. Foque em casas, apartamentos e terrenos. Por exemplo, o tipo terrenos_lotes_condominio considere apenas como terrenos e o tipo casas_de_condominio considere como sendo casas. Voc√™ poder√° utilizar um one hot encoding para tornar essa vari√°vel num√©rica;\nVoc√™ n√£o ir√° precisar das features endereco e bairro, j√° que essas informa√ß√µes est√° contida nas coordenadas geogr√°ficas;\nDesconsidere as colunas iptu e condom√≠nio, j√° que s√£o bastante incipientes;\nImpute observa√ß√µes faltantes (as que cont√©m NA) pelo m√©todo kNN. Veja como fazer isso usando a fun√ß√£o step_impute_knn da biblioteca recipes.\n\nVoc√™ tamb√©m estar√° livre para realizar outras receitas na base de dados antes dos treinamentos dos modelos."
  },
  {
    "objectID": "index.html#exerc√≠cios-14",
    "href": "index.html#exerc√≠cios-14",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üìö Exerc√≠cios",
    "text": "üìö Exerc√≠cios\n\nExerc√≠cio: Refa√ßa o exerc√≠cio anterior para outras cidades. Acesse os dados clicando nos nomes das cidades abaixo:\n\n\nRecife üóÉÔ∏è\nNatal üóÉÔ∏è\nMacei√≥ üóÉÔ∏è\nBras√≠lia üóÉÔ∏è"
  },
  {
    "objectID": "index.html#redes-neurais-artificiais",
    "href": "index.html#redes-neurais-artificiais",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "üß† Redes neurais artificiais",
    "text": "üß† Redes neurais artificiais\n\n\n\nDepartamento de Estat√≠stica da UFPB"
  },
  {
    "objectID": "index.html#ridge-2",
    "href": "index.html#ridge-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ridge",
    "text": "Ridge\n\nNa documenta√ß√£o da fun√ß√£o glmnet, note que a fun√ß√£o realiza o lasso mais o ridge, i.e.,\n\n(1 - \\alpha)/2 ||\\beta_j||^2_2 + \\alpha||\\beta_j||_2.\n\nNote que para \\alpha = 1, temos uma regress√£o do tipo lasso, j√° para \\alpha = 0 reca√≠mos para uma penaliza√ß√£o do tipo ridge. Ok?!"
  }
]