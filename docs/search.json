[
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "",
    "text": "Sobre mim\n \n\nMe chamo Prof.¬†Dr.¬†Pedro Rafael D. Marinho. Meu curr√≠culo Lattes poder√° ser acessado clicando aqui.\nSou docente do Departamento de Estat√≠stica da UFPB. üë®‚Äçüè´\nToda minha forma√ß√£o acad√™mica √© na √°rea de estat√≠stica (bacharelado ao doutorado).\nTenho entusiasmo por programa√ß√£o, ci√™ncia de dados e aprendizagem de m√°quina üíªüìà.\n Me acompanhe no GitHub: https://github.com/prdm0.\n Me acompanhe no Linkedin: https://www.linkedin.com/in/prdm0/."
  },
  {
    "objectID": "index.html#sobre-mim",
    "href": "index.html#sobre-mim",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Sobre mim",
    "text": "Sobre mim\n \n\nMe chamo Prof.¬†Dr.¬†Pedro Rafael D. Marinho. Meu curr√≠culo Lattes poder√° ser acessado clicando aqui.\nSou docente do Departamento de Estat√≠stica da UFPB. üë®‚Äçüè´\nToda minha forma√ß√£o acad√™mica √© na √°rea de estat√≠stica (bacharelado ao doutorado).\nTenho entusiasmo por programa√ß√£o, ci√™ncia de dados e aprendizagem de m√°quina üíªüìà.\n Me acompanhe no GitHub: https://github.com/prdm0.\n Me acompanhe no Linkedin: https://www.linkedin.com/in/prdm0/."
  },
  {
    "objectID": "index.html#meu-segundo-lar",
    "href": "index.html#meu-segundo-lar",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Meu segundo lar",
    "text": "Meu segundo lar\n\n\n\n\nDepartamento de Estat√≠stica da UFPB."
  },
  {
    "objectID": "index.html#que-linguagem-de-programa√ß√£o-utilizar",
    "href": "index.html#que-linguagem-de-programa√ß√£o-utilizar",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Que linguagem de programa√ß√£o utilizar?",
    "text": "Que linguagem de programa√ß√£o utilizar?\n\nNesse curso, ser√° abordado a linguagem de programa√ß√£o R, mas lembre-se que voc√™ poder√° utilizar qualquer linguagem de programa√ß√£o para fazer ci√™ncia de dados. Por√©m, R e Python s√£o as minhas sugest√µes, haja vista que, atualmente, elas s√£o as linguagens com maior quantidade de ferramentas e usu√°rios trabalhando na √°rea de ci√™ncia de dados.\n\nOutros motivos que me leva a lecionar a disciplina utilizando a linguagem R s√£o:\n\nPossui ferramentas muito bem pensadas para manipula√ß√£o e tratamento de dados;\nNormalmente, os frameworks de machine learning de R s√£o menos verbosos que os de Python;\nMatrizes e data frames s√£o estruturas de dados que j√° encontra-se definidas dentro da linguagem, n√£o precisando assim de importar bibliotecas.\n\nIsso √© meu gosto pessoal! √â um gosto que, talvez, faz mais sentido, em se tratando de algu√©m que vem da estat√≠stica. No mercado de trabalho e em seus estudos, ap√≥s cursar as disciplinas de R e Python, fornecidas pelo Bacharelado em Estat√≠stica da UFPB, voc√™ ter√° a capacidade de estudar os frameworks de machine learning, aos seus pr√≥prios passos e escolher o que melhor te agrada. A linguagem Julia tamb√©m poder√° ser uma √≥tima op√ß√£o."
  },
  {
    "objectID": "index.html#aprendizagem-de-m√°quina",
    "href": "index.html#aprendizagem-de-m√°quina",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Aprendizagem de m√°quina",
    "text": "Aprendizagem de m√°quina"
  },
  {
    "objectID": "index.html#aprendizagem-de-m√°quina-1",
    "href": "index.html#aprendizagem-de-m√°quina-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Aprendizagem de m√°quina",
    "text": "Aprendizagem de m√°quina\n \nAlguns pontos:\n\n\nA Aprendizagem de M√°quina (AM), tamb√©m chamada de Machine Learning (ML), no ingl√™s, nasceu na d√©cada de 60 como um campo da intelig√™nica artificial;\nEm sua origem, as aplica√ß√µes de AM tinha como objetivo aprender padr√µes com base nos dados;\nOriginalmente, as aplica√ß√µes de AM eram de cunho estritamente computacional. Todavia, desde o in√≠cio dos anos 90, a √°rea de aprendizagem de m√°quina expandiu seus horizontes e come√ßou a se estabelecer como um campo por sim mesma;\nEm particular, a √°rea de aprendizagem de m√°quina come√ßou a estabelecer muitas intersec√ß√µes com a estat√≠stica. Muitos de seus algoritmos s√£o constru√≠dos com base em metodologias que surgiram na estat√≠stica;\nAtualmente, a comunidade de AM √© bastante interdisciplinar e utiliza-se de ideias desenvolvidas em diversas √°reas, sendo a estat√≠stica uma delas."
  },
  {
    "objectID": "index.html#tipos-de-aprendizado",
    "href": "index.html#tipos-de-aprendizado",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tipos de Aprendizado",
    "text": "Tipos de Aprendizado\n\nAprendizado supervisionado\n\nNesse curso, inicialmente estudaremos problemas de aprendizado supervisionado, que consiste em aprender a fazer predi√ß√µes a partir de conjunto de dados em que r√≥tulos (valores da vari√°vel resposta Y) s√£o observados. Trataremos tanto de problemas de regress√£o (estimar um valor n√∫m√©rico) quanto problemas de classifica√ß√£o (classificar um cliente como aprovado ou reprovado, em um problema de concess√£o de cr√©dito). Por exemplo, os modelos de regress√£o s√£o exemplos de aprendizado supervisionado.\n\nAprendizado n√£o-supervisionado\n\nNa segunda parte do curso, aprenderemos alguns m√©todos de aprendizado n√£o-supervisionado, ou seja, algoritmos que n√£o utilizam-se de r√≥tulos, em que busca-se aprender mais sobre a estrutura dos dados. Por exemplo, os m√©todos de agrupamento (cluster), s√£o exempƒ∫os de m√©todos de aprendizado n√£o-supervisionado."
  },
  {
    "objectID": "index.html#tipos-de-aprendizado-1",
    "href": "index.html#tipos-de-aprendizado-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tipos de Aprendizado",
    "text": "Tipos de Aprendizado\n\nMuito embora no nosso curso focaremos nas abordagens de aprendizagem supervisionada e n√£o-supervisionada, os tipos de aprendizagem, em geral, podem ser mais amplos, em que temos:\n\n\nAprendizagem supervisionada;\nAprendizagem n√£o-supervisionada;\nAprendizagem semi-supervisionada;\nAprendizagem por refor√ßo."
  },
  {
    "objectID": "index.html#o-que-√©-aprender",
    "href": "index.html#o-que-√©-aprender",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "O que √© aprender?",
    "text": "O que √© aprender?\n\nAntes de detalharmos os tipos de aprendizagem de m√°quina, uma d√∫vida que poder√° surgir √©: ‚ÄúO que √© aprender?‚Äù. ‚ÄúComo a m√°quina aprende?‚Äù."
  },
  {
    "objectID": "index.html#o-que-√©-aprender-1",
    "href": "index.html#o-que-√©-aprender-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "O que √© aprender?",
    "text": "O que √© aprender?\n\nDe forma simples, aprender √© ganhar conhecimento atrav√©s de estudo, experi√™ncias, por meio de ensinamentos.\n\nT√°, mais como √© que a m√°quina aprende?\n\n\nAprendizagem √© o processo em que se adquire conhecimento, isto √©, √© o processo em que utilizamos de algoritmos e fornecemos dados a esses algoritmos para que possamos extrair conhecimento. Nesse processo de aprendizagem, os algoritmos fazem uso de dados para a extress√£o de conhecimento, atrav√©s de procedimentos supervisionado, n√£o-supervisionado, semi-supervisionado ou por refor√ßo, a depender do algoritmo que voc√™ deseja utilizar.\nAprendizado √© o modelo ajustado, isto √©, √© o conhecimento adquirido ap√≥s o treinamamento obtido no processo de aprendizagem. Voc√™ poder√° entender como sendo o modelo ajustado e que utilizamores para a tomada de decis√µes."
  },
  {
    "objectID": "index.html#o-que-√©-aprender-2",
    "href": "index.html#o-que-√©-aprender-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "O que √© aprender?",
    "text": "O que √© aprender?\n\nPortanto, voc√™ poder√° entender, basiciamente, existe quatro tipos de aprendizagem, sendo os dois primeiros o que mais focaremos nesse curso e que de longe s√£o os mais utilizados:\n\n\nAprendizagem supervisionada;\nAprendizagem n√£o-supervisionada;\nAprendizagem semi-supervisionada;\nAprendizagem por refor√ßo."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada",
    "href": "index.html#aprendizagem-supervisionada",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\nNesse tipo de aprendizagem, o algoritmo ir√° receber um conjunto de dados em que conhecemos r√≥tulos para a vari√°vel de interesse. √â como se voc√™ soubesse onde um bom modelo deve chegar, para assim ser reconhecido como um bom modelo. Por exemplo,\n\n\nClassifica√ß√£o: precisamos determinar a classe de uma inst√¢ncia de dados, o seu atributo, i.e., \\widehat{y} = \\mathrm{argmax}_y\\,P(Y = y\\,|\\, X = \\bf{x}), em que y √© um atributo que desejamos prever (cahorro, gato, sapo), e \\bf{x} √© um vetor de caracter√≠sticas (peso, altura, comprimento, se tem rabo, etc).\nRegress√£o: precisamos estimar uma quantidade num√©rica, i.e., o valor da vari√°vel alvo por meio de uma inst√¢ncia de dados, ou seja, precisamos estimar Y = \\mathbb{E}(Y|X = \\bf{x}), i.e., devemos encontrar meios de obter \\widehat{Y}.\n\n\n\n\nAlgumas observa√ß√µes de nomenclaturas:\n\n√â comum chamar cada exemplo de dados, i.e., o vetor \\bf{x} que ser√° passado ao modelo de atributos ou features;\nTamb√©m √© comum chamarmos de r√≥tulo ou label a classe ou valor alvo, ou seja, estas s√£o as formas de nomearmos Y, sendo Y uma quantidade num√©rica (modelos de regress√£o) ou n√£o (modelos de classifica√ß√£o)."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-1",
    "href": "index.html#aprendizagem-supervisionada-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\nEm se tratando de m√©todos de classifica√ß√£o, podemos ter os m√©todos:\n\n\nGenerativos: s√£o os m√©todos que dada as vari√°veis X e Y, o objetivo √© encontrar a distribui√ß√£o de probabilidade conjunta P(X, Y), para ent√£o poder determinar P(Y|X = \\bf{x}). Alguns m√©todos s√£o:\n\nNaive Bayes;\nDescriminante linear.\n\n\n\n\nDescriminativos: s√£o os m√©todos que estimam diretamente a probabilidade condicional P(Y|X = \\bf{x}) ou que mesmo nem assumem modelos probabil√≠sticos. Os modelos dessa classe s√£o projetados para aprender a fronteira de decis√£o que separa as classes diretamente com base nas caracter√≠sticas de entrada. Podemos citar:\n\nRegress√£o logistica;\nPerceptron;\nSupport Vector Machine - SVM."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-2",
    "href": "index.html#aprendizagem-supervisionada-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\n\n\n\n\n Poder√≠amos estar interessados em classificar o tamanho de morangos:\n\n\nS (Slow): pequeno;\nM (Medium): m√©dio;\nL (Large): grande."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-3",
    "href": "index.html#aprendizagem-supervisionada-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n \n\nMais dois problemas de classifica√ß√£o (linear x n√£o-linear)."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-4",
    "href": "index.html#aprendizagem-supervisionada-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n \n\nUm exemplo de de um problema de regress√£o. Aqui, a ideia √© utilizar a equa√ß√£o da reta estimada, a reta que minimiza a soma dos quadrados entre a reta e os ponto seria a melhor, de modo a ter uma estimativa num√©rica atrav√©s de novos atributos passado ao modelo, i.e., por meio da equa√ß√£o da reta e de um novo valor de x."
  },
  {
    "objectID": "index.html#aprendizagem-supervisionada-5",
    "href": "index.html#aprendizagem-supervisionada-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem supervisionada",
    "text": "Aprendizagem supervisionada\n\nUm outro exemplo seria a classifica√ß√£o de imagem/v√≠deo, utilizando um algoritmo de rede neural, por exemplo, usando uma Convolutional Neural Network - CNN. Foram utilizados diversas imagens de pessoas ‚Äúcom‚Äù e ‚Äúsem‚Äù m√°scara. Em que ‚Äúcom‚Äù representa detec√ß√£o da m√°scara na face da pessoa e ‚Äúsem‚Äù a n√£o detec√ß√£o."
  },
  {
    "objectID": "index.html#aprendizagem-n√£o-supervisionada",
    "href": "index.html#aprendizagem-n√£o-supervisionada",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem n√£o-supervisionada",
    "text": "Aprendizagem n√£o-supervisionada\n\nNesse tipo de aprendizagem, os algoritmos trabalham sobre dados n√£o rotulados, por exemplo, em uma trarefa de agrupamento.\n\nOs algoritmos verificam se as inst√¢ncias observadas poder√£o ser arranjadas de alguma maneira, por exemplo, usando alguma m√©trica de dist√¢ncia, formando grupos (clusters).\n\nA ideia √© maximizar a dist√¢ncia entre os clusters e minimizar a dist√¢ncia entre os elementos no interrior do grupo. Em outras palavras, o que se quer √© tornar os grupos mais diferentes poss√≠veis e tornar os elementos dos grupos o mais parecido poss√≠vel.\n\nAqui, por n√£o haver r√≥tulos, um problema comum √© determinar a quantidade de grupos ideal que muitas vezes s√£o obtidos de forma subjetiva ou por heur√≠sticas. A quantidade de grupos √© um dilema!"
  },
  {
    "objectID": "index.html#aprendizagem-n√£o-supervisionada-1",
    "href": "index.html#aprendizagem-n√£o-supervisionada-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem n√£o-supervisionada",
    "text": "Aprendizagem n√£o-supervisionada\n\n\nAp√≥s a detec√ß√£o dos grupos, √© preciso analisar o resultado de modo a tentar extrair informa√ß√µes coerentes de modo a saber o que cada grupo representa no problema em quest√£o."
  },
  {
    "objectID": "index.html#aprendizagem-semi-supervisionada",
    "href": "index.html#aprendizagem-semi-supervisionada",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem semi-supervisionada",
    "text": "Aprendizagem semi-supervisionada\n\nA aprendizagem semi-supervisionada √© uma abordagem na √°rea de aprendizagem de m√°quina em que um algoritmo utiliza tanto dados rotulados quanto n√£o rotulados para treinamento. Por exemplo, algoritmos que propagam r√≥tulos, como o Label Propagation, em que r√≥tulos conhecidos s√£o propagados para dados n√£o rotulados com base em sua sua proximidade no espa√ßo de caracter√≠sticas.\n\nUma outra abordagem seria misturar modelos (Model Blending), em que diferentes modelos s√£o treinados em diferentes partes do conjunto de dados, por exemplo, um modelo para a parte roturada e um para a parte n√£o rotulada."
  },
  {
    "objectID": "index.html#aprendizagem-por-refor√ßo",
    "href": "index.html#aprendizagem-por-refor√ßo",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Aprendizagem por refor√ßo",
    "text": "Aprendizagem por refor√ßo\n\nNesse tipo de aprendizagem, n√£o h√° uma fonte externa de exemplos. O agente (modelo) aprende aprende com sua pr√≥pria experi√™ncia, por tentativas e erros, em que voc√™ dever√° definir uma medida de sucesso, e eventualmente recompensar os acertos. No v√≠deo abaixo, veja um joguinho que criei em R, em que o carrinho aprendeu a desviar de obst√°culos aleat√≥rios que aparecem em sua frente. Utilizou-se uma rede neural cuja a sa√≠da poderia ser (‚Äúparado‚Äù, ‚Äúpara cima‚Äù ou ‚Äúpara baixo‚Äù). Veja o c√≥digo clicando aqui."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamentom",
    "href": "index.html#dados-explora√ß√£o-e-tratamentom",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamentom",
    "text": "Dados: explora√ß√£o e tratamentom\n\nUm dos passos mais importante no fluxo de trabalho (workflow) de um modelo de aprendizagem de m√°quina, consiste na prepara√ß√£o dos dados, onde realizamos transforma√ß√µes, inputa√ß√µes de valores ausentes, identifica√ß√£o de outliers, remo√ß√£o de vari√°veis altamente correlacionadas, entre outros.\n\nFazer uma an√°lise explorat√≥ria dos dados √© um passo importante para que se possa entender e detecatar poss√≠veis inconsist√™ncias na base de dados. N√£o adianta fazer uso de modelos muito sofisticados quando se tem uma base de dados cheia de problemas.\n\nNormalmente trabalhamos com juntos de dados (tabelas) relacionais, em que cada linha √© uma observa√ß√£o e cada coluna representa um atributo do objeto/observa√ß√£o. A linha de uma base de dados relacional, sem sua a vari√°vel de interesse, lembre-se que denominamos Y de r√≥tulo ou label, fornece o vetor de caracter√≠sticas \\bf{x} que descreve uma dada observa√ß√£o."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento",
    "href": "index.html#dados-explora√ß√£o-e-tratamento",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nUm dos passos mais importante no fluxo de trabalho (workflow) de um modelo de aprendizagem de m√°quina, consiste na prepara√ß√£o dos dados, em que realizamos transforma√ß√µes, inputa√ß√µes de valores ausentes, identifica√ß√£o de outliers, remo√ß√£o de vari√°veis altamente correlacionadas, entre outros.\n\nFazer uma an√°lise explorat√≥ria dos dados √© um passo importante para que se possa entender e detecatar poss√≠veis inconsist√™ncias na base de dados. N√£o adianta fazer uso de modelos muito sofisticados quando se tem uma base de dados cheia de problemas.\n\nNormalmente trabalhamos com juntos de dados (tabelas) relacionais, em que cada linha √© uma observa√ß√£o e cada coluna representa um atributo do objeto/observa√ß√£o. A linha de uma base de dados relacional, sem sua a vari√°vel de interesse, lembre-se que denominamos Y de r√≥tulo ou label, fornece o vetor de caracter√≠sticas \\bf{x} que descreve uma dada observa√ß√£o."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-1",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\nNo artigo Tidy Data, 2014, publicado no Journal of Statistical Sofware, o Hadley Wickham discute que o princ√≠pio de dados organizados est√£o intimamente relacionados com banco de dados relacional e mais pr√≥ximo do recioc√≠nio que empregamos na √°lgebra. Nesse artigo, ele define o que √© Tidy Data, sendo essa uma maneira de mapear um conjunto de dados.\n\nSegundo o artigo, um conjunto de dados √© bagun√ßado ou arrumado/tidy, dependendo de como as linhas, colunas e tabelas s√£o combinadas com as observa√ß√µes, vari√°veis e tipos. Em dados arrumados (dados tidy), temos que:\n\n\nCada vari√°vel forma uma coluna;\nCada observa√ß√£o forma uma linha;\nCada valor deve ter sua pr√≥pria c√©lula.\n\n\nEmbora existam situa√ß√µes em que j√° podemos come√ßar a analisar uma base de dados real, essa √© a exce√ß√£o e n√£o a regra. Normalmente, nos deparamos com bases de dados que violam uma ou mais dessas regras. Sempre, que poss√≠vel, procure utilizar dados no formato Tidy."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-2",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\n\nRepresenta√ß√£o de uma base de dados no formato tidy."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-3",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\n\n‚ÄúAs fam√≠lias felizes s√£o todas iguais; toda fam√≠lia infeliz √© infeliz √† sua maneira.‚Äù ‚Äì Leo Tolstoy\n\n\n‚ÄúConjuntos de dados organizados s√£o todos iguais, mas todo conjunto de dados confuso √© confuso √† sua maneira.‚Äù ‚Äì Hadley Wickham\n\n\n\nTrabalhar com a Tabela do lado esquerdo √© melhor que a Tabela do lado direito. Prefira, sempre que poss√≠vel, o formato tidy. N√£o permita-se ficar estressado t√£o facilmente. üòÉ"
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-4",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\nA linguagem de programa√ß√£o R possue diversas ferramentas que permite manipular e explorar bases de dados. Enumero algumas:\n\ndplyr: biblioteca que implementa √© uma gram√°tica de manipula√ß√£o de dados, fornecendo um conjunto consistente de verbos que ajudam a resolver os desafios mais comuns de manipula√ß√£o de dados;\ntidyr: ferramentas para ajudar a criar dados organizados, em que cada coluna √© uma vari√°vel, cada linha √© uma observa√ß√£o e cada c√©lula cont√©m um √∫nico valor;\nggplot2: um sistema para criar gr√°ficos ‚Äòdeclarativamente‚Äô, baseado no livro The Grammar of Graphics, de Leland Wilkinson;\nvisdat: uma biblioteca √∫til para um visualiza√ß√£o explorat√≥ria preliminar de dados;\nexplore: biblioteca que apresenta algumas rotinas de an√°lise para realizar uma an√°lise explorat√≥ria nos dados.\n\nTodas essas bibliotecas est√£o muito bem documentadas. √â importante que voc√™s explorem as documentas dessas bibliotecas, pois eventualmente irei utizar alguma delas."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-5",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nNo Cap√≠tulo 12, do livro R for Data Science, o autor aborda mais sobre o formato Tidy e como trabalhar com a biblioteca tidyr. Aqui o autor aborda de forma b√°sica o pacote dplyr.\n\nDurante o curso, na medida da necessidade de utiliza√ß√£o dessas ferramentas, durante a exposi√ß√£o de exemplos, abordaremos alguns conceitos. Ok?!"
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-6",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nMuitas vezes, no processo de tratamento dos dados, tamb√©m estamos preocupados em remover atributos que n√£o s√£o significativo para a modelagem, em que nesse momento a experi√™ncia dos especialistas s√£o fundamentais.\n\n√â comum enriquercermos a base de dados com informa√ß√µes de outras bases de dados, em um sistema de gerenciamento de banco de dados relacional, em que as bases de dados est√£o relacionadas por uma chave. Nesse caso, buscamos por novos atributos para um mesmo objeto (para uma mesma linha da base), em que atributos cruzados devem ter um √∫nico valor, para cada objeto, respeitando a regra tr√™s de conjuntos de dados tidy.\n\nAs vezes transformamos vari√°veis. Por exemplo, √© comum tomar o logaritmo de uma vari√°vel num√©rica que √© assim√©trica, se x \\geq 1, em que x √© um atributo num√©rico qualquer.\n\nEm diveras situa√ß√µes, tamb√©m √© comum a base de dados apresentar informa√ß√µes faltantes. Nos data frames de R, a falta de informa√ß√£o na base, normlamente ser√£o representadas por NA."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-7",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nPoder√° ser que um dado atributo apresente informa√ß√£o faltante, e normalmente n√£o optaremos em remover a observa√ß√£o e precisaremos imputar a informa√ß√£o, por exemplo:\n\n\nTomando alguma medida de tend√™ncia central como m√©dia/moda/mediana dos valores que s√£o conhecidos para aquele atributo;\nCriar um novo valor que √© indica√ß√£o de valor faltante;\nUsar algoritmos como k-nearest neighbors - KNN (k vizinhos mais pr√≥ximos) para imputar valores coerentes;\nInterpolar os dados.\n\nEsses s√£o alguns exemplos de como podemos imputar observa√ß√µes faltantes. Muitas vezes n√£o podemos nos dar o luxo de percer observa√ß√µes de nossa base de dados."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-8",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\n√â comum ser necess√°rio transformar os dados:\n\nPode ser necess√°rio transformar os tipos ou os valores dos atributos para tentar obter um melhor ajuste do modelo;\nPode-se discretizar valores cont√≠nuos ou transform√°-los em intervalos;\n√â comum transformar atributos categ√≥ricos com p categorias, em p novos atributos bin√°rios.\n\nOne-hot encoding\nVari√°veis dummy\n\nOutra transforma√ß√£o muito comum √© a normaliza√ß√£o dos dados. Normalizar os dados √© muito √∫til quando os atributos num√©ricos possuem escalas muito diferentes.\n\n\n\nX_{novo} = \\frac{X - X_{min}}{X_{max} - X_{min}}, em que X_{novo} \\in [0, 1].\n\nX_{novo} = Z = \\frac{X - \\mu}{\\sigma^2}, em que \\mathbb{E}(X) = \\mu √© a m√©dia dos dados e \\mathrm{Var}(X) = \\sigma^2. Na pr√°tica, em um contexto de v.a., iids, usamos \\overline{x} como estimador de \\mu e S^2 (vari√¢ncia amostral) como estimador de \\sigma^2."
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-9",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-9",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nLembre-se, como citado anteriormente, tomar o logaritmo natural, ou mesmo na base 10 de vari√°veis num√©ricas muito assim√©tricas, poder√° ajudar um pouco, desde que seja possivel tomar o \\log(\\cdot).\n\n\n\n\nset.seed(0)\nrgamma(1000, 2, 2) |&gt; \n  hist()\n\n\n\n\n\n\nset.seed(0)\nrgamma(1000, 2, 2) |&gt; \n  log() |&gt; hist()"
  },
  {
    "objectID": "index.html#as-duas-culturas",
    "href": "index.html#as-duas-culturas",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "As duas culturas",
    "text": "As duas culturas\n\nEm Breiman, L. (2001a). Statistical modeling: The two cultures. Statistical Science, 16(3), 199‚Äì231, o Leo Breiman argumenta que existe duas culturas no uso de modelos estat√≠sticos, em especialmente na √°rea de modelos de regress√£o. Segundo eles, as culturas s√£o:\n\n\nData modeling culture: nela, em geral, se assume que o modelo de regress√£o utilizado r(x), por exemplo, r(x) = \\beta_0 + \\sum_{i = 1}^d \\beta_ix_i √© correto. O principal objetivo dessa abordagem √© a interpreta√ß√£o dos par√¢metros que indexam o modelo r(x). Nesse tipo de cultura, a ideia tamb√©m √© construir intervalos aleat√≥rios e testar hip√≥teses para os \\beta_i's. Sob essa √≥tica, muitas suposi√ß√µes sob o modelo s√£o realizadas, em que formas para checar essas suposi√ß√µes s√£o desenvolvidas, uma vez que elas s√£o fundamentais para esse tipo de modelagem.\n\n\n\nAlgorithmic modeling culture: essa √© a cultura que domina a comunidade de aprendizagem de m√°quina. Nessa abordagem, o principal objetivo s√£o as predi√ß√µes por meio de novas observa√ß√µes. N√£o se assume que o modelo utilizado √© o modelo correto. Nesse tipo de modelagem, muitas vezes os algoritmos n√£o envolve nenhuma estrutura probabil√≠stica. Muitas vezes, modelos n√£o bem especificado conduzem a boas predi√ß√µes."
  },
  {
    "objectID": "index.html#as-duas-culturas-1",
    "href": "index.html#as-duas-culturas-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "As duas culturas",
    "text": "As duas culturas\n\n\n\n\n\n\nBreiman, L. (2001a). Statistical modeling: The two cultures. Statistical Science, 16(3), 199‚Äì231.\n\n\n\n\n\n\nLeo, na √©poca em que era um jovem probabilista na Universidade da Calif√≥rina."
  },
  {
    "objectID": "index.html#as-duas-culturas-2",
    "href": "index.html#as-duas-culturas-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "As duas culturas",
    "text": "As duas culturas\n\nH√° diversos artigos interessantes que s√£o respostas ao artigo do Leo Breiman, como por exemplo, o artigo Statistical Modeling: The Two Cultures: Comment do David Cox e com coment√°rios do Brad Efron.\n\nSir David Cox."
  },
  {
    "objectID": "index.html#as-duas-culturas-3",
    "href": "index.html#as-duas-culturas-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "As duas culturas",
    "text": "As duas culturas\n\nMuito embora exista essa divis√£o entre as culturas, Breiman foi um estat√≠stico que desempenhou um grande trabalho para unir a √°rea de estat√≠stica com aprendizado de m√°quina. Por conta dessa grande import√¢ncia, um pr√™mio concedido em sua homenagem foi criado pela American Statistical Association.\n\nLeo Breiman trabalhando em sua resid√™ncia, em 1985."
  },
  {
    "objectID": "index.html#regress√£o",
    "href": "index.html#regress√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o",
    "text": "Regress√£o\n\nM√©todos de regress√£o surgiram h√° mais de dois s√©culos com Legendre (1805) e Gauss (1809), que exploraram o m√©todo dos m√≠nimos quadrados com o objetivo de prever √≥rbitas ao redor do Sol. Hoje em dia, o problema de estima√ß√£o de uma fun√ß√£o de regress√£o possui papel central em estat√≠stica.\n\n\nApesar de as primeiras t√©cnicas para solucionar esse problema datarem de ao menos 200 anos, os avan√ßos computacionais recentes permitiram que novas metodologias fossem exploradas. Em particular, com a capacidade cada vez maior de armazenamento de dados, m√©todos com menos suposi√ß√µes sobre o verdadeiro estado da natureza ganham cada vez mais espa√ßo. Com isso, v√°rios desafios surgiram: por exemplo, m√©todos tradicionais n√£o s√£o capazes de lidar de forma satisfat√≥ria com bancos de dados em que h√° mais covari√°veis que observa√ß√µes, uma situa√ß√£o muito comum nos dias de hoje. Similarmente, s√£o frequentes as aplica√ß√µes em que cada observa√ß√£o consiste em uma imagem ou um documento de texto, objetos complexos que levam a an√°lises que requerem metodologias mais elaboradas. ‚Äì Izbick et al."
  },
  {
    "objectID": "index.html#regress√£o-1",
    "href": "index.html#regress√£o-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o",
    "text": "Regress√£o\n\nDe forma geral, temos que o objetivo de um modelo de regress√£o √© determinar a rela√ß√£o entre uma vari√°vel aleat√≥ria (label) Y \\in \\mathbb{R} e um vetor de covari√°veis (features) \\mathbf{x} = (x_1, \\cdots, x_d) \\in \\mathbb{R}^d. Mais especificamente, busaca-se estimar\nr(\\bf{x}) := \\mathbb{E}(Y|\\bf{X} = \\bf{x}),\nsendo esta chamada de fun√ß√£o de regress√£o. Temos que:\n\n\nSe Y √© uma vari√°vel quantitativa, ent√£o estamos sob um problema de regress√£o;\nSe Y √© uma vari√°vel qualitativa, ent√£o teremos um problema de classifica√ß√£o.\n\nEm aprendizagem de m√°quina, assumimos que n√£o temos meios de calcular r({\\bf{x}}), i.e., n√£o conhecemos a distribui√ß√£o condicional de {\\bf{Y}\\,|\\,X}. Portanto, n√£o temos meios de calcular\n\\mathbb{E}({\\bf X}|Y = y) = \\int x\\,\\mathrm{d}F_{\\bf X}({\\bf x} | Y = y)."
  },
  {
    "objectID": "index.html#nota√ß√µes",
    "href": "index.html#nota√ß√µes",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nota√ß√µes",
    "text": "Nota√ß√µes\n\nA vari√°vel Y recebe frequentemente o nome de vari√°vel resposta, vari√°vel dependente, r√≥tulo ou label. J√° as observa√ß√µes contidas no vetor \\bf{x} = (x_1, \\cdots, x_d), s√£o, em geral, denominadas de vari√°veis explicativas, vari√°veis independentes, caracter√≠sticas, atributos, preditores, covari√°veis ou features.\n\nA ideia, nessa primeira parte do curso, √© descrever algumas t√©cnicas para estimar (treinar, como √© dito em aprendizagem de m√°quina) r(\\bf{x}).\n\nA menos quando dito o contr√°rio, assumiremos que nossa amostra s√£o i.i.d. (independentes e identicamente distribu√≠das), ou seja, (\\bf{X}_1, Y_1), \\cdots, (\\bf{X}_n, Y_n) s√£o i.i.d.\n\nDenota-se por x_{i,j} o valor da j-√©sima covari√°vel na i-√©sima amostra, com j = 1, \\cdots, d e i = 1, \\cdots, n."
  },
  {
    "objectID": "index.html#nota√ß√µes-1",
    "href": "index.html#nota√ß√µes-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nota√ß√µes",
    "text": "Nota√ß√µes\n\n\nNota√ß√£o utilizada nesse material para as vari√°veis envolvidas em um problema de regress√£o.\n\n\n\n\n\n\nLabel\nFeatures\n\n\n\n\nY_1\nX_{1,1},\\cdots, X_{1,d}\\,\\,\\, (= \\bf{X}_1)\n\n\n\\vdots\n\\,\\,\\,\\vdots\\,\\,\\,\\,\\, \\ddots\\,\\,\\ \\vdots\n\n\nY_n\nX_{n,1},\\cdots, X_{n,d}\\,\\,\\, (= \\bf{X}_n)"
  },
  {
    "objectID": "index.html#regress√£o-2",
    "href": "index.html#regress√£o-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o",
    "text": "Regress√£o\nNossa ideia √© construir uma boa estimativa g da fun√ß√£o de regress√£o r(\\bf{x}) := \\mathbb{E}(Y\\,|\\,\\bf{X} = \\bf{x}), para novas observa√ß√µes, i.e., queremos obter uma fun√ß√£o g, tal que:\ng: \\mathbb{R}^d \\rightarrow \\mathbb{R},\nde tal forma que g possua um bom poder preditivo. Em aprendizagem de m√°quina, s√≥ estaremos interessados em obter uma fun√ß√£o g que estime bem um n√∫mero real (em problemas de regress√£o), ou que classifique bem (em um problema de classifica√ß√£o), utilizando as d covari√°veis. Ou seja, para m novas observa√ß√µes, desejamos obter g, que\ng({\\bf{x}}_{n + 1}) \\approx y_{n + 1}, \\cdots, g({\\bf{x}}_{n + m}) \\approx y_{n + m}."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco",
    "href": "index.html#fun√ß√£o-de-risco",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nPara que possamos construir boas fun√ß√µes de predi√ß√£o, √© preciso que tenhamos um crit√©rio para medir o desempenho de uma dada fun√ß√£o g:\\mathbb{R}^d \\rightarrow \\mathbb{R}. Em contexto de regress√£o, usaremos o risco quadr√°tico, muito embora esta n√£o √© a √∫nica op√ß√£o. Denotaremos a fun√ß√£o de risco quadr√°tico por:\nR_{pred}(g) = \\mathbb{E}\\left[({\\bf Y} - g({\\bf X}))^2\\right], em que (\\bf X, Y) s√£o observa√ß√µes novas que n√£o foram utilizadas para treinar/estimar g. L√™-se R_{pred}(g) como ‚Äúrisco preditivo de g‚Äù. Note que, como \\bf X s√£o observa√ß√µes conhecidas e g(\\cdot) √© um modelo preditivo, portanto, g √© conhecido, ent√£o, \\widehat{\\bf Y} = g(\\bf X) √© um estimador dos labels, i.e., de \\bf Y.\n\nDiremos que L(g({\\bf X}); {\\bf Y}) = ({\\bf Y} - g({\\bf X}))^2 √© a fun√ß√£o de perda quadr√°tica, as vezes chamado de perda L_2. Outra fun√ß√µes como a fun√ß√£o de perda absoluta denotada por L(g({\\bf X}); {\\bf Y}) = |{\\bf Y} - g({\\bf X})|, as vezes chamada de perda L_1 poderiam ser consideradas."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-1",
    "href": "index.html#fun√ß√£o-de-risco-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nEm linhas gerais, seja L(\\cdot) uma fun√ß√£o qualquer, tal que \\forall \\, 0 &lt; u &lt; v, de modo que:\n\n\n0 = L(0) \\leq L(u) \\leq L(v);\n0 = L(0) \\leq L(-u) \\leq L(-v).\n\n\nQualquer fun√ß√£o L(\\cdot) que satisfaz as propriedades acima √© chamada de fun√ß√£o de perda. Em especial, temos que:\n\n\nFun√ß√£o de perda quadr√°tica: L(u) = u^2;\nFun√ß√£o de perda absoluta: L(u) = |u|;\nFun√ß√£o de perda degrau: L(0) = 0, se |u| &lt; \\delta e 1 caso contr√°rio, para algum \\delta &gt; 0;"
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-2",
    "href": "index.html#fun√ß√£o-de-risco-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nNormalmente considera-se a perda L_2, uma vez que em modelos de regress√£o, minimizar R_{pred}(g), em g, equivale a encontrar r({\\bf x}) = \\mathbb{E}({\\bf X}|{\\bf Y}), i.e., equivale a estimar a fun√ß√£o de regress√£o.\n\nTeorema: Suponha que definimos o risco de uma fun√ß√£o de predi√ß√£o g: \\mathbb{R}^d \\rightarrow \\mathbb{R} via fun√ß√£o perda quadr√°tica, i.e, R_{pred}(g) = \\mathbb{E}\\left[({\\bf Y} - g({\\bf X}))^2\\right], em que \\bf (X, Y) s√£o novas observa√ß√µes que n√£o foram utilizadas para estimar g. Suponha tamb√©m que estimamos o risco de um estimador de regress√£o r({\\bf X}) via fun√ß√£o perda quadr√°tica R_{reg}(g) = \\mathbb{E}\\left[(r({\\bf X}) - g({\\bf X}))^2\\right]. Ent√£o,\nR_{pred}(g) = R_{reg}(g) + \\mathbb{E}\\left[\\mathbb{V}[{\\bf Y} | {\\bf X}]\\right],\nem que \\mathbb{E}\\left[\\mathbb{V}[{\\bf Y} | {\\bf X}]\\right] √© a vari√¢ncia m√©dia do modelo que n√£o depende de g. Portanto, estimar bem r({\\bf x}) √© de fundamental import√¢ncia para criar uma boa fun√ß√£o de predi√ß√£o. Em especial, sob a √≥tica do risco quadr√°tico, a melhor fun√ß√£o de predi√ß√£o para \\bf Y √© a fun√ß√£o de regress√£o r({\\bf x}), de tal modo que:\n\\argmin_g R_{pred}(g) = \\argmin_g R_{reg}(g) = r({\\bf x})."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-3",
    "href": "index.html#fun√ß√£o-de-risco-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nLembre-se: r({\\bf x}) = \\mathbb{E}(Y | \\bf{X} = \\bf{x}) √© a nossa fun√ß√£o de regress√£o.\n\nA defini√ß√£o de risco preditivo R_{pred}, que tamb√©m denotaremos simplesmente por R, tem um apelo frequentista. Dessa forma, para um novo conjunto com m novas observa√ß√µs, ({\\bf X}_{n+1}, Y_{n+1}), \\cdots, ({\\bf X}_{n+m}, Y_{n+m}), temos que que essa nova amostra √© i.i.d √† amostra observada (utilizada no treinamento do modelo/na estima√ß√£o). Ent√£o, pela Lei dos Grandes N√∫meros, temos que um bom estimador para a fun√ß√£o para o risco preditivo √© dado por:\n\\frac{1}{m}\\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \\approx R(g) := \\mathbb{E}\\left[(Y - g({\\bf X}))^2\\right]. \\tag{1}\nChamaremos a quantidade acima de Erro Quadr√°tico M√©dio - EQM. Em aprendizagem de m√°quina, normalmente estaremos no contexto em que temos muitas observa√ß√µes, e que portanto, poderemos fazer esse apelo frequentista.\n\nDesejamos encontrar g (encontrar m√©todos) que minimize de forma satisfat√≥ria R, i.e., m√©todos que nos conduzam √† um risco baixo."
  },
  {
    "objectID": "index.html#fun√ß√£o-de-risco-4",
    "href": "index.html#fun√ß√£o-de-risco-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Fun√ß√£o de risco",
    "text": "Fun√ß√£o de risco\n\nSendo assim, se R(g) possui um valor baixo, ent√£o, temos que\ng({\\bf x}_{n+1}) \\approx y_{n+1}, \\cdots, g({\\bf x}_{n+m}) \\approx y_{n+m}."
  },
  {
    "objectID": "index.html#regress√£o-linear",
    "href": "index.html#regress√£o-linear",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear",
    "text": "Regress√£o linear\n\nNesse momento, vamos pensar um pouco em regress√£o linear. No caso mais simples, queremos prever o comportamento de uma vari√°vel de interesse Y condicional a uma vari√°vel explicativa X (regress√£o linear simples, i.e., d = 1). O melhor preditor de Y condicional em X √© aquele que minimiza a fun√ß√£o de perda esperada, ou seja, √© aquele que resolve:\n\\argmin_g \\mathbb{E}(L(Y - g)|X).\nPara o caso da fun√ß√£o perda quadr√°tica (fun√ß√£o L_2), o melhor preditor de Y condicional √† X √© a m√©dia condicional de Y dado X, i.e., r(X) = \\mathbb{E}(Y|X). J√°, na situa√ß√£o em que considera-se a perda absoluta (fun√ß√£o L_1), o melhor estimador √© a mediana condicional.\n\nOs modelos de regress√£o, em geral, fazem uso da fun√ß√£o de perda quadr√°tica."
  },
  {
    "objectID": "index.html#regress√£o-linear-simples",
    "href": "index.html#regress√£o-linear-simples",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear simples",
    "text": "Regress√£o linear simples\n\nNo caso da regress√£o linear simples (d = 1), temos que o modelo √© dado por:\ng(x) = \\beta_0 + \\beta_1 x_{i,1} + \\varepsilon_i, \\,\\, i = 1, \\cdots, n, em que \\varepsilon_i √© um erro aleat√≥rio. Na abordagem data modeling culture, v√°rias suposi√ß√µes poderem ser feitas para \\varepsilon_i.\nAssumindo que a regress√£o linear simples √© o modelo g que iremos utilizar, ent√£o, desejamos minimizar:\n\\argmin_{\\beta} R(g_\\beta) = \\argmin_{\\beta} \\sum_{i = 1}^n(y_i - \\beta_0 - \\beta_1x_{i,1})^2. Derivando em rela√ß√£o √† \\beta e igualando a zero, ap√≥s algumas manipula√ß√µes alg√©bricas, temos que:\n\\widehat{\\beta} = \\frac{\\sum_{i = 1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n(x_i - \\overline{x})^2} = r_{xy}\\frac{s_y}{s_x}, em que s_x e s_y s√£o os desvio-padr√£o de x e y, respectivamente, e r_{xy} √© o coeficiente de correla√ß√£o da amostra."
  },
  {
    "objectID": "index.html#regress√£o-linear-simples-1",
    "href": "index.html#regress√£o-linear-simples-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear simples",
    "text": "Regress√£o linear simples\n\nr_{xy} = \\frac{\\overline{xy} - \\overline{x}\\,\\overline{y}}{\\sqrt{(\\overline{x^2} - \\overline{x}^2)(\\overline{y^2} - \\overline{y}^2)}}. O coeficiente de determina√ß√£o R^2 do modelo √© dado por r_{xy}^2, quando o modelo √© linear e possue uma √∫nica vari√°vel independente (feature).\n\nPortanto, temos que:\n\\widehat{\\beta_0} = \\overline{y} - \\widehat{\\beta}\\overline{x},\nNa data modeling culture (na estat√≠stica), normalmente assumimos que o \\varepsilon_i tem distribui√ß√£o normal e vari√¢ncia constante, \\forall\\, i = 1, \\cdots, n. Assume-se tamb√©m que \\mathbb{E}(\\varepsilon_i) = 0, \\, \\forall i."
  },
  {
    "objectID": "index.html#regress√£o-linear-simples-2",
    "href": "index.html#regress√£o-linear-simples-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear simples",
    "text": "Regress√£o linear simples\n\nAqui n√£o iremos nos preocupar com essas suposi√ß√µes, uma vez que em algorithmic modeling culture, n√£o estamos preocupados com suposi√ß√µes nem interpreta√ß√µes, ok!?"
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla",
    "href": "index.html#regress√£o-linear-multipla",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nA fun√ß√£o de perda quadr√°tica (fun√ß√£o L_2) tem algumas vantagens em rela√ß√£o a fun√ß√£o de perda absoluta. Listo algumas:\n\nA fun√ß√£o de perda quadr√°tica penaliza mais os erros maiores, devido ao fato dos erros serem levado ao quadrado;\nA fun√ß√£o de perda quadr√°tica √© mais sens√≠vel a presen√ßa de outlier, que em compensa√ß√£o s√£o menos penalizados ao se considerar a fun√ß√£o de perda absoluta (fun√ß√£o L_1);\nEm situa√ß√µes em que o erro tem distribui√ß√£o normal, a estimativa de m√≠nimos quadrados √© a solu√ß√£o de m√°xima verossimilhan√ßa e √© a estimativa linear n√£o viesada e com menor vari√¢ncia. Portanto, gozamos de um estimador com √≥timas propriedades, muito embora ele tamb√©m √© um bom estimador mesmo quando a suposi√ß√£o de normalidade n√£o √© verificada;\nA fun√ß√£o de perda quadr√°tica √© deferenci√°vel, j√° a fun√ß√£o de perda absoluta n√£o √©.\n\nPara o caso de regress√£o linear m√∫ltipla, i.e., quando d &gt; 1, poderemos utilizar uma nota√ß√£o matricial para representar o modelo linear m√∫ltiplo de regress√£o."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-1",
    "href": "index.html#regress√£o-linear-multipla-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nConsiderando o modelo de regress√£o linear m√∫ltiplo, temos que:\nY = g({\\bf X}) = \\beta^{T}{\\bf X} + \\varepsilon,\nem que Y √© um vetor n \\times 1, {\\bf X} √© uma matriz fixa e conhecida com os atributos de dimens√£o n \\times d, em que a primeira coluna √© preenchida de 1, \\beta = (\\beta_0, \\cdots, \\beta_d). Na cultura de machine learning, iremos desconsiderar \\varepsilon, i.e., n√£o feremos suposi√ß√µes sobre \\varepsilon. Portanto, considere\ng({\\bf x}) = \\beta^{T}{\\bf X} = \\beta_{0}x_0 + \\beta_1x_{i,1} + \\cdots + \\beta_dx_{i,d}, em que x_0 \\equiv 1."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-2",
    "href": "index.html#regress√£o-linear-multipla-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nO m√©todo dos m√≠nimos quadrados, para o caso de regress√£o linear m√∫ltipla (d &gt; 1) √© dado por aquele que minimiza R(\\beta^{T}{\\bf X}), i.e., minimiza:\n\\argmin_\\beta \\sum_{i = 1}^n (Y_i - \\beta_0 - \\beta_1x_{i,1} - \\cdots - \\beta_dx_{i,d})^2. Temos que\n\\widehat{\\beta} = ({\\bf X}^{T}{\\bf X})^{-1}{\\bf X}^{T}Y.\nPortanto, a fun√ß√£o de regress√£o estimada √© dada por:\ng({\\bf x}) = \\widehat{\\beta}^{T}{\\bf x}."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-3",
    "href": "index.html#regress√£o-linear-multipla-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nGrande parte da literatura estat√≠stica √© voltada para justificar que o m√©todo de m√≠nimos quadrados sob um ponto de vista de um estimador de m√°xima verossimilhan√ßa, assim como tamb√©m para constru√ß√£o de testes de ader√™ncia, m√©todos para constru√ß√£o de intervalos de confian√ßa e teste de hip√≥tese para \\beta_i (par√¢metros que indexam o modelo), an√°lise de res√≠duos, entre outros.\n\nAssumir que a verdadeira regress√£o r({\\bf x}) = \\mathbb{E}({\\bf X}\\,|\\,Y) √© uma suposi√ß√£o muito forte. Contudo, existe, na literatura, justificativas para o uso de m√©todos de m√≠nimos quadrados para estimar os coeficientes, mesmo quando a regress√£o real r({\\bf x}) n√£o satisfaz a suposi√ß√£o de linearidade."
  },
  {
    "objectID": "index.html#regress√£o-linear-multipla-4",
    "href": "index.html#regress√£o-linear-multipla-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear multipla",
    "text": "Regress√£o linear multipla\n\nO estimador de m√≠nimos quadrados \\widehat{\\beta} = ({\\bf X}^{T}{\\bf X})^{-1}{\\bf X}^{T}Y √© bom, por alguns motivos:\n\n\n√â igual ao estimador de m√°xima verossimilhan√ßa sob normalidade, linearidade e homoscedasticidade, portanto, consistente sob essas condi√ß√µes\n√â best linear unbiased prediction - BLUE sob linearidade e homoscedasticidade;\nO m√©todo de m√≠nimos quadrados tem alguma garantia, mesmo sem assumir muitas suposi√ß√µes."
  },
  {
    "objectID": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade",
    "href": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√≠nimos quadrados sem suposi√ß√£o de linearidade",
    "text": "M√≠nimos quadrados sem suposi√ß√£o de linearidade\n\nQuando a suposi√ß√£o de linearidade falha, ou seja, quando a regress√£o verdadeira que desconhecemos r({\\bf x}) n√£o √© linear, frequentemente existe um vetor \\beta_{*}, tal que g_{\\beta_{*}}({\\bf x}) = \\beta_{*}^{T}{\\bf x} tem um bom poder preditivo. Nesses casos, o m√©trodo dos m√≠nimos quadrados \\widehat{\\beta} tende a produzir estimadores com baixo risco. Isso se deve ao fato que \\widehat{\\beta} converge para o melhor preditor linear (para o or√°culo \\beta_{*}) que √© dado por:\n\\beta_{*} = \\argmin_\\beta R(g_\\beta) =  \\argmin_\\beta \\mathbb{E}\\left[(Y - \\beta^{T}X)^2\\right], mesmo que a verdadeira regress√£o r({\\bf x}) n√£o seja linear, em que ({\\bf X}, Y) √© uma nova observa√ß√£o.\n\nTeorema: Seja \\beta_{*} o melhor estimador linear e \\widehat{\\beta} o estimador de m√≠nimos quadrados. Ent√£o,\n\\widehat{\\beta}\\overset{p}{\\longrightarrow}  \\beta_{*}\\,\\, \\mathrm{e}\\,\\, R(g_{\\widehat{\\beta}})\\overset{p}{\\longrightarrow} R(g_{\\beta_{*}}),  quando n \\longrightarrow \\infty. Para uma demonstra√ß√£o, veja http://www.rizbicki.ufscar.br/AME.pdf, p√°gina. 29."
  },
  {
    "objectID": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade-1",
    "href": "index.html#m√≠nimos-quadrados-sem-suposi√ß√£o-de-linearidade-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√≠nimos quadrados sem suposi√ß√£o de linearidade",
    "text": "M√≠nimos quadrados sem suposi√ß√£o de linearidade\n\nEm palavras, o que o Teorema anterior diz √© que mesmo quando a regress√£o verdadeira n√£o √© linear, o estimador de m√≠nimos quadrados √© consistente para nos conduzir a um bom estimador linear, ou seja, ao menos conseguiremos o melhor estimador linear como uma aproxima√ß√£o √† r({\\bf x}) que n√£o √© linear.\n\nIsso n√£o quer dizer que voc√™ ter√° boas estimativas em todas as situa√ß√µes, muito embora o or√°culo \\beta_{*}, em muitas situa√ß√µes, ter√° bom poder preditivo. Em outras palavras, em situa√ß√µes que um problema, em sua natureza, n√£o linear, poderemos alcan√ßar boas estimativas por uma aproxima√ß√£o linear pelo m√©todo dos m√≠nimos quadrados."
  },
  {
    "objectID": "index.html#predi√ß√£o-versus-infer√™ncia",
    "href": "index.html#predi√ß√£o-versus-infer√™ncia",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Predi√ß√£o versus Infer√™ncia",
    "text": "Predi√ß√£o versus Infer√™ncia\n\nInfer√™ncia: assume que o modelo linear √© correto. O principal objetivo consiste em interpretar os par√¢metros:\n\n\nQuais s√£o os par√¢metros significantes?\nQual o efeito do aumento da dose de um rem√©dio no paciente?\n\n\nPredi√ß√£o: queremos criar g({\\bf x}) com bom poder preditivo, mesmo que a especifica√ß√£o do modelo n√£o esteja correta. N√£o assume que a verdadeira regress√£o √© de fato linear! A interpreta√ß√£o aqui n√£o √© o foco. Tudo bem?!"
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\nCaso voc√™ n√£o queira implementar o estimador de m√≠nimos quadrados \\widehat{\\beta} = ({\\bf X}^{T}{\\bf X})^{-1}{\\bf X}^{T}Y, voc√™ poder√° utilizar a famosa fun√ß√£o lm. Na verdade √© melhor que n√£o implemente o estimador \\widehat{\\beta}, uma vez que a fun√ß√£o lm, assim como a fun√ß√£o glmnet do pacote glmnet, utilizam-se de truques num√©ricos para um c√°lculo mais eficiente.\n\nFalaremos do pacote glmnet, um pouco mais a frente, quando abordarmos regress√£o penalizada. Certo!?"
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r-1",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\nConsidere o conjunto de dados de expectativa de vida versus PIB per Capita dispon√≠veis aqui. O comportamente entre as vari√°veis LifeExpectancy e GDPercapita, se fizermos um gr√°fico, n√£o √© linear.\n\nTodavia, isso n√£o impede que possamos ajustar um modelo de regress√£o linear, muito embora o seu poder preditivo ser√° baixo.\n\nPor√©m, como j√° sabemos, ao menos conseguiremos o melhor or√°culo, denotado por \\beta_{*}, i.e., o melhor estimador dentre os poss√≠veis estimadores lineares, como mostrado em teoremas anteriores.\n\nE est√° tudo bem. Aqui n√£o estou querendo defender que voc√™ use uma aproxima√ß√£o linear para esse caso. Em breve, com um pequeno truque, poderemos ajustar uma regress√£o polinomial √† esses dados, e incorporaremos um pouco da tend√™ncia n√£o linar presente nos dados."
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r-2",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\n\n\nVeja o c√≥digo do gr√°fico\nlibrary(ggplot2)\n\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\n\n# Criando um arquivo tempor√°rio\narquivo_temp &lt;- tempfile()\n\n# Baixando um arquivo tempor√°rio\ndownload.file(url = url, destfile = arquivo_temp)\n\n# Carregando os dados\nload(arquivo_temp)\n\ndados_expectativa_renda |&gt; \n  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +\n  geom_point() +\n  labs(\n    title = \"PIB per Capita versus Expectativa de Vida\",\n    x = \"PIB per Capita\",\n    y = \"Expectativa de Vida\"\n  ) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )"
  },
  {
    "objectID": "index.html#ajustando-uma-regress√£o-linear-no-r-3",
    "href": "index.html#ajustando-uma-regress√£o-linear-no-r-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ajustando uma regress√£o linear no R",
    "text": "Ajustando uma regress√£o linear no R\n\nClaramente, a reta de regress√£o (linha azul) do gr√°fico anterior n√£o tem um bom poder preditivo. O ajuste foi feito diretamente usando o pacote ggplot2, utilizando a fun√ß√£o geom_smooth, em que foi escolhido o m√©todo \"lm\".\n\nPoder√≠amos ter utilizado a fun√ß√£o lm:\n\n\n\nVeja o c√≥digo do gr√°fico\nlibrary(ggplot2)\n\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\n\n# Criando um arquivo tempor√°rio\narquivo_temp &lt;- tempfile()\n\n# Baixando um arquivo tempor√°rio\ndownload.file(url = url, destfile = arquivo_temp)\n\n# Carregando os dados\nload(arquivo_temp)\n\n# Ajustando o modelo usando a fun√ß√£o lm\najuste &lt;- lm(LifeExpectancy ~ GDPercapita, data = dados_expectativa_renda)\n\nmodelo &lt;- function(x){\n  novos_dados &lt;- tibble::tibble(GDPercapita = x)\n  predict(ajuste, newdata = novos_dados)\n}\n\ndados_expectativa_renda |&gt; \n  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +\n  geom_point() +\n  labs(\n    title = \"PIB per Capita versus Expectativa de Vida\",\n    x = \"PIB per Capita\",\n    y = \"Expectativa de Vida\"\n  ) +\n  stat_function(fun = modelo, color = \"red\", size = 1.2) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )"
  },
  {
    "objectID": "index.html#matriz-esparsa",
    "href": "index.html#matriz-esparsa",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Matriz esparsa",
    "text": "Matriz esparsa\n\nPara grandes bases de dados, em um problema real que voc√™ venha trabalhar, e se o custo computacional voc√™ considera elevado, poder√° utilizar o pacote biglm.\n\nEm situa√ß√µes em que h√° muitos zeros na sua matriz, poder√° utilizar representa√ß√£o esparsa.\n\nMatrizes esparsas s√£o matrizes com muitas entradas iguais √† 0. Elas ocorrem naturalmente em diversas aplica√ß√µes, como por exemplo uma matriz de termos presentes em um documento, em que se o termo estiver no documento resebe 1, e zero, caso contr√°rio. Abaixo, {\\bf X} √© um exemplo de matriz esparsa.\n\n\n{\\bf X} =\n\\begin{bmatrix}\n1 & 0 & 0 & 0 & 0 \\\\\n0 & 2 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 3 & 0 & 0 \\\\\n0 & 0 & 0 & 4 & 0 \\\\\n\\end{bmatrix}"
  },
  {
    "objectID": "index.html#matriz-esparsa-1",
    "href": "index.html#matriz-esparsa-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Matriz esparsa",
    "text": "Matriz esparsa\n\nConsidere os textos:\n\nTexto 1: ‚ÄúEu amo essa disciplina.‚Äù\nTexto 2: ‚ÄúEu adoro meu professor.‚Äù\nTexto 3: ‚ÄúEu serei muito bom em aprendizagem de m√°quina.‚Äù\nTexto 4: ‚ÄúAdoro o departamento de estat√≠stica da UFPB.‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTextos\ndisciplina\namo\naprendizagem\nm√°quina\nestatistica\nadoro\nUFPB\n\n\n\n\nTexto 1\n1\n1\n0\n0\n0\n0\n0\n\n\nTexto 2\n0\n0\n0\n0\n0\n1\n0\n\n\nTexto 3\n0\n0\n1\n1\n0\n0\n0\n\n\nTexto 4\n0\n0\n0\n0\n1\n1\n1"
  },
  {
    "objectID": "index.html#matriz-esparsa-2",
    "href": "index.html#matriz-esparsa-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Matriz esparsa",
    "text": "Matriz esparsa\n\nA matriz com a ocorr√™ncia de determinados termos nos textos √© dada por:\n\n{\\bf X} =\n\\begin{bmatrix}\n1 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 1 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 1 \\\\\n\\end{bmatrix}\n\nA representa√ß√£o esparsa de {\\bf X}, aqui denotada por {\\bf X_*} √©:\n\n{\\bf X_*} =\n\\begin{bmatrix}\n1 & 1 & 1 \\\\\n2 & 6 & 1 \\\\\n3 & 3 & 1 \\\\\n3 & 4 & 1 \\\\\n4 & 5 & 1 \\\\\n4 & 6 & 1 \\\\\n4 & 7 & 1 \\\\\n\\end{bmatrix},\n em que as duas primeiras colunas, s√£o as linhas e colunas de {\\bf X} com valor diferente de 0. A √∫ltima coluna representa o valor."
  },
  {
    "objectID": "index.html#regress√£o-linear-com-matriz-esparsa",
    "href": "index.html#regress√£o-linear-com-matriz-esparsa",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o linear com matriz esparsa",
    "text": "Regress√£o linear com matriz esparsa\n\nExemplo: Ajuste de um modelo de regerss√£o linear m√∫ltiplo, em que {\\bf X} poder√° ter uma representa√ß√£o esparsa. Aqui n√£o estamos interessados em verificar qualidade de predi√ß√µes. Trata-se apenas de um exemplo de como utilizar uma representa√ß√£o esparsa para ajustar um modelo de regess√£o linear com algumas covari√°veis, em R.\n\n\n\nEstude o c√≥digo\nlibrary(glmnet)\nlibrary(Matrix)\n\n# Dados de exemplo\nx1 &lt;- c(1, 0, 2, 0, 0)\nx2 &lt;- c(0, 3, 0, 4, 0)\nx3 &lt;- c(5, 0, 6, 0, 7)\ny &lt;- c(1, 2, 3, 4, 5)\n\n# Criar data frame com as vari√°veis explicativas\ndados &lt;- data.frame(x1, x2, x3)\n\n# Converter o data frame para matriz esparsa\nX &lt;- sparse.model.matrix(~ ., data = dados)\n\n# Ajustar a regress√£o linear utilizando glmnet\nmodelo &lt;- glmnet(x = X, y = y, alpha = 0, lambda = 0)\n\n# Realizar previs√µes\npredicoes &lt;- predict(modelo, newx = X)"
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio",
    "href": "index.html#erro-quadr√°tico-m√©dio",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nComo exposto anteriormente, para avaliar o poder preditivo de uma modelo, i.e., a aprendizagem de um modelo, devemos avaliar a fun√ß√£o de risco, i.e., devemos avaliar R(g) := \\mathbb{E}\\left[L(g({\\bf X}); Y)\\right]. Em particular, considere L = L_2 (fun√ß√£o perda quadr√°tica). Ent√£o, poder√≠amos ser levados a acreditar que o melhor estimador de R(g), utilizando a Lei dos Grandes N√∫meros seria:\n\\frac{1}{n}\\sum_{i = 1}^n(Y_{i} - g({\\bf X_{i}}))^2 \\approx R(g) := \\mathbb{E}\\left[L_2(g({\\bf X}); Y)\\right].\n\nEssa quantidade √© chamada, de Erro Quadr√°tico M√©dio - EQM. Desejamos escolher o melhor mode, entre os modelos testados, que minimiza o EQM.\n\nO apelo frequentista em utilizar a Lei dos Grandes N√∫meros na forma acima n√£o √© correto, uma vez que usamos as n observa√ß√µes para treinar/ajustar o modelo g."
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio-1",
    "href": "index.html#erro-quadr√°tico-m√©dio-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nPor exemplo, no problema de PIB per Capita versus expectativa de vida, em que consideramos uma aproxima√ß√£o linear, n√£o poder√≠amos utilizar o EQM da forma acima, com as n observa√ß√µes utilizadas para treinar o modelo. √â um detalhe sutil, mas que muitas pessoas cometem esse erro.\n\nN√£o podemos utilizar as n observa√ß√µes para estimar o risco R(g) atrav√©s do EQM, uma vez que estamos utilizando o mesmo conjunto de dados para ajustar e avaliar g.\n\nQual o problema?\n\n\nN√£o vale a Lei dos Grandes N√∫meros;\nUsamos os mesmos valores de {\\bf x} e y para treinar e avaliar o modelo."
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio-2",
    "href": "index.html#erro-quadr√°tico-m√©dio-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nO que diz a Lei dos Grandes N√∫meros, em particular, a Lei Forte de Kolmogorov?\n\nTeorema (Lei Forte de Kolmogorov): Sejam X_1, \\cdots, X_n uma sequ√™ncia de veri√°veis aleat√≥rias - v.a. i.i.d. e integr√°veis, i.e., com valor esperado limitado, tal que \\mathbb{E}(X) = \\mu\\,\\, \\forall i. Ent√£o,\n\\frac{X_1 + X_2 + \\cdots + X_n}{n} \\rightarrow \\mu,\nquase certamente, i.e., com probabilidade 1.\n\nNote que se desejamos comparar diversos modelos, g_1({\\bf x}), g_2({\\bf x}), \\cdots, e se utilizarmos as mesmas n oberva√ß√µes para calularmos R(g_1({\\bf x})), R(g_2({\\bf x})), \\cdots, os termos de cada uma das somas n√£o s√£o independentes. Lembre-se que desejamos obter \\argmin_g R_{pred}(g)."
  },
  {
    "objectID": "index.html#erro-quadr√°tico-m√©dio-3",
    "href": "index.html#erro-quadr√°tico-m√©dio-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Erro quadr√°tico m√©dio",
    "text": "Erro quadr√°tico m√©dio\n\nPortanto, nunca utilize as mesmas observa√ß√µes utilizadas para treinar o modelo, como aquelas que ser√£o utilizadas para se estimar R(g). Nunca! Isso √© um pecado mortal! Ok?!"
  },
  {
    "objectID": "index.html#data-splitting",
    "href": "index.html#data-splitting",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nCorrigir o problema de depend√™ncia que h√° ao estimarmos o risco usando o EQM √© f√°cil. Uma abordagem muito utilizada √© utilizar data splitting, tamb√©m chamado de m√©todo hold-out. Algo como a segunda linha da imagem abaixo:"
  },
  {
    "objectID": "index.html#data-splitting-1",
    "href": "index.html#data-splitting-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nEssa divis√£o √© feita de forma aleat√≥ria, algumas vezes estratificada de acordo com algumas vari√°v√°veis. A ideia de aleatorizar √© se livrar de problemas de conjunto de dados ordenados. Queremos que tanto no conjunto de treinamento Training quanto no conjunto de teste Testing, na imagem, contenham a mesma diversidade de observa√ß√µes.\n\nPor exemplo, ainda no exemplo de PIB per Capita versus Expectaitiva de Vida, n√£o quero correr o risco de ter no conjunto de treinamento apenas o pa√≠ses com maiores valores de PIB per Capita, caso o conjunto de dados tenha sido ordenado pela vari√°vel GDPercapita. Por isso aleatorizar o conjunto de treinamento e teste √© simple uma √≥tima ideia. Certo!?"
  },
  {
    "objectID": "index.html#data-splitting-2",
    "href": "index.html#data-splitting-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nO percentual de divis√£o dos dados normalmente √© emp√≠rico. Usa-se normalmente a propor√ß√£o de 70\\% para treinamento e 30\\% para teste (70\\%, 30\\%). Outros esquemas de divis√µes s√£o bastante utilizados, por exemplo, (80\\%, 20\\%), (99\\%, 1\\%), a depender da quantidade de observa√ß√µes (tamanho do conjunto de dados).\n\nPortanto, utilizar o EQM sob o conjunto de dados de teste para avaliar g_1({\\bf x}), g_2({\\bf x}), \\cdots,, √© uma boa estrat√©gia, uma vez que agora n√£o teremos mais uma depend√™ncia no numerador do c√°lculo do EQM. Em nota√ß√£o matem√°tica, poder√≠amos escrever como j√° apresentado anteriormente, em Equa√ß√£o¬†1, i.e,\n\\frac{1}{m}\\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \\approx R(g) := \\mathbb{E}\\left[(Y - g({\\bf X}))^2\\right].\n\nEsse resultado valeria para qualquer outra fun√ß√£o de perda."
  },
  {
    "objectID": "index.html#data-splitting-3",
    "href": "index.html#data-splitting-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\nReescrevendo, suponha que o conjunto de dados total possua n observa√ß√µes e que separamos aleatoriamente s &lt; n observa√ß√µes para o conjunto de treinamento. Assim, temos, algo como:\n\n\\overbrace{(X_1, Y_1), (X_2, Y_2), \\cdots, (X_s, Y_s)}^{70\\%}, \\,\\,\\, \\overbrace{(X_{s + 1}, Y_{s + 1}), (X_{s + 2}, Y_{s + 2}), \\cdots, (X_n, Y_n)}^{30\\%}.\n\nEnt√£o, temos que uma boa estimativa de R(g) √© dada pelo EQM calculado sobre o conjunto de dados de teste, que nesse caso considerei o conjunto com 30\\%, mas esse percentual poderia ser outro. Ent√£o, temos que um bom estimador √©:\n\\frac{1}{n - s}\\sum_{i = s + 1}^n (Y_{i} - g(X_{i}))^2 \\approx R(g) := \\mathbb{E}\\left[(Y - g({\\bf X}))^2\\right]."
  },
  {
    "objectID": "index.html#data-splitting-4",
    "href": "index.html#data-splitting-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nAgora voc√™ entende por que dividimos os dados em treinamento e teste?\n\n\n\nDividimos para obermos um bom estimador do risco utilizando o EQM. üéä"
  },
  {
    "objectID": "index.html#data-splitting-5",
    "href": "index.html#data-splitting-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nPodemos argumentar que o procedimento de data splitting, em que dividimos o nosso conjunto de dados em treinamento e teste far√° com que venhamos perder muitas observa√ß√µes que poderiam ter sido utilizadas para treinar o modelo. E de certa forma isso √© verdade, principalmente quando termos um conjunto n√£o muito grande de observa√ß√µes.\n\nPortanto, uma melhor abordagem, sendo esta uma varia√ß√£o do m√©todo de data splitting √© o procedimento de cross-validation - cv (valida√ß√£o cruzada). Uma vers√£o mais geral de uma valida√ß√£o cruzada √© o leave-one-out cross-validation.\n\nEm palavras, o procedimento consiste em tirar de fora uma √∫nica observa√ß√£o das n observa√ß√µes da base de dados para ser o nosso conjunto de teste e treinar o modelo com as observa√ß√µes que permaneceram. Da√≠, calcula-se o risco observado (EQM, sob o conjunto de teste). Na segunda itera√ß√£o, a observa√ß√£o que antes era de teste volta para perterncer ao conjunto de treinamento e uma nova observa√ß√£o √© removida para ser teste. Esse procedimento ocorre de forma iterativa at√© a retirada da √∫ltima observa√ß√£o como teste."
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation",
    "href": "index.html#leave-one-out-cross-validation",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nObserve a anima√ß√£o abaixo que ilustra o procedimento de leave-one-out cross-validation - LOOCV, em uma amostra de tamanho n = 8. Ao fim, teremos n modelos ajustados, em que calculamos as suas respectivas performances, i.e., com o risco observado, estimamos o risco de R(g)."
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation-1",
    "href": "index.html#leave-one-out-cross-validation-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nVejo muitas pessoas que usam uma valida√ß√£o cruzada, por exemplo, leave-one-out cross-validation - LOOCV comparando com o m√©todo Jackknife e algumas inclusive dizendo ser a mesma coisa. N√£o, n√£o s√£o!\n\nO algoritmo Jackknife √© um procedimento de estima√ß√£o e que por sua vez deve estar dentro do conjunto de treinamento. Para haver algum Jackknife, a estimativa com n-1 observa√ß√µes deve estar dentro do conjunto de treinamento, em que dentro do treinamento teria a remo√ß√£o de um observa√ß√£o por vez. Consegue perceber a diferen√ßa sutil?"
  },
  {
    "objectID": "index.html#leave-one-out-cross-validation-2",
    "href": "index.html#leave-one-out-cross-validation-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leave-one-out cross-validation",
    "text": "Leave-one-out cross-validation\n\nO m√©todo LOOCV foi proposto por Stones (1974), no artigo intitulado Cross-Validatory Choice and Assessment of Statistical Predictions, no Royal Statistical Society, S√©rie B. Clique aqui se tiver curiosidade em ler o artigo.\n\nEscrevendo o estimador do risco em um procedimento de LOOCV, temos que:\n\\widehat{R}(g) = \\frac{1}{n}\\sum_{i = 1}^n (Y_i - g_{-i}({\\bf X}_i))^2, em que g_{-i}(\\bf{X}_i), representa o ajuste do modelo no conjunto de dados sem a i-√©sima observa√ß√£o.\n\nN√£o √© dif√≠cil perceber que a depender do valor de n, o m√©todo LOOCV √© computacionalmente intensivo. O m√©todo requer que ajustemos n modelos. Em algumas situa√ß√µes isso n√£o √© um grande problema, por√©m, em diversas outras pode ser impeditivo utilizar o LOOCV. ü§Ø"
  },
  {
    "objectID": "index.html#k-fold-cross-validation",
    "href": "index.html#k-fold-cross-validation",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\nUma alternativa ao LOOCV √© utilizar o m√©todo k-fold cross-validation. Nessa abordagem, dividimos o conjunto de dados em k-folds (lotes) disjuntos e com aproximadamente o mesmo tamanho. Dessa forma, temos L_1, \\cdots, L_k \\subset \\{1, \\cdots, n\\} s√£o, cada um, um conjunto de indices aleat√≥rios associados a cada um dos lotes. A ideia aqui √© construir k estimadores da fun√ß√£o de regress√£o, denotados por \\widehat{g}_{-1}, \\cdots, \\widehat{g}_{-k}, em que \\widehat{g}_{-j} √© criado usando todas as observa√ß√µes do banco de dados, com exce√ß√£o daquelas do lote L_j, utilizado para valida√ß√£o. O estimador do risco √© dado por:\n\\widehat{R}(g) = \\frac{1}{n}\\sum_{j=1}^k \\sum_{i \\in L_j}(Y_i - g_{-j}({\\bf X}_i))^2. Perceba que, que o LOOCV √© um caso particular do k-fold cross-validation, quando fazemos k = n. Em outras palavras, L_1, \\cdots, L_k \\subset \\{1, \\cdots, n\\} representam os √≠ndices aleat√≥rios do conjunto de treinamento nos k lotes."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-1",
    "href": "index.html#k-fold-cross-validation-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\nA anima√ß√£o abaixo, ilustra o procedimento de 3-fold cross-validation (k = 3), para uma amostra de tamanho n = 12 observa√ß√µes. Note que os valores que pertencem a cada um dos lotes s√£o aleat√≥rios. Portanto, o procedimento LOOCV √© deterministico, j√° o procedimento de k-fold cross-validation √© randomizado.\n\n\nPerceba que teremos agora apenas 3 modelos. Para cada um desses lotes, calulamos o EQM com o conjunto de teste (parte azul) e treinamos o modelo com o conjunto de treinamento (parte vermelha)."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-2",
    "href": "index.html#k-fold-cross-validation-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\nMuitos modelos mais sofisticados apresentam hiperpar√¢metros (par√¢metros de sintoniza√ß√£o) que n√£o dependem dos dados. √â muito comum os algoritmos de aprendizagem de m√°quina se utilizarem do procedimento de valida√ß√£o cruzada, para al√©m da estima√ß√£o do risco R(g).\n\nAo estimar k modelos, normalmente faz-se um grid de poss√≠veis valores para esses hiperpar√¢metros em que ao final, escolhe-se como hiperpar√¢metro o modelo com menor EQM. Por fim, ajusta-se um modelo final, com todo o conjunto de treinamento usando o valor do hiperpar√¢metro que retornou o menor EQM no conjunto de valida√ß√£o."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-3",
    "href": "index.html#k-fold-cross-validation-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\n\n\nO termo valida√ß√£o refere-se √† parcela do conjunto de treinamento incial que dividimos em valida√ß√£o e treinamento, dentro de uma valida√ß√£o cruzada.\n\nO conjunto Testing na segunda hierarquia da √°rvore ao lado, s√≥ usamos no final para avaliar o desempenho do modelo nesse conjunto.\n\nPerceba que o conjunto de treinamento (Not Testing) √© particionado em treinamento e valida√ß√£o. Poder√≠amos fazer uma √∫nica parti√ß√£o, mas o procedimento comumente utilizado √© particionar entre Training e Validation uzando algum procedimento de valida√ß√£o cruzada."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n\n\n\n\nO simples procedimento de dividir o conjunto de dados em dois, uma parte para treinar o modelo e a outra parte (conjunto de teste) para estimar o risco R(g) √© denominado de data splitting ou Hold-out Method. √â um procedimento mais simples, por√©m, pode n√£o ser √∫til em conjunto de dados n√£o muito grandes.\nA segunda linha da ilustra√ß√£o, demonstra o procedimento de cross-validation (valida√ß√£o cruzada), procedimento mais utilizado nos treinamentos de modelos de aprendizagem de m√°quina.\nA terceira linha √© uma abordagem tamb√©m utilizada, por√©m n√£o t√£o interessante quanto a valida√ß√£o cruzada. Nessa abordagem o banco de dados √© dividido aleatoriamente em tr√™s partes. Treina-se o modelo com a parte verde, estima-se o risco com o conjunto de valida√ß√£o amarelo e testa-se o modelo com o conjunto de teste."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-1",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n A abordagem do conjunto de valida√ß√£o envolve dividir o conjunto de treinamento em duas partes: uma parte √© usada para treinar o modelo e a outra parte √© usada para avaliar o desempenho do modelo. O conjunto de valida√ß√£o √© utilizado para ajustar os hiperpar√¢metros do modelo, como a taxa de aprendizado, o n√∫mero de camadas ocultas em uma rede neural, entre outros. Ap√≥s o ajuste dos hiperpar√¢metros, o modelo final √© treinado com o conjunto de treinamento completo e avaliado em um conjunto separado chamado conjunto de teste. Essa abordagem √© conhecida como divis√£o simples de treinamento/valida√ß√£o/teste.\n\nPor outro lado, a valida√ß√£o cruzada k-fold √© uma abordagem que visa obter uma estimativa mais robusta do desempenho do modelo. Nessa abordagem, o conjunto de treinamento √© dividido em k subconjuntos (folds) de tamanho aproximadamente igual. O modelo √© treinado k vezes, cada vez usando k-1 folds como conjunto de treinamento e 1 fold como conjunto de valida√ß√£o. O desempenho do modelo √© ent√£o calculado como a m√©dia dos resultados obtidos em cada itera√ß√£o. Isso permite avaliar o modelo de forma mais precisa, pois utiliza todos os dados para treinamento e valida√ß√£o, evitando a depend√™ncia de uma √∫nica divis√£o do conjunto de treinamento."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-2",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n\nA valida√ß√£o cruzada k-fold √© particularmente √∫til quando o conjunto de dados √© limitado, pois aproveita ao m√°ximo os dados dispon√≠veis. Al√©m disso, ela permite verificar se o modelo √© est√°vel e se seu desempenho varia significativamente com diferentes divis√µes dos dados. √â importante ressaltar que a valida√ß√£o cruzada k-fold pode ser computacionalmente mais cara do que a abordagem do conjunto de valida√ß√£o, uma vez que envolve treinar e avaliar o modelo v√°rias vezes."
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Balan√ßo vi√©s e vari√¢ncia",
    "text": "Balan√ßo vi√©s e vari√¢ncia\n\nA ideia de precis√£o e exatid√£o est√£o ligadas ao vi√©s e vari√¢ncia do modelo g, em que precis√£o est√° ligado a ideia de vari√¢ncia pequena e exatid√£o est√° ligada a ideia de baixo vi√©s. A ideia √© termos um estimador pr√≥ximo o que ilustra o item d. Muitas vezes temos um estimador nas situa√ß√µes b e c. O ideal √© o balan√ßo de vi√©s e vari√¢ncia, que seria o estimador ilustrado pelo item d."
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-1",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Balan√ßo vi√©s e vari√¢ncia",
    "text": "Balan√ßo vi√©s e vari√¢ncia\n\nUm grande apelo para o uso do risco quadr√°tico, i.e., risco que utiliza a fun√ß√£o de perda L_2 √© sua interpretabilidade. Temos que o risco quadr√°tico R(g) condicional a um novo {\\bf x} poder√° ser decomposto por:\n\\mathbb{E}\\left[(Y - \\widehat{g}({\\bf X}))^2| {\\bf X} = {\\bf x}\\right] = \\underbrace{\\mathbb{V}[Y | {\\bf X = x}]}_{\\mathrm{i - Vari√¢ncia\\,\\, intr√≠nseca}} + \\overbrace{(r({\\bf x}) - \\mathbb{E}[\\widehat{g}({\\bf x})])^2}^{\\mathrm{ii - Vi√©s\\, ao\\, quadrado\\, do\\, modelo}} + \\underbrace{\\mathbb{V}[\\widehat{g}({\\bf x})]}_{\\mathrm{iii - Vari√¢ncia\\, do\\, modelo}}. Temos que:\n\ni - √â a vari√¢ncia intr√≠nseca da vair√°vel resposta (label), que n√£o depende da fun√ß√£o \\widehat{g} escolhida e, assim, n√£o poder√° ser reduzida. Na verdade, poderemos reduzir i, se incluirmos mais features (covari√°veis/vari√°veis explicativas) ao nosso modelo;\nii - √â o vi√©s ao quadrado do estimador \\widehat{g} (vi√©s ao quadrado do modelo);\niii - √â a vari√¢ncia do estimador \\widehat{g}."
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-2",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Balan√ßo vi√©s e vari√¢ncia",
    "text": "Balan√ßo vi√©s e vari√¢ncia\n\nAssim, lembre-se que uma escolha adequada de \\widehat{g} nos garante que conseguiremos reduzir o risco preditivo R(g), pois a escolha apropriada implica em escolhermos um estimador de \\widehat{g} com balan√ßo entre v√≠es e vari√¢ncia.\n\nModelos com muitos par√¢metros possuem vi√©s relativamente baixo, por√©m, tendem a ter vari√¢ncia muito alta, em geral, uma vez que precisamos estimar muitos par√¢metros. J√° modelos com poucos par√¢metros, normalmente tendem a ter vari√¢ncia baixa, acompanhados normalmente de um alto vi√©s.\n\nGeralmente, modelos com muitos par√¢metros nos levam a termos overffiting (super-ajuste), o que n√£o √© bom pois s√£o acompanhados de alta vari√¢ncia. J√° modelos muito simplistas nos conduzem √† um ajuste muito ruim (underffiting ou sub-ajuste). Entendeu!?"
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-3",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Balan√ßo vi√©s e vari√¢ncia",
    "text": "Balan√ßo vi√©s e vari√¢ncia\n\n\n\nEstude o c√≥digo\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Fun√ß√£o de regress√£o verdadeira. Na pr√°tica √© desconhecida.\nregressao_verdadeira &lt;- function(x)\n  45 * tanh(x/1.9 - 7) + 57\n\nobservacoes_regressao_real &lt;- function(n, desvio_padrao = 0.2) {\n  # Permitindo que o mesmo x possa ter dois pontos de y, como ocorre na \n  # pratica\n  seq_x &lt;- sample(seq(0, 17.5, length.out = n), size = n, replace = TRUE)\n  \n  step &lt;- function(x)\n    regressao_verdadeira(x) + rnorm(n = 1L, mean = 0, sd = desvio_padrao)\n  \n  tibble::tibble(y = purrr::map_vec(.x = seq_x, .f = step), x = seq_x)\n}\n\n# Usaremos uma regress√£o polinomial para tentar ajustar √† regress√£o -------\nregressao_polinomial &lt;- function(n = 30L, desvio_padrao = 4, grau = 1L) {\n  \n  dados &lt;- observacoes_regressao_real(n = n, desvio_padrao = desvio_padrao)\n    \n  iteracoes &lt;- function(tibble_data, grau) {\n      x &lt;- tibble_data$x\n      iteracoes &lt;- lapply(X = 2L:grau, FUN = function(i) x^i)\n      \n      result &lt;- cbind(tibble_data, do.call(cbind, iteracoes))\n      colnames(result)[(ncol(tibble_data) + 1):ncol(result)] &lt;- paste0(\"x\", 2L:grau)\n      \n      as_tibble(result)\n  }  \n  \n  if(grau &gt;= 2L)\n    dados &lt;- iteracoes(dados, grau = grau)\n  \n  ajuste &lt;- lm(formula = y ~ ., data = dados)\n  dados$y_chapeu &lt;- predict(ajuste, new.data = dados)\n  \n  dados |&gt; \n    dplyr::relocate(y_chapeu, .before = x)\n}\n\nplotando &lt;- function(dados){\n  dados |&gt;  \n    ggplot(aes(x = x, y = y_chapeu)) +\n    geom_point()\n}\n\nmc_ajustes &lt;- function(mc = 100L, n = 50L, desvio_padrao = 5, grau = 1L){\n\n  p &lt;- \n    ggplot(data = NULL) +\n      coord_cartesian(xlim = c(0, 17.5), ylim = c(0, 110)) +      \n      ylab(\"Valores estimados\")\n  \n  df &lt;- NULL\n  for(i in 1L:mc){\n    df &lt;- regressao_polinomial(n = n, desvio_padrao = desvio_padrao, grau = grau)\n    p &lt;- p + geom_line(data = df, aes(x = x, y = y_chapeu))\n  }\n  p + \n    stat_function(fun = regressao_verdadeira, col = \"red\", size= 1.4) +\n    labs(\n      title = \"Regress√£o Polinomial\",\n      subtitle = paste(\"Grau: \", grau)\n    ) +\n    theme(\n      plot.title = element_text(face = \"bold\"),\n      axis.title = element_text(face = \"bold\")\n    )\n}\n\n# Fixando uma semente\nset.seed(0)\n\np1 &lt;- mc_ajustes(grau = 1, n = 100, desvio_padrao = 10)\np2 &lt;- mc_ajustes(grau = 7, n = 100, desvio_padrao = 10)\np3 &lt;- mc_ajustes(grau = 70, n = 100, desvio_padrao = 10)\np4 &lt;- mc_ajustes(grau = 200, n = 100, desvio_padrao = 10)\n\np &lt;- ((p1 | p2) / (p3 | p4)) + plot_annotation(tag_levels = \"A\")\n\nggsave(p, file = \"imgs/vies_variancia.png\", device = \"png\", width = 40, height = 30, units = \"cm\")"
  },
  {
    "objectID": "index.html#tuning-parameters",
    "href": "index.html#tuning-parameters",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tuning Parameters",
    "text": "Tuning Parameters\n\nNo exemplo anterior, note que os par√¢metros dos modelos s√£o os coeficientes \\beta‚Äôs que indexam a regress√£o polinomial. Por√©m, perceba que √° um par√¢metro de sintoniza√ß√£o (tuning parameter) que √© o valor de p, isto √©, qual o grau do polin√¥mio que iremos utilizar.\n\nNormalmente a escolha √© feita realizando um grid search por meio de um cross-validation.\n\nNo exemplo anterior, fizemos uma simula√ß√£o e observamos que ao considerar graus nem muito grandes nem muito pequenos, aparentemente teremos escolhas razo√°veis."
  },
  {
    "objectID": "index.html#exerc√≠cios",
    "href": "index.html#exerc√≠cios",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Exerc√≠cios",
    "text": "Exerc√≠cios\n\nExerc√≠cio: Explique resumidamente o que √© aprendizagem supervisionada e n√£o-supervisionada. Cite um problema de aprendizagem supervisionada e um outro de aprendizagem n√£o-supervisionada.\n\nExerc√≠cio: Considere o conjunto de dados de Expectativa de vida versus PIB per Capita, dispon√≠vel aqui. Considere a fun√ß√£o g, da seguinte forma:\ng(x) = \\beta_0 + \\sum_{i = 1}^p \\beta_i x^i, com p \\in \\{1, 2, ..., 50\\}. Utilizando o erro quadr√°tico m√©dio observado, sem fazer nenhuma estrat√©gia de divis√£o dos dados, implemente um c√≥digo em R para checar qual o melhor modelo.\n\nExerc√≠cio: Explique qual o motivo que faz com que o Erro Quadr√°tico M√©dio - EQM para avaliar o desempenho de um modelo √© ruim quando n√£o adotamos nenhuma estrat√©gia de divis√£o do conjunto de dados em treinamento e teste."
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html",
    "href": "shiny_apps/balanco_vies_variancia.html",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "",
    "text": ".shiny-output-area {\n  margin: 0;\n}\n\n.full-width-image {\n    width: 100vw; /* Define a largura igual √† largura da janela do navegador */\n    height: auto; /* Mant√©m a propor√ß√£o original da imagem */\n}"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#experimete",
    "href": "shiny_apps/balanco_vies_variancia.html#experimete",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Experimete",
    "text": "Experimete"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#row",
    "href": "shiny_apps/balanco_vies_variancia.html#row",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Row",
    "text": "Row\n\nAll Lung Deaths\n\nsliderInput(\"numeromodelos\", \"N√∫mero de modelos:\",\n    min = 2, max = 100, value = 50\n)\n\n\nN√∫mero de modelos:\n\n\n\nsliderInput(\"tamanhoamostral\", \"Tamanho amostral:\",\n    min = 20, max = 250, value = 250\n)\n\n\nTamanho amostral:\n\n\n\nsliderInput(\"grau\", \"Grau do polin√¥mio:\",\n    min = 1, max = 100, value = 1\n)\n\n\nGrau do polin√¥mio:\n\n\n\nrenderPlot({\n  mc_ajustes(mc = input$numeromodelos, n = input$tamanhoamostral, desvio_padrao = 5, grau = input$grau)\n})"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#column",
    "href": "shiny_apps/balanco_vies_variancia.html#column",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEntrada de informa√ß√µes\n\nsliderInput(\"numeromodelos\", \"N√∫mero de modelos:\",\n    min = 1, max = 100, value = 50\n)\n\n\nN√∫mero de modelos:\n\n\n\nsliderInput(\"tamanhoamostral\", \"Tamanho amostral:\",\n    min = 100, max = 250, value = 100\n)\n\n\nTamanho amostral:\n\n\n\nsliderInput(\"grau\", \"Grau do polin√¥mio:\",\n    min = 1, max = 200, value = 1\n)\n\n\nGrau do polin√¥mio:"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#balan√ßa-entre-vi√©s-e-vari√¢ncia",
    "href": "shiny_apps/balanco_vies_variancia.html#balan√ßa-entre-vi√©s-e-vari√¢ncia",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Balan√ßa entre vi√©s e vari√¢ncia",
    "text": "Balan√ßa entre vi√©s e vari√¢ncia\n\nsliderInput(\"numeromodelos\", \"N√∫mero de modelos:\",\n    min = 2, max = 100, value = 50\n)\n\n\nN√∫mero de modelos:\n\n\n\nsliderInput(\"tamanhoamostral\", \"Tamanho amostral:\",\n    min = 20, max = 250, value = 250\n)\n\n\nTamanho amostral:\n\n\n\nsliderInput(\"grau\", \"Grau do polin√¥mio:\",\n    min = 1, max = 100, value = 1\n)\n\n\nGrau do polin√¥mio:\n\n\n\n### Balan√ßo entre Vi√©s e Vari√¢ncia\n\n\nrenderPlot({\n  mc_ajustes(mc = input$numeromodelos, n = input$tamanhoamostral, desvio_padrao = 5, grau = input$grau)\n})"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#balan√ßo-entre-vi√©s-e-vari√¢ncia",
    "href": "shiny_apps/balanco_vies_variancia.html#balan√ßo-entre-vi√©s-e-vari√¢ncia",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Balan√ßo entre vi√©s e vari√¢ncia",
    "text": "Balan√ßo entre vi√©s e vari√¢ncia\n\nBalan√ßo entre Vi√©s e Vari√¢ncia\n\nsliderInput(\"numeromodelos\", \"N√∫mero de modelos:\",\n    min = 2, max = 100, value = 50\n)\n\n\nN√∫mero de modelos:\n\n\n\nsliderInput(\"tamanhoamostral\", \"Tamanho amostral:\",\n    min = 20, max = 250, value = 250\n)\n\n\nTamanho amostral:\n\n\n\nsliderInput(\"grau\", \"Grau do polin√¥mio:\",\n    min = 1, max = 100, value = 1\n)\n\n\nGrau do polin√¥mio:\n\n\n\nrenderPlot({\n  mc_ajustes(mc = input$numeromodelos, n = input$tamanhoamostral, desvio_padrao = 5, grau = input$grau)\n})"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#experi√™ncias-iterativas",
    "href": "shiny_apps/balanco_vies_variancia.html#experi√™ncias-iterativas",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Experi√™ncias iterativas",
    "text": "Experi√™ncias iterativas\n\nsliderInput(\"numeromodelos\", \"N√∫mero de modelos:\",\n    min = 2, max = 100, value = 50\n)\n\n\nN√∫mero de modelos:\n\n\n\nsliderInput(\"tamanhoamostral\", \"Tamanho amostral:\",\n    min = 20, max = 250, value = 250\n)\n\n\nTamanho amostral:\n\n\n\nsliderInput(\"grau\", \"Grau do polin√¥mio:\",\n    min = 1, max = 100, value = 1\n)\n\n\nGrau do polin√¥mio:\n\n\n\nrenderPlot({\n  mc_ajustes(mc = input$numeromodelos, n = input$tamanhoamostral, desvio_padrao = 5, grau = input$grau)\n})"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#balan√ßo",
    "href": "shiny_apps/balanco_vies_variancia.html#balan√ßo",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Balan√ßo",
    "text": "Balan√ßo\n\nsliderInput(\"numeromodelos\", \"N√∫mero de modelos:\",\n    min = 2, max = 100, value = 50\n)\n\n\nN√∫mero de modelos:\n\n\n\nsliderInput(\"tamanhoamostral\", \"Tamanho amostral:\",\n    min = 20, max = 250, value = 250\n)\n\n\nTamanho amostral:\n\n\n\nsliderInput(\"grau\", \"Grau do polin√¥mio:\",\n    min = 1, max = 100, value = 1\n)\n\n\nGrau do polin√¥mio:\n\n\n\nrenderPlot({\n  mc_ajustes(mc = input$numeromodelos, n = input$tamanhoamostral, desvio_padrao = 5, grau = input$grau)\n})"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#teste",
    "href": "shiny_apps/balanco_vies_variancia.html#teste",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "## Teste",
    "text": "## Teste\n\nsliderInput(\"numeromodelos\", \"N√∫mero de modelos:\",\n    min = 2, max = 100, value = 50\n)\n\n\nN√∫mero de modelos:\n\n\n\nsliderInput(\"tamanhoamostral\", \"Tamanho amostral:\",\n    min = 20, max = 250, value = 250\n)\n\n\nTamanho amostral:\n\n\n\nsliderInput(\"grau\", \"Grau do polin√¥mio:\",\n    min = 1, max = 100, value = 1\n)\n\n\nGrau do polin√¥mio:\n\n\n\nrenderPlot({\n  mc_ajustes(mc = input$numeromodelos, n = input$tamanhoamostral, desvio_padrao = 5, grau = input$grau)\n})"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#rows",
    "href": "shiny_apps/balanco_vies_variancia.html#rows",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Rows",
    "text": "Rows\n\n\n\n\n\n\nEssa aplica√ß√£o foi constru√≠da para conter alguns exempos da disciplina de Aprendizagem de M√°quina, lecionada aos dicentes do curso de bacharelado em estat√≠stica da UFPB."
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#column-1",
    "href": "shiny_apps/balanco_vies_variancia.html#column-1",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nResultado gr√°fico das simula√ß√µes\n\nrenderPlot({\n  mc_ajustes(mc = input$numeromodelos, n = input$tamanhoamostral, desvio_padrao = 5, grau = input$grau)\n})"
  },
  {
    "objectID": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-4",
    "href": "index.html#balan√ßo-vi√©s-e-vari√¢ncia-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Balan√ßo vi√©s e vari√¢ncia",
    "text": "Balan√ßo vi√©s e vari√¢ncia\n\nExperimente de forma interativa altera a complefixade do modelo."
  },
  {
    "objectID": "index.html#exerc√≠cios-1",
    "href": "index.html#exerc√≠cios-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Exerc√≠cios",
    "text": "Exerc√≠cios\n\nExerc√≠cio: Com suas palavras, explique o dilema de balan√ßo entre v√≠es e vari√¢ncia.\n\nExerc√≠cio: Refa√ßa o exerc√≠cio do polin√¥mio, utilizando a estrat√©gia de data splitting, em que divide-se o conjunto de dados em treinamento e teste. Utilize o conjunto de teste para calcular a estimativa do risco, usando o EQM.\n\nExerc√≠cio: Ainda considerando o exerc√≠cio do polin√¥mio, implemente uma estrat√©gia de leave-one-out cross-validation e selecione o melhor modelo minimizando a fun√ß√£o de risco.\n\nExerc√≠cio: Por fim, considerando o exerc√≠cio do polin√¥mio, rafa√ßa-o utilizando um procedimento de k-fold cross-validation. Considere k = 5. Dica: considere utiliza a biblioteca rsample."
  },
  {
    "objectID": "index.html#regress√£o-stepwise",
    "href": "index.html#regress√£o-stepwise",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o Stepwise",
    "text": "Regress√£o Stepwise\n Devido a impossibilidade de experimentar uma grande quantidade de modelos (2^d), existe uma s√©rie de algoritmos (heur√≠sticas), que visam reduzir a quantidade de modelos avaliados. Um dos mais conhecidos √© o forward stepwise. Trata-se de um algoritmo sequencial, que em cada passo, apenas uma vari√°vel √© adicionada:\n\n1 - Para j = 1, \\cdots, d, ajuste a regress√£o de Y na j-√©sima vari√°vel X_j. Seja \\widehat{R}(g_j) o risco estimado desta fun√ß√£o. Ent√£o,\n\\widehat{j} = \\argmin_j \\widehat{R}(g_j)\\,\\,\\,\\,\\,\\, \\text{e}\\,\\,\\,\\,\\,\\, S = \\{\\widehat{j}\\}. 2 - Para cada j \\in S^c, ajuste a regress√£o Y = \\beta_jX_j + \\sum_{s \\in S}\\beta_sX_S, em que \\widehat{R}(g_j) √© o risco estimado desta fun√ß√£o. Defina\n\\widehat{j} = \\argmin_{j \\in S^c} \\widehat{R}(g_j)\\,\\,\\,\\,\\,\\, \\text{e atualize}\\,\\,\\,\\,\\,\\, S \\leftarrow \\{S \\cup \\widehat{j}\\}.\n3 - Repita os passos anteriores at√© que todas as vari√°veis estejam em S ou at√© quando n√£o seja mais poss√≠vel ajustar o modelo de regress√£o.\n4 - Selecione o modelo com menor risco estimado."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis",
    "href": "index.html#melhor-subconjunto-de-covari√°veis",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nO estimador de m√≠nimos quadrados - EMQ, na presen√ßa de muitas features (covari√°veis), i.e., quando temos d grande, possui um baixo poder preditivo devido overfitting (super-ajuste). Isso, porqu√™ haver√° muitos par√¢metros a serem estimados, e portanto, a fun√ß√£o de regress√£o estimada \\widehat{r}({\\bf x}) ter√° baixo poder preditivo.\n\nIsso se deve ao fato do balan√ßo de vi√©s e vari√¢ncia. Havendo muitos par√¢metros, como j√° tinhamos visto, a vari√¢ncia do modelo ser√° muito alta.\n\nPortanto, deveremos buscar meios de encontrar o melhor (ao menos um bom) comjunto de covari√°veis."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-1",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nA ideia para resolver esse problema √© retirar algumas covari√°veis do modelo de regress√£o, com o objetivo de diminuir a vari√¢ncia de \\widehat{g}.\n\nVoc√™ poder√° entender que estamos em busca de um estimador \\widehat{g} de g um pouco mais viesado. Trata-se de uma troca em que desejamos reduzir substancialmente a variabilidade do estiamdor do modelo e troca de ganharmos um pouco mais de vi√©s."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-2",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nMatematicamente, uma maneira de fazer isso, √© buscar a estimativa para\n\\widehat{\\beta}_{L_0} = \\argmin_{\\beta_0 \\in \\mathbb{R}, \\beta \\in \\mathbb{R}^d}\\sum_{k = 1}^n\\left(y_k - \\beta_0 - \\sum_{i = 1}^d \\beta_i x_{x,i}\\right)^2 + \\lambda \\,\\,\\underbrace{\\sum_{i = 1}^d \\mathbb{I}(\\beta_i \\neq 0)}_{\\text{Penaliza√ß√£o}}. \\tag{2}\nNote que a penaliza√ß√£o \\sum_{i = 1}^d \\mathbb{I}(\\beta_i \\neq 0) nos conduz na dire√ß√£o de modelos com poucas covari√°veis, quando \\lambda √© um valor alto. Em particualr, quando \\lambda \\to \\infty, for√ßamos a retirada de todas as covari√°veis \\beta_i‚Äôs, i.e., a solu√ß√£o para o problema seria \\widehat{\\beta}_{L_0} \\equiv (\\overline{y}, {\\bf 0}). Note que n√£o h√° penaliza√ß√£o para o intercepto \\beta_0.\n No outro extremo, para \\lambda = 0, temos o estimador de m√≠nimos quadrados, em que nenhuma penaliza√ß√£o ser√° considerada.\n N√£o h√° uma forma f√°cil de minimizar \\widehat{\\beta}_{L_0}."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-3",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nPoder√≠amos, ingenuamente, pensar em ajustar todas as combina√ß√µes poss√≠veis de par√¢metros e utilizar algum crit√©rio, por exemplo, o EQM em novas observa√ß√µes para escolher o melhor modelo de todas as combina√ß√µes poss√≠veis. Isto √©, escolher o melhor modelo entre todas as 2^d combina√ß√µes poss√≠veis de modelos em \\mathbb{G}.\n\nSe \\widehat{\\lambda} = \\frac{2}{n}\\widehat{\\sigma}^2, estimar \\widehat{\\beta}_{L_0} equivale uma busca entre 2^d modelos da classe \\mathbb{G}:\n\n\\begin{align*}\n\\mathbb{G} = \\{\n&g({\\bf x}) = \\widehat{\\beta}_0, \\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_2x_2,\\\\\n&\\cdots\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_dx_d,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_2x_2,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_3x_3,\\\\\n&\\cdots\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_dx_d,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_2x_2 + \\widehat{\\beta}_3x_3,\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_2x_2 + \\widehat{\\beta}_dx_d,\\\\\n&\\cdots\\\\\n&g({\\bf x}) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_1 + \\widehat{\\beta}_2x_2 + \\widehat{\\beta}_3x_3 + \\cdots + &\\widehat{\\beta}_dx_d\n\\}.\n\\end{align*}"
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-4",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nUtilizar \\lambda = \\frac{2}{n}\\widehat{\\sigma}^2 √© o mesmo que utilizar o crit√©rio AIC para determinar o melhor modelo, em que dado\n\\widehat{R}(g) = \\frac{1}{m}\\sum_{k = 1}^m \\underbrace{(\\widetilde{Y}_k - g({\\bf \\widetilde{X}}_k))^2}_{W_k}, em que (\\widetilde{{\\bf X}}_1, \\widetilde{Y}_1), \\cdots, (\\widetilde{{\\bf X}}_m, \\widetilde{Y}_m), representa o conjunto de teste, i.e., calculado com base em m observa√ß√µes em um conjundo de dados n√£o utilizados para treinar o modelo, independentemente da estrat√©gia de divis√£o utilizada, em que\n\\widehat{\\sigma}^2 = \\frac{1}{m}\\sum_{k = 1}^m (W_k - \\overline{W})^2, com \\overline{W} = \\frac{1}{m}\\sum_{k=1}^m W_k."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-5",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nTemos que \\widehat{R}(g), calculado em novas observa√ß√µes (oboserva√ß√µes n√£o utilizadas no treinamento), pode se valer do Teorema Central do Limite, uma vez que \\widehat{R}(g) √© calculado em uma sequ√™ncia de vari√°veis aleat√≥rias i.i.d.‚Äôs. Ent√£o:\n\\widehat{R}(g) \\sim \\text{Normal}\\left(R(g), \\frac{1}{m}\\mathbb{V}[W_1]\\right).\nPortanto, um intervalo aleat√≥rio de aproximadamente 95\\% de confian√ßa para o erro preditivo R(g) poder√° ser calculado como:\n\\widehat{R}(g) \\pm 1,645 \\sqrt{\\frac{1}{m}\\widehat{\\sigma}^2}.\nO c√°lculo de um intervalo de confian√ßa poder√° ser √∫til para entendermos como est√° variando o risco preditivo do nosso modelo. Gostamos de ter modelos com intervalo de amplitude pequena. O intervalo poder√° ser utilizado para fornecer insight de como escolher a divis√£o de treinamento e teste. Por exemplo, pode-se escolher o menor valor de m de modo que a amplitude seja a menor poss√≠vel."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-6",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nPor que essa seria uma escolha ing√™nua? Pense na situa√ß√£o em que temos d = 30, i.e., trinta covari√°veis. Ter√≠amos portanto 2^{30} modelos para ajustar, ou seja, um bilh√£o e setenta e tr√™s milh√µes, setecentos e quarenta e um mil, oitocentos e vinte e quatro modelos para ajustar. √â um a quantidade absurda de modelos para serem estimados!\n\nSe d = 100, ter√≠amos que estimar uma quantidade de modelos que a quantidade estimada de estrelas no universo. Alias, seriam mais modelos para ajustar que a quantidade de √°tomos no universo."
  },
  {
    "objectID": "index.html#melhor-subconjunto-de-covari√°veis-7",
    "href": "index.html#melhor-subconjunto-de-covari√°veis-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Melhor subconjunto de covari√°veis",
    "text": "Melhor subconjunto de covari√°veis\n\nN√£o h√° uma forma f√°cil de minimizar \\widehat{\\beta}_{L_0}."
  },
  {
    "objectID": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-3",
    "href": "index.html#resumindo-data-splitting-valida√ß√£o-cruzada-e-conjunto-de-valida√ß√£o-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o",
    "text": "Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o\n\nUm outro detalhe que muitas vezes n√£o √© falado √© que apesar de temos duas tarefas de estima√ß√£o, uma envolvendo o conjunto de treinamento, em que treinamos o modelo e outra envolvendo o conjunto de teste, em que queremos estimar o risco R(g), de modo a poder selecionar o melhor modelo, a segunda tarefa √© bem mais f√°cil √â por isso que o conjunto de treinamento tende a ser menor que o conjunto de teste."
  },
  {
    "objectID": "index.html#regress√£o-stepwise-1",
    "href": "index.html#regress√£o-stepwise-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Regress√£o Stepwise",
    "text": "Regress√£o Stepwise\n\nUtilizar o algoritmo de sele√ß√£o de vari√°veis foward stepwise, ao inv√©s de buscarmos o melhor ajuste entre 2^d poss√≠veis modelos, que muitas vezes √© imposs√≠vel, precisaremos investigar apenas 1 + d(d + 1)/2 modelos. Reduzimos a complexidade da sele√ß√£o que antes era um problema exponencial. Melhor, n√£o?!"
  },
  {
    "objectID": "index.html#penaliza√ß√£o",
    "href": "index.html#penaliza√ß√£o",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Penaliza√ß√£o",
    "text": "Penaliza√ß√£o\n\nQuando temos modelos que envolve d par√¢metros e que temos controle sobre eles (conhecemos muito bem cada um deles), acrescentar algum tipo de penaliza√ß√£o √† fun√ß√£o objetivo poder√° ser √∫til. A penaliza√ß√£o √© uma medida de complexidade, em que √© √∫til para equilibrar o modelo, de modo a tentar buscar um equilibrio entre vi√©s e vari√¢ncia, discutidos anteriormente. Assim, sob novas observa√ß√µes, desejamos estimar o risco R(g), por\n\nR(g) \\approx EQM(g) + \\mathcal{P}(g).\n\nDesejamos minimiar R(g), mas n√£o a custa de muitos par√¢metros, pois assim ter√≠amos overfitting. Portanto, para muitos par√¢metros temos que ter EQM baixo, por√©m, \\mathcal{P}(g) deve ser alto. J√° em modelos viesados, quando temos poucos par√¢metros, o EQM normalmente √© alto, mas a complexidade \\mathcal{P}(g) deve ser baixo, pois temos um modelo mais simplista."
  },
  {
    "objectID": "index.html#penaliza√ß√£o-1",
    "href": "index.html#penaliza√ß√£o-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Penaliza√ß√£o",
    "text": "Penaliza√ß√£o\n\nExistem diversas penaliza√ß√µes, em que o AIC (Akaike Information Criterion) e BIC (Bayesian Information Criterion) s√£o as mais conhecidas. Com base nesses crit√©rios, temos que\n\n\nAIC: EQM + \\frac{2}{n\\,d\\, \\widehat{\\sigma}^2}.\nBIC: EQM + \\frac{\\log(n)}{n\\, d\\, \\widehat{\\sigma}^2}.\n\n\nAqui, d √© a quantidade de par√¢metros no modelo e \\widehat{\\sigma}^2 √© uma estimativa da vari√¢ncia do erro, que para um conjunto de teste suficientemente grande, poder√° ser considerado o estimador de \\widehat{\\sigma}^2 conforme descrito anteriormente.\n\n\n\nDepartamento de Estat√≠stica da UFPB"
  },
  {
    "objectID": "index.html#aic-e-bic",
    "href": "index.html#aic-e-bic",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "AIC e BIC",
    "text": "AIC e BIC\n\nExistem diversas penaliza√ß√µes, em que o AIC (Akaike Information Criterion) e BIC (Bayesian Information Criterion) s√£o as mais conhecidas. Com base nesses crit√©rios, temos que\n\n\n\n\nAIC: EQM + \\frac{2}{n\\,d\\, \\widehat{\\sigma}^2}.\nBIC: EQM + \\frac{\\log(n)}{n\\, d\\, \\widehat{\\sigma}^2}.\n\n\n\n\\widehat{\\sigma}^2 = \\frac{1}{m}\\sum_{k = 1}^m (W_k - \\overline{W})^2.\n\n\n\nAqui, d √© a quantidade de par√¢metros no modelo e \\widehat{\\sigma}^2 √© uma estimativa da vari√¢ncia do erro, que para um conjunto de teste suficientemente grande, poder√° ser considerado o estimador de \\widehat{\\sigma}^2 conforme descrito anteriormente. Segundo James, Gareth, et al.¬†An introduction to statistical learning. Ed. 2, p. 233, assume-se o modelo com todos os preditores para o c√°lculo de \\widehat{\\sigma}^2."
  },
  {
    "objectID": "index.html#lasso",
    "href": "index.html#lasso",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n\n\n\nO lasso foi desenvolvido pelo Robert Tibshirani, em um artigo publicado no artigo Regression Shrinkage and Selection via the Lasso."
  },
  {
    "objectID": "index.html#lasso-1",
    "href": "index.html#lasso-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n\nO lasso tem como objetivo encontrar um estimador de uma regress√£o linear que possui risco menor que o de m√≠nimos quadrados, possuindo duas grandes vantagens, em rela√ß√£o ao stepwise:\n\n\nSua solu√ß√£o √© mais r√°pida, ainda que stepwise seja consideravalmente mais r√°pido do que avaliar 2^d modelos;\nO lasso √© capaz de selecionar automaticamente as vari√°veis mais relevantes para o modelo, reduzindo a dimensionalidade dos dados.\n\n\nA segunda vantagem ocorre, uma vez que ele realiza uma penaliza√ß√£o que leva √† estimativas de alguns coeficientes \\beta_i igual a zero, eliminando as vari√°veis menos importantes."
  },
  {
    "objectID": "index.html#lasso-2",
    "href": "index.html#lasso-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n\nNo lasso, ao inv√©s de reduzir a vari√¢ncia do estimador de m√≠nimos quadrados usando a complexidade (L_0 = \\sum_{i = 1}^d\\mathbb{I}(\\beta_i) \\neq 0) em Equa√ß√£o¬†2, usa-se a penaliza√ß√£o L_1 = \\sum_{i = 1}^d|\\beta_i|. No lasso, buscamos:\n\\widehat{\\beta}_{L_1,\\lambda} = \\argmin_{\\beta_0 \\in \\mathbb{R}, \\beta \\in \\mathbb{R}^d}\\sum_{k = 1}^n\\left(y_k - \\beta_0 - \\sum_{i = 1}^d \\beta_i x_{x,i}\\right)^2 + \\lambda \\,\\,\\underbrace{\\sum_{j = 1}^d|\\beta_j|}_{\\text{Penaliza√ß√£o}}, em que \\lambda √© um tuning parameter. Perceba que quando \\lambda = 0, ca√≠mos no caso do modelo de regress√£o por m√≠nimos quadrados sem penaliza√ß√£o. J√°, quando \\lambda \\rightarrow \\infty, temos um modelo em que todas as vari√°veis s√£o removidas, uma vez que a primeira parte do modelo torna-se insignificante."
  },
  {
    "objectID": "index.html#lasso-4",
    "href": "index.html#lasso-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n\nO lasso √© extremamente r√°pido, e nos √∫ltimos anos, diversos algoritmos foram constru√≠dos para fazer essa tar√©fa de forma eficiente. O LARS foi um dos primeiros algoritmos desenvolvidos em 2010. Para detalhes, ler Friedman, J. H. (2001). Greedy function approximation: a gradient boosting machine. Annals of statistics, 1189‚Äì1232.\n\nNo R, a regress√£o lasso poder√° ser feita usando a biblioteca glmnet, assim:\n\n\nlibrary(glmnet)\najuste &lt;- cv.glmnet(x, y, alpha = 1)"
  },
  {
    "objectID": "index.html#lasso-3",
    "href": "index.html#lasso-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n \nQuando \\lambda √© grande, temos que\n\\sum_{k = 1}^n \\left(y_k - \\beta_0 - \\sum_{j = 1}^d \\beta_j x_{k,j}\\right)^2 + \\lambda \\sum_{j = 1}^d |\\beta_j| \\approx \\lambda \\sum_{j = 1}^d |\\beta_j|, e portanto, \\widehat{\\beta}_1 = 0, \\cdots, \\widehat{\\beta}_d = 0.\n\nA escolha de \\lambda, em geral, √© feita utilizado algum m√©todo de valida√ß√£o cruzada."
  },
  {
    "objectID": "index.html#lasso-5",
    "href": "index.html#lasso-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Lasso",
    "text": "Lasso\n\nUma alternativa que surgiu antes do lasso √© a regress√£o ridge. Ela foi proposta no artigo Hoerl, A. E. & Kennard, R. W. (1970). Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1), 55‚Äì67. Aqui, utiliza-se como medida de complexidade a norma L_2, em que, o estimador √© dado por:\n\\widehat{\\beta}_{L_2,\\lambda} = \\argmin_{\\beta_0 \\in \\mathbb{R}, \\beta \\in \\mathbb{R}^d}\\sum_{k = 1}^n\\left(y_k - \\beta_0 - \\sum_{i = 1}^d \\beta_i x_{x,i}\\right)^2 + \\lambda \\,\\,\\underbrace{\\sum_{j = 1}^d\\beta_j^2}_{\\text{Penaliza√ß√£o}}. Diferentemente do lasso, a regress√£o ridge possui solu√ß√£o anal√≠tica, dada por:\n\\widehat{\\beta}_{L_2,\\lambda} = ({\\bf X}^{T}{\\bf X} + \\lambda\\mathbb{\\bf I}_0)^{-1}{\\bf X}^{T}Y, em que \\mathbb{\\bf I}_0 √© a matriz identidade (d + 1) \\times (d + 1) com \\mathbb{\\bf I}_0(1,1) = 0.\n\n\n\n\nDepartamento de Estat√≠stica da UFPB"
  },
  {
    "objectID": "index.html#ridge",
    "href": "index.html#ridge",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ridge",
    "text": "Ridge\n\nUma alternativa que surgiu antes do lasso √© a regress√£o ridge. Ela foi proposta no artigo Hoerl, A. E. & Kennard, R. W. (1970). Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1), 55‚Äì67. Aqui, utiliza-se como medida de complexidade a norma L_2, em que, o estimador √© dado por:\n\\widehat{\\beta}_{L_2,\\lambda} = \\argmin_{\\beta_0 \\in \\mathbb{R}, \\beta \\in \\mathbb{R}^d}\\sum_{k = 1}^n\\left(y_k - \\beta_0 - \\sum_{i = 1}^d \\beta_i x_{x,i}\\right)^2 + \\lambda \\,\\,\\underbrace{\\sum_{j = 1}^d\\beta_j^2}_{\\text{Penaliza√ß√£o}}. Diferentemente do lasso, a regress√£o ridge possui solu√ß√£o anal√≠tica, dada por:\n\\widehat{\\beta}_{L_2,\\lambda} = ({\\bf X}^{T}{\\bf X} + \\lambda\\mathbb{\\bf I}_0)^{-1}{\\bf X}^{T}Y, em que \\mathbb{\\bf I}_0 √© a matriz identidade (d + 1) \\times (d + 1) com \\mathbb{\\bf I}_0(1,1) = 0."
  },
  {
    "objectID": "index.html#ridge-1",
    "href": "index.html#ridge-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Ridge",
    "text": "Ridge\n\nA regress√£o ridge poder√° ter uma vari√¢ncia menor que a regress√£o lasso, por√©m seu vi√©s poder√° ser maior. Outra caracter√≠stica da regress√£o ridge √© que ela possue uma √∫nica solu√ß√£o, enquanto a regress√£o lasso poder√° ter multiplas solu√ß√µes. Os autores tamb√©m demonstram que a regress√£o ridge lida melhor com multicolinearidade.\n\nNo R, tamb√©m poderemos utilizar a biblioteca glmnet:\n\n\nlibrary(glmnet)\najuste &lt;- cv.glmnet(x, y, alpha = 0)"
  },
  {
    "objectID": "index.html#elastic-net",
    "href": "index.html#elastic-net",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Elastic Net",
    "text": "Elastic Net\n\nNesse tipo de modelo de gress√£o, combina-se as penaliza√ß√µes da regress√£o ridge com a utilizada na regress√£o lasso, herdando os benef√≠cios do uso de cada um dos m√©todos isoladamente, melhorando a estabilidade das estimativas do lasso, em situa√ß√µes de multicolinearidade entre as vari√°veis e tamb√©m permitindo a sele√ß√£o autom√°tica de vari√°veis.\n(1-\\alpha)\\widehat{\\beta}_{L_2,\\lambda} + \\alpha\\widehat{\\beta}_{L_1,\\lambda}, em que 0 \\leq \\alpha \\leq1. Em R, basta especificar para a fun√ß√£o glmnet um valor de \\alpha diferente de 0 e 1."
  },
  {
    "objectID": "index.html#tuning-parameters-1",
    "href": "index.html#tuning-parameters-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tuning Parameters",
    "text": "Tuning Parameters\n\nExemplo: Consedere os dados de expectativa de vida versus PIB per Capita, dispon√≠veis aqui. Selecione o melhor estimador g da classe \\mathbb{G}, em que\n\\mathbb{G} = \\left\\{g(x)\\,\\,:\\,\\, \\beta_0 + \\sum_{i = 1}^p \\beta_i x^i\\,\\, \\text{para } p \\in \\{1, 2, \\cdots,11\\} \\right\\}. Note que selecionar o melhor polin√¥mio √© uma busca em p. Devemos utilizar o erro quadr√°tico m√©dio - EQM sob o conjunto de valida√ß√£o, uma vez que sabemos que apenas em um conjunto de valida√ß√£o ou em novas observa√ß√µes o estimador do risco pelo EQM √© consistente, pela Lei dos Grandes N√∫meros.\n\nVamos utilizar a biblioteca rsample para a tarefa de valida√ß√£o cruzada. Leia a documenta√ß√£o da biblioteca, em especial, a da fun√ß√£o vfold_cv, respons√°vel por construir a valida√ß√£o cruzada. Na verdade ela faz a divis√£o da base de dados em v splits de tamanho aproximadamente iguais. Por padr√£o, v = 10. Esse √© o procedimento de k-fold cross-validation que apresentamos aqui, em que v = k."
  },
  {
    "objectID": "index.html#tuning-parameters-2",
    "href": "index.html#tuning-parameters-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tuning Parameters",
    "text": "Tuning Parameters\n\nAlgumas observa√ß√µes gerais a respetio da biblioteca rsample, que s√£o √∫teis para resolver esse problema:\n\n\nPara realizar uma primeira divis√£o do conjunto de dados (data splitting/hold-out), utiliza-se a fun√ß√£o initial_split;\nPara acessar o conjunto de treinamento dos dados, usamos a fun√ß√£o training;\nPara acessar o conjunto de teste, usamos a fun√ß√£o testing;\nPara constuir todas as divis√µes da valida√ß√£o cruzada, entre treinamento e valida√ß√£o, no conjunto de treinamento inicial, usamos a fun√ß√£o vfold_cv j√° mencionada;\nPara acessar o conjunto de treinamento de um split da valida√ß√£o cruzada, usamos a fun√ß√£o analysis;\nPara acessar o conjunto de valida√ß√£o, utilizamos a fun√ß√£o assessment."
  },
  {
    "objectID": "index.html#tuning-parameters-3",
    "href": "index.html#tuning-parameters-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tuning Parameters",
    "text": "Tuning Parameters\n\n Note que realizar uma valida√ß√£o cruzada √© importante para podemos selecionar o melhor polin√¥mio, i.e., o melhor valor de p. Caso venhamos negligenciar esse aspecto da an√°lise, iremos cair na fal√°cia de acreditarmos que quanto maior o grau do polin√¥mio, maior ser√° o poder preditivo do modelo. Isso n√£o √© verdade e voc√™ dever√° selecionar o melhor modelo dentro de um esquema de valida√ß√£o cruzada.\n\nNo mundo de aprendizagem de m√°quina, muitos chamam o processo de encontrar o melhor hiperpar√¢metro de ‚Äútunagem‚Äù. Em v√°rios modelos, podemos ter mais de um."
  },
  {
    "objectID": "index.html#tuning-parameters-4",
    "href": "index.html#tuning-parameters-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tuning Parameters",
    "text": "Tuning Parameters\n\nAs Figuras abaixo, mostram a avalia√ß√£o dos polin√¥mios da classe \\mathbb{G}, usando o risco estimado \\widehat{R}(g) pelo erro quadr√°tico m√©dio - EQM. Por√©m, a Figura A aprenseta a avalia√ß√£o dos modelos, usando simplesmente o conjunto de treinamento e a Figura B aprensenta a avalia√ß√£o do grau do polin√¥mio considerando uma valida√ß√£o cruzada dentro do conjunto de treinamento.\n \n\nA mensagem equivocada passada pela Figura A √© que supostamente aumentar a complexidade do modelo seria uma uma boa alternativa e nos conduzir√≠amos √† bons modelos preditivos. Mas sempre se lembre do equil√≠brio que temos que ter entre vi√©s e vari√¢ncia. A Figura B mostra que um polin√¥mio com grau pr√≥ximo √† p = 8 √© a melhor alternativa."
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#column-2",
    "href": "shiny_apps/balanco_vies_variancia.html#column-2",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEntrada de informa√ß√µes\n\nsliderInput(\"grau_polinomio\", \"p:\",\n    min = 1L, max = 30L,\n    value = 1L,\n    step = 1L\n)\n\n\np:\n\n\n\n# Lendo dados\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados &lt;- \n  dados_expectativa_renda |&gt; \n  dplyr::select(-CountryName) |&gt; \n  dplyr::rename(y = LifeExpectancy, x = GDPercapita)\n  \niteracoes &lt;- function(tibble_data, grau) {\n  x &lt;- tibble_data$x\n  iteracoes &lt;- lapply(X = 2L:grau, FUN = function(i) x^i)\n  \n  result &lt;- cbind(tibble_data, do.call(cbind, iteracoes))\n  colnames(result)[(ncol(tibble_data) + 1):ncol(result)] &lt;- paste0(\"x\", 2L:grau)\n  \n  as_tibble(result)\n}  \n\nreg_polinomial &lt;- function(dados, grau = 1L) {\n  if(grau &gt;= 2L)\n    dados &lt;- iteracoes(dados, grau = grau)\n  \n  lm(formula = y ~ ., data = dados)\n}\n\n# Divis√£o dos dados\ndivisao_inicial &lt;- rsample::initial_split(dados)\ntreinamento &lt;- rsample::training(divisao_inicial)\nteste &lt;- rsample::testing(divisao_inicial) # Teste final\n\n# v-folds cross-validation\nvalidacao &lt;- function(dados, grau = 1L, errado = FALSE, ...){\n  \n  # Todas as divis√µes da validacao cruzada\n  cv &lt;- rsample::vfold_cv(dados, ...)\n  \n  hiper &lt;- function(i){\n    treino &lt;- rsample::analysis(cv$splits[[i]]) # Treinamento\n    validacao &lt;- rsample::assessment(cv$splits[[i]]) # Validaca√ß√£o\n    ajuste &lt;- reg_polinomial(dados = treino, grau = grau)\n    \n    if(errado){\n      df_treino &lt;- iteracoes(treino, grau = grau)\n      df_treino &lt;- df_treino |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_treino))\n      yardstick::rmse(data = df_treino, truth = y, estimate = y_chapeu)$.estimate\n    } else {\n      df_validacao &lt;- iteracoes(validacao, grau = grau)\n      df_validacao &lt;- df_validacao |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_validacao))\n      yardstick::rmse(data = df_validacao, truth = y, estimate = y_chapeu)$.estimate\n    }\n  }\n  purrr::map_dbl(.x = seq_along(cv$splits), .f = hiper) |&gt; \n    mean()\n}\n\nplot_bar &lt;- function(grau){\n  ruim &lt;- validacao(dados, errado = TRUE, grau = grau)\n  bom &lt;- validacao(dados, errado = FALSE, grau = grau)\n  df &lt;- tibble::tibble(x = c(\"Errado\", \"Certo\"), y = c(log(ruim), log(bom)))\n  \n  df |&gt; \n    ggplot(aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\", fill = \"#0f385d\") +\n    geom_text(aes(label = round(y, digits = 2L)), vjust = -0.5, size = 10) +\n    labs(x = \"Estrat√©gia\", y = \"EQM estimado\") + \n    theme(\n      plot.title = element_text(size = 18, face = \"bold\"),\n      plot.subtitle = element_text(size = 16),\n      axis.text = element_text(size = 10), \n      axis.title = element_text(size = 14, face = \"bold\")\n    )\n}"
  },
  {
    "objectID": "shiny_apps/balanco_vies_variancia.html#column-3",
    "href": "shiny_apps/balanco_vies_variancia.html#column-3",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nAvalia√ß√£o do risco estimado\n\nrenderPlot({\n  plot_bar(input$grau_polinomio)\n})"
  },
  {
    "objectID": "index.html#tuning-parameters-5",
    "href": "index.html#tuning-parameters-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tuning Parameters",
    "text": "Tuning Parameters\n\nObserve o dashboard interativo! Sabemos que para que tenhamos uma boa estimativa do risco preditivo, devemos utilizar novas observa√ß√µes. No dashboard √© poss√≠vel observar que a forma errada (usando o conjunto de treinamento para avaliar o risco), sugere que sempre ser√° bom adicionar mais par√¢metros ao modelo, levando a overfitting. Perceba que usando a forma correta (usando valida√ß√£o cruzada), o EQM (risco estimado) sugere que n√£o podemos aumentar muito a quantidade de par√¢metros."
  },
  {
    "objectID": "shiny_apps/index.html",
    "href": "shiny_apps/index.html",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "",
    "text": ".shiny-output-area {\n  margin: 0;\n}\n\n.full-width-image {\n    width: 100vw; /* Define a largura igual √† largura da janela do navegador */\n    height: auto; /* Mant√©m a propor√ß√£o original da imagem */\n}"
  },
  {
    "objectID": "shiny_apps/index.html#rows",
    "href": "shiny_apps/index.html#rows",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Rows",
    "text": "Rows\n\n\n\n\n\n\nEssa aplica√ß√£o foi constru√≠da para conter alguns exempos da disciplina de Aprendizagem de M√°quina, lecionada aos dicentes do curso de bacharelado em estat√≠stica da UFPB."
  },
  {
    "objectID": "shiny_apps/index.html#column",
    "href": "shiny_apps/index.html#column",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEntrada de informa√ß√µes\n\nsliderInput(\"numeromodelos\", \"N√∫mero de modelos:\",\n    min = 1, max = 100, value = 50\n)\n\n\nN√∫mero de modelos:\n\n\n\nsliderInput(\"tamanhoamostral\", \"Tamanho amostral:\",\n    min = 100, max = 250, value = 100\n)\n\n\nTamanho amostral:\n\n\n\nsliderInput(\"grau\", \"Grau do polin√¥mio:\",\n    min = 1, max = 200, value = 1\n)\n\n\nGrau do polin√¥mio:"
  },
  {
    "objectID": "shiny_apps/index.html#column-1",
    "href": "shiny_apps/index.html#column-1",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nResultado gr√°fico das simula√ß√µes\n\nrenderPlot({\n  mc_ajustes(mc = input$numeromodelos, n = input$tamanhoamostral, desvio_padrao = 5, grau = input$grau)\n})"
  },
  {
    "objectID": "shiny_apps/index.html#column-2",
    "href": "shiny_apps/index.html#column-2",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nEntrada de informa√ß√µes\n\nsliderInput(\"grau_polinomio\", \"p:\",\n    min = 1L, max = 30L,\n    value = 1L,\n    step = 1L\n)\n\n\np:\n\n\n\n# Lendo dados\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados &lt;- \n  dados_expectativa_renda |&gt; \n  dplyr::select(-CountryName) |&gt; \n  dplyr::rename(y = LifeExpectancy, x = GDPercapita)\n  \niteracoes &lt;- function(tibble_data, grau) {\n  x &lt;- tibble_data$x\n  iteracoes &lt;- lapply(X = 2L:grau, FUN = function(i) x^i)\n  \n  result &lt;- cbind(tibble_data, do.call(cbind, iteracoes))\n  colnames(result)[(ncol(tibble_data) + 1):ncol(result)] &lt;- paste0(\"x\", 2L:grau)\n  \n  as_tibble(result)\n}  \n\nreg_polinomial &lt;- function(dados, grau = 1L) {\n  if(grau &gt;= 2L)\n    dados &lt;- iteracoes(dados, grau = grau)\n  \n  lm(formula = y ~ ., data = dados)\n}\n\n# Divis√£o dos dados\ndivisao_inicial &lt;- rsample::initial_split(dados)\ntreinamento &lt;- rsample::training(divisao_inicial)\nteste &lt;- rsample::testing(divisao_inicial) # Teste final\n\n# v-folds cross-validation\nvalidacao &lt;- function(dados, grau = 1L, errado = FALSE, ...){\n  \n  # Todas as divis√µes da validacao cruzada\n  cv &lt;- rsample::vfold_cv(dados, ...)\n  \n  hiper &lt;- function(i){\n    treino &lt;- rsample::analysis(cv$splits[[i]]) # Treinamento\n    validacao &lt;- rsample::assessment(cv$splits[[i]]) # Validaca√ß√£o\n    ajuste &lt;- reg_polinomial(dados = treino, grau = grau)\n    \n    if(errado){\n      df_treino &lt;- iteracoes(treino, grau = grau)\n      df_treino &lt;- df_treino |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_treino))\n      yardstick::rmse(data = df_treino, truth = y, estimate = y_chapeu)$.estimate\n    } else {\n      df_validacao &lt;- iteracoes(validacao, grau = grau)\n      df_validacao &lt;- df_validacao |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_validacao))\n      yardstick::rmse(data = df_validacao, truth = y, estimate = y_chapeu)$.estimate\n    }\n  }\n  purrr::map_dbl(.x = seq_along(cv$splits), .f = hiper) |&gt; \n    mean()\n}\n\nplot_bar &lt;- function(grau){\n  ruim &lt;- validacao(dados, errado = TRUE, grau = grau)\n  bom &lt;- validacao(dados, errado = FALSE, grau = grau)\n  df &lt;- tibble::tibble(x = c(\"Errado\", \"Certo\"), y = c(log(ruim), log(bom)))\n  \n  df |&gt; \n    ggplot(aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\", fill = \"#0f385d\") +\n    geom_text(aes(label = round(y, digits = 2L)), vjust = -0.5, size = 10) +\n    labs(x = \"Estrat√©gia\", y = \"EQM estimado\") + \n    theme(\n      plot.title = element_text(size = 18, face = \"bold\"),\n      plot.subtitle = element_text(size = 16),\n      axis.text = element_text(size = 20), \n      axis.title = element_text(size = 14, face = \"bold\")\n    )\n}"
  },
  {
    "objectID": "shiny_apps/index.html#column-3",
    "href": "shiny_apps/index.html#column-3",
    "title": "Aprendizagem de M√°quina - UFPB",
    "section": "Column",
    "text": "Column\n\nAvalia√ß√£o do risco estimado\n\nrenderPlot({\n  plot_bar(input$grau_polinomio)\n})"
  },
  {
    "objectID": "index.html#tuning-parameters-6",
    "href": "index.html#tuning-parameters-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Tuning Parameters",
    "text": "Tuning Parameters\n\nAbaixo voc√™ poder√° acessar o c√≥digo que soluciona o problema. O par√¢metro errado = FALSE da fun√ß√£o valida√ß√£o no c√≥digo que segue, conduz a solu√ß√£o correta (usando a valida√ß√£o cruzada), que sempre voc√™ dever√° considerar na pr√°tica.\n\n\n\nEstude o c√≥digo da solu√ß√£o de exemplo\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Lendo dados\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados &lt;- \n  dados_expectativa_renda |&gt; \n  dplyr::select(-CountryName) |&gt; \n  dplyr::rename(y = LifeExpectancy, x = GDPercapita)\n  \niteracoes &lt;- function(tibble_data, grau) {\n  x &lt;- tibble_data$x\n  iteracoes &lt;- lapply(X = 2L:grau, FUN = function(i) x^i)\n  \n  result &lt;- cbind(tibble_data, do.call(cbind, iteracoes))\n  colnames(result)[(ncol(tibble_data) + 1):ncol(result)] &lt;- paste0(\"x\", 2L:grau)\n  \n  as_tibble(result)\n}  \n\nregressao_polinomial &lt;- function(dados, grau = 1L) {\n  if(grau &gt;= 2L)\n    dados &lt;- iteracoes(dados, grau = grau)\n  \n  lm(formula = y ~ ., data = dados)\n}\n\n# Divis√£o dos dados\ndivisao_inicial &lt;- rsample::initial_split(dados)\ntreinamento &lt;- rsample::training(divisao_inicial)\nteste &lt;- rsample::testing(divisao_inicial) # Teste final\n\n# v-folds cross-validation\nvalidacao &lt;- function(dados, grau = 1L, errado = FALSE, ...){\n  \n  # Todas as divis√µes da validacao cruzada\n  cv &lt;- rsample::vfold_cv(dados, ...)\n  \n  hiper &lt;- function(i){\n    treino &lt;- rsample::analysis(cv$splits[[i]]) # Treinamento\n    validacao &lt;- rsample::assessment(cv$splits[[i]]) # Validaca√ß√£o\n    ajuste &lt;- regressao_polinomial(dados = treino, grau = grau)\n    \n    if(errado){\n      df_treino &lt;- iteracoes(treino, grau = grau)\n      df_treino &lt;- df_treino |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_treino))\n      yardstick::rmse(data = df_treino, truth = y, estimate = y_chapeu)$.estimate\n    } else {\n      df_validacao &lt;- iteracoes(validacao, grau = grau)\n      df_validacao &lt;- df_validacao |&gt; dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_validacao))\n      yardstick::rmse(data = df_validacao, truth = y, estimate = y_chapeu)$.estimate\n    }\n  }\n  purrr::map_dbl(.x = seq_along(cv$splits), .f = hiper) |&gt; \n    mean()\n}\n\nplot_avaliacao &lt;- function(dados, errado = FALSE){\n  # Testando iterativamente, v√°rios valores de p:\n  p &lt;- seq(1L:11L)\n  risco &lt;- purrr::map_dbl(.x = p, .f = \\(p) validacao(dados = dados, grau = p, errado = errado))\n  df_risco &lt;- tibble::tibble(p = p, risco = risco)\n  \n  # Plotando\n  df_risco |&gt; \n    ggplot(aes(x = p, y = risco, color = risco)) +\n    geom_point(size = 5) +\n    scale_x_continuous(breaks = p) +\n    scale_y_continuous(breaks = p) +\n    labs(\n      title = \"Valiando o risco estimado para diversos graus do polin√¥mio\",\n      subtitle = \"EQM no conjunto de valida√ß√£o\"\n    ) +\n    theme(\n      plot.title = element_text(size = 18, face = \"bold\"),\n      plot.subtitle = element_text(size = 16),\n      axis.text = element_text(size = 10), \n      axis.title = element_text(size = 14, face = \"bold\")\n    )\n}\n\n# Avaliac√£o errada versus correta\nset.seed(0)\ngrafico &lt;- \n  plot_avaliacao(dados, errado = TRUE) + \n  plot_avaliacao(dados, errado = FALSE) +\n  plot_annotation(tag_levels = c(\"A\", \"B\"))\n\nggsave(grafico, file = \"imgs/avaliacao_risco.png\", device = \"png\", width = 50, height = 20, units = \"cm\", limitsize = F)\n\nplot_bar &lt;- function(grau){\n  ruim &lt;- validacao(dados, errado = TRUE, grau = grau)\n  bom &lt;- validacao(dados, errado = FALSE, grau = grau)\n  df &lt;- tibble::tibble(x = c(\"Errado\", \"Certo\"), y = c(log(ruim), log(bom)))\n  \n  df |&gt; \n    ggplot(aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = y), vjust = 0)\n}"
  },
  {
    "objectID": "index.html#exemplo-emq-ridge-lasso-e-elastic-net",
    "href": "index.html#exemplo-emq-ridge-lasso-e-elastic-net",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Exemplo: EMQ, Ridge, Lasso e Elastic Net",
    "text": "Exemplo: EMQ, Ridge, Lasso e Elastic Net\n\nExemplo: Considere uma base de dados simulada, com n = 500 observa√ß√µes, de tal forma que\nY = 3X_{1} - 2X_2 + X_3 + -3X_4 + X_5 + \\sum_{i = 6}^{20}0X_i + \\varepsilon, em que \\varepsilon \\sim \\text{Normal}(0, 0.5^2) e X_i \\sim \\text{Normal}(0, 1), independentes, com i = 1, \\cdots, 20. Desejamos ajustar quatro modelos de regress√£o. Para o caso do Estimador de M√≠nimos Quadrados - EMQ e do modelo Ridge, que n√£o tem sele√ß√£o autom√°tica de vari√°veis, usaremos todas as vari√°veis. Desejamos avaliar o risco estimado de cada uma das regress√µes."
  },
  {
    "objectID": "index.html#k-fold-cross-validation-4",
    "href": "index.html#k-fold-cross-validation-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\nA imagem abaixo ilustra o procedimento k-fold cross-validation, em que uma 5-fold cross-validation √© realizada dentro do conjunto de treinamento. Em cada split, o conjunto verde de observa√ß√µes (fold verde) s√£o utilizados para treinar/ajustar o modelo e o conjunto azul, em cada um dos splits √© utilizado para avaliar o risco preditivo R(g) (atrav√©s, por exemplo do EQM).\n\n\n \n\nN√£o confunda os folds azuis com o conjunto de teste (Test data), este √∫ltimo utilizado por fim, depois do modelo pronto, para avaliar o desempenho do modelo treinado.\nNote tamb√©m que a valida√ß√£o cruzada tamb√©m √© utilizada para o ajuste de hiperpar√¢metros, que s√£o par√¢metros de sintoniza√ß√£o que n√£o dependem dos dados para serem equalizados. Por exemplo, em uma regress√£o lasso, que veremos adiante, h√° o hiperpar√¢metro \\lambda que precisamos obter, normalmente por meio de um grid search (sequ√™ncia finita), por exemplo, \\lambda \\in [0.5, 1, 1.5, 2, 2.5] de poss√≠veis valores. Cada split pode ser utilizado para avaliar um valor de \\lambda, dos poss√≠veis valores dispostos no grid. Aumentar√≠amos a quantidade de splits para mais valores de \\lambda na sequ√™ncia."
  },
  {
    "objectID": "index.html#exemplo-mmq-ridge-lasso-e-elastic-net",
    "href": "index.html#exemplo-mmq-ridge-lasso-e-elastic-net",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Exemplo: MMQ, Ridge, Lasso e Elastic Net",
    "text": "Exemplo: MMQ, Ridge, Lasso e Elastic Net\n\nExemplo: Considere uma base de dados simulada, com n = 500 observa√ß√µes, de tal forma que\nY = 3X_{1} - 2X_2 + X_3, -3X_4 + X_5 + \\sum_{i = 6}^{20} + \\varepsilon, em que \\varepsilon \\sim \\text{Normal}(0, 0.5^2) e X_i \\sim \\text{Normal}(0, 1), independentes, com i = 1, \\cdots, 20. Desejamos ajustar quatro modelos de regress√£o. Para o caso do Modelo de M√≠nimos Quadrados - MMQ e do modelo Ridge, que n√£o tem sele√ß√£o autom√°tica de vari√°veis, usaremos todas as vari√°veis. Desejamos avaliar o risco estimado de cada uma das regress√µes.\n\n\n\nDepartamento de Estat√≠stica da UFPB"
  },
  {
    "objectID": "index.html#exemplo-emq-ridge-lasso-e-elastic-net-1",
    "href": "index.html#exemplo-emq-ridge-lasso-e-elastic-net-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Exemplo: EMQ, Ridge, Lasso e Elastic Net",
    "text": "Exemplo: EMQ, Ridge, Lasso e Elastic Net\n\n\n\nSolu√ß√£o utilizando o tidymodels\nlibrary(tidymodels)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Removendo poss√≠veis conflitos de pacotes --------------------------------\ntidymodels::tidymodels_prefer()\n\n# Fun√ß√£o para gerar os dados ----------------------------------------------\ngerando_dados &lt;- function(n = 300L){\n  regressao &lt;- function(i){\n    x &lt;- rnorm(n = 5L)\n    y &lt;- 3*x[1L] - 2*x[2L] + x[3L] - 3*x[4L] + x[5L] + rnorm(1L, 0, 0.5)\n    tibble(\n      y = y,\n      x1 = x[1L],\n      x2 = x[2L],\n      x3 = x[3L],\n      x4 = x[4L],\n      x5 = x[5L]\n    )\n  }\n  dados &lt;- purrr::map(.x = 1L:n, .f = regressao) |&gt; \n    purrr::list_rbind()\n  \n  parte_esparsa &lt;- matrix(0, n, 15)\n  \n  dados &lt;- cbind(dados, parte_esparsa)\n  colnames(dados) &lt;- c(\"y\", paste0(\"x\", 2L:ncol(dados)))\n  as_tibble(dados)\n}\n\ndados &lt;- gerando_dados(n = 500)\n\n# Divis√£o inicial da base -------------------------------------------------\nhod_out &lt;- initial_split(dados, prop = 0.7)\ntreinamento &lt;- training(hod_out)\nteste &lt;- testing(hod_out)\n\n# Setando o modelo (set engine) -------------------------------------------\nmodelo_eqm &lt;- \n  linear_reg(penalty = 0, mixture = 0) |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine(\"glmnet\")\n  \nmodelo_ridge &lt;- \n  linear_reg(penalty = tune::tune(), mixture = 0) |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine(\"glmnet\")\n\nmodelo_lasso &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) |&gt; \n  set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"glmnet\")\n  \nmodelo_elastic &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) |&gt; \n  set_mode(\"regression\") |&gt; \n  parsnip::set_engine(\"glmnet\")\n\n# Criando workflows -------------------------------------------------------\nall_wf &lt;- \n  workflow_set(\n    preproc = list(y ~ . ),\n    models = list(eqm = modelo_eqm, ridge = modelo_ridge, lasso = modelo_lasso, elastic = modelo_elastic), \n    cross = TRUE\n  )\n\n# Valida√ß√£o cruzada -------------------------------------------------------\nset.seed(0)\ncv &lt;- rsample::vfold_cv(treinamento, v = 5L)\n\n# Setando a m√©trica -------------------------------------------------------\nmetrica &lt;- yardstick::metric_set(rmse)\n\n# Tunagem dos hiperpar√¢metros ---------------------------------------------\n# A semente (seed = 0) faz com que dentro da valida√ß√£o cruzada para cada modelo\n# a semente seja sempre a mesma.\ntunagem &lt;- \n  all_wf |&gt; \n  workflow_map(\n    seed = 0, \n    verbose = TRUE,\n    resamples = cv,\n    grid = 50,\n    metrics = metrica\n  )\n\n# Rank dos melhores modelos -----------------------------------------------\nmodelos_rank &lt;- tunagem |&gt; rank_results()\n\nmelhor_eqm &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"formula_eqm\") |&gt; \n  select_best(\"rmse\")\n\nmelhor_ridge &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"formula_ridge\") |&gt; \n  select_best(\"rmse\")\n\nmelhor_lasso &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"formula_lasso\") |&gt; \n  select_best(\"rmse\")\n\nmelhor_elastic &lt;- \n  tunagem |&gt; \n  extract_workflow_set_result(\"formula_elastic\") |&gt; \n  select_best(\"rmse\")\n\nfinalizando_eqm &lt;- \n  tunagem |&gt; \n  extract_workflow(\"formula_eqm\") |&gt; \n  finalize_workflow(melhor_eqm) |&gt; \n  last_fit(split = hod_out)\n\nfinalizando_ridge &lt;- \n  tunagem |&gt; \n  extract_workflow(\"formula_ridge\") |&gt; \n  finalize_workflow(melhor_ridge) |&gt; \n  last_fit(split = hod_out)\n\nfinalizando_lasso &lt;- \n  tunagem |&gt; \n  extract_workflow(\"formula_lasso\") |&gt; \n  finalize_workflow(melhor_lasso) |&gt; \n  last_fit(split = hod_out)\n\nfinalizando_elastic &lt;- \n  tunagem |&gt; \n  extract_workflow(\"formula_elastic\") |&gt; \n  finalize_workflow(melhor_elastic) |&gt; \n  last_fit(split = hod_out)\n\n# Visualizando as m√©tricas\nfinalizando_eqm |&gt; collect_metrics()\nfinalizando_ridge |&gt; collect_metrics()\nfinalizando_lasso |&gt; collect_metrics()\nfinalizando_elastic |&gt; collect_metrics()\n\n# Visualizando predi√ß√µes:\nfinalizando_eqm |&gt; collect_predictions()\nfinalizando_ridge |&gt; collect_predictions()\nfinalizando_lasso |&gt; collect_predictions()\nfinalizando_elastic |&gt; collect_predictions()"
  },
  {
    "objectID": "index.html#exerc√≠cios-2",
    "href": "index.html#exerc√≠cios-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Exerc√≠cios",
    "text": "Exerc√≠cios\n Exerc√≠cio: Utilizando os dados de vinho vermelhoüç∑, dispon√≠veis aqui, fa√ßa uma pequena an√°lise explorat√≥ria dos dados. No link do Kaggle voc√™ consegue uma explica√ß√£o sobre o que significa cada uma das vari√°veis."
  },
  {
    "objectID": "index.html#exerc√≠cios-3",
    "href": "index.html#exerc√≠cios-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Exerc√≠cios",
    "text": "Exerc√≠cios\n\nExerc√≠cio: Utilizando os dados de vinho vermelhoüç∑, dispon√≠veis aqui, obtenha o melhor modelo de regress√£o linar para modelar a qualidade do vinho, considerando:\n\n\ng_1 - M√©todo dos m√≠nimos quadrados;\ng_2 - Regress√£o ridge;\ng_3 - Regressao lasso;\ng_4 - Elastic Net.\n\n\nVoc√™ dever√° selecionar o melhor modelo de cada uma das classes de modelos de regress√£o e construir uma tabela com o risco estimado \\widehat{R}(g_i),\\,\\, i = 1, \\cdots, 4, em que aqui g_i representa o modelo geral n√£o estimado. Ao fim, construa quatro gr√°ficos mostrando o ajuste de cada um dos modelos.\n\nExerc√≠cio: Se voc√™ utilizou o tidymodels para resolver o exerc√≠cio anterior, rafa√ßa usando a biblioteca glmnet. Caso contr√°rio, resolva-o utilizando o tidymodels."
  },
  {
    "objectID": "index.html#exerc√≠cios-4",
    "href": "index.html#exerc√≠cios-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Exerc√≠cios",
    "text": "Exerc√≠cios\n\nExerc√≠cio: Considere agora o conjunto de dados de despesas m√©dicas, dispon√≠vel aqui, refa√ßa o mesmo exerc√≠cio dos dados de vinho vermelho, em que aqui, o objetivo √© prever a vari√°vel charges. Perceba que algumas vari√°veis s√£o qualitativas, e port√£o, voc√™ dever√° transform√°-las em dummy. Indique os melhores cen√°rios dos quatro modelos e informe qual modelo voc√™ utilizaria. Explique!"
  },
  {
    "objectID": "index.html#m√©todos-n√£o-param√©tricos",
    "href": "index.html#m√©todos-n√£o-param√©tricos",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√©todos n√£o-param√©tricos",
    "text": "M√©todos n√£o-param√©tricos\n\nM√©todos param√©tricos podem impor muitas limita√ß√µes na solu√ß√£o de um problema de regress√£o, i.e., em problemas que desejamos estimar a fun√ß√£o de regress√£o r({\\bf x}). Por exemplo, nem sempre o melhor estimador linear √© um bom estimador para r({\\bf x}).\n\nM√©todos param√©tricos s√£o muitas vezes simplistas e restritivos, em que normalmente abrimos m√£os para se ter um estimador um pouco mais viesado, em detrimento da diminui√ß√£o da vari√¢ncia do modelo. Por exemplo, nas regress√µes penalizadas que vimos anteriormente (ridge, lasso e elastic-net), penalizamos modelos com muitas covari√°veis o que naturalmente aumentar√° o vi√©s, na maioria das vezes."
  },
  {
    "objectID": "index.html#m√©todos-n√£o-param√©tricos-1",
    "href": "index.html#m√©todos-n√£o-param√©tricos-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√©todos n√£o-param√©tricos",
    "text": "M√©todos n√£o-param√©tricos\n\nEm situa√ß√µes em que temos muitos dados (n grande), os modelos n√£o-param√©tricos possuem, em geral, boa peformance, uma vez que apesar de que nessa classe de modelos existir um aumento da vari√¢ncia, por√©m, seguida de uma redu√ß√£o de vi√©s, a vari√¢ncia do modelo n√£o aumenta muito.\n\nDe um lado, nos modelos de regress√£o que vimos at√© o momento, introduzimos uma penaliza√ß√£o para diminuir a vari√¢ncia do modelo frente ao m√©todo dos m√≠nimos quadrados (quando n√£o usamos penaliza√ß√£o) em troca de um aumento no v√≠es. Aqui, em modelos n√£o param√©tricos, desejamos fazer a troca oposta, i.e., diminuir o vi√©s, em troca de um ganho na vari√¢ncia no modelo.\n\nQualquer abordagem param√©trica tr√°s consigo a possibilidade de que a forma funcional g para estimar f seja muito diferente da verdadeira, claro, se o modelo resultante n√£o se ajustar bem aos dados, isto √© \\widehat{g} n√£o tem boa capacidade preditiva, muito embora, tamb√©m √© poss√≠vel que tenhamos \\widehat{g} com boa capacidade preditiva, por√©m, n√£o represente a estrutura real de f (sempre desconhecida)."
  },
  {
    "objectID": "index.html#m√©todos-n√£o-param√©tricos-2",
    "href": "index.html#m√©todos-n√£o-param√©tricos-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "M√©todos n√£o-param√©tricos",
    "text": "M√©todos n√£o-param√©tricos\n \nIsso n√£o √© regra, por√©m ajuda a entender um pouco o dilema entre essas classes de modelos (param√©tricos e n√£o-param√©tricos)."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nTamb√©m chamado de k-nearest neighbours - KNN, o KNN √© um dos m√©todos mais populares na comunidade de aprendizagem de m√°quina. O m√©todo foi formulado em uma sequ√™ncia de dois artigos:\n\n1 - Benedetti, J. K. (1977). On the nonparametric estimation of regression functions. Journal of the Royal Statistical Society. Series B (Methodological), 248‚Äì253;\n\n2 - Stone, C. J. (1977). Consistent nonparametric regression. The Annals of Statistics, 595‚Äì 620.\n\nA ideia do m√©todo √© estimar a fun√ß√£o de regress√£o r({\\bf x}), para um dado {\\bf x} com base nas respostas Y dos k-vizinhos mais pr√≥ximos de {\\bf x}."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-1",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nFormalmente, temos que\ng({\\bf x^*}) = \\frac{1}{k}\\sum_{i \\in \\mathcal{N}_{\\bf x^*}}y_i, em que \\mathcal{N}_{\\bf x} √© o conjunto √≠ndices das k observa√ß√µes mais pr√≥ximas de {\\bf x}, i.e,\n\\mathcal{N}_{\\bf x^*} = \\{i \\in \\{1, \\cdots, n\\}\\, : \\, d({\\bf x}_i, {\\bf x^*}) \\leq d_{\\bf x^*}^k\\}, em que d_{\\bf x^*}^k √© a dist√¢ncia do k-√©simo vizinho mais pr√≥ximo de \\bf{x^*} em \\bf{x}. Portanto, o valor da regress√£o no ponto {\\bf x^*}, i.e., o valor de r({\\bf x^*}) = \\mathbb{E}(Y|{\\bf X} = {\\bf x^*}) √© estimado pela m√©dia de Y_{N_{\\bf x^*}}. Ou seja, estimamos por:\n\\overline{Y}_{N_{\\bf x^*}} = \\frac{1}{k} \\sum_{i \\in \\mathcal{N}_{\\bf x^*}}y_i."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-2",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n  Para determinar d_{\\bf x^*}^k, poderemos utilizar alguma m√©trica de dist√¢ncia e assim mensurarmos a proximidade. Entre elas:\n\n\nDist√¢ncia Euclidiana ou dist√¢ncia L_2: d(x^a, x^b) = \\sqrt{(x_1^a - x_1^b)^2 + \\cdots + (x_d^a - x_d^b)^2};\n\n\n\nDist√¢ncia de Manhattan, City Block ou dist√¢ncia L_1: d(x^a, x^b) = \\sqrt{|x_1^a - x_1^b| + \\cdots + |x_d^a - x_d^b|};\n\n\n\nDist√¢ncia de Mahalanobis: d(x^a, x^b) = \\sqrt{(x^a - x^b)^{T}S^{-1}(x^a - x^b)}, em que S √© a matriz de covari√¢ncia, em que na diagonal princial temos as vari√¢ncias e fora dela as covari√¢ncias entre os pontos. Lembre-se que se x e y s√£o vetores de dados quaisquer, a interdepend√™ncia linear entre eles poder√° ser estimada como:\n\n\n\\mathrm{cov}(x, y) = \\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\overline{x})(y_i - \\overline{y})."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-3",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nVoc√™ poder√° utilizar qualquer outra medida de dist√¢ncia al√©m das que foram citadas acima.\n\n√â importante perceber que o m√©todo KNN n√£o faz uma ‚Äúcompress√£o‚Äù dos dados como a regress√£o linear que estudamos. L√°, temos uma equa√ß√£o que utilizamos para estimar o valor de Y, ap√≥s as estima√ß√£o dos coeficientes do modelo de regress√£o, ou seja, n√£o precisamos mais dos dados para estimar novas observa√ß√µes. J√° no KNN, precisamos sempre nos recorrer aos dados para fazer novas predi√ß√µes, ou seja, sempre que desejarmos calcular r({\\bf x}) = \\mathbb{E}(Y|{\\bf X} = {\\bf x}) deveremos sempre fazer uma nova consulta aos dados para calcular a m√©dia dos vizinhos mais pr√≥ximos. O KNN n√£o possui coeficientes para interpretar. Diferentemente da regress√£o linear, o KNN √© um pouco mais ‚Äúblack box‚Äù."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-4",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n O valor da constante k √© um hiperpar√¢metro do KNN e dever√° ser obtido por valida√ß√£o cruzada. Perceba que se k = n temos um modelo muito viesado, por√©m com vari√¢ncia pequena. Isso, porqu√™ para k = n basicamente iremos tirar uma m√©dia dos dados. Para k = 1, teremos um overfitting, uma vez que o estimador ir√° interpolar os dados.\n Exemplo: Considere novamente o conjunto de dados de expectativa de vida versus PIB per Capita dispon√≠veis aqui. Utilizando o tidymodels, vamos construir uma fu√ß√£o que retorne um gr√°fico com as estimativas do KNN. A fun√ß√£o receber√° como argumentos o conjunto de dados e o valor de k. Voc√™ tamb√©m poderia utilizar outras bibliotecas, como por exemplo a FNN, ou a KKNN, esta √∫tlima √© a que √© utilizada internamente na biblioteca parsnip do tidymodels."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-5",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nAbrindo apenas um par√™ntese, o tidymodels refere-se a um conjunto de pacotes que s√£o √∫teis para o tratamento, treinamento, tunagem e avalia√ß√£o de modelos de aprendizagem de m√°quina, em que o parsnip implementa as engines (algoritmos/motores) que iremos utilizar para treinar um modelo. Na verdade, os algoritmos est√£o implementados em pacotes de terceiros e n√£o precisamente no parsnip. Por√©m, o parsnip unifica a sintaxe de diversos algoritmos implementados em pacotes separados."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-6",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nObserve que na imagem abaixo, a Figura A, quando k=1, percebemos initidamente que houve overfitting, i.e., h√° uma interpola√ß√£o dos dados. J√° na Figura D temos um modelo com vari√¢ncia menor, por√©m, este √© muito simplista, o que sugere um alto vi√©s."
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-7",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nEstude o c√≥digo! Ele fornece a solu√ß√£o para o exemplo.\n\n\n\nSolu√ß√£o pelo m√©todo knn do exemplo anterior\nlibrary(tidymodels)\nlibrary(glue)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\ntidymodels::tidymodels_prefer()\n\n# Lendo dados\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados &lt;- \n  dados_expectativa_renda |&gt; \n  dplyr::select(-CountryName) |&gt; \n  dplyr::rename(y = LifeExpectancy, x = GDPercapita)\n\nknn_exp_pip &lt;- function(dados, k = 1L){\n  # Criando receita\n  receita &lt;- recipe(y ~ x, data = dados)\n  \n  # Definindo o modelo\n  modelo_knn &lt;- nearest_neighbor(neighbors = k) |&gt; \n    set_mode(\"regression\") |&gt; \n    set_engine(\"kknn\")\n  \n  # Workflow\n  ajuste_final &lt;- \n    workflow() |&gt; \n    add_model(modelo_knn) |&gt; \n    add_recipe(receita) |&gt; \n    fit(data = dados)\n  \n  # Retornando previsoes\n  y_chapeu &lt;- predict(ajuste_final, new_data = dados)\n  \n  dados &lt;- \n    dados |&gt; \n    mutate(y_chapeu = y_chapeu$.pred)\n  \n  dados |&gt; \n    ggplot() +\n    geom_point(aes(x = x, y = y), size = 3) +\n    geom_line(aes(x = x, y = y_chapeu), col = \"red\", alpha = 0.6, size = 2) +\n    labs(title = \"k-nearest neighbours\", subtitle = glue(\"k = {k}\")) +\n    theme(\n      title = element_text(face = \"bold\")\n    )\n}\n\np1 &lt;- knn_exp_pip(dados, k = 1L)\np2 &lt;- knn_exp_pip(dados, k = 7L)\np3 &lt;- knn_exp_pip(dados, k = 10L)\np4 &lt;- knn_exp_pip(dados, k = 200L)\n\np &lt;- p1 + p2 + p3 + p4 + plot_annotation(tag_levels = \"A\")\n\nggsave(p, file = \"imgs/knn_plot.png\", width = 50, height = 30, units = \"cm\")"
  },
  {
    "objectID": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-8",
    "href": "index.html#k-vizinhos-mais-pr√≥ximo-pr√≥ximos-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "k-vizinhos mais pr√≥ximo pr√≥ximos",
    "text": "k-vizinhos mais pr√≥ximo pr√≥ximos\n\nAlgumas limita√ß√µes do KNN s√£o:\n\n\n√â totalmente dependente do conjunto de dados para fazer novas predi√ß√µes;\nPara novas observa√ß√µes que s√£o fora dos limites dos dados de treinamento, as predi√ß√µes do KNN tendem a serem imprecisas;\nPode ser custoso para uma grande base de dados;\nO c√°lculo de dist√¢ncias pode sofrer com a chamada ‚Äúmaldi√ß√£o da dimensionalidade‚Äù, em que a depender da m√©trica de dist√¢ncia utilizada, tudo fica muito distante.\n\n\nAlgumas vantagens s√£o:\n\n\n√â um m√©todo simples de ser implementado;\n√â muito utilizado para imputa√ß√£o de observa√ß√µes faltantes;\n√â comumente utilizado, por conta de sua simplicidade, em explora√ß√µes iniciais."
  },
  {
    "objectID": "index.html#nadaraya-watson",
    "href": "index.html#nadaraya-watson",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nUma varia√ß√£o do m√©todo KNN que √© bastante difundida na comunidade estat√≠stica √© o m√©todo de Nadaraya-Watson, propostos nos artigos:\n\n\nNadaraya, E. A. (1964). On estimating regression. Theory of Probability & Its Applications, 9(1), 141‚Äì142;\nWatson, G. S. (1964). Smooth regression analysis. Sankhya: The Indian Journal of Statistics, Series A, 359‚Äì372.\n\n\nEsse m√©todo tamb√©m √© chamado de estimador k-vizinhos ponderados (KNN ponderado), uma vez que a estima√ß√£o da fun√ß√£o de regress√£o em um dado ponto {\\bf x} utiliza de m√©dias ponderadas das observa√ß√µes do conjunto de treinamento:\ng({\\bf x}) = \\sum_{i = 1}^n w_i({\\bf x})y_i, em que w_i({\\bf x}) √© o peso atribu√≠do √† i-√©sima observa√ß√£o, medindo a similaridade de {\\bf x}_i √† {\\bf x}."
  },
  {
    "objectID": "index.html#nadaraya-watson-1",
    "href": "index.html#nadaraya-watson-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nTemos que w_i({\\bf x}) √© definido por:\nw_i({\\bf x}) = \\frac{K({\\bf x}, {\\bf x}_i)}{\\sum_{j = 1}^n K({\\bf x}, {\\bf x}_j)}, em que K({\\bf x}, {\\bf x}_j) √© um kernel de suaviza√ß√£o usado para medir a similaridade entre as observa√ß√µes. Escolhas que s√£o populares para K({\\bf x}, {\\bf x}_j), s√£o:\n\n\nKernel uniforme: K({\\bf x}, {\\bf x}_i) = \\mathbb{I}(d({\\bf x}, {\\bf x}_i) \\leq h);\nKernel gaussiano: K({\\bf x}, {\\bf x}_i) = (\\sqrt{2\\pi h^2})^{-1}\\exp\\left\\{ -\\frac{d^2({\\bf x}, {\\bf x}_i)}{2h^2}\\right\\};\nKernel triangular: K({\\bf x}, {\\bf x}_i) = (1 - d({\\bf x}, {\\bf x}_i)/h)\\mathbb{I}(d({\\bf x}, {\\bf x}_i) \\leq h);\nKernel de Epanechnikov: K({\\bf x}, {\\bf x}_i) = (1 - d^2({\\bf x}, {\\bf x}_i)/h^2)\\mathbb{I}(d({\\bf x}, {\\bf x}_i) \\leq h)."
  },
  {
    "objectID": "index.html#nadaraya-watson-2",
    "href": "index.html#nadaraya-watson-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nEnquanto no kernel uniforme, os pesos s√£o iguais para as observa√ß√µes a uma dist√¢ncia menor que h de {\\bf x} e atribui peso zero para observa√ß√µes maiores que h, os kernels triangular e de Epanechnikov atribui pesos maiores para observa√ß√µes mais pr√≥ximas de {\\bf x}. A quantidade h √© um tuning parameter, e na pr√°tica, deve ser estimada por um procedimento de valida√ß√£o cruzada.\n\nAlgumas propriedades de uma fun√ß√£o kernel s√£o:\n\n\nSimetria: K(x,y) = K(y,x), permitindo que a fun√ß√£o de similaridade seja invariante em rela√ß√£o a ordem dos argumentos;\nPositiva definida: Para qualquer vetor c, em que seja poss√≠vel fazer c^{T}K(x,y), temos que c^{T}K(x,y)c &gt; 0.\n\n\nVoc√™ poder√° encontrar outras fun√ß√µes kernel aqui."
  },
  {
    "objectID": "index.html#nadaraya-watson-3",
    "href": "index.html#nadaraya-watson-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nExemplo: Novamente, considerando o conjunto de dados de expectativa de vida versus PIB per Capita dispon√≠veis aqui. Utilizando o tidymodels, vamos construir uma fu√ß√£o que retorne um gr√°fico com as estimativas. A fun√ß√£o receber√° como argumentos o conjunto de dados e o valor de h. Observe a documenta√ß√£o da fun√ß√£o nearest_neighbor do pacote parsnip. Perceba que o argumento weight_func permite que possamos escolher entre algumas fun√ß√µes kernel. Por√©m, como m√©trica de dist√¢ncias, apenas poderemos utilizar a de Minkowski. Seja x = (x_1, \\cdots, x_n) e y = (y_1, \\cdots, y_n), ambos vetores do \\mathbb{R}^n. Ent√£o, a dist√¢ncia de Minkowski √© dada por:\nd(x,y) = \\left(\\sum_{i = 1}^n |x_i - y_i|^p\\right)^{\\frac{1}{p}}, com p \\geq 1. Note que se p = 1 temos a dist√¢ncia euclidiana (dist√¢ncia L_1) e se p = 2 teremos a distancia de Manhattan (dist√¢ncia L_2)."
  },
  {
    "objectID": "index.html#nadaraya-watson-4",
    "href": "index.html#nadaraya-watson-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\nPortanto, com o argumento dist_power da fun√ß√£o nearest_neighbor, do pacote parsnip, voc√™ poder√° especificar o valor de p, que inclusive poder√° ser um hiperpar√¢metro, podendo ser obtido por meio de uma valida√ß√£o cruzada.\n\n\n\nNo exemplo n√£o iremos fazer a valida√ß√£o cruzada, pois apenas queremos implementar uma fun√ß√£o em que seja poss√≠vel experimentar o m√©todo para diferentes valores de h e diferentes fun√ß√µes de kernel."
  },
  {
    "objectID": "index.html#nadaraya-watson-5",
    "href": "index.html#nadaraya-watson-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n A imagem abaixo utiliza o kernel gaussiano:"
  },
  {
    "objectID": "index.html#nadaraya-watson-6",
    "href": "index.html#nadaraya-watson-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Nadaraya-Watson",
    "text": "Nadaraya-Watson\n\n\n\nSolu√ß√£o do exempƒ∫o de Nadaraya-Watson\nlibrary(tidymodels)\nlibrary(glue)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\ntidymodels::tidymodels_prefer()\n\n\n# Lendo dados\nurl &lt;- \"https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData\"\narquivo_temp &lt;- tempfile()\ndownload.file(url = url, destfile = arquivo_temp)\nload(arquivo_temp)\n\ndados &lt;- \n  dados_expectativa_renda |&gt; \n  dplyr::select(-CountryName) |&gt; \n  dplyr::rename(y = LifeExpectancy, x = GDPercapita)\n\nnadaraya_watson_exp_pip &lt;- function(dados, h = 1, ...){\n  # Criando receita\n  receita &lt;- \n    recipe(y ~ x, data = dados) |&gt; \n    step_normalize()\n  \n  # Definindo o modelo\n  modelo_knn &lt;- nearest_neighbor(dist_power = h, ...) |&gt; \n    set_mode(\"regression\") |&gt; \n    set_engine(\"kknn\")\n  \n  # Workflow\n  ajuste_final &lt;- \n    workflow() |&gt; \n    add_model(modelo_knn) |&gt; \n    add_recipe(receita) |&gt; \n    fit(data = dados)\n  \n  # Retornando previsoes\n  y_chapeu &lt;- predict(ajuste_final, new_data = dados)\n  \n  dados &lt;- \n    dados |&gt; \n    mutate(y_chapeu = y_chapeu$.pred)\n  \n  dados |&gt; \n    ggplot() +\n    geom_point(aes(x = x, y = y), size = 3) +\n    geom_line(aes(x = x, y = y_chapeu), col = \"red\", alpha = 0.6, size = 2) +\n    labs(title = \"Nadaraya-Watson\", subtitle = glue(\"h = {h}\")) +\n    theme(\n      title = element_text(face = \"bold\")\n    )\n}\n\np1 &lt;- nadaraya_watson_exp_pip(dados, h = 1, weight_func = \"gaussian\")\np2 &lt;- nadaraya_watson_exp_pip(dados, h = 1000, weight_func = \"gaussian\")\n\np &lt;- p1 + p2 + plot_annotation(tag_levels = \"A\")\n\nggsave(p, file = \"imgs/nadaraya_watson.png\", width = 30, height = 15, units = \"cm\")\n\n\n\n\n\n\n\nDepartamento de Estat√≠stica da UFPB"
  },
  {
    "objectID": "index.html#tidymodels",
    "href": "index.html#tidymodels",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels",
    "text": "Tidymodels\n\nDiversas bibliotecas na linguagem R s√£o preparadas para trabalharem na √°rea de aprendizagem de m√°quina. V√°rias dessas bibliotecas vem sendo desenvolvidas h√° anos. Por exemplo,as bibliotecas glmnet, ranger, kknn, xgboost, keras, rpart, randomForest, entre diversos outros.\n\n\n\nO n√∫mero de pacotes abaixo √© o mais recente. Obtido automaticamente por webscraping.\nlibrary(xml2)\nlibrary(httr)\nlibrary(stringr)\n\nnumero_pacotes_r &lt;- httr::GET(\"https://cloud.r-project.org/web/packages/index.html\") |&gt; \n  xml2::read_html() |&gt; \n  xml2::xml_find_all(\"//p[1]\") |&gt; \n  xml2::xml_text() |&gt; \n  stringr::str_extract(pattern = \"[0-9]+\")\n\n\n\nAtualmente, a linguagem R possui 19835, em que muitos deles s√£o preparados para para trabalharem em tarefas de aprendizagem de m√°quina, por√©m, cada com sua sintaxe espec√≠fica. Muitos implementam o mesmo modelo, uns com algumas varia√ß√µes, por√©m, o uso √© totalmente diferente, nomes de par√¢metros distintos, sa√≠das distintas, etc."
  },
  {
    "objectID": "index.html#tidymodels-1",
    "href": "index.html#tidymodels-1",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels",
    "text": "Tidymodels\n\nEssas diferentes implementa√ß√µes torna confuso trabalhar e testar diferentes modelos ao mesmo tempo.\n\n\n\nUma das primeiras ideias mais conhecidas de unifica√ß√£o de sintaxe do workflow de machine learning, na linguagem R, foi idealizada pelo estat√≠stico Max Khun.\n\nEle criou a biblioteca caret - Classification And REgression Training de R que √© muito bem desenvolvida e abrangente. Voc√™ poder√° estudar o caret clicando aqui.\n\nN√£o foi um trabalho simples, veja uma tabela com a quantidade de modelos que o caret suporta, clicando aqui. Ent√£o, ‚Äúpor baixo dos panos‚Äù, a ideia era unificar a entrada e sa√≠da. A biblioteca caret continua sendo mantida, apesar da exist√™ncia do tidymodels."
  },
  {
    "objectID": "index.html#tidymodels-2",
    "href": "index.html#tidymodels-2",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels",
    "text": "Tidymodels\n\n\n\n\n\n\n\n\n\nMax Kuhn, atualmente, no momento de escrita desse frame √© funcion√°rio da Posit Ltda e foi contratado para estar a frente do desenvolvimento de uma vers√£o ‚Äúarrumada‚Äù (tidy) do caret, que √© o tidymodels."
  },
  {
    "objectID": "index.html#tidymodels-3",
    "href": "index.html#tidymodels-3",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels",
    "text": "Tidymodels\n\n\nO workflow (pipeline) do treinamento de um modelo usando o framework tidymodels. Todos os pacotes (rsample, recipes, parsnip, tune, dails, yardstick) s√£o gerenciados pelo pacote tidymodels. Cada um desses pacotes fornece um conjunto de fun√ß√µes √∫teis em tarefas espec√≠ficas no workflow de machine learning."
  },
  {
    "objectID": "index.html#tidymodels-4",
    "href": "index.html#tidymodels-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels",
    "text": "Tidymodels\n\n\nrsample: respons√°vel pela reamostragem dos dados, parte importante para que possamos treinar um modelo de aprendizagem de m√°quina. √â nele que encontra-se fun√ß√µes para realizar reamostragem como bootstrap, k-folds cross-validation, nested cross-validation, entre outras.\n\n\n\n\n\n\n\nrecipes: apresenta diversas fun√ß√µes para transforma√ß√µes de vari√°veis como cria√ß√£o de vari√°veis dummy, normaliza√ß√£o de vari√°veis, inputa√ß√£o de dados pela m√©dia, mediana, knn, entre outras formas de imputa√ß√£o, transforma√ß√µes de vari√°veis categ√≥rias em num√©ricas, entre outras funcionalidades. Ele permite que possamos criar uma receita de transforma√ß√µes nos dados para que esses, ap√≥s transformados, possam entrar no modelo.\n\n\n\n\n\n\n\nparsnip: √© o pacote que unifica as entradas e sa√≠das de diversos pacotes de aprendizagem de m√°quina de R. Ele possui os motores (engines) que s√£o as comunica√ß√µes com os algoritmos implementados em diversos pacotes de R que trabalham com tarefas de regress√£o e classifica√ß√£o, em aprendizagem de m√°quina."
  },
  {
    "objectID": "index.html#tidymodels-5",
    "href": "index.html#tidymodels-5",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels",
    "text": "Tidymodels\n\n\n\nOs pacotes tune, dails e yardstick tomar√° conta da parte de treino do modelo. Os pacote tune e dails s√£o respons√°veis pela ‚Äútunagem‚Äù dos eventuais hiperpar√¢metros e o yardstick √© mais respons√°vel pelas m√©tricas de avalia√ß√£o do modelo.\n\nA biblioteca dails est√° mais relacionada a cria√ß√£o dos grids para os hiperpar√¢metros eventuais do modelo. J√° o pacote tune, utiliza-se da valida√ß√£o cruzada criada pelo pacote rsample para varrer as combina√ß√µes de hiperpar√¢metros criadas pelo dails, i.e., o tune est√° mais relacionado com a otimiza√ß√£o dos hiperpar√¢metros."
  },
  {
    "objectID": "index.html#tidymodels-6",
    "href": "index.html#tidymodels-6",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels",
    "text": "Tidymodels\n\nTodo o fluxo de trabalho √© gerido pela biblioteca workflows de R."
  },
  {
    "objectID": "index.html#tidymodels-7",
    "href": "index.html#tidymodels-7",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels",
    "text": "Tidymodels\n\n\nPerceba o papel da biblioteca workflows de R. Basicamente gostar√≠amos de ter uma automa√ß√£o da faze do tratamento das features realizada com o recipes com a modelagem."
  },
  {
    "objectID": "index.html#tidymodels-8",
    "href": "index.html#tidymodels-8",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Tidymodels",
    "text": "Tidymodels\n\nN√£o necessariamente iremos utilizar o tidymodels em todos os exemplos e exerc√≠cios. Por√©m, iremos explorar bastante, at√© o fim do curso, o treinamento de modelos usando o tidymodels. Por tanto, aos poucos, a medida em que exemplos s√£o apresentados e exerc√≠cios forem passados, o aprendizado do uso do tidymodels se dar√°.\n\n \n\nSempre que poss√≠vel, deveremos colocar as ‚Äúm√£os na massa‚Äù üçù para que possamos dominar e compreender uma ferramenta computacional. A pr√°tica √© importante!"
  },
  {
    "objectID": "index.html#dados-explora√ß√£o-e-tratamento-10",
    "href": "index.html#dados-explora√ß√£o-e-tratamento-10",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": " Dados: explora√ß√£o e tratamento",
    "text": "Dados: explora√ß√£o e tratamento\n\nAnteriormente eu citei algumas bibliotecas √∫teis de R para explorar os dados, na fase de tratamento das observa√ß√µes. Por√©m, n√£o estranhe n√£o ter, at√© o momento, citado bibliotecas do framework tidymodels, em especial o recipes que √© muito utilizado no workflow de aprendizagem de m√°quina na fase de pr√©-processamento dos dados. Muitas dessas transforma√ß√µes s√£o aplicadas como receitas de pr√©-processamento com o pacote recipes.\n\nO tidymodels ser√° muito √∫til para n√≥s, mas, aos poucos, seu uso e explica√ß√µes mais detalhadas ser√£o apresentadas, apesar que em algumas situa√ß√µes mais simples, poderei n√£o utiliz√°-lo, para expor detalhes que eventualmente n√£o ser√° poss√≠vel ou estariam camuflados na utiliza√ß√£o do tidymodels."
  },
  {
    "objectID": "index.html#as-duas-culturas-4",
    "href": "index.html#as-duas-culturas-4",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "As duas culturas",
    "text": "As duas culturas\n\n\n\nLeo Breiman, renomado estat√≠stico, contribuiu significativamente para o campo de aprendizagem de m√°quina. Ele √© conhecido por ter criado m√©todos populares e influentes para a √°rea. Entre tais m√©todos famosos, cito dois:\n\n\nRandom forest (florestas aleat√≥rias): m√©todo que combina a previs√£o de v√°rios modelos de √°rvores de decis√£o (decision tree), que veremos mais a frente, por isso o termo ‚Äúfloresta‚Äù para problemas de regress√£o e classifica√ß√£o;\nBootstrap aggregating (bagging): t√©cnica de aprendizagem ensemble, em que cria-se multiplos conjuntos de dados obtidos com reposi√ß√£o da amostra de treinamento. O modelo de aprendizagem de m√°quina √© treinado em cada conjunto de dados e as previs√µes de cada um dos modelos s√£o combinadas por meio da m√©dia (em problemas de regress√£o), ou por voto majorit√°rio, em problemas de classifica√ß√£o. O bagging √© utilizado para reduzir a vari√¢ncia e melhorar a estabilidade do modelo."
  },
  {
    "objectID": "index.html#leia-mais-sobre-regress√£o-linear",
    "href": "index.html#leia-mais-sobre-regress√£o-linear",
    "title": "Machine Learning / Aprendizagem de M√°quina",
    "section": "Leia mais sobre regress√£o linear",
    "text": "Leia mais sobre regress√£o linear\n\nCaso voc√™ deseje ler um pouco mais sobre regress√£o linear sob homocedasticidade e sob heteroscedasticidades, leia o segundo Cap√≠tulo de minha disserta√ß√£o de mestrado intitulada Estimadores Intervalares sob Heteroscedasticidade de Forma Desconhecida via Bootstrap Duplo. Apesar do t√≠tulo, o segundo cap√≠tulo √© uma revis√£o do conceito de regress√£o linear √© apresentado de forma did√°tica. Clique aqui para ler."
  }
]