---
title: "Machine Learning / Aprendizagem de M√°quina"
author: "Prof. Dr. Pedro Rafael D. Marinho<br>Departamento de Estat√≠stica - UFPB<br>"
date: '`r Sys.Date()`'
format: 
  revealjs:
    theme: [default, style.scss]
    width: 1920
    height: 1080
    logo: "https://www.ufpb.br/de/contents/imagens/logode.png"
    footer: '<a href="https://www.ufpb.br/de">Departamento de Estat√≠stica da UFPB</a>'
    transition: slide
    background-transition: fade
    preview-links: auto
    slide-number: true
    chalkboard: true
    scrollable: true
    controls: true
    incremental: true  
    code-tools: true
    auto-stretch: true
    code-link: true
    html-math-method: katex
  pdf: 
    include-in-header:  
      - text: |
            \usepackage{amsfonts}
            \usepackage{amsmath}
revealjs-plugins:
  - pointer
  - attribution
  - roughnotation
filters:
   - roughnotation
execute:
  refresh: true
  warning: false
  error: false
  eval: true
  echo: true
editor: 
  markdown: 
    wrap: 72
lang: pt
---

<!-- ```{r} -->

<!-- #| echo: false -->

<!-- #| warning: false -->

<!-- #| eval: true -->

<!-- if(fs::dir_exists("index_files/")) -->

<!--   fs::dir_delete("index_files/") -->

<!-- ``` -->

::: r-fit-text
Aprendizagem de M√°quina

[Bacharelado em Estat√≠stica]{.flow}

UFPB
:::

#  {.title}

::: r-fit-text
[Apresenta√ß√£o]{.flow}
:::

##  {background-image="https://raw.githubusercontent.com/prdm0/imagens/main/eu.jpg" background-size="contain" background-position="left"}

::: columns
::: {.column width="40%"}
:::

::: {.column width="60%"}
## Sobre mim {.r-fit-text}

<br> <br>

-   Me chamo [Prof. Dr. Pedro Rafael D.
    Marinho](https://prdm.netlify.app/about_pt_br.html){preview-link="true"}.
    Meu curr√≠culo Lattes poder√° ser acessado clicando
    [aqui](http://lattes.cnpq.br/7185368598935272){preview-link="true"}.

-   Sou docente do Departamento de Estat√≠stica da UFPB. üë®‚Äçüè´

-   Toda minha forma√ß√£o acad√™mica √© na √°rea de estat√≠stica (bacharelado
    ao doutorado).

-   Tenho entusiasmo por programa√ß√£o, ci√™ncia de dados e aprendizagem de
    m√°quina üíªüìà.

-   `r fontawesome::fa("github", "black")` Me acompanhe no GitHub:
    <https://github.com/prdm0>.

-   `r fontawesome::fa("linkedin", "black")` Me acompanhe no Linkedin:
    <https://www.linkedin.com/in/prdm0/>.
:::
:::

# O Departamento {.title}

## Meu segundo lar {.r-fit-text background-color="black" background-image="https://raw.githubusercontent.com/prdm0/imagens/main/foto_aerea_ufpb.jpeg" background-size="1600px" background-repeat="repeat" background-opacity="0.35"}

```{r width = 100, height = 100, echo = FALSE, fig.cap="Departamento de Estat√≠stica da UFPB."}
library(leaflet)
leaflet() |>
  addMarkers(-34.846199, -7.140400) |>
  leaflet::addTiles() |>
  setView(
  -34.846199, -7.140400, zoom = 37,
  options = popupOptions(
    minWidth = 1600,
    maxWidth = 1500
  ))
```

## `r fontawesome::fa("laptop-code", "black")` Que linguagem de programa√ß√£o utilizar?

<br>

Nesse curso, ser√° abordado a linguagem de programa√ß√£o
[R](https://www.r-project.org/), mas lembre-se que voc√™ poder√° utilizar
qualquer linguagem de programa√ß√£o para fazer ci√™ncia de dados. Por√©m, R
e Python s√£o as minhas sugest√µes, haja vista que, atualmente, elas s√£o
as linguagens com maior quantidade de ferramentas e usu√°rios trabalhando
na √°rea de [ci√™ncia de
dados](https://en.wikipedia.org/wiki/Data_science).

<br>

[Outros motivos que me leva a lecionar a disciplina utilizando a
linguagem R s√£o:]{.black}

1.  Possui ferramentas muito bem pensadas para manipula√ß√£o e tratamento
    de dados;
2.  Normalmente, os frameworks de machine learning de R s√£o menos
    verbosos que os de Python;
3.  Matrizes e data frames s√£o estruturas de dados que j√° encontra-se
    definidas dentro da linguagem, n√£o precisando assim de importar
    bibliotecas.

Isso √© meu gosto pessoal. √â um gosto que, talvez, faz mais sentido, em
se tratando de algu√©m que vem da estat√≠stica. No mercado de trabalho e
em seus estudos, ap√≥s cursar as disciplinas de R e Python, fornecidas
pelo [Bacharelado em Estat√≠stica da UFPB](https://www.ufpb.br/de), voc√™
ter√° a capacidade de estudar os frameworks de machine learning, aos seus
pr√≥prios passos e escolher o que melhor te agrada. A linguagem
[Julia](https://julialang.org/) tamb√©m poder√° ser uma √≥tima op√ß√£o.

#  {.title}

::: r-fit-text
[Aprendizagem de M√°quina: O que √©?]{.flow}
:::

## `r fontawesome::fa("robot", "black")` Aprendizagem de m√°quina

<br>

![](gifs/am.gif){.fragment width="800" height="600"}

## `r fontawesome::fa("robot", "black")` Aprendizagem de m√°quina

<br> <br>

**Alguns pontos**:

<br>

1.  A **A**prendizagem de **M**√°quina (AM), tamb√©m chamada de
    **M**achine **L**earning (ML), no ingl√™s, nasceu na d√©cada de 60
    como um campo da intelig√™nica artificial.

2.  Em sua origem, as aplica√ß√µes de AM tinha como objetivo aprender
    padr√µes com base nos dados.

3.  Originalmente, as aplica√ß√µes de AM eram de cunho estritamente
    computacional. Todavia, desde o in√≠cio dos anos 90, a √°rea de
    aprendizagem de m√°quina expandiu seus horizontes e come√ßou a se
    estabelecer como um campo por sim mesma.

4.  Em particular, a √°rea de aprendizagem de m√°quina come√ßou a
    estabelecer muitas intersec√ß√µes com a estat√≠stica. Muitos de seus
    algoritmos s√£o constru√≠dos com base em metodologias que surgiram na
    estat√≠stica.

5.  Atualmente, a comunidade de AM √© bastante interdisciplinar e
    utiliza-se de ideias desenvolvidas em diversas √°reas, sendo a
    estat√≠stica uma delas.

## `r fontawesome::fa("robot", "black")` Tipos de Aprendizado

<br>

[Aprendizado supervisionado]{.black}

<br>

Nesse curso, inicialmente estudaremos problemas de [aprendizado
supervisionado]{.red}, que consiste em aprender a fazer predi√ß√µes a
partir de conjunto de dados em que r√≥tulos (valores da vari√°vel resposta
$Y$) s√£o observados. Trataremos tanto de problemas de regress√£o (estimar
um valor n√∫m√©rico) quanto problemas de classifica√ß√£o (classificar um
cliente como aprovado ou reprovado, em um problema de concess√£o de
cr√©dito). Por exemplo, os [modelos de regress√£o]{.red} s√£o exemplos de
aprendizado supervisionado.

<br>

[Aprendizado n√£o supervisionado]{.black}

<br>

Na segunda parte do curso, aprenderemos alguns m√©todos de aprendizado
[n√£o supervisionado]{.red}, ou seja, algoritmos que n√£o utilizam-se de
r√≥tulos, em que busca-se aprender mais sobre a estrutura dos dados. Por
exemplo, os [m√©todos de agrupamento]{.red} (cluster), s√£o exempƒ∫os de
m√©todos de aprendizado n√£o supervisionado.

## `r fontawesome::fa("robot", "black")` Tipos de Aprendizado

<br>

Muito embora no nosso curso focaremos nas abordagens de aprendizagem
**supervisionada** e **n√£o-supervisionada**, os tipos de aprendizagem,
em geral, podem ser mais amplos, em que temos:

<br>

1.  Aprendizagem supervisionada;
2.  Aprendizagem n√£o-supervisionada;
3.  Aprendizagem semi-supervisionada;
4.  Aprendizagem por refor√ßo.

## O que √© aprender?

<br>

Antes de detalharmos os tipos de aprendizagem de m√°quina, uma d√∫vida que
poder√° surgir √©: ["O que √© aprender?"]{.red}. ["Como a m√°quina
aprende?"]{.red}.

<br>

![](gifs/am.gif){.fragment width="900" height="600"}

## O que √© aprender?

<br>

De forma simples, aprender √© ganhar conhecimento atrav√©s de estudo,
experi√™ncias, por meio de ensinamentos.

<br>

T√°, mais como √© que a [m√°quina]{.red} aprende?

<br>

1.  [Aprendizagem]{.red} √© o processo em que se adquire conhecimento,
    isto √©, √© o processo em que utilizamos de algoritmos e fornecemos
    dados a esses algoritmos para que possamos extrair conhecimento.
    Nesse processo de aprendisagem, os algoritmos fazem uso de dados
    para a extress√£o de conhecimento, atrav√©s de procedimentos
    **supervisionado**, **n√£o-supervisionado**, **semi-supervisionado**
    ou **por refor√ßo**, a depender do algoritmo que voc√™ deseja
    utilizar.

<br>

2.  [Aprendizado]{.red} √© o modelo ajustado, isto √©, √© o conhecimento
    adquirido ap√≥s o treinamamento obtido no processo de aprendizagem.
    Voc√™ poder√° entender como sendo o modelo ajustado e que utilizamores
    para a tomada de decis√µes.

## O que √© aprender?

<br>

Portanto, voc√™ poder√° entender, basiciamente, existe quatro tipos de
aprendizagem, sendo os dois primeiros o que mais focaremos nesse curso e
que de loge s√£o os mais utilizados:

<br>

1.  Aprendizagem supervisionada;
2.  Aprendizagem n√£o-supervisionada;
3.  Aprendizagem semi-supervisionada;
4.  Aprendizagem por refor√ßo.

## Aprendizagem supervisionada

<br>

Nesse tipo de aprendizagem, o algoritmo ir√° receber um conjunto de dados
em que conhecemos r√≥tulos para a vari√°vel de interesse. √â como se voc√™
soubesse onde um bom modelo deve chegar, para assim ser reconhecido como
um bom modelo. Por exemplo,

<br>

1.  [Classifica√ß√£o]{.red}: precisamos determinar a classe de uma
    inst√¢ncia de dados, o seu atributo, i.e.,
    $\widehat{y} = \mathrm{argmax}_y\,P(Y = y\,|\, X = \bf{x})$, em que
    y √© um atributo que desejamos prever (cahorro, gato, sapo), e
    $\bf{x}$ √© um vetor de caracter√≠sticas (peso, altura, comprimento,
    se tem rabo, etc).

<br>

2.  [Regress√£o]{.red}: precisamos estimar uma quantidade num√©rica, i.e.,
    o valor da vari√°vel alvo por meio de uma inst√¢ncia de dados, ou
    seja, precisamos estimar $Y = \mathbb{E}(Y\,|\,X = \bf{x})$, i.e.,
    devemos encontrar meios de obter $\widehat{Y}$.

::: aside
**Algumas observa√ß√µes de nomenclaturas**:

1.  √â comum chamar cada exemplo de dados, i.e., o vetor $\bf{x}$ que
    ser√° passado ao modelo de [atributos]{.red} ou [features]{.red};
2.  Tamb√©m √© comum chamarmos de [r√≥tulo]{.red} ou [label]{.red} a classe
    ou valor alvo, ou seja, estas s√£o as formas de nomearmos $Y$, sendo
    $Y$ uma quantidade num√©rica (modelos de regress√£o) ou n√£o (modelos
    de classifica√ß√£o).
:::

## Aprendizagem supervisionada

<br>

Em se tratando de m√©todos de classifica√ß√£o, podemos ter os m√©todos:

<br>

1.  [Generativos]{.red}: s√£o os m√©todos que dada as vari√°veis $X$ e $Y$,
    o objetivo √© encontrar a distribui√ß√£o de probabilidade conjunta
    $P(X, Y)$, para ent√£o poder determinar $P(Y\, | \, X = \bf{x})$.
    Alguns m√©todos s√£o:

    -   Naive Bayes;
    -   Descriminante linear.

<br>

2.  [Descriminativos]{.red}: s√£o os m√©todos que estimam diretamente a
    probabilidade condicional $P(Y \, | \, X = \bf{x})$ ou que mesmo nem
    assumem modelos probabil√≠sticos. Podemos citar:
    -   Regress√£o logistica;
    -   Perceptron;
    -   Support Vector Machine - SVM.

## Aprendizagem supervisionada

<br>

::: columns
::: {.column width="60%"}
![](gifs/classificacao.webp)
:::

::: {.column width="40%"}
<br> Poder√≠amos estar interessados em classificar o tamanho de morangos:

<br>

1.  S (**S**low): pequeno;

2.  M (**M**edium): m√©dio;

3.  L (**L**arge): grande.
:::
:::

## Aprendizagem supervisionada

<br> <br>

![Mais dois problemas de classifica√ß√£o (linear x
n√£o-linear).](gifs/Classification-Examples.gif){.fragment
fig-align="center" width="900"}

## Aprendizagem supervisionada

<br> <br>

![](gifs/regression.gif){.fragment fig-align="center" width="1200"}

Um exemplo de de um problema de regress√£o. Aqui, a ideia √© utilizar a
equa√ß√£o da reta estimada, a reta que minimiza a soma dos quadrados entre
a reta e os ponto seria a melhor, de modo a ter uma estimativa num√©rica
atrav√©s de novos atributos passado ao modelo, i.e., por meio da equa√ß√£o
da reta e de um novo valor de $x$.

## Aprendizagem supervisionada

<br>

Um outro exemplo seria a classifica√ß√£o de imagem/v√≠deo, utilizando um
algoritmo de rede neural, por exemplo, usando uma **C**onvolutional
**N**eural **N**etwork -
[CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network). Foram
utilizados diversas imagens de pessoas "com" e "sem" m√°scara. Em que
"com" representa detec√ß√£o da m√°scara na face da pessoa e "sem" a n√£o
detec√ß√£o.

<br>

{{< video https://www.youtube.com/watch?v=Zt_Fr7YbU1c width="50%" height="50%" >}}

## Aprendizagem n√£o-supervisionada

<br>

Nesse tipo de aprendizagem, os algoritmos trabalham sobre dados n√£o
rotulados, por exemplo, em uma trarefa de agrupamento.

<br>

Os algoritmos verificam se as inst√¢ncias observadas poder√£o ser
arranjadas de alguma maneira, por exemplo, usando alguma m√©trica de
dist√¢ncia, formando grupos (*clusters*).

<br>

A ideia √© maximizar a dist√¢ncia entre os clusters e minimizar a
dist√¢ncia entre os elementos no interrior do grupo. Em outras palavras,
o que se quer √© tornar os grupos mais diferentes poss√≠veis e tornar os
elementos dos grupos o mais parecido poss√≠vel.

<br>

Aqui, por n√£o haver r√≥tulos, um problema comum √© determinar a quantidade
de grupos ideal que muitas vezes s√£o obtidos de forma subjetiva ou por
heur√≠sticas. A quantidade de grupos √© um dilema!

## Aprendizagem n√£o-supervisionada

<br>

![](gifs/kmeans.gif){.fragment fig-align="center" width="900"}

Ap√≥s a detec√ß√£o dos grupos, √© preciso analisar o resultado de modo a
tentar extrair informa√ß√µes coerentes de modo a saber o que cada grupo
representa no problema em quest√£o.

## Aprendizagem semi-supervisionada

<br>

A aprendizagem semi-supervisionada √© uma abordagem na √°rea de
aprendizagem de m√°quina onde um algoritmo utiliza tanto dados rotulados
quanto n√£o rotulados para treinamento. Por exemplo, algoritmos que
propagam r√≥tulos, como o *Label Propagation*, em que r√≥tulos conhecidos
s√£o propagados para dados n√£o rotulados com base em sua sua proximidade
no espa√ßo de caracter√≠sticas.

<br>

Uma outra abordagem seria misturar modelos (*Model Blending*), em que
diferentes modelos s√£o treinados em diferentes partes do conjunto de
dados, por exemplo, um modelo para a parte roturada e um para a parte
n√£o rotulada.

<br>

![](gifs/hum.gif){.fragment width="50%"}

## Aprendizagem por refor√ßo

<br>

Nesse tipo de aprendizagem, n√£o h√° uma fonte externa de exemplos. O
agente (modelo) aprende aprende com sua pr√≥pria experi√™ncia, por
tentativas e erros, em que voc√™ dever√° definir uma medida de sucesso, e
eventualmente recompensar os acertos. No v√≠deo abaixo, veja um joguinho
que criei em R, onde o carrinho aprendeu a desviar de obst√°culos
aleat√≥rios que aparecem em sua frente. Utilizou-se uma rede neural cuja
a sa√≠da poderia ser ("parado", "para cima" ou "para baixo"). Veja o
c√≥digo clicando
[**aqui**](https://github.com/prdm0/desviando_obstaculos).

<br>

{{< video https://www.youtube.com/watch?v=9NXUtwGkkDw&t=2s width="50%" height="50%" >}}

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamentom

<br>

Um dos passos mais importante no fluxo de trabalho (*workflow*) de um
modelo de aprendizagem de m√°quina, consiste na prepara√ß√£o dos dados,
onde realizamos transforma√ß√µes, inputa√ß√µes de valores ausentes,
identifica√ß√£o de outliers, remo√ß√£o de vari√°veis altamente
correlacionadas, entre outros.

<br>

Fazer uma an√°lise explorat√≥ria dos dados √© um passo importante para que
se possa entender e detecatar poss√≠veis inconsist√™ncias na base de
dados. N√£o adianta fazer uso de modelos muito sofisticados quando se tem
uma base de dados cheia de problemas.

<br>

Normalmente trabalhamos com juntos de dados (tabelas) relacionais, em
que cada linha √© uma observa√ß√£o e cada coluna representa um atributo do
objeto/observa√ß√£o. A linha de uma base de dados relacional, sem sua a
vari√°vel de interesse, lembre-se que denominamos $Y$ de [r√≥tulo]{.red}
ou [label]{.red}, fornece o vetor de caracter√≠sticas $\bf{x}$ que
descreve uma dada observa√ß√£o.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

No artigo [Tidy Data](https://www.jstatsoft.org/article/view/v059i10),
2014, publicado no Journal of Statistical Sofware, o Hadley Wickham
discute que o princ√≠pio de dados organizados est√£o intimamente
relacionados com banco de dados relacional e mais pr√≥ximo do recioc√≠nio
que empregamos na √°lgebra. Nesse artigo, ele define o que √© [Tidy
Dados]{.red}, sendo essa uma maneira de mapear um conjunto de dados.

<br>

Segundo o artigo, um conjunto de dados √© [bagun√ßado]{.red} ou
[arrumado]{.red}/[tidy]{.red}, dependendo de como as linhas, colunas e
tabelas s√£o combinadas com as observa√ß√µes, vari√°veis e tipos. Em dados
arrumados (dados tidy), temos que:

<br>

1.  Cada vari√°vel forma uma coluna;
2.  Cada observa√ß√£o forma uma linha;
3.  Cada valor deve ter sua pr√≥pria c√©lula.

<br>

Embora existam situa√ß√µes em que j√° podemos come√ßar a analisar uma base
de dados real, essa √© a exce√ß√£o e n√£o a regra. Normalmente, nos
deparamos com bases de dados que violam uma ou mais dessas regras.
Sempre, que poss√≠vel, procure utilizar dados no formato [Tidy]{.red}.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

![Representa√ß√£o de uma base de dados no formato tidy.](imgs/tidy-1.png)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

> "As fam√≠lias felizes s√£o todas iguais; toda fam√≠lia infeliz √© infeliz
> √† sua maneira." -- [Leo
> Tolstoy](https://en.wikipedia.org/wiki/Leo_Tolstoy)

> "Conjuntos de dados organizados s√£o todos iguais, mas todo conjunto de
> dados confuso √© confuso √† sua maneira." -- [Hadley
> Wickham](https://hadley.nz/)

<br>

![Trabalhar com a Tabela do lado esquerdo √© melhor que a Tabela do lado
direito. Prefira, sempre que poss√≠vel, o formato tidy. N√£o permita-se
ficar estressado t√£o facilmente.](imgs/tidy-2.png){width="50%"}

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

A linguagem de programa√ß√£o R possue diversas ferramentas que permite
manipular e explorar bases de dados. Enumero algumas:

1.  [dplyr](https://dplyr.tidyverse.org/): biblioteca que implementa √©
    uma gram√°tica de manipula√ß√£o de dados, fornecendo um conjunto
    consistente de verbos que ajudam a resolver os desafios mais comuns
    de manipula√ß√£o de dados;
2.  [tidyr](https://tidyr.tidyverse.org/): ferramentas para ajudar a
    criar dados organizados, onde cada coluna √© uma vari√°vel, cada linha
    √© uma observa√ß√£o e cada c√©lula cont√©m um √∫nico valor;
3.  [ggplot2](https://ggplot2-book.org/): um sistema para criar gr√°ficos
    'declarativamente', baseado no livro [The Grammar of
    Graphics](https://www.amazon.com.br/Grammar-Graphics-Leland-Wilkinson/dp/0387245448),
    de [Leland
    Wilkinson](https://en.wikipedia.org/wiki/Leland_Wilkinson);
4.  [visdat](https://docs.ropensci.org/visdat/): uma biblioteca √∫til
    para um visualiza√ß√£o explorat√≥ria preliminar de dados;
5.  [explore](https://github.com/rolkra/explore): biblioteca que
    apresenta algumas rotinas de an√°lise para realizar uma an√°lise
    explorat√≥ria nos dados.

Todas essas bibliotecas est√£o muito bem documentadas. √â importante que
voc√™s explorem as documentas dessas bibliotecas, pois eventualmente irei
utizar alguma delas.

![](gifs/ok.gif)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

No [Cap√≠tulo 12](https://r4ds.had.co.nz/tidy-data.html), do livro [R for
Data Science](https://r4ds.had.co.nz/index.html), o autor aborda mais
sobre o formato Tidy e como trabalhar com a biblioteca
[tidyr](https://tidyr.tidyverse.org/).
[Aqui](https://r4ds.had.co.nz/transform.html?q=dplyr#dplyr-basics) o
autor aborda de forma b√°sica o pacote
[dplyr](https://dplyr.tidyverse.org/).

<br>

Durante o curso, na medida da necessidade de utiliza√ß√£o dessas
ferramentas, durante a exposi√ß√£o de exemplos, abordaremos alguns
conceitos. Ok?

<br>

![](gifs/ok.gif)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Muitas vezes, no processo de tratamento dos dados, tamb√©m estamos
preocupados em remover atributos que n√£o s√£o significativo para a
modelagem, em que nesse momento a experi√™ncia dos especialistas s√£o
fundamentais.

<br>

√â comum enriquercermos a base de dados com informa√ß√µes de outras bases
de dados, em um sistema de gerenciamento de banco de dados relacional,
em que as bases de dados est√£o relacionadas por uma chave. Nesse caso,
buscamos por novos atributos para um mesmo objeto (para uma mesma linha
da base), em que atributos cruzados devem ter um √∫nico valor, para cada
objeto, respeitando a regra tr√™s de conjuntos de dados tidy.

<br>

As vezes transformamos vari√°veis. Por exemplo, √© comum tomar o logaritmo
de uma vari√°vel num√©rica que √© assim√©trica, se $x >= 1$, em que $x$ √© um
atributo num√©rico qualquer.

<br>

Em diveras situa√ß√µes, tamb√©m √© comum a base de dados apresentar
informa√ß√µes faltantes. Nos data frames de R, a falta de informa√ß√£o na
base, normlamente ser√£o representadas por `NA`.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Poder√° ser que um dado atributo apresente informa√ß√£o faltante, e
normalmente n√£o optaremos em remover a observa√ß√£o e precisaremos imputar
a informa√ß√£o, por exemplo:

<br>

1.  Tomando alguma medida de tend√™ncia central como m√©dia/moda/mediana
    dos valores que s√£o conhecidos para aquele atributo;
2.  Criar um novo valor que √© indica√ß√£o de valor faltante;
3.  Usar algoritmos como $k$-nearest neighbors - KNN ($k$ vizinhos mais
    pr√≥ximos) para imputar valores coerentes;
4.  Interpolar os dados.

<br>

Esses s√£o alguns exemplos de como podemos imputar observa√ß√µes faltantes.
Muitas vezes n√£o podemos nos dar o luxo de percer observa√ß√µes de nossa
base de dados.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

√â comum ser necess√°rio transformar os dados:

1.  Pode ser necess√°rio transformar os tipos ou os valores dos atributos
    para tentar obter um melhor ajuste do modelo;

2.  Pode-se discretizar valores cont√≠nuos ou transform√°-los em
    intervalos;

3.  √â comum transformar atributos categ√≥ricos com $p$ categorias, em $p$
    novos atributos bin√°rios.

    -   [One-hot encoding](https://en.wikipedia.org/wiki/One-hot)
    -   [Vari√°veis
        dummy](https://en.wikipedia.org/wiki/Dummy_variable_(statistics))

4.  Outra transforma√ß√£o muito comum √© a normaliza√ß√£o dos dados.
    Normalizar os dados √© muito √∫til quando os atributos num√©ricos
    possuem escalas muito diferentes.

::: columns
::: {.column width="50%"}
$$X_{novo} = \frac{X - X_{min}}{X_{max} - X_{min}},$$ em que
$X_{novo} \in [0, 1].$
:::

::: {.column width="50%"}
$$X_{novo} = Z = \frac{X - \mu}{\sigma^2},$$ em que
$\mathbb{E}(X) = \mu$ √© a m√©dia dos dados e
$\mathrm{Var}(X) = \sigma^2$. Na pr√°tica, em um contexto de v.a., iids,
usamos $\overline{x}$ como estimador de $\mu$ e $S^2$ (vari√¢ncia
amostral) como estimador de $\sigma^2$.
:::
:::

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Lembre-se, como citado anteriormente, tomar o logaritmo natural, ou
mesmo na base 10 de vari√°veis num√©ricas muito assim√©tricas, poder√°
ajudar um pouco, desde que seja possivel tomar o $\log(\cdot)$.

<br>

::: columns
::: {.column width="50%"}
```{r}
set.seed(0)
rgamma(1000, 2, 2) |> 
  hist()
```
:::

::: {.column width="50%"}
```{r}
set.seed(0)
rgamma(1000, 2, 2) |> 
  log() |> hist()
```
:::
:::

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Anteriormente eu citei algumas bibliotecas √∫teis de R para explorar os
dados, na fase de tratamento das observa√ß√µes. Por√©m, n√£o estranhe n√£o
ter cidado bibliotecas do framework
[tidymodels](https://www.tidymodels.org/packages/), em especial o
[recipes](https://recipes.tidymodels.org/) que √© muito utilizado no
workflow de aprendizagem de m√°quina na fase de pr√©-processamento dos
dados. Muitas dessas transforma√ß√µes s√£o aplicadas como receitas de
pr√©-processamento com o pacote
[recipes](https://recipes.tidymodels.org/).

<br>

O tidymodels ser√° muito √∫til para n√≥s, mas, aos poucos, seu uso e
explica√ß√µes mais detalhadas ser√£o apresentadas, apesar que em algumas
situa√ß√µes mais simples, poderei n√£o utiliz√°-lo, expor detalhes que
eventualmente n√£o ser√° poss√≠vel ou estariam camuflados na utiliza√ß√£o do
tidymodels.

<br>

![](gifs/ok-2.gif){width="20%"}

## As duas culturas

<br>

Em [Breiman, L. (2001a). Statistical modeling: The two cultures.
Statistical Science, 16(3),
199--231](https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2Fss%2F1009213726),
o Leo Breiman argumenta que existe duas culturas no uso de modelos
estat√≠sticos, em especialmente na √°rea de modelos de regress√£o. Segundo
eles, as culturas s√£o:

<br>

1.  [Data modeling culture]{.red}: nela, em geral, se assume que o
    modelo de regress√£o utilizado $r(x)$, por exemplo,
    $r(x) = \beta_0 + \sum_{i = 1}^d \beta_ix_i$ √© correto. O principal
    objetivo dessa abordagem √© a interpreta√ß√£o dos par√¢metros que
    indexam o modelo $r(x)$. Nesse tipo de cultura, a ideia tamb√©m √©
    construir intervalos aleat√≥rios e testar hip√≥teses para os
    $\beta_i's$. Sob essa √≥tica, muitas suposi√ß√µes sob o modelo s√£o
    realizadas, em que formas para checar essas suposi√ß√µes s√£o
    desenvolvidas, uma vez que elas s√£o fundamentais para esse tipo de
    modelagem.

<br>

2.  [Algorithmic modeling culture]{.red}: essa √© a cultura que domina a
    comunidade de aprendizagem de m√°quina. Nessa abordagem, o principal
    objetivo s√£o as predi√ß√µes por meio de novas observa√ß√µes. N√£o se
    assume que o modelo utilizado √© o modelo correto. Nesse tipo de
    modelagem, muitas vezes os algoritmos n√£o envolve nenhuma estrutura
    probabil√≠stica. Muitas vezes, modelos n√£o bem especificado conduzem
    a boas predi√ß√µes.

## As duas culturas

<br>

::: columns
::: {.column width="50%"}
![Breiman, L. (2001a). Statistical modeling: The two cultures.
Statistical Science, 16(3), 199--231.](imgs/paper_breiman){width="70%"}
:::

::: {.column width="50%"}
![Leo como um probabilista jovem na Universidade da
Calif√≥rina.](imgs/leo_breiman){width="60%"}
:::
:::

## As duas culturas

<br>

H√° diversos artigos interessantes que s√£o respostas ao artigo do Leo
Breiman, como por exemplo, o artigo [Statistical Modeling: The Two
Cultures: Comment](https://www.jstor.org/stable/2676682) do David Cox e
com coment√°rios do Brad Efron.

![[Sir David
Cox.](https://en.wikipedia.org/wiki/David_Cox_(statistician))](imgs/david_cox.png){width="20%"}

## As duas culturas

<br>

Muito embora exista essa divis√£o entre as culturas, Breiman foi um
estat√≠stico que desempenhou um grande trabalho para unir a √°rea de
estat√≠stica com aprendizado de m√°quina. Por conta dessa grande
import√¢ncia, um pr√™mio concedido em sua homenagem foi criado pela
[American Statistical
Association](https://community.amstat.org/slds/awards/breiman-award).

![[Leo Breiman trabalhando em sua resid√™ncia, em
1985.](https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2Fss%2F1009213290)](imgs/breiman_residencia.png){width="30%"}

#  {.title background-image="imgs/rawpixel/freight.jpg"}

::: r-fit-text
[Regress√£o / Parte I]{.flow}
:::

## Regress√£o

<br>

M√©todos de regress√£o surgiram h√° mais de dois s√©culos com Legendre
(1805) e Gauss (1809), que exploraram o m√©todo dos m√≠nimos quadrados com
o objetivo de prever √≥rbitas ao redor do Sol. Hoje em dia, o problema de
estima√ß√£o de uma fun√ß√£o de regress√£o possui papel central em
estat√≠stica.

<br>

> Apesar de as primeiras t√©cnicas para solucionar esse problema datarem
> de ao menos 200 anos, os avan√ßos computacionais recentes permitiram
> que novas metodologias fossem exploradas. Em particular, com a
> capacidade cada vez maior de armazenamento de dados, m√©todos com menos
> suposi√ß√µes sobre o verdadeiro estado da natureza ganham cada vez mais
> espa√ßo. Com isso, v√°rios desafios surgiram: por exemplo, m√©todos
> tradicionais n√£o s√£o capazes de lidar de forma satisfat√≥ria com bancos
> de dados em que h√° mais covari√°veis que observa√ß√µes, uma situa√ß√£o
> muito comum nos dias de hoje. Similarmente, s√£o frequentes as
> aplica√ß√µes em que cada observa√ß√£o consiste em uma imagem ou um
> documento de texto, objetos complexos que levam a an√°lises que
> requerem metodologias mais elaboradas. -- Izbick et al.

## Regress√£o

<br>

De forma geral, temos que o objetivo de um modelo de regress√£o √©
determinar a rela√ß√£o entre uma vari√°vel aleat√≥ria (label)
$Y \in \mathbb{R}$ e um vetor de covari√°veis (features)
$\mathbf{x} = (x_1, \cdots, x_d) \in \mathbb{R}^d$. Mais
especificamente, busaca-se estimar

$$r(\bf{x}) := \mathbb{E}(Y\,|\,\bf{X} = \bf{x}),$$

sendo esta chamada de [fun√ß√£o de regress√£o]{.red}. Temos que:

<br>

1.  Se $Y$ √© uma vari√°vel quantitativa, ent√£o estamos sob um problema de
    [regress√£o]{.red};
2.  Se $Y$ √© uma vari√°vel qualitativa, ent√£o teremos um problema de
    [classifica√ß√£o]{.red}.


Em aprendizagem de m√°quina, assumimos que n√£o temos meios de calcular $r({\bf{x}})$, i.e., n√£o conhecemos a distribui√ß√£o condicional de ${\bf{Y}\,|\,X}$. Portanto, n√£o temos meios de calcular

$$\mathbb{E}({\bf X}|Y = y) = \int x\,\mathrm{d}F_{\bf X}({\bf x} | Y = y).$$

## Nota√ß√µes

<br>

A vari√°vel $Y$ recebe frequentemente o nome de vari√°vel resposta,
vari√°vel dependente, r√≥tulo ou *label*. J√° as observa√ß√µes contidas no
vetor $\bf{x} = (x_1, \cdots, x_d)$, s√£o, em geral, denominadas de
vari√°veis explicativas, vari√°veis independentes, caracter√≠sticas,
atributos, preditores, covari√°veis ou *features*.

<br>

A ideia, nessa primeira parte do curso, √© descrever algumas t√©cnicas
para estimar (**treinar**, como √© dito em aprendizagem de m√°quina)
$r(\bf{x})$.

<br>

A menos quando dito o contr√°rio, assumiremos que nossa amostra s√£o
i.i.d. (independentes e identicamente distribu√≠das), ou seja,
$(\bf{X}_1, Y_1), \cdots, (\bf{X}_n, Y_n)$ s√£o i.i.d.

<br>

Denota-se por $x_{i,j}$ o valor da $j$-√©sima covari√°vel na $i$-√©sima
amostra, com $j = 1, \cdots, d$ e $i = 1, \cdots, n$.

## Nota√ß√µes

<br>

| Label    | Features                                     |
|----------|----------------------------------------------|
| $Y_1$    | $X_{1,1},\cdots, X_{1,d}\,\,\, (= \bf{X}_1)$ |
| $\vdots$ | $\,\,\,\vdots\,\,\,\,\, \ddots\,\,\ \vdots$  |
| $Y_n$    | $X_{n,1},\cdots, X_{n,d}\,\,\, (= \bf{X}_n)$ |

: Nota√ß√£o utilizada nesse material para as vari√°veis envolvidas em um
problema de regress√£o. {tbl-colwidths="\[25,25\]"}

## Regress√£o

Nossa ideia √© construir uma boa estimativa $g$ da fun√ß√£o de regress√£o
$r(\bf{x}) := \mathbb{E}(Y\,|\,\bf{X} = \bf{x})$, para novas
observa√ß√µes, i.e., queremos obter uma fun√ß√£o $g$, tal que:

$$g: \mathbb{R}^d \rightarrow \mathbb{R},$$

de tal forma que $g$ possua um bom poder preditivo. Em aprendizagem de
m√°quina, s√≥ estaremos interessados em obter uma fun√ß√£o $g$ que estime
bem um n√∫mero real (em problemas de regress√£o), ou que classifique bem
(em um problema de classifica√ß√£o), utilizando as $d$ covari√°veis. Ou
seja, para $m$ novas observa√ß√µes, desejamos obter $g$, que

$$g({\bf{x}}_{n + 1}) \approx y_{n + 1}, \cdots, g({\bf{x}}_{n + m}) \approx y_{n + m}.$$

## Fun√ß√£o de risco

<br>

Para que possamos construir boas fun√ß√µes de predi√ß√£o, √© preciso que tenhamos um crit√©rio para medir o desempenho de uma dada fun√ß√£o $g:\mathbb{R}^d \rightarrow \mathbb{R}$. Em contexto de regress√£o, usaremos o risco quadr√°tico, muito embora esta n√£o √© a √∫nica op√ß√£o. Denotaremos a fun√ß√£o de risco quadr√°tico por:

$$R_{pred}(g) = \mathbb{E}\left[({\bf Y} - g({\bf X}))^2\right],$$
em que $(\bf X, Y)$ s√£o observa√ß√µes novas que n√£o foram utilizadas para treinar/estimar $g$. L√™-se $R_{pred}(g)$ como "risco preditivo de $g$". Note que, como $\bf X$ s√£o observa√ß√µes conhecidas e $g(\cdot)$ √© um modelo preditivo, portanto, $g$ √© conhecido, ent√£o, $\widehat{\bf Y} = g(\bf X)$ √© um estimador dos labels, i.e., de $\bf Y$.

<br>

Diremos que $L(g({\bf X}); {\bf Y}) = ({\bf Y} - g({\bf X}))^2$ √© a [fun√ß√£o de perda quadr√°tica]{.red}, as vezes chamado de perda $L_2$. Outra fun√ß√µes como a [fun√ß√£o de perda absoluta]{.red} denotada por $L(g({\bf X}); {\bf Y}) = |{\bf Y} - g({\bf X})|$, as vezes chamada de perda $L_1$ poderiam ser consideradas.

## Fun√ß√£o de risco

<br>

Em linhas gerais, seja $L(\cdot)$ uma fun√ß√£o qualquer, tal que $\forall \, 0 < u < v$, de modo que:

<br>

i) $0 = L(0) \leq L(u) \leq L(v)$;
ii) $0 = L(0) \leq L(-u) \leq L(-v)$.

<br>

Qualquer fun√ß√£o $L(\cdot)$ que satisfaz as propriedades acima √© chamada de [fun√ß√£o de perda](https://en.wikipedia.org/wiki/Loss_function). Em especial, temos que:

<br>

- Fun√ß√£o de perda quadr√°tica: $L(u) = u^2$;
- Fun√ß√£o de perda absoluta: $L(u) = |u|$;
- Fun√ß√£o de perda degradu: $L(0) = 0$, se $|u| < \delta$ e $1$ caso contr√°rio, para algum $\delta > 0$;

## Fun√ß√£o de risco

<br>

Normalmente considera-se a perda $L_2$, uma vez que em modelos de regress√£o, minimizar $R_{pred}(g)$, em $g$, equivale a encontrar $r({\bf x}) = \mathbb{E}({\bf X}|{\bf Y})$, i.e., equivale a estimar a fun√ß√£o de regress√£o. 

<br>

[Teorema]{.red}: Suponha que definimos o risco de uma fun√ß√£o de predi√ß√£o $g: \mathbb{R}^d \rightarrow \mathbb{R}$ via fun√ß√£o perda quadr√°tica, i.e, $R_{pred}(g) = \mathbb{E}\left[({\bf Y} - g({\bf X}))^2\right]$, em que $\bf (X, Y)$ s√£o novas observa√ß√µes que n√£o foram utilizadas para estimar $g$. Suponha tamb√©m que estimaos o risco de um estimador de regress√£o $r({\bf X})$ via fun√ß√£o perda quadr√°tica $R_{pred}(g) = \mathbb{E}\left[r({\bf X} - g({\bf X}))^2\right]$. Ent√£o,

$$R_{pred}(g) = R_{reg}(g) + \mathbb{E}\left[\mathbb{V}[{\bf Y} | {\bf X}]\right],$$

em que $\mathbb{E}\left[\mathbb{V}[{\bf Y} | {\bf X}]\right]$ √© a vari√¢ncia m√©dia do modelo que n√£o depende de $g$. Portanto, estimar bem $r({\bf x})$ √© de fundamental import√¢ncia para criar uma boa fun√ß√£o de predi√ß√£o. Em especial, sob a √≥tica do risco quadr√°tico, a melhor fun√ß√£o de predi√ß√£o para $\bf Y$ √© a fun√ß√£o de regress√£o $r({\bf x})$, de tal modo que:


$$\argmin_g R_{pred}(g) = \argmin_g R_{reg}(g) = r({\bf x}).$$

## Fun√ß√£o de risco

<br>

**Lembre-se**: $r({\bf x}) = \mathbb{E}(Y | \bf{X} = \bf{x})$ √© a nossa [fun√ß√£o de regress√£o]{.red}.

<br>

A defini√ß√£o de risco preditivo $R_{pred}$, que tamb√©m denotaremos simplesmente por $R$, tem um apelo frequentista. Dessa forma, para um novo conjunto com $m$ novas observa√ß√µs, $({\bf X}_{n+1}, Y_{n+1}), \cdots, ({\bf X}_{n+m}, Y_{n+m})$, temos que que essa nova amostra √© i.i.d √† amostra observada (utilizada no treinamento do modelo/na estima√ß√£o). Ent√£o, pela Lei dos Grandes N√∫meros, temos que um bom estimador para a fun√ß√£o para o risco preditivo √© dado por:


$$\frac{1}{m}\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \approx R(g) := \mathbb{E}\left[(Y - g({\bf X}))^2\right].$$
Chamaremos a quantidade acima de [Erro Quadr√°tico M√©dio - EQM](https://pt.wikipedia.org/wiki/Erro_quadr%C3%A1tico_m%C3%A9dio). Em aprendizagem de m√°quina, normalmente estaremos no contexto em que temos muitas observa√ß√µes, e que portanto, poderemos fazer esse apelo frequentista.

<br>

''Desejamos encontrar $g$ (encontrar m√©todos) que minimize de forma satisfat√≥ria $R$, i.e., m√©todos que nos conduzam √† um risco baixo.

## Fun√ß√£o de risco

<br>

Sendo assim, se $R(g)$ possui um valor baixo, ent√£o, temos que 

$$g({\bf x}_{n+1}) \approx y_{n+1}, \cdots, g({\bf x}_{n+m}) \approx y_{n+m}.$$
<br>
![](gifs/hum.gif){width="25%"}

## Regress√£o linear

<br>

Nesse momento, vamos pensar um pouco em regress√£o linear. No caso mais simples, queremos prever o comportamento de uma vari√°vel de interesse $Y$ condicional a uma vari√°vel explicativa $X$ (regress√£o linear simples, i.e., $d = 1$). O melhor preditor de $Y$ condicional em $X$ √© aquele que minimiza a fun√ß√£o de perda esperada, ou seja, √© aquele que resolve:

$$\argmin_g \mathbb{E}(L(Y - g)\,|\,X).$$

Para o caso da fun√ß√£o perda quadr√°tica (fun√ß√£o $L_2$), o melhor preditor de $Y$ condicional √† $X$ √© a m√©dia condicional de $Y$ dado $X$, i.e., $r(X) = \mathbb{E}(Y\,|\,X)$. J√°, na situa√ß√£o em que considera-se a perda absoluta (fun√ß√£o $L_1$), o melhor estimador √© a mediana condicional.

<br>

**Os modelos de regress√£o, em geral, fazem uso da fun√ß√£o de perda quadr√°tica.**

## Regress√£o linear simples

<br>

No caso da regress√£o linear simples ($d = 1$), temos que o modelo √© dado por:

$$g(x) = \beta_0 + \beta_1 x_{i,1} + \varepsilon_i, \,\, i = 1, \cdots, n.$$

Assumindo que a regress√£o linear simples √© o modelo $g$ que iremos utilizar, ent√£o, desejamos minimizar:

$$\argmin_{\beta} R(g_\beta) = \argmin_{\beta} \sum_{i = 1}^n(y_i - \beta_0 - \beta_1x_{i,1})^2.$$
Derivando em rela√ß√£o √† $\beta$ e igualando a zero, ap√≥s algumas manipula√ß√µes alg√©bricas, temos que:

$$\widehat{\beta} = \frac{\sum_{i = 1}^n (x_i - \overline{x})(y_i - \overline{y})}{\sum_{i=1}^n(x_i - \overline{x})^2} = r_{xy}\frac{s_y}{s_x},$$
em que $s_x$ e $s_y$ s√£o os desvio-padr√£o de $x$ e $y$, respectivamente, e $r_{xy}$ √© o coeficiente de correla√ß√£o da amostra.

## Regress√£o linear simples

<br>

$$r_{xy} = \frac{\overline{xy} - \overline{x}\,\overline{y}}{\sqrt{(\overline{x^2} - \overline{x}^2)(\overline{y^2} - \overline{y}^2)}}.$$
O coeficiente de determina√ß√£o $R^2$ do modelo √© dado por $r_{xy}^2$, quando o modelo √© linear e possue uma √∫nica vari√°vel independente (feature).

<br>

Portanto, temos que:

$$\widehat{\beta_0} = \overline{y} - \widehat{\beta}\overline{x},$$

Na [*data modeling culture*]{.red} (na estat√≠stica), normalmente assumimos que o $\varepsilon_i$ tem distribui√ß√£o normal e vari√¢ncia constante, $\forall\, i = 1, \cdots, n$. Assume-se tamb√©m que $\mathbb{E}(\varepsilon_i) = 0, \, \forall i$.

## Regress√£o linear simples

<br>

Aqui n√£o iremos nos preocupar com essas suposi√ß√µes, uma vez que em [*algorithmic modeling culture*]{.red}, n√£o estamos preocupados com suposi√ß√µes nem interpreta√ß√µes, ok!?

<br>

![](gifs/ok-2.gif)


## Regress√£o linear multipla

<br>

A fun√ß√£o de perda quadr√°tica (fun√ß√£o $L_2$) tem algumas vantagens em rela√ß√£o a fun√ß√£o de perda absoluta. Listo algumas:

1. A fun√ß√£o de perda quadr√°tica penaliza mais os erros maiores, devido ao vato dos erros serem levado ao quadrado;

2. A fun√ß√£o de perda quadr√°tica √© mais sens√≠vel a presen√ßa de [outlier](https://en.wikipedia.org/wiki/Outlier), que em compensa√ß√£o s√£o menos penalizados ao se considerar a fun√ß√£o de perda absoluta (fun√ß√£o $L_1$);

3. Em situa√ß√µes em que o erro tem distribui√ß√£o normal, a estimativa de m√≠nimos quadrados √© a solu√ß√£o de m√°xima verossimilhan√ßa e √© a estimativa linear n√£o viesada e com menor vari√¢ncia. Portanto, gozamos de um estimador com √≥timas propriedades, muito embora ele tamb√©m √© um bom estimador mesmo quando a suposi√ß√£o de normalidade n√£o √© verificada;

4. A fun√ß√£o de perda quadr√°tica √© deferenci√°vel, j√° a fun√ß√£o de perda absoluta n√£o √©.

Para o caso de regerss√£o linear m√∫ltipla, i.e., quando $d > 1$, poderemos utilizar uma nota√ß√£o matricial para representar o modelo linear m√∫ltiplo de regress√£o.

## Regress√£o linear multipla

<br>

Considerando o modelo de regress√£o linear m√∫ltiplo, temos que:


$$Y = g({\bf X}) = \beta^{T}{\bf X} + \varepsilon,$$

em que $Y$ √© um vetor $n \times 1$, ${\bf X}$ √© uma matriz fixa e conhecida com os atributos de dimens√£o $n \times d$, em que a primeira coluna √© preenchida de 1, $\beta = (\beta_0, \cdots, \beta_d)$. Na cultura de machine learning, iremos desconsiderar $\varepsilon$, n√£o feremos suposi√ß√µes sobre $\varepsilon$. Portanto, considere

$$g({\bf x}) = \beta^{T}{\bf X} = \beta_{0}x_0 + \beta_1x_{i,1} + \cdots + \beta_dx_{i,d},$$
em que $x_0 \equiv 1$.

## Regress√£o linear multipla

<br>

O m√©todo dos m√≠nimos quadrados, para o caso de regress√£o linear m√∫ltipla ($d > 1$) √© dado por aquele que minimiza $R(\beta^{T}{\bf X})$, i.e., minimiza:


$$\argmin_\beta \sum_{i = 1}^n (Y_i - \beta_0 - \beta_1x_{i,1} - \cdots - \beta_dx_{i,d})^2.$$
Temos que 

$$\widehat{\beta} = ({\bf X}^{T}{\bf X})^{-1}{\bf X}^{T}Y.$$

Portanto, a fun√ß√£o de regress√£o estimada √© dada por:

$$g({\bf x}) = \widehat{\beta}^{T}{\bf x}.$$

## Regress√£o linear multipla

<br>

Grande parte da literatura estat√≠stica √© voltada para justificar que o m√©todo de m√≠nimos quadrados sob um ponto de vista de um estimador de m√°xima verossimilhan√ßa, assim como tamb√©m para constru√ß√£o de testes de ader√™ncia, m√©todos para constru√ß√£o de intervalos de confian√ßa e teste de hip√≥tese para $\beta_i$ (par√¢metros que indexam o modelo), an√°lise de res√≠duos, entre outros.

<br> 

Assumir que a verdadeira regress√£o $r({\bf x}) = \mathbb{E}({\bf X}\,|\,Y)$ √© uma suposi√ß√£o muito forte. Contudo, existe, na literatura, justificativas para o uso de m√©todos de m√≠nimos quadrados para estimar os coeficientes, mesmo quando a regress√£o real $r({\bf x})$ n√£o satisfaz a suposi√ß√£o de linearidade.

## Regress√£o linear multipla

<br>

O estimador de m√≠nimos quadrados $\widehat{\beta} = ({\bf X}^{T}{\bf X})^{-1}{\bf X}^{T}Y$ √© bom, por alguns motivos:

<br>

1. √â igual ao estimador de m√°xima verossimilhan√ßa sob normalidade, linearidade e homoscedasticidade, portanto, consistente sob essas condi√ß√µes

2. √â [*best linear unbiased prediction* - BLUE]{.red} sob linearidade e homoscedasticidade;

3. O m√©todo de m√≠nimos quadrados tem alguma garantia, mesmo sem assumir muitas suposi√ß√µes.

<br>

![](gifs/hum.gif)

## M√≠nimos quadrados sem suposi√ß√£o de linearidade

<br>

Quando a suposi√ß√£o de linearidade falha, ou seja, quando a regress√£o verdadeira que desconhecemos $r({\bf x})$ n√£o √© linear, frequentemente existe um vetor $\beta_{*}$, tal que $g_{\beta_{*}}({\bf x}) = \beta_{*}^{T}{\bf x}$ tem um bom poder preditivo. Nesses casos, o m√©trodo dos m√≠nimos quadrados $\widehat{\beta}$ tende a produzir estimadores com baixo risco. Isso se deve ao fato que $\widehat{\beta}$ converge para o melhor preditor linear (para o or√°culo $\beta_{*}$) que √© dado por:

$$\beta_{*} = \argmin_\beta R(g_\beta) =  \argmin_\beta \mathbb{E}\left[(Y - \beta^{T}X)^2\right],$$
mesmo que a verdadeira regress√£o $r({\bf x})$ n√£o seja linear, em que $({\bf X}, Y)$ √© uma nova observa√ß√£o.

<br>

[Teorema]{.red}: Seja $\beta_{*}$ o melhor estimador linear e $\widehat{\beta}$ o estimador de m√≠nimos quadrados. Ent√£o,



$$\widehat{\beta}\overset{p}{\longrightarrow}  \beta_{*}\,\, \mathrm{e}\,\, R(g_{\widehat{\beta}})\overset{p}{\longrightarrow} R(g_{\beta_{*}}), $$
quando $n \longrightarrow \infty$. Para uma demonstra√ß√£o, veja <http://www.rizbicki.ufscar.br/AME.pdf>, p√°gina. 29.

## M√≠nimos quadrados sem suposi√ß√£o de linearidade

<br>

Em palavras, o que o Teorema anterior diz √© que mesmo quando a regress√£o verdadeira n√£o √© linear, o estimador de m√≠nimos quadrados √© consistente para nos conduzir a um bom estimador **linear**, ou seja, ao menos conseguiremos o melhor estimador linear como uma aproxima√ß√£o √† $r({\bf x})$ que n√£o √© linear.

<br>

Isso n√£o quer dizer que voc√™ ter√° boas estimativas em todas as situa√ß√µes, muito embora o or√°culo $\beta_{*}$, em muitas situa√ß√µes, ter√° bom poder preditivo. Em outras palavras, em situa√ß√µes que um problema, em sua natureza, n√£o linear, poderemos alcan√ßar boas estimativas por uma aproxima√ß√£o linear pelo m√©todo dos m√≠nimos quadrados.

<br>

![](gifs/uau.gif)

## Predi√ß√£o versus Infer√™ncia

<br>

**Infer√™ncia**: assume que o modelo linear √© correto. O principal objetivo consiste em interpretar os par√¢metros:

<br>

- Quais s√£o os par√¢metros significantes?
- Qual o efeito do aumento da dose de um rem√©dio no paciente?

<br>

**Predi√ß√£o**: queremos criar $g({\bf x})$ com bom poder preditivo, mesmo que a especifica√ß√£o do modelo n√£o esteja correta. N√£o assume que a verdadeira regress√£o √© de fato linear! A interpreta√ß√£o aqui n√£o √© o foco. Tudo bem?

<br>

![](gifs/ok.gif){width='15%'}