---
title: "Machine Learning / Aprendizagem de M√°quina"
author: "Prof. Dr. Pedro Rafael D. Marinho<br>Departamento de Estat√≠stica - UFPB<br>"
date: '`r Sys.Date()`'
format: 
  revealjs:
    theme: [default, style.scss]
    width: 1920
    height: 1080
    logo: "https://www.ufpb.br/de/contents/imagens/logode.png"
    footer: '<a href="https://www.ufpb.br/de">Departamento de Estat√≠stica da UFPB</a>'
    transition: slide
    background-transition: fade
    preview-links: true
    slide-number: true
    chalkboard: true
    scrollable: true
    controls: true
    incremental: true  
    code-tools: true
    auto-stretch: true
    code-link: true
    html-math-method: katex
    auto-animate: false
  pdf: 
    include-in-header:  
      - text: |
            \usepackage{amsfonts}
            \usepackage{amsmath}
revealjs-plugins:
  - pointer
  - attribution
  - roughnotation
filters:
   - roughnotation
execute:
  refresh: true
  warning: false
  error: false
  eval: true
  echo: true
editor: 
  markdown: 
    wrap: 72
lang: pt
---

<!-- ```{r} -->

<!-- #| echo: false -->

<!-- #| warning: false -->

<!-- #| eval: true -->

<!-- if(fs::dir_exists("index_files/")) -->

<!--   fs::dir_delete("index_files/") -->

<!-- ``` -->

::: r-fit-text
Aprendizagem de M√°quina

[Bacharelado em Estat√≠stica]{.flow}

UFPB
:::

#  {.title}

::: r-fit-text
[Apresenta√ß√£o]{.flow}
:::

##  {background-image="https://raw.githubusercontent.com/prdm0/imagens/main/eu.jpg" background-size="contain" background-position="left"}

::: columns
::: {.column width="40%"}
:::

::: {.column width="60%"}
## Sobre mim {.r-fit-text}

<br> <br>

-   Me chamo [Prof. Dr. Pedro Rafael D.
    Marinho](https://prdm.netlify.app/about_pt_br.html){preview-link="true"}.
    Meu curr√≠culo Lattes poder√° ser acessado clicando
    [aqui](http://lattes.cnpq.br/7185368598935272){preview-link="true"}.

-   Sou docente do Departamento de Estat√≠stica da UFPB. üë®‚Äçüè´

-   Toda minha forma√ß√£o acad√™mica √© na √°rea de estat√≠stica (bacharelado
    ao doutorado).

-   Tenho entusiasmo por programa√ß√£o, ci√™ncia de dados e aprendizagem de
    m√°quina üíªüìà.

-   `r fontawesome::fa("github", "black")` Me acompanhe no GitHub:
    <https://github.com/prdm0>.

-   `r fontawesome::fa("linkedin", "black")` Me acompanhe no Linkedin:
    <https://www.linkedin.com/in/prdm0/>.
:::
:::

# O Departamento {.title}

## Meu segundo lar {.r-fit-text background-color="black" background-image="https://raw.githubusercontent.com/prdm0/imagens/main/foto_aerea_ufpb.jpeg" background-size="1600px" background-repeat="repeat" background-opacity="0.35"}

```{r width = 100, height = 100, echo = FALSE, fig.cap="Departamento de Estat√≠stica da UFPB."}
library(leaflet)
leaflet() |>
  addMarkers(-34.846199, -7.140400) |>
  leaflet::addTiles() |>
  setView(
  -34.846199, -7.140400, zoom = 37,
  options = popupOptions(
    minWidth = 1600,
    maxWidth = 1500
  ))
```

## `r fontawesome::fa("laptop-code", "black")` Que linguagem de programa√ß√£o utilizar?

<br>

Nesse curso, ser√° abordado a linguagem de programa√ß√£o
[R](https://www.r-project.org/), mas lembre-se que voc√™ poder√° utilizar
qualquer linguagem de programa√ß√£o para fazer ci√™ncia de dados. Por√©m, R
e Python s√£o as minhas sugest√µes, haja vista que, atualmente, elas s√£o
as linguagens com maior quantidade de ferramentas e usu√°rios trabalhando
na √°rea de [ci√™ncia de
dados](https://en.wikipedia.org/wiki/Data_science).

<br>

[Outros motivos que me leva a lecionar a disciplina utilizando a
linguagem R s√£o:]{.black}

1.  Possui ferramentas muito bem pensadas para manipula√ß√£o e tratamento
    de dados;
2.  Normalmente, os *frameworks* de *machine learning* de R s√£o menos
    verbosos que os de Python;
3.  Matrizes e data frames s√£o estruturas de dados que j√° encontra-se
    definidas dentro da linguagem, n√£o precisando assim de importar
    bibliotecas.

[Isso √© meu gosto pessoal]{.red}! √â um gosto que, talvez, faz mais
sentido, em se tratando de algu√©m que vem da estat√≠stica. No mercado de
trabalho e em seus estudos, ap√≥s cursar as disciplinas de R e Python,
fornecidas pelo [Bacharelado em Estat√≠stica da
UFPB](https://www.ufpb.br/de), voc√™ ter√° a capacidade de estudar os
*frameworks* de *machine learning*, aos seus pr√≥prios passos e escolher
o que melhor te agrada. A linguagem [Julia](https://julialang.org/)
tamb√©m poder√° ser uma √≥tima op√ß√£o.

#  {.title}

::: r-fit-text
[Aprendizagem de M√°quina: O que √©?]{.flow}
:::

## `r fontawesome::fa("robot", "black")` Aprendizagem de m√°quina

<br> <br>

![](gifs/am.gif){.fragment width="930" height="600"}

## `r fontawesome::fa("robot", "black")` Aprendizagem de m√°quina

<br> <br>

**Alguns pontos**:

<br>

1.  A **A**prendizagem de **M**√°quina (AM), tamb√©m chamada de
    **M**achine **L**earning (ML), no ingl√™s, nasceu na d√©cada de 60
    como um campo da intelig√™nica artificial;

2.  Em sua origem, as aplica√ß√µes de AM tinha como objetivo aprender
    padr√µes com base nos dados;

3.  Originalmente, as aplica√ß√µes de AM eram de cunho estritamente
    computacional. Todavia, desde o in√≠cio dos anos 90, a √°rea de
    aprendizagem de m√°quina expandiu seus horizontes e come√ßou a se
    estabelecer como um campo por sim mesma;

4.  Em particular, a √°rea de aprendizagem de m√°quina come√ßou a
    estabelecer muitas intersec√ß√µes com a estat√≠stica. Muitos de seus
    algoritmos s√£o constru√≠dos com base em metodologias que surgiram na
    estat√≠stica;

5.  Atualmente, a comunidade de AM √© bastante interdisciplinar e
    utiliza-se de ideias desenvolvidas em diversas √°reas, sendo a
    estat√≠stica uma delas.

## `r fontawesome::fa("robot", "black")` Tipos de Aprendizado

<br>

[Aprendizado supervisionado]{.black}

<br>

Nesse curso, inicialmente estudaremos problemas de [aprendizado
supervisionado]{.red}, que consiste em aprender a fazer predi√ß√µes a
partir de conjunto de dados em que r√≥tulos (valores da vari√°vel resposta
$Y$) s√£o observados. Trataremos tanto de problemas de regress√£o (estimar
um valor n√∫m√©rico) quanto problemas de classifica√ß√£o (classificar um
cliente como aprovado ou reprovado, em um problema de concess√£o de
cr√©dito). Por exemplo, os [modelos de regress√£o]{.red} s√£o exemplos de
aprendizado supervisionado.

<br>

[Aprendizado n√£o-supervisionado]{.black}

<br>

Na segunda parte do curso, aprenderemos alguns m√©todos de aprendizado
[n√£o-supervisionado]{.red}, ou seja, algoritmos que n√£o utilizam-se de
r√≥tulos, em que busca-se aprender mais sobre a estrutura dos dados. Por
exemplo, os [m√©todos de agrupamento]{.red} (cluster), s√£o exempƒ∫os de
m√©todos de aprendizado n√£o-supervisionado.

## `r fontawesome::fa("robot", "black")` Tipos de Aprendizado

<br>

Muito embora no nosso curso focaremos nas abordagens de aprendizagem
**supervisionada** e **n√£o-supervisionada**, os tipos de aprendizagem,
em geral, podem ser mais amplos, em que temos:

<br>

1.  **Aprendizagem supervisionada**;
2.  **Aprendizagem n√£o-supervisionada**;
3.  Aprendizagem semi-supervisionada;
4.  Aprendizagem por refor√ßo.

## O que √© aprender?

<br>

Antes de detalharmos os tipos de aprendizagem de m√°quina, uma d√∫vida que
poder√° surgir √©: ["O que √© aprender?"]{.red}. ["Como a m√°quina
aprende?"]{.red}.

<br>

![](gifs/am.gif){.fragment width="900" height="600"}

## O que √© aprender?

<br>

De forma simples, aprender √© ganhar conhecimento atrav√©s de estudo,
experi√™ncias, por meio de ensinamentos.

<br>

**T√°, mais como √© que a [m√°quina]{.red} aprende?**

<br>

1.  [Aprendizagem]{.red} √© o processo em que se adquire conhecimento,
    isto √©, √© o processo em que utilizamos de algoritmos e fornecemos
    dados a esses algoritmos para que possamos extrair conhecimento.
    Nesse processo de aprendizagem, os algoritmos fazem uso de dados
    para a extress√£o de conhecimento, atrav√©s de procedimentos
    **supervisionado**, **n√£o-supervisionado**, **semi-supervisionado**
    ou **por refor√ßo**, a depender do algoritmo que voc√™ deseja
    utilizar.

2.  [Aprendizado]{.red} √© o modelo ajustado, isto √©, √© o conhecimento
    adquirido ap√≥s o treinamamento obtido no processo de aprendizagem.
    Voc√™ poder√° entender como sendo o modelo ajustado e que utilizamores
    para a tomada de decis√µes.

![](gifs/hum.gif)

## O que √© aprender?

<br>

Portanto, voc√™ poder√° entender, basiciamente, existe quatro tipos de
aprendizagem, sendo os dois primeiros o que mais focaremos nesse curso e
que de longe s√£o os mais utilizados:

<br>

1.  **Aprendizagem supervisionada**;
2.  **Aprendizagem n√£o-supervisionada**;
3.  Aprendizagem semi-supervisionada;
4.  Aprendizagem por refor√ßo.

<br>

![](gifs/hum.gif)

## Aprendizagem supervisionada

<br>

Nesse tipo de aprendizagem, o algoritmo ir√° receber um conjunto de dados
em que conhecemos r√≥tulos para a vari√°vel de interesse. √â como se voc√™
soubesse onde um bom modelo deve chegar, para assim ser reconhecido como
um bom modelo. Por exemplo,

<br>

1.  [Classifica√ß√£o]{.red}: precisamos determinar a classe de uma
    inst√¢ncia de dados, o seu atributo, i.e.,
    $\widehat{y} = \mathrm{argmax}_y\,P(Y = y\,|\, X = \bf{x})$, em que
    y √© um atributo que desejamos prever (cahorro, gato, sapo), e
    $\bf{x}$ √© um vetor de caracter√≠sticas (peso, altura, comprimento,
    se tem rabo, etc).

2.  [Regress√£o]{.red}: precisamos estimar uma quantidade num√©rica, i.e.,
    o valor da vari√°vel alvo por meio de uma **inst√¢ncia de dados**, ou
    seja, precisamos estimar $Y = \mathbb{E}(Y|X = \bf{x})$, i.e.,
    devemos encontrar meios de obter $\widehat{Y}$.

<br>

::: aside
**Algumas observa√ß√µes de nomenclaturas**:

1.  √â comum chamar cada exemplo de dados, i.e., o vetor $\bf{x}$ que
    ser√° passado ao modelo de [atributos]{.red} ou [*features*]{.red};
2.  Tamb√©m √© comum chamarmos de [r√≥tulo]{.red} ou [*label*]{.red} a
    classe ou valor alvo, ou seja, estas s√£o as formas de nomearmos $Y$,
    sendo $Y$ uma quantidade num√©rica (modelos de regress√£o) ou n√£o
    (modelos de classifica√ß√£o).
:::

## Aprendizagem supervisionada

<br>

Em se tratando de m√©todos de classifica√ß√£o, podemos ter os m√©todos:

<br>

1.  [Generativos]{.red}: s√£o os m√©todos que dada as vari√°veis $X$ e $Y$,
    o objetivo √© encontrar a distribui√ß√£o de probabilidade conjunta
    $P(X, Y)$, para ent√£o poder determinar $P(Y|X = \bf{x})$. Alguns
    m√©todos s√£o:

    -   Naive Bayes;
    -   Descriminante linear.

<br>

2.  [Descriminativos]{.red}: s√£o os m√©todos que estimam diretamente a
    probabilidade condicional $P(Y|X = \bf{x})$ ou que mesmo nem assumem
    modelos probabil√≠sticos. Os modelos dessa classe s√£o projetados para
    aprender a fronteira de decis√£o que separa as classes diretamente
    com base nas caracter√≠sticas de entrada. Podemos citar:
    -   Regress√£o logistica;
    -   Perceptron;
    -   **S**upport **V**ector **M**achine - SVM.

## Aprendizagem supervisionada

<br>

::: columns
::: {.column width="60%"}
![](gifs/classificacao.webp)
:::

::: {.column width="40%"}
<br> Poder√≠amos estar interessados em classificar o tamanho de morangos:

<br>

1.  S (**S**low): pequeno;

2.  M (**M**edium): m√©dio;

3.  L (**L**arge): grande.
:::
:::

## Aprendizagem supervisionada

<br> <br>

![Mais dois problemas de classifica√ß√£o (linear x
n√£o-linear).](gifs/Classification-Examples.gif){fig-align="center"
width="45%"}

## Aprendizagem supervisionada

<br> <br>

![](gifs/regression.gif){fig-align="center" width="1200"}

Um exemplo de de um problema de regress√£o. Aqui, a ideia √© utilizar a
equa√ß√£o da reta estimada, a reta que minimiza a soma dos quadrados entre
a reta e os ponto seria a melhor, de modo a ter uma estimativa num√©rica
atrav√©s de novos atributos passado ao modelo, i.e., por meio da equa√ß√£o
da reta e de um novo valor de $x$.

## Aprendizagem supervisionada

<br>

Um outro exemplo seria a classifica√ß√£o de imagem/v√≠deo, utilizando um
algoritmo de rede neural, por exemplo, usando uma **C**onvolutional
**N**eural **N**etwork -
[CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network). Foram
utilizados diversas imagens de pessoas "com" e "sem" m√°scara. Em que
"com" representa detec√ß√£o da m√°scara na face da pessoa e "sem" a n√£o
detec√ß√£o.

<br>

{{< video https://www.youtube.com/watch?v=Zt_Fr7YbU1c width="50%" height="50%" >}}

## Aprendizagem n√£o-supervisionada

<br>

Nesse tipo de aprendizagem, os algoritmos trabalham sobre dados n√£o
rotulados, por exemplo, em uma trarefa de agrupamento.

<br>

Os algoritmos verificam se as inst√¢ncias observadas poder√£o ser
arranjadas de alguma maneira, por exemplo, usando alguma m√©trica de
dist√¢ncia, formando grupos (*clusters*).

<br>

A ideia √© maximizar a dist√¢ncia entre os clusters e minimizar a
dist√¢ncia entre os elementos no interior do grupo. Em outras palavras, o
que se quer √© tornar os grupos mais diferentes poss√≠veis e tornar os
elementos dos grupos o mais parecido poss√≠vel.

<br>

Aqui, por n√£o haver r√≥tulos, um problema comum √© determinar a quantidade
de grupos ideal que muitas vezes s√£o obtidos de forma subjetiva ou por
heur√≠sticas. A quantidade de grupos √© um dilema!

![](gifs/hum.gif)

## Aprendizagem n√£o-supervisionada

<br>

![](gifs/kmeans.gif){fig-align="center" width="900"}

Ap√≥s a detec√ß√£o dos grupos, √© preciso analisar o resultado de modo a
tentar extrair informa√ß√µes coerentes de modo a saber o que cada grupo
representa no problema em quest√£o.

## Aprendizagem semi-supervisionada

<br>

A aprendizagem semi-supervisionada √© uma abordagem na √°rea de
aprendizagem de m√°quina, em que um algoritmo utiliza tanto dados
rotulados quanto n√£o rotulados para treinamento. Por exemplo, algoritmos
que propagam r√≥tulos, como o *Label Propagation*, em que r√≥tulos
conhecidos s√£o propagados para dados n√£o rotulados com base em sua sua
proximidade no espa√ßo de caracter√≠sticas.

<br>

Uma outra abordagem seria misturar modelos (*Model Blending*), em que
diferentes modelos s√£o treinados em diferentes partes do conjunto de
dados, por exemplo, um modelo para a parte roturada e um para a parte
n√£o rotulada.

<br>

![](gifs/hum.gif){width="50%"}

## Aprendizagem por refor√ßo

<br>

Nesse tipo de aprendizagem, n√£o **h√° uma fonte externa de exemplos**. O
agente (modelo) aprende aprende com sua pr√≥pria experi√™ncia, por
tentativas e erros, em que voc√™ dever√° definir uma medida de sucesso, e
eventualmente recompensar os acertos. No v√≠deo abaixo, veja um joguinho
que criei em R, em que o carrinho aprendeu a desviar de obst√°culos
aleat√≥rios que aparecem em sua frente. Utilizou-se uma rede neural cuja
a sa√≠da poderia ser ("parado", "para cima" ou "para baixo"). Veja o
c√≥digo clicando
[**aqui**](https://github.com/prdm0/desviando_obstaculos).

<br>

{{< video https://www.youtube.com/watch?v=9NXUtwGkkDw&t=2s width="50%" height="50%" >}}

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Um dos passos mais importante no fluxo de trabalho (*workflow*) de um
modelo de aprendizagem de m√°quina, consiste na prepara√ß√£o dos dados, em
que realizamos transforma√ß√µes, inputa√ß√µes de valores ausentes,
identifica√ß√£o de *outliers*, remo√ß√£o de vari√°veis altamente
correlacionadas, entre outros.

<br>

Fazer uma **an√°lise explorat√≥ria** dos dados √© um passo importante para
que se possa entender e detecatar poss√≠veis inconsist√™ncias na base de
dados. N√£o adianta fazer uso de modelos muito sofisticados quando se tem
uma base de dados cheia de problemas.

<br>

Normalmente trabalhamos com juntos de dados (tabelas) relacionais, em
que cada linha √© uma observa√ß√£o e cada coluna representa um atributo do
objeto/observa√ß√£o. A linha de uma base de dados relacional, sem sua a
vari√°vel de interesse, lembre-se que denominamos $Y$ de [r√≥tulo]{.red}
ou [*label*]{.red}, fornece o vetor de caracter√≠sticas $\bf{x}$ que
descreve uma dada observa√ß√£o.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

No artigo [Tidy Data](https://www.jstatsoft.org/article/view/v059i10),
2014, publicado no Journal of Statistical Sofware, o Hadley Wickham
discute que o princ√≠pio de dados organizados est√£o intimamente
relacionados com banco de dados relacional e mais pr√≥ximo do recioc√≠nio
que empregamos na √°lgebra. Nesse artigo, ele define o que √© [Tidy
Data]{.red}, sendo essa uma maneira de mapear um conjunto de dados.

<br>

Segundo o artigo, um conjunto de dados √© [bagun√ßado]{.red} ou
[arrumado]{.red}/[tidy]{.red}, dependendo de como as linhas, colunas e
tabelas s√£o combinadas com as observa√ß√µes, vari√°veis e tipos. Em dados
arrumados (dados *tidy*), temos que:

<br>

1.  Cada vari√°vel forma uma coluna;
2.  Cada observa√ß√£o forma uma linha;
3.  Cada valor deve ter sua pr√≥pria c√©lula.

<br>

Embora existam situa√ß√µes em que j√° podemos come√ßar a analisar uma base
de dados real, essa √© a exce√ß√£o e n√£o a regra. Normalmente, nos
deparamos com bases de dados que violam uma ou mais dessas regras.
Sempre, que poss√≠vel, procure utilizar dados no formato [Tidy]{.red}.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

![Representa√ß√£o de uma base de dados no formato
*tidy*.](imgs/tidy-1.png)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

> "As fam√≠lias felizes s√£o todas iguais; toda fam√≠lia infeliz √© infeliz
> √† sua maneira." -- [Leo
> Tolstoy](https://en.wikipedia.org/wiki/Leo_Tolstoy)

> "Conjuntos de dados organizados s√£o todos iguais, mas todo conjunto de
> dados confuso √© confuso √† sua maneira." -- [Hadley
> Wickham](https://hadley.nz/)

<br>

![Trabalhar com a Tabela do lado esquerdo √© melhor que a Tabela do lado
direito. Prefira, sempre que poss√≠vel, o formato tidy. N√£o permita-se
ficar estressado t√£o facilmente. üòÉ](imgs/tidy-2.png){width="50%"}

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

A linguagem de programa√ß√£o R possue diversas ferramentas que permite
manipular e explorar bases de dados. Enumero algumas:

1.  [dplyr](https://dplyr.tidyverse.org/): biblioteca que implementa √©
    uma gram√°tica de manipula√ß√£o de dados, fornecendo um conjunto
    consistente de verbos que ajudam a resolver os desafios mais comuns
    de manipula√ß√£o de dados;
2.  [tidyr](https://tidyr.tidyverse.org/): ferramentas para ajudar a
    criar dados organizados, em que cada coluna √© uma vari√°vel, cada
    linha √© uma observa√ß√£o e cada c√©lula cont√©m um √∫nico valor;
3.  [ggplot2](https://ggplot2-book.org/): um sistema para criar gr√°ficos
    'declarativamente', baseado no livro [The Grammar of
    Graphics](https://www.amazon.com.br/Grammar-Graphics-Leland-Wilkinson/dp/0387245448),
    de [Leland
    Wilkinson](https://en.wikipedia.org/wiki/Leland_Wilkinson);
4.  [visdat](https://docs.ropensci.org/visdat/): uma biblioteca √∫til
    para um visualiza√ß√£o explorat√≥ria preliminar de dados;
5.  [explore](https://github.com/rolkra/explore): biblioteca que
    apresenta algumas rotinas de an√°lise para realizar uma an√°lise
    explorat√≥ria nos dados.

Todas essas bibliotecas est√£o muito bem documentadas. √â importante que
voc√™s explorem as documentas dessas bibliotecas, pois eventualmente irei
utizar alguma delas.

![](gifs/ok.gif)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

No [Cap√≠tulo 12](https://r4ds.had.co.nz/tidy-data.html), do livro [R for
Data Science](https://r4ds.had.co.nz/index.html), o autor aborda mais
sobre o formato *Tidy* e como trabalhar com a biblioteca
[tidyr](https://tidyr.tidyverse.org/).
[Aqui](https://r4ds.had.co.nz/transform.html?q=dplyr#dplyr-basics) o
autor aborda de forma b√°sica o pacote
[dplyr](https://dplyr.tidyverse.org/).

<br>

Durante o curso, na medida da necessidade de utiliza√ß√£o dessas
ferramentas, durante a exposi√ß√£o de exemplos, abordaremos alguns
conceitos. Voc√™ ter√° a oportunidade de tamb√©m explorar essas bibliotecas
nos exerc√≠cios. Ok?!

<br>

![](gifs/ok.gif)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Muitas vezes, no processo de tratamento dos dados, tamb√©m estamos
preocupados em **remover atributos que n√£o s√£o significativo** para a
modelagem, em que nesse momento a experi√™ncia dos especialistas s√£o
fundamentais.

<br>

**√â comum enriquercermos a base de dados com informa√ß√µes de outras bases
de dados**, em um sistema de gerenciamento de banco de dados relacional,
em que as bases de dados est√£o relacionadas por uma chave. Nesse caso,
buscamos por novos atributos para um mesmo objeto (para uma mesma linha
da base), em que atributos cruzados devem ter um √∫nico valor, para cada
objeto, respeitando a regra tr√™s de conjuntos de dados *tidy*.

<br>

**As vezes transformamos vari√°veis**. Por exemplo, √© comum tomar o
logaritmo de uma vari√°vel num√©rica que √© assim√©trica, se $x \geq 1$, em
que $x$ √© um atributo num√©rico qualquer.

<br>

Em diveras situa√ß√µes, tamb√©m √© comum a base de dados apresentar
**informa√ß√µes faltantes**. Nos data frames de R, a falta de informa√ß√£o
na base, normlamente ser√£o representadas por `NA`.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Poder√° ser que um dado atributo apresente informa√ß√£o faltante, e
normalmente n√£o optaremos em remover a observa√ß√£o e precisaremos imputar
a informa√ß√£o, por exemplo:

<br>

1.  Tomando alguma medida de tend√™ncia central como m√©dia/moda/mediana
    dos valores que s√£o conhecidos para aquele atributo;
2.  Criar um novo valor que √© indica√ß√£o de valor faltante;
3.  Usar algoritmos como $k$-nearest neighbors - $k$**NN** ($k$ vizinhos
    mais pr√≥ximos) para imputar valores coerentes;
4.  Interpolar os dados.

Esses s√£o alguns exemplos de como podemos imputar observa√ß√µes faltantes.
Muitas vezes n√£o podemos nos dar o luxo de percer observa√ß√µes de nossa
base de dados.

![](gifs/chapulin-colorado-no.gif)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

√â comum ser necess√°rio transformar os dados:

1.  Pode ser necess√°rio transformar os tipos ou os valores dos atributos
    para tentar obter um melhor ajuste do modelo;

2.  Pode-se discretizar valores cont√≠nuos ou transform√°-los em
    intervalos;

3.  √â comum transformar atributos categ√≥ricos com $p$ categorias, em $p$
    novos atributos bin√°rios.

    -   [One-hot encoding](https://en.wikipedia.org/wiki/One-hot)
    -   [Vari√°veis
        dummy](https://en.wikipedia.org/wiki/Dummy_variable_(statistics))

4.  Outra transforma√ß√£o muito comum √© a normaliza√ß√£o dos dados.
    Normalizar os dados √© muito √∫til quando os atributos num√©ricos
    possuem escalas muito diferentes.

::: columns
::: {.column width="50%"}
$$X_{novo} = \frac{X - X_{min}}{X_{max} - X_{min}},$$ em que
$X_{novo} \in [0, 1].$
:::

::: {.column width="50%"}
$$X_{novo} = Z = \frac{X - \mu}{\sigma^2},$$ em que
$\mathbb{E}(X) = \mu$ √© a m√©dia dos dados e
$\mathrm{Var}(X) = \sigma^2$. Na pr√°tica, em um contexto de v.a., iids,
usamos $\overline{x}$ como estimador de $\mu$ e $S^2$ (vari√¢ncia
amostral) como estimador de $\sigma^2$.
:::
:::

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Lembre-se, como citado anteriormente, tomar o logaritmo natural, ou
mesmo na base 10 de vari√°veis num√©ricas muito assim√©tricas, poder√°
ajudar um pouco, desde que seja possivel tomar o $\log(\cdot)$.

<br>

::: columns
::: {.column width="50%"}
```{r}
set.seed(0)
rgamma(1000, 2, 2) |> 
  hist()
```
:::

::: {.column width="50%"}
```{r}
set.seed(0)
rgamma(1000, 2, 2) |> 
  log() |> hist()
```
:::
:::

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Anteriormente eu citei algumas bibliotecas √∫teis de R para explorar os
dados, na fase de tratamento das observa√ß√µes. Por√©m, n√£o estranhe n√£o
ter, at√© o momento, citado bibliotecas do *framework*
[tidymodels](https://www.tidymodels.org/packages/), em especial o
[recipes](https://recipes.tidymodels.org/) que √© muito utilizado no
*workflow* de aprendizagem de m√°quina, na fase de pr√©-processamento dos
dados. Muitas dessas transforma√ß√µes s√£o aplicadas como receitas de
pr√©-processamento com o pacote
[recipes](https://recipes.tidymodels.org/).

<br>

![](imgs/recipes.png)

<br>

O [tidymodels](https://www.tidymodels.org/packages/) ser√° muito √∫til
para n√≥s, mas, aos poucos, seu uso e explica√ß√µes mais detalhadas ser√£o
apresentadas, apesar que em algumas situa√ß√µes mais simples, poderei n√£o
utiliz√°-lo, para expor detalhes que eventualmente n√£o ser√° poss√≠vel ou
estariam camuflados (*black box*) na utiliza√ß√£o do
[tidymodels](https://www.tidymodels.org/packages/).

<br>

Para n√£o deixar de valar sobre o
[tidymodels](https://www.tidymodels.org/packages/), explicarei, agora, a
sua filosofia e como ele est√° dividido em outras bibliotecas que s√£o
√∫teis em cada parte do processo de treinamento de um modelo de *machine
learning*.

![](gifs/ok-2.gif){width="20%"}

## Tidymodels

<br>

Diversas bibliotecas na linguagem R s√£o preparadas para trabalharem na
√°rea de aprendizagem de m√°quina. V√°rias dessas bibliotecas vem sendo
desenvolvidas h√° anos. Por exemplo,as bibliotecas
[glmnet](https://cran.r-project.org/web/packages/glmnet/index.html),
[ranger](https://cran.r-project.org/web/packages/ranger/index.html),
[kknn](https://cran.r-project.org/web/packages/kknn/index.html),
[xgboost](https://cran.r-project.org/web/packages/xgboost/index.html),
[keras](https://cran.r-project.org/web/packages/keras/index.html),
[rpart](https://cran.r-project.org/web/packages/rpart/index.html),
[randomForest](https://cran.r-project.org/web/packages/randomForest/index.html),
entre diversos outros.

<br>

```{r}
#| code-fold: true
#| eval: true
#| code-summary: O n√∫mero de pacotes abaixo √© o mais recente. Obtido automaticamente por webscraping.
library(xml2)
library(httr)
library(stringr)

numero_pacotes_r <- httr::GET("https://cloud.r-project.org/web/packages/index.html") |> 
  xml2::read_html() |> 
  xml2::xml_find_all("//p[1]") |> 
  xml2::xml_text() |> 
  stringr::str_extract(pattern = "[0-9]+")
```

<br>

Atualmente, a linguagem R possui [`r numero_pacotes_r`]{.red}, em que
muitos deles s√£o preparados para para trabalharem em tarefas de
aprendizagem de m√°quina, por√©m, cada com sua sintaxe espec√≠fica. Muitos
implementam o mesmo modelo, uns com algumas varia√ß√µes, por√©m, o uso √©
totalmente diferente, nomes de par√¢metros distintos, sa√≠das distintas,
etc.

![](gifs/chaves-isso.gif)

## Tidymodels

<br>

Essas diferentes implementa√ß√µes torna confuso trabalhar e testar
diferentes modelos ao mesmo tempo.

<br>

::: columns
::: {.column width="50%"}
Uma das primeiras ideias mais conhecidas de unifica√ß√£o de sintaxe do
*workflow* de machine learning, na linguagem R, foi idealizada pelo
estat√≠stico [Max Khun](https://www.linkedin.com/in/max-kuhn-864a9110/).

<br>

Ele criou a biblioteca
[caret](https://cran.r-project.org/web/packages/caret/index.html) -
**C**lassification **A**nd **RE**gression **T**raining de R que √© muito
bem desenvolvida e abrangente. Voc√™ poder√° estudar o
[caret](https://cran.r-project.org/web/packages/caret/index.html)
clicando [aqui](https://topepo.github.io/caret/).

<br>

N√£o foi um trabalho simples, veja uma tabela com a quantidade de modelos
que o [caret](https://cran.r-project.org/web/packages/caret/index.html)
suporta, clicando
[aqui](https://topepo.github.io/caret/available-models.html). Ent√£o,
"por baixo dos panos", a ideia era unificar a entrada e sa√≠da. A
biblioteca **caret** continua sendo mantida, apesar da exist√™ncia do
[tidymodels](https://www.tidymodels.org/).
:::

::: {.column width="50%"}
![](imgs/max_kuhn.jpeg){fig-aling="center"}
:::
:::

## Tidymodels

<br>

::: columns
::: {.column width="50%"}
![](imgs/max_kuhn.jpeg){fig-aling="center"}
:::

::: {.column width="50%"}
Max Kuhn, atualmente, no momento de escrita desse mateiral, √©
funcion√°rio da [Posit Ltda](https://posit.co/) e foi contratado para
estar a frente do desenvolvimento de uma vers√£o "arrumada" (*tidy*) do
[caret](https://cran.r-project.org/web/packages/caret/index.html), que √©
o [tidymodels](https://www.tidymodels.org/).

<br>

![](imgs/tidymodels.png){width="50%" fig-aling="center"}
:::
:::

## Tidymodels

<br>

![O *workflow* (*pipeline*) do treinamento de um modelo usando o
*framework* [tidymodels](https://www.tidymodels.org/). Todos os pacotes
(rsample, recipes, parsnip, tune, dails, yardstick) s√£o gerenciados pelo
pacote [tidymodels](https://www.tidymodels.org/). Cada um desses pacotes
fornece um conjunto de fun√ß√µes √∫teis em tarefas espec√≠ficas no workflow
de machine learning.](imgs/workflow_tidymodels.png){fig-aling="center"
width="70%"}

## Tidymodels

<br>

1.  [rsample](https://rsample.tidymodels.org/): respons√°vel pela
    reamostragem dos dados, parte importante para que possamos treinar
    um modelo de aprendizagem de m√°quina. √â nele que encontra-se fun√ß√µes
    para realizar reamostragem como bootstrap, $k$-folds
    cross-validation, nested cross-validation, entre outras.

![](imgs/rsample.png){width="10%" fig-aling="center"}

2.  [recipes](https://recipes.tidymodels.org/): apresenta diversas
    fun√ß√µes para transforma√ß√µes de vari√°veis como cria√ß√£o de vari√°veis
    dummy, normaliza√ß√£o de vari√°veis, inputa√ß√£o de dados pela m√©dia,
    mediana, $k$NN, entre outras formas de imputa√ß√£o, transforma√ß√µes de
    vari√°veis categ√≥rias em num√©ricas, entre outras funcionalidades. Ele
    permite que possamos criar uma receita de transforma√ß√µes nos dados
    para que esses, ap√≥s transformados, possam entrar no modelo.

![](imgs/recipes.png){width="10%" fig-aling="center"}

3.  [parsnip](https://parsnip.tidymodels.org/): √© o pacote que unifica
    as entradas e sa√≠das de diversos pacotes de aprendizagem de m√°quina
    de R. Ele possui os motores (engines) que s√£o as comunica√ß√µes com os
    algoritmos implementados em diversos pacotes de R que trabalham com
    tarefas de regress√£o e classifica√ß√£o, em aprendizagem de m√°quina.

## Tidymodels

<br>

::: columns
::: {.column width="50%"}
Os pacotes [tune](https://tune.tidymodels.org/),
[dails](https://dials.tidymodels.org/) e
[yardstick](https://yardstick.tidymodels.org/) tomar√° conta da parte de
treino do modelo. Os pacote [tune](https://tune.tidymodels.org/) e
[dails](https://dials.tidymodels.org/) s√£o respons√°veis pela "tunagem"
dos eventuais hiperpar√¢metros, j√° o
[yardstick](https://yardstick.tidymodels.org/) √© respons√°vel pelas
m√©tricas de avalia√ß√£o do modelo.

<br>

A biblioteca [dails](https://dials.tidymodels.org/) est√° mais
relacionada a cria√ß√£o dos *grids* para os eventuais hiperpar√¢metros do
modelo. J√° o pacote [tune](https://tune.tidymodels.org/), utiliza-se da
valida√ß√£o cruzada criada pelo pacote
[rsample](https://rsample.tidymodels.org/) para varrer as combina√ß√µes de
hiperpar√¢metros criadas pelo [dails](https://dials.tidymodels.org/),
i.e., o [tune](https://tune.tidymodels.org/) est√° mais relacionado com a
otimiza√ß√£o dos hiperpar√¢metros.
:::

::: {.column width="25%"}
![](imgs/tune.png){fig-aling="right"}
:::

::: {.column width="25%"}
![](imgs/dails.png){fig-aling="right"}
![](imgs/yardstick.png){fig-aling="right"}
:::
:::

## Tidymodels

<br>

Todo o fluxo de trabalho √© gerido pela biblioteca
[workflows](https://workflows.tidymodels.org/) de R. Em especial, as
etapas de *feature engineering* e especifica√ß√£o do modelo.

<br>

![](imgs/workflows_lib.png){fig-aling="center"}

## Tidymodels

<br>

![Perceba o papel da biblioteca
[workflows](https://workflows.tidymodels.org/) de R. Basicamente
gostar√≠amos de ter uma automa√ß√£o da faze do tratamento das *features*
realizada com o [recipes](https://recipes.tidymodels.org/) com a
modelagem.](imgs/MachineLearning_tidymodels.png){fig-aling="center"}

## Tidymodels

<br>

N√£o necessariamente iremos utilizar o
[tidymodels](https://www.tidymodels.org/) em todos os exemplos e
exerc√≠cios. Por√©m, iremos explorar bastante, at√© o fim do curso, o
treinamento de modelos usando o
[tidymodels](https://www.tidymodels.org/). Por tanto, aos poucos, a
medida em que exemplos s√£o apresentados e exerc√≠cios forem passados, o
aprendizado do uso do [tidymodels](https://www.tidymodels.org/) se dar√°.

<br>

![](gifs/thumbs-up-nod.gif){width="25%"}
![](gifs/teclado-anime.gif){width="25%"}

<br>

Sempre que poss√≠vel, deveremos colocar as "m√£os na massa" üçù para que
possamos dominar e compreender uma ferramenta computacional. A pr√°tica √©
importante!

## As duas culturas

<br>

Em [Breiman, L. (2001a). **Statistical modeling: The two cultures**.
Statistical Science, 16(3),
199--231](https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2Fss%2F1009213726),
o Leo Breiman argumenta que existe duas culturas no uso de modelos
estat√≠sticos, em especialmente na √°rea de modelos de regress√£o. Segundo
eles, as culturas s√£o:

<br>

1.  [Data modeling culture]{.red}: nela, em geral, se assume que o
    modelo de regress√£o utilizado $r(x)$, por exemplo,
    $r(x) = \beta_0 + \sum_{i = 1}^d \beta_ix_i$ √© correto. O principal
    objetivo dessa abordagem √© a interpreta√ß√£o dos par√¢metros que
    indexam o modelo $r(x)$. Nesse tipo de cultura, a ideia tamb√©m √©
    construir intervalos aleat√≥rios e testar hip√≥teses para os
    $\beta_i's$. Sob essa √≥tica, muitas suposi√ß√µes sob o modelo s√£o
    realizadas, em que formas para checar essas suposi√ß√µes s√£o
    desenvolvidas, uma vez que elas s√£o fundamentais para esse tipo de
    modelagem.

<br>

2.  [Algorithmic modeling culture]{.red}: essa √© a cultura que domina a
    comunidade de aprendizagem de m√°quina. Nessa abordagem, o principal
    objetivo s√£o as predi√ß√µes por meio de novas observa√ß√µes. N√£o se
    assume que o modelo utilizado √© o modelo correto. Nesse tipo de
    modelagem, muitas vezes os algoritmos n√£o envolve nenhuma estrutura
    probabil√≠stica. Muitas vezes, modelos n√£o bem especificado conduzem
    a boas predi√ß√µes.

## As duas culturas

<br>

::: columns
::: {.column width="50%"}
![Breiman, L. (2001a). Statistical modeling: The two cultures.
Statistical Science, 16(3), 199--231.](imgs/paper_breiman){width="70%"}
:::

::: {.column width="50%"}
![Leo, na √©poca em que era um jovem probabilista na Universidade da
Calif√≥rina.](imgs/leo_breiman){width="60%"}
:::
:::

## As duas culturas

<br>

H√° diversos artigos interessantes que s√£o respostas ao artigo do Leo
Breiman, como por exemplo, o artigo [Statistical Modeling: The Two
Cultures: Comment](https://www.jstor.org/stable/2676682) do David Cox e
com coment√°rios do Brad Efron.

![[Sir David
Cox.](https://en.wikipedia.org/wiki/David_Cox_(statistician))](imgs/david_cox.png){width="20%"}

## As duas culturas

<br>

Muito embora exista essa divis√£o entre as culturas, Breiman foi um
estat√≠stico que desempenhou um grande trabalho para unir a √°rea de
estat√≠stica com aprendizado de m√°quina. Por conta dessa grande
import√¢ncia, um pr√™mio concedido em sua homenagem foi criado pela
[American Statistical
Association](https://community.amstat.org/slds/awards/breiman-award).

![[Leo Breiman trabalhando em sua resid√™ncia, em
1985.](https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2Fss%2F1009213290)](imgs/breiman_residencia.png){width="30%"}

## As duas culturas

<br>

::: columns
::: {.column width="70%"}
Leo Breiman, renomado estat√≠stico, contribuiu significativamente para o
campo de aprendizagem de m√°quina. Ele √© conhecido por ter criado m√©todos
populares e influentes para a √°rea. Entre tais m√©todos famosos, cito
dois:

<br>

1.  **Random forest** (**florestas aleat√≥rias**): m√©todo que combina a
    previs√£o de v√°rios modelos de √°rvores de decis√£o (*decision tree*),
    que veremos mais a frente, por isso o termo "floresta" para
    problemas de regress√£o e classifica√ß√£o;

2.  **Bootstrap aggregating** (**bagging**): t√©cnica de aprendizagem
    *ensemble*, em que cria-se multiplos conjuntos de dados obtidos com
    reposi√ß√£o da amostra de treinamento. O modelo de aprendizagem de
    m√°quina √© treinado em cada conjunto de dados e as previs√µes de cada
    um dos modelos s√£o combinadas por meio da m√©dia (em problemas de
    regress√£o), ou por voto majorit√°rio, em problemas de classifica√ß√£o.
    O *bagging* √© utilizado para reduzir a vari√¢ncia e melhorar a
    estabilidade do modelo.
:::

::: {.column width="30%"}
![](imgs/sign1357-gra-0003-m.jpg){fig-aling="right"}
:::
:::

#  {.title background-image="imgs/rawpixel/freight.jpg"}

::: r-fit-text
[Regress√£o / Parte I]{.flow}
:::

## Regress√£o

<br>

M√©todos de regress√£o surgiram h√° mais de dois s√©culos com Legendre
(1805) e Gauss (1809), que exploraram o m√©todo dos m√≠nimos quadrados com
o objetivo de prever √≥rbitas ao redor do Sol. Hoje em dia, o problema de
estima√ß√£o de uma fun√ß√£o de regress√£o possui papel central em
estat√≠stica.

<br>

> Apesar de as primeiras t√©cnicas para solucionar esse problema datarem
> de ao menos 200 anos, os avan√ßos computacionais recentes permitiram
> que novas metodologias fossem exploradas. Em particular, com a
> capacidade cada vez maior de armazenamento de dados, m√©todos com menos
> suposi√ß√µes sobre o verdadeiro estado da natureza ganham cada vez mais
> espa√ßo. Com isso, v√°rios desafios surgiram: por exemplo, m√©todos
> tradicionais n√£o s√£o capazes de lidar de forma satisfat√≥ria com bancos
> de dados em que h√° mais covari√°veis que observa√ß√µes, uma situa√ß√£o
> muito comum nos dias de hoje. Similarmente, s√£o frequentes as
> aplica√ß√µes em que cada observa√ß√£o consiste em uma imagem ou um
> documento de texto, objetos complexos que levam a an√°lises que
> requerem metodologias mais elaboradas. -- Izbick et al.

## Regress√£o

<br>

De forma geral, temos que o objetivo de um modelo de regress√£o √©
determinar a rela√ß√£o entre uma vari√°vel aleat√≥ria (label)
$Y \in \mathbb{R}$ e um vetor de covari√°veis (features)
$\mathbf{x} = (x_1, \cdots, x_d) \in \mathbb{R}^d$. Mais
especificamente, busaca-se estimar

$$r(\bf{x}) := \mathbb{E}(Y|\bf{X} = \bf{x}),$$

sendo esta chamada de [fun√ß√£o de regress√£o]{.red}. Temos que:

<br>

1.  Se $Y$ √© uma vari√°vel quantitativa, ent√£o estamos sob um problema de
    [regress√£o]{.red};
2.  Se $Y$ √© uma vari√°vel qualitativa, ent√£o teremos um problema de
    [classifica√ß√£o]{.red}.

Em aprendizagem de m√°quina, assumimos que n√£o temos meios de calcular
$r({\bf{x}})$, i.e., n√£o conhecemos a distribui√ß√£o condicional de
${\bf{Y}\,|\,X}$. Portanto, n√£o temos meios de calcular

$$\mathbb{E}({\bf X}|Y = y) = \int x\,\mathrm{d}F_{\bf X}({\bf x} | Y = y).$$

## Nota√ß√µes

<br>

A vari√°vel $Y$ recebe frequentemente o nome de vari√°vel resposta,
vari√°vel dependente, r√≥tulo ou *label*. J√° as observa√ß√µes contidas no
vetor $\bf{x} = (x_1, \cdots, x_d)$, s√£o, em geral, denominadas de
vari√°veis explicativas, vari√°veis independentes, caracter√≠sticas,
atributos, preditores, covari√°veis ou *features*.

<br>

A ideia, nessa primeira parte do curso, √© descrever algumas t√©cnicas
para estimar (**treinar**, como √© dito em aprendizagem de m√°quina)
$r(\bf{x})$.

<br>

A menos quando dito o contr√°rio, assumiremos que nossa amostra s√£o
i.i.d. (independentes e identicamente distribu√≠das), ou seja,
$(\bf{X}_1, Y_1), \cdots, (\bf{X}_n, Y_n)$ s√£o i.i.d.

<br>

Denota-se por $x_{i,j}$ o valor da $j$-√©sima covari√°vel na $i$-√©sima
amostra, com $j = 1, \cdots, d$ e $i = 1, \cdots, n$.

## Nota√ß√µes

<br>

| Label    | Features                                     |
|----------|----------------------------------------------|
| $Y_1$    | $X_{1,1},\cdots, X_{1,d}\,\,\, (= \bf{X}_1)$ |
| $\vdots$ | $\,\,\,\vdots\,\,\,\,\, \ddots\,\,\ \vdots$  |
| $Y_n$    | $X_{n,1},\cdots, X_{n,d}\,\,\, (= \bf{X}_n)$ |

: Nota√ß√£o utilizada nesse material para as vari√°veis envolvidas em um
problema de regress√£o. {tbl-colwidths="\[25,25\]"}

## Regress√£o

Nossa ideia √© construir uma boa estimativa $g$ da fun√ß√£o de regress√£o
$r(\bf{x}) := \mathbb{E}(Y\,|\,\bf{X} = \bf{x})$, para novas
observa√ß√µes, i.e., queremos obter uma fun√ß√£o $g$, tal que:

$$g: \mathbb{R}^d \rightarrow \mathbb{R},$$

de tal forma que $g$ possua um bom poder preditivo. Em aprendizagem de
m√°quina, s√≥ estaremos interessados em obter uma fun√ß√£o $g$ que estime
bem um n√∫mero real (em problemas de regress√£o), ou que classifique bem
(em um problema de classifica√ß√£o), utilizando as $d$ covari√°veis. Ou
seja, para $m$ novas observa√ß√µes, desejamos obter $g$, que

$$g({\bf{x}}_{n + 1}) \approx y_{n + 1}, \cdots, g({\bf{x}}_{n + m}) \approx y_{n + m}.$$

## Fun√ß√£o de risco

<br>

Para que possamos construir boas fun√ß√µes de predi√ß√£o, √© preciso que
tenhamos um crit√©rio para medir o desempenho de uma dada fun√ß√£o
$g:\mathbb{R}^d \rightarrow \mathbb{R}$. Em contexto de regress√£o,
usaremos o risco quadr√°tico, muito embora esta n√£o √© a √∫nica op√ß√£o.
Denotaremos a fun√ß√£o de risco quadr√°tico por:

$$R_{pred}(g) = \mathbb{E}\left[({\bf Y} - g({\bf X}))^2\right],$$ em
que $(\bf X, Y)$ s√£o observa√ß√µes novas que n√£o foram utilizadas para
treinar/estimar $g$. L√™-se $R_{pred}(g)$ como "risco preditivo de $g$".
Note que, como $\bf X$ s√£o observa√ß√µes conhecidas e $g(\cdot)$ √© um
modelo preditivo, portanto, $g$ √© conhecido, ent√£o,
$\widehat{\bf Y} = g(\bf X)$ √© um estimador dos *labels*, i.e., de
$\bf Y$.

<br>

Diremos que $L(g({\bf X}); {\bf Y}) = ({\bf Y} - g({\bf X}))^2$ √© a
[fun√ß√£o de perda quadr√°tica]{.red}, as vezes chamado de perda $L_2$.
Outra fun√ß√µes como a [fun√ß√£o de perda absoluta]{.red} denotada por
$L(g({\bf X}); {\bf Y}) = |{\bf Y} - g({\bf X})|$, as vezes chamada de
perda $L_1$ poderiam ser consideradas.

## Fun√ß√£o de risco

<br>

Em linhas gerais, seja $L(\cdot)$ uma fun√ß√£o qualquer, tal que
$\forall \, 0 < u < v$, de modo que:

<br>

i)  $0 = L(0) \leq L(u) \leq L(v)$;
ii) $0 = L(0) \leq L(-u) \leq L(-v)$.

<br>

Qualquer fun√ß√£o $L(\cdot)$ que satisfaz as propriedades acima √© chamada
de [fun√ß√£o de perda](https://en.wikipedia.org/wiki/Loss_function). Em
especial, temos que:

<br>

-   Fun√ß√£o de perda quadr√°tica: $L(u) = u^2$;
-   Fun√ß√£o de perda absoluta: $L(u) = |u|$;
-   Fun√ß√£o de perda degrau: $L(0) = 0$, se $|u| < \delta$ e $1$ caso
    contr√°rio, para algum $\delta > 0$;

## Fun√ß√£o de risco

<br>

Normalmente considera-se a perda $L_2$, uma vez que em modelos de
regress√£o, minimizar $R_{pred}(g)$, em $g$, equivale a encontrar
$r({\bf x}) = \mathbb{E}({\bf X}|{\bf Y})$, i.e., equivale a estimar a
fun√ß√£o de regress√£o.

<br>

[Teorema]{.red}: Suponha que definimos o risco de uma fun√ß√£o de predi√ß√£o
$g: \mathbb{R}^d \rightarrow \mathbb{R}$ via fun√ß√£o perda quadr√°tica,
i.e, $R_{pred}(g) = \mathbb{E}\left[({\bf Y} - g({\bf X}))^2\right]$, em
que $\bf (X, Y)$ s√£o novas observa√ß√µes que n√£o foram utilizadas para
estimar $g$. Suponha tamb√©m que estimamos o risco de um estimador de
regress√£o $r({\bf X})$ via fun√ß√£o perda quadr√°tica
$R_{reg}(g) = \mathbb{E}\left[(r({\bf X}) - g({\bf X}))^2\right]$.
Ent√£o,

$$R_{pred}(g) = R_{reg}(g) + \mathbb{E}\left[\mathbb{V}[{\bf Y} | {\bf X}]\right],$$

em que $\mathbb{E}\left[\mathbb{V}[{\bf Y} | {\bf X}]\right]$ √© a
vari√¢ncia m√©dia do modelo que n√£o depende de $g$. Portanto, estimar bem
$r({\bf x})$ √© de fundamental import√¢ncia para criar uma boa fun√ß√£o de
predi√ß√£o. Em especial, sob a √≥tica do risco quadr√°tico, a melhor fun√ß√£o
de predi√ß√£o para $\bf Y$ √© a fun√ß√£o de regress√£o $r({\bf x})$, de tal
modo que:

$$\argmin_g R_{pred}(g) = \argmin_g R_{reg}(g) = r({\bf x}).$$

## Fun√ß√£o de risco

<br>

**Lembre-se**: $r({\bf x}) = \mathbb{E}(Y | \bf{X} = \bf{x})$ √© a nossa
[fun√ß√£o de regress√£o]{.red}.

<br>

A defini√ß√£o de risco preditivo $R_{pred}$, que tamb√©m denotaremos
simplesmente por $R$, tem um apelo frequentista. Dessa forma, para um
novo conjunto com $m$ novas observa√ß√µs,
$({\bf X}_{n+1}, Y_{n+1}), \cdots, ({\bf X}_{n+m}, Y_{n+m})$, temos que
essa nova amostra √© i.i.d. √† amostra observada (utilizada no treinamento
do modelo/na estima√ß√£o). Ent√£o, pela Lei dos Grandes N√∫meros, temos que
um bom estimador para a fun√ß√£o para o risco preditivo √© dado por:

$$\frac{1}{m}\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \approx R(g) := \mathbb{E}\left[(Y - g({\bf X}))^2\right].$$ {#eq-risco-correto}

Chamaremos a quantidade acima de [Erro Quadr√°tico M√©dio -
EQM](https://pt.wikipedia.org/wiki/Erro_quadr%C3%A1tico_m%C3%A9dio). Em
aprendizagem de m√°quina, normalmente estaremos no contexto em que temos
muitas observa√ß√µes, e que portanto, poderemos fazer esse apelo
frequentista.

<br>

Desejamos encontrar $g$ (encontrar m√©todos) que minimize de forma
satisfat√≥ria $R$, i.e., m√©todos que nos conduzam √† um risco baixo.

## Fun√ß√£o de risco

<br>

Sendo assim, se $R(g)$ possui um valor baixo, ent√£o, temos que

$$g({\bf x}_{n+1}) \approx y_{n+1}, \cdots, g({\bf x}_{n+m}) \approx y_{n+m}.$$
<br> ![](gifs/hum.gif){width="25%"}

## Regress√£o linear

<br>

Nesse momento, vamos pensar um pouco em regress√£o linear. No caso mais
simples, queremos prever o comportamento de uma vari√°vel de interesse
$Y$ condicional a uma vari√°vel explicativa $X$ (regress√£o linear
simples, i.e., $d = 1$). O melhor preditor de $Y$ condicional em $X$ √©
aquele que minimiza a fun√ß√£o de perda esperada, ou seja, √© aquele que
resolve:

$$\argmin_g \mathbb{E}(L(Y - g)|X).$$

Para o caso da fun√ß√£o perda quadr√°tica (fun√ß√£o $L_2$), o melhor preditor
de $Y$ condicional √† $X$ √© a m√©dia condicional de $Y$ dado $X$, i.e.,
$r(X) = \mathbb{E}(Y|X)$. J√°, na situa√ß√£o em que considera-se a perda
absoluta (fun√ß√£o $L_1$), o melhor estimador √© a mediana condicional.

<br>

**Os modelos de regress√£o, em geral, fazem uso da fun√ß√£o de perda
quadr√°tica.**

## Regress√£o linear simples

<br>

No caso da regress√£o linear simples ($d = 1$), temos que o modelo √© dado
por:

$$g(x) = \beta_0 + \beta_1 x_{i,1} + \varepsilon_i, \,\, i = 1, \cdots, n,$$
em que $\varepsilon_i$ √© um erro aleat√≥rio. Na abordagem *data modeling
culture*, v√°rias suposi√ß√µes poderem ser feitas para $\varepsilon_i$.

Assumindo que a regress√£o linear simples √© o modelo $g$ que iremos
utilizar, ent√£o, desejamos minimizar:

$$\argmin_{\beta} R(g_\beta) = \argmin_{\beta} \sum_{i = 1}^n(y_i - \beta_0 - \beta_1x_{i,1})^2.$$
Derivando em rela√ß√£o √† $\beta$ e igualando a zero, ap√≥s algumas
manipula√ß√µes alg√©bricas, temos que:

$$\widehat{\beta} = \frac{\sum_{i = 1}^n (x_i - \overline{x})(y_i - \overline{y})}{\sum_{i=1}^n(x_i - \overline{x})^2} = r_{xy}\frac{s_y}{s_x},$$
em que $s_x$ e $s_y$ s√£o os desvio-padr√£o de $x$ e $y$, respectivamente,
e $r_{xy}$ √© o coeficiente de correla√ß√£o da amostra, em que
$-1 \leq r_{xy} \leq 1$.

## Regress√£o linear simples

<br>

$$r_{xy} = \frac{\overline{xy} - \overline{x}\,\overline{y}}{\sqrt{(\overline{x^2} - \overline{x}^2)(\overline{y^2} - \overline{y}^2)}}.$$
O coeficiente de determina√ß√£o $R^2$ do modelo √© dado por $r_{xy}^2$,
quando o modelo √© linear e possue uma √∫nica vari√°vel independente
(feature).

<br>

Portanto, temos que:

$$\widehat{\beta_0} = \overline{y} - \widehat{\beta}\overline{x},$$

Na [*data modeling culture*]{.red} (na estat√≠stica), normalmente
assumimos que o $\varepsilon_i$ tem distribui√ß√£o normal e vari√¢ncia
constante, $\forall\, i = 1, \cdots, n$. Assume-se tamb√©m que
$\mathbb{E}(\varepsilon_i) = 0, \, \forall i$.

## Regress√£o linear simples

<br>

Aqui n√£o iremos nos preocupar com essas suposi√ß√µes, uma vez que em
[*algorithmic modeling culture*]{.red}, n√£o estamos preocupados com
suposi√ß√µes nem interpreta√ß√µes, ok!?

<br>

![](gifs/ok-2.gif)

## Regress√£o linear multipla

<br>

A fun√ß√£o de perda quadr√°tica (fun√ß√£o $L_2$) tem algumas vantagens em
rela√ß√£o a fun√ß√£o de perda absoluta. Listo algumas:

1.  A fun√ß√£o de perda quadr√°tica penaliza mais os erros maiores, devido
    ao fato dos erros serem levado ao quadrado;

2.  A fun√ß√£o de perda quadr√°tica √© mais sens√≠vel a presen√ßa de
    [*outlier*](https://en.wikipedia.org/wiki/Outlier), que em
    compensa√ß√£o s√£o menos penalizados ao se considerar a fun√ß√£o de perda
    absoluta (fun√ß√£o $L_1$);

3.  Em situa√ß√µes em que o erro tem distribui√ß√£o normal, a estimativa de
    m√≠nimos quadrados √© a solu√ß√£o de m√°xima verossimilhan√ßa e √© a
    estimativa linear n√£o viesada e com menor vari√¢ncia. Portanto,
    gozamos de um estimador com √≥timas propriedades, muito embora ele
    tamb√©m √© um bom estimador mesmo quando a suposi√ß√£o de normalidade
    n√£o √© verificada;

4.  A fun√ß√£o de perda quadr√°tica √© deferenci√°vel, j√° a fun√ß√£o de perda
    absoluta n√£o √©.

Para o caso de regress√£o linear m√∫ltipla, i.e., quando $d > 1$,
poderemos utilizar uma nota√ß√£o matricial para representar o modelo
linear m√∫ltiplo de regress√£o.

## Regress√£o linear multipla

<br>

Considerando o modelo de regress√£o linear m√∫ltiplo, temos que:

$$Y = g({\bf X}) = \beta^{T}{\bf X} + \varepsilon,$$

em que $Y$ √© um vetor $n \times 1$, ${\bf X}$ √© uma matriz fixa e
conhecida com os atributos de dimens√£o $n \times d$, em que a primeira
coluna √© preenchida de 1, $\beta = (\beta_0, \cdots, \beta_d)$. Na
cultura de *machine learning*, iremos desconsiderar $\varepsilon$, i.e.,
n√£o feremos suposi√ß√µes sobre $\varepsilon$. Portanto, considere

$$g({\bf x}) = \beta^{T}{\bf X} = \beta_{0}x_0 + \beta_1x_{i,1} + \cdots + \beta_dx_{i,d},$$
em que $x_0 \equiv 1$.

## Regress√£o linear multipla

<br>

O m√©todo dos m√≠nimos quadrados, para o caso de regress√£o linear m√∫ltipla
($d > 1$) √© dado por aquele que minimiza $R(\beta^{T}{\bf X})$, i.e.,
minimiza:

$$\argmin_\beta \sum_{i = 1}^n (Y_i - \beta_0 - \beta_1x_{i,1} - \cdots - \beta_dx_{i,d})^2.$$
Temos que

$$\widehat{\beta} = ({\bf X}^{T}{\bf X})^{-1}{\bf X}^{T}Y.$$

Portanto, a fun√ß√£o de regress√£o estimada √© dada por:

$$g({\bf x}) = \widehat{\beta}^{T}{\bf x}.$$

## Regress√£o linear multipla

<br>

Grande parte da literatura estat√≠stica √© voltada para justificar que o
m√©todo de m√≠nimos quadrados sob um ponto de vista de um estimador de
m√°xima verossimilhan√ßa, assim como tamb√©m para constru√ß√£o de testes de
ader√™ncia, m√©todos para constru√ß√£o de intervalos de confian√ßa e teste de
hip√≥tese para $\beta_i$ (par√¢metros que indexam o modelo), an√°lise de
res√≠duos, entre outros.

<br>

Assumir que a verdadeira regress√£o
$r({\bf x}) = \mathbb{E}({\bf X}\,|\,Y)$ √© uma suposi√ß√£o muito forte.
Contudo, existe, na literatura, justificativas para o uso de m√©todos de
m√≠nimos quadrados para estimar os coeficientes, mesmo quando a regress√£o
real $r({\bf x})$ n√£o satisfaz a suposi√ß√£o de linearidade.

<br>

![](gifs/chapulin-colorado-no.gif)

## Regress√£o linear multipla

<br>

O estimador de m√≠nimos quadrados
$\widehat{\beta} = ({\bf X}^{T}{\bf X})^{-1}{\bf X}^{T}Y$ √© bom, por
alguns motivos:

<br>

1.  √â igual ao estimador de m√°xima verossimilhan√ßa sob normalidade,
    linearidade e homoscedasticidade, portanto, consistente sob essas
    condi√ß√µes

2.  √â [*best linear unbiased prediction* - BLUE]{.red} sob linearidade e
    homoscedasticidade;

3.  O m√©todo de m√≠nimos quadrados tem alguma garantia, mesmo sem assumir
    muitas suposi√ß√µes.

<br>

![](gifs/hum.gif)

## M√≠nimos quadrados sem suposi√ß√£o de linearidade

<br>

Quando a suposi√ß√£o de linearidade falha, ou seja, quando a regress√£o
verdadeira que desconhecemos $r({\bf x})$ n√£o √© linear, frequentemente
existe um vetor $\beta_{*}$, tal que
$g_{\beta_{*}}({\bf x}) = \beta_{*}^{T}{\bf x}$ tem um bom poder
preditivo. Nesses casos, o m√©trodo dos m√≠nimos quadrados
$\widehat{\beta}$ tende a produzir estimadores com baixo risco. Isso se
deve ao fato que $\widehat{\beta}$ converge para o melhor preditor
linear (para o or√°culo $\beta_{*}$) que √© dado por:

$$\beta_{*} = \argmin_\beta R(g_\beta) =  \argmin_\beta \mathbb{E}\left[(Y - \beta^{T}X)^2\right],$$
mesmo que a verdadeira regress√£o $r({\bf x})$ n√£o seja linear, em que
$({\bf X}, Y)$ √© uma nova observa√ß√£o.

<br>

[Teorema]{.red}: Seja $\beta_{*}$ o melhor estimador linear e
$\widehat{\beta}$ o estimador de m√≠nimos quadrados. Ent√£o,

$$\widehat{\beta}\overset{p}{\longrightarrow}  \beta_{*}\,\, \mathrm{e}\,\, R(g_{\widehat{\beta}})\overset{p}{\longrightarrow} R(g_{\beta_{*}}), $$
quando $n \longrightarrow \infty$. Para uma demonstra√ß√£o, veja
<http://www.rizbicki.ufscar.br/AME.pdf>, p√°gina. 29.

## M√≠nimos quadrados sem suposi√ß√£o de linearidade

<br>

Em palavras, o que o Teorema anterior diz √© que mesmo quando a regress√£o
verdadeira n√£o √© linear, o estimador de m√≠nimos quadrados √© consistente
para nos conduzir a um bom estimador **linear**, ou seja, ao menos
conseguiremos o melhor estimador linear como uma aproxima√ß√£o √†
$r({\bf x})$ que n√£o √© linear.

<br>

Isso n√£o quer dizer que voc√™ ter√° boas estimativas em todas as
situa√ß√µes, muito embora o or√°culo $\beta_{*}$, em muitas situa√ß√µes, ter√°
bom poder preditivo. Em outras palavras, em situa√ß√µes que um problema,
em sua natureza, n√£o linear, poderemos alcan√ßar boas estimativas por uma
aproxima√ß√£o linear pelo m√©todo dos m√≠nimos quadrados.

<br>

![](gifs/uau.gif)

## Leia mais sobre regress√£o linear

<br>

Caso voc√™ deseje ler um pouco mais sobre regress√£o linear sob
homocedasticidade e sob heteroscedasticidades, leia o segundo Cap√≠tulo
de minha disserta√ß√£o de mestrado intitulada **Estimadores Intervalares
sob Heteroscedasticidade de Forma Desconhecida via Bootstrap Duplo**.
Apesar do t√≠tulo, o segundo cap√≠tulo √© uma revis√£o do conceito de
regress√£o linear √© apresentado de forma did√°tica. Clique
[aqui](pdf/regressao_linear.pdf) para ler.

<br>

![](gifs/chapulin-colorado-no.gif){width="20%"}

## Predi√ß√£o versus Infer√™ncia

<br>

**Infer√™ncia**: assume que o modelo linear √© correto. O principal
objetivo consiste em interpretar os par√¢metros:

<br>

-   Quais s√£o os par√¢metros significantes?
-   Qual o efeito do aumento da dose de um rem√©dio no paciente?

<br>

**Predi√ß√£o**: queremos criar $g({\bf x})$ com bom poder preditivo, mesmo
que a especifica√ß√£o do modelo n√£o esteja correta. N√£o assume que a
verdadeira regress√£o √© de fato linear! A interpreta√ß√£o aqui n√£o √© o
foco. Tudo bem?!

<br>

![](gifs/ok.gif){width="15%"}

## Ajustando uma regress√£o linear no R

<br>

Caso voc√™ n√£o queira implementar o estimador de m√≠nimos quadrados
$\widehat{\beta} = ({\bf X}^{T}{\bf X})^{-1}{\bf X}^{T}Y$, voc√™ poder√°
utilizar a famosa fun√ß√£o `lm`. Na verdade √© melhor que n√£o implemente o
estimador $\widehat{\beta}$, uma vez que a fun√ß√£o `lm`, assim como a
fun√ß√£o `glmnet` do pacote
[glmnet](https://glmnet.stanford.edu/articles/glmnet.html), utilizam-se
de truques num√©ricos para um c√°lculo mais eficiente.

<br>

Falaremos do pacote
[glmnet](https://glmnet.stanford.edu/articles/glmnet.html), um pouco
mais a frente, quando abordarmos regress√£o penalizada. Certo!?

<br>

![](gifs/bom.gif)

## Ajustando uma regress√£o linear no R

<br>

Considere o conjunto de dados de expectativa de vida versus PIB per
Capita dispon√≠veis
[aqui](https://github.com/prdm0/dados/blob/main/dados_expectativa_renda.RData).
O comportamente entre as vari√°veis `LifeExpectancy` e `GDPercapita`, se
fizermos um gr√°fico, n√£o √© linear.

<br>

Todavia, isso n√£o impede que possamos ajustar um modelo de regress√£o
linear, muito embora o seu poder preditivo ser√° baixo.

<br>

Por√©m, como j√° sabemos, ao menos conseguiremos o melhor or√°culo,
denotado por $\beta_{*}$, i.e., o melhor estimador dentre os poss√≠veis
estimadores lineares, como mostrado em teoremas anteriores.

<br>

E est√° tudo bem. Aqui n√£o estou querendo defender que voc√™ use uma
aproxima√ß√£o linear para esse caso. Em breve, com um pequeno truque,
poderemos ajustar uma regress√£o polinomial √† esses dados, e
incorporaremos um pouco da tend√™ncia n√£o linar presente nos dados.

## Ajustando uma regress√£o linear no R

<br>

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Veja o c√≥digo do gr√°fico"
#| fig-align: center
#| out-width: "1200px"
#| out-height: "700px"

library(ggplot2)

url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"

# Criando um arquivo tempor√°rio
arquivo_temp <- tempfile()

# Baixando um arquivo tempor√°rio
download.file(url = url, destfile = arquivo_temp)

# Carregando os dados
load(arquivo_temp)

dados_expectativa_renda |> 
  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +
  geom_point() +
  labs(
    title = "PIB per Capita versus Expectativa de Vida",
    x = "PIB per Capita",
    y = "Expectativa de Vida"
  ) +
  geom_smooth(method = "lm", se = FALSE) +
  theme(
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold")
  )
```

## Ajustando uma regress√£o linear no R

<br>

Claramente, a reta de regress√£o (linha azul) do gr√°fico anterior n√£o tem
um bom poder preditivo. O ajuste foi feito diretamente usando o pacote
[ggplot2](https://ggplot2.tidyverse.org/), utilizando a fun√ß√£o
`geom_smooth`, em que foi escolhido o m√©todo `"lm"`.

<br>

Poder√≠amos ter utilizado a fun√ß√£o `lm`:

<br>

```{r}
#| code-fold: true
#| code-summary: "Veja o c√≥digo do gr√°fico"
#| fig-align: center
#| out-width: "1200px"
#| out-height: "700px"
#| results: markup

library(ggplot2)

url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"

# Criando um arquivo tempor√°rio
arquivo_temp <- tempfile()

# Baixando um arquivo tempor√°rio
download.file(url = url, destfile = arquivo_temp)

# Carregando os dados
load(arquivo_temp)

# Ajustando o modelo usando a fun√ß√£o lm
ajuste <- lm(LifeExpectancy ~ GDPercapita, data = dados_expectativa_renda)

modelo <- function(x){
  novos_dados <- tibble::tibble(GDPercapita = x)
  predict(ajuste, newdata = novos_dados)
}

dados_expectativa_renda |> 
  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +
  geom_point() +
  labs(
    title = "PIB per Capita versus Expectativa de Vida",
    x = "PIB per Capita",
    y = "Expectativa de Vida"
  ) +
  stat_function(fun = modelo, color = "red", size = 1.2) +
  theme(
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold")
  )
```

## Matriz esparsa

<br>

Para grandes bases de dados, em um problema real que voc√™ venha
trabalhar, e se o custo computacional voc√™ considera elevado, poder√°
utilizar o pacote
[biglm](https://cran.r-project.org/web/packages/biglm/index.html).

<br>

Em situa√ß√µes em que h√° muitos zeros na sua matriz, poder√° utilizar
representa√ß√£o [esparsa](https://en.wikipedia.org/wiki/Sparse_matrix).

<br>

[Matrizes esparsas]{.red} s√£o matrizes com muitas entradas iguais √† $0$.
Elas ocorrem naturalmente em diversas aplica√ß√µes, como por exemplo uma
matriz de termos presentes em um documento, em que se o termo estiver no
documento resebe 1, e zero, caso contr√°rio. Abaixo, ${\bf X}$ √© um
exemplo de matriz esparsa.

<br>

$$
{\bf X} = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 2 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 3 & 0 & 0 \\
0 & 0 & 0 & 4 & 0 \\
\end{bmatrix}
$$

## Matriz esparsa

<br>

Considere os textos:

1.  [Texto 1]{.red}: "Eu amo essa disciplina."
2.  [Texto 2]{.red}: "Eu adoro meu professor."
3.  [Texto 3]{.red}: "Eu serei muito bom em aprendizagem de m√°quina."
4.  [Texto 4]{.red}: "Adoro o departamento de estat√≠stica da UFPB."

<br>

| Textos          | disciplina | amo | aprendizagem | m√°quina | estatistica | adoro | UFPB |
|---------|---------|---------|---------|---------|---------|---------|---------|
| [Texto 1]{.red} | 1          | 1   | 0            | 0       | 0           | 0     | 0    |
| [Texto 2]{.red} | 0          | 0   | 0            | 0       | 0           | 1     | 0    |
| [Texto 3]{.red} | 0          | 0   | 1            | 1       | 0           | 0     | 0    |
| [Texto 4]{.red} | 0          | 0   | 0            | 0       | 1           | 1     | 1    |

## Matriz esparsa

<br>

A matriz com a ocorr√™ncia de determinados termos nos textos √© dada por:

$$
{\bf X} = 
\begin{bmatrix}
1 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 1 & 1 \\
\end{bmatrix}
$$

A representa√ß√£o esparsa de ${\bf X}$, aqui denotada por ${\bf X_*}$ √©:

$$
{\bf X_*} = 
\begin{bmatrix}
1 & 1 & 1 \\
2 & 6 & 1 \\
3 & 3 & 1 \\
3 & 4 & 1 \\
4 & 5 & 1 \\
4 & 6 & 1 \\
4 & 7 & 1 \\
\end{bmatrix},
$$ em que as duas primeiras colunas, s√£o as linhas e colunas de
${\bf X}$ com valor diferente de 0. A √∫ltima coluna representa o valor.

## Regress√£o linear com matriz esparsa

<br>

**Exemplo**: Ajuste de um modelo de regerss√£o linear m√∫ltiplo, em que
${\bf X}$ poder√° ter uma representa√ß√£o esparsa. Aqui n√£o estamos
interessados em verificar qualidade de predi√ß√µes. Trata-se apenas de um
exemplo de como utilizar uma representa√ß√£o esparsa para ajustar um
modelo de regess√£o linear com algumas covari√°veis, em R.

<br>

```{r}
#| code-fold: true
#| code-summary: "Estude o c√≥digo"
library(glmnet)
library(Matrix)

# Dados de exemplo
x1 <- c(1, 0, 2, 0, 0)
x2 <- c(0, 3, 0, 4, 0)
x3 <- c(5, 0, 6, 0, 7)
y <- c(1, 2, 3, 4, 5)

# Criar data frame com as vari√°veis explicativas
dados <- data.frame(x1, x2, x3)

# Converter o data frame para matriz esparsa
X <- sparse.model.matrix(~ ., data = dados)

# Ajustar a regress√£o linear utilizando glmnet
modelo <- glmnet(x = X, y = y, alpha = 0, lambda = 0)

# Realizar previs√µes
predicoes <- predict(modelo, newx = X)
```

## Erro quadr√°tico m√©dio

<br>

Como exposto anteriormente, para avaliar o poder preditivo de uma
modelo, i.e., a aprendizagem de um modelo, devemos avaliar a fun√ß√£o de
risco, i.e., devemos avaliar
$R(g) := \mathbb{E}\left[L(g({\bf X}); Y)\right]$. Em particular,
considere $L = L_2$ (fun√ß√£o perda quadr√°tica). Ent√£o, poder√≠amos ser
levados a acreditar que o melhor estimador de $R(g)$, utilizando a Lei
dos Grandes N√∫meros seria:

$$\frac{1}{n}\sum_{i = 1}^n(Y_{i} - g({\bf X_{i}}))^2 \approx R(g) := \mathbb{E}\left[L_2(g({\bf X}); Y)\right].$$

<br>

Essa quantidade √© chamada, de **E**rro **Q**uadr√°tico **M**√©dio -
**EQM**. Desejamos escolher o melhor mode, entre os modelos testados,
que minimiza o EQM.

<br>

O apelo frequentista em utilizar a Lei dos Grandes N√∫meros na forma
acima n√£o √© correto, uma vez que usamos as $n$ observa√ß√µes para
treinar/ajustar o modelo $g$.

## Erro quadr√°tico m√©dio

<br>

Por exemplo, no problema de PIB per Capita versus expectativa de vida,
em que consideramos uma aproxima√ß√£o linear, n√£o poder√≠amos utilizar o
EQM da forma acima, com as $n$ observa√ß√µes utilizadas para treinar o
modelo. √â um detalhe sutil, mas que muitas pessoas cometem esse erro.

<br>

N√£o podemos utilizar as $n$ observa√ß√µes para estimar o risco $R(g)$
atrav√©s do EQM, uma vez que estamos utilizando o mesmo conjunto de dados
para ajustar e avaliar $g$.

<br>

**Qual o problema?**

<br>

1.  N√£o vale a Lei dos Grandes N√∫meros;
2.  Usamos os mesmos valores de ${\bf x}$ e $y$ para treinar e avaliar o
    modelo.

## Erro quadr√°tico m√©dio

<br>

O que diz a Lei dos Grandes N√∫meros, em particular, a Lei Forte de
Kolmogorov?

<br>

[Teorema]{.red} (**Lei Forte de Kolmogorov**): Sejam $X_1, \cdots, X_n$
uma sequ√™ncia de veri√°veis aleat√≥rias - v.a. i.i.d. e integr√°veis, i.e.,
com valor esperado limitado, tal que
$\mathbb{E}(X) = \mu\,\, \forall i$. Ent√£o,

$$\frac{X_1 + X_2 + \cdots + X_n}{n} \rightarrow \mu,$$

quase certamente, i.e., com probabilidade 1.

<br>

Note que se desejamos comparar diversos modelos,
$g_1({\bf x}), g_2({\bf x}), \cdots,$ e se utilizarmos as mesmas $n$
oberva√ß√µes para calularmos $R(g_1({\bf x})), R(g_2({\bf x})), \cdots$,
os termos de cada uma das somas **n√£o s√£o independentes**. Lembre-se que
desejamos obter $\argmin_g R_{pred}(g)$.

## Erro quadr√°tico m√©dio

<br>

Portanto, nunca utilize as mesmas observa√ß√µes utilizadas para treinar o
modelo, como aquelas que ser√£o utilizadas para se estimar $R(g)$. Nunca!
Isso √© um pecado mortal! Ok?!

<br>

![](gifs/thumbs-up-nod.gif){width="20%"}

## Data Splitting

<br>

Corrigir o problema de depend√™ncia que h√° ao estimarmos o risco usando o
EQM √© f√°cil. Uma abordagem muito utilizada √© utilizar [*data
splitting*]{.red}, tamb√©m chamado de m√©todo [hold-out]{.red}. Algo como
a segunda linha da imagem abaixo:

<br>

![](imgs/train-and-test-1-min-1.webp){width="35%"}

## Data Splitting

<br>

Essa divis√£o √© feita de forma aleat√≥ria, algumas vezes estratificada de
acordo com algumas vari√°v√°veis. A ideia de aleatorizar √© se livrar de
problemas de conjunto de dados ordenados. Queremos que tanto no conjunto
de treinamento [*Training*]{.red} quanto no conjunto de teste
[*Testing*]{.red}, na imagem, contenham a mesma diversidade de
observa√ß√µes.

<br>

Por exemplo, ainda no exemplo de PIB per Capita versus Expectaitiva de
Vida, n√£o quero correr o risco de ter no conjunto de treinamento apenas
o pa√≠ses com maiores valores de PIB per Capita, caso o conjunto de dados
tenha sido ordenado pela vari√°vel `GDPercapita`. Por isso aleatorizar o
conjunto de treinamento e teste √© simple uma √≥tima ideia. Certo!?

<br>

![](gifs/ok-2.gif){width="20%"}

## Data Splitting

<br>

O percentual de divis√£o dos dados normalmente √© emp√≠rico. Usa-se
normalmente a propor√ß√£o de $70\%$ para treinamento e $30\%$ para teste
$(70\%, 30\%)$. Outros esquemas de divis√µes s√£o bastante utilizados, por
exemplo, $(80\%, 20\%)$, $(99\%, 1\%)$, a depender da quantidade de
observa√ß√µes (tamanho do conjunto de dados).

<br>

Portanto, utilizar o EQM sob o conjunto de dados de teste para avaliar
$g_1({\bf x}), g_2({\bf x}), \cdots,$, √© uma boa estrat√©gia, uma vez que
agora n√£o teremos mais uma depend√™ncia no numerador do c√°lculo do EQM.
Em nota√ß√£o matem√°tica, poder√≠amos escrever como j√° apresentado
anteriormente, em @eq-risco-correto, i.e,

$$\frac{1}{m}\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \approx R(g) := \mathbb{E}\left[(Y - g({\bf X}))^2\right].$$

<br>

Esse resultado valeria para qualquer outra fun√ß√£o de perda.

## Data Splitting

Reescrevendo, suponha que o conjunto de dados total possua $n$
observa√ß√µes e que separamos aleatoriamente $s < n$ observa√ß√µes para o
conjunto de treinamento. Assim, temos, algo como:

<br>

$$\overbrace{(X_1, Y_1), (X_2, Y_2), \cdots, (X_s, Y_s)}^{70\%}, \,\,\, \overbrace{(X_{s + 1}, Y_{s + 1}), (X_{s + 2}, Y_{s + 2}), \cdots, (X_n, Y_n)}^{30\%}.$$

<br>

Ent√£o, temos que uma boa estimativa de $R(g)$ √© dada pelo EQM calculado
sobre o conjunto de dados de teste, que nesse caso considerei o conjunto
com $30\%$, mas esse percentual poderia ser outro. Ent√£o, temos que um
bom estimador √©:

$$\frac{1}{n - s}\sum_{i = s + 1}^n (Y_{i} - g(X_{i}))^2 \approx R(g) := \mathbb{E}\left[(Y - g({\bf X}))^2\right].$$

## Data Splitting

<br>

**Agora voc√™ entende por que dividimos os dados em treinamento e
teste?**

<br>

![](gifs/yes.gif){width="25%"}

<br>

Dividimos para obermos um bom estimador do risco utilizando o
[EQM](https://en.wikipedia.org/wiki/Mean_squared_error). üéä

## Data Splitting

<br>

Podemos argumentar que o procedimento de *data splitting*, em que
dividimos o nosso conjunto de dados em treinamento e teste far√° com que
venhamos perder muitas observa√ß√µes que poderiam ter sido utilizadas para
treinar o modelo. E de certa forma isso √© verdade, principalmente quando
termos um conjunto n√£o muito grande de observa√ß√µes.

<br>

Portanto, uma melhor abordagem, sendo esta uma varia√ß√£o do m√©todo de
*data splitting* √© o procedimento de [*cross-validation - cv (valida√ß√£o
cruzada)*](https://en.wikipedia.org/wiki/Cross-validation_(statistics)).
Uma vers√£o mais geral de uma valida√ß√£o cruzada √© o [*leave-one-out
cross-validation*]{.red}.

<br>

Em palavras, o procedimento consiste em tirar de fora uma √∫nica
observa√ß√£o das $n$ observa√ß√µes da base de dados para ser o nosso
conjunto de teste e treinar o modelo com as observa√ß√µes que
permaneceram. Da√≠, calcula-se o **risco observado** (EQM, sob o conjunto
de teste). Na segunda itera√ß√£o, a observa√ß√£o que antes era de teste
volta para perterncer ao conjunto de treinamento e uma nova observa√ß√£o √©
removida para ser teste. Esse procedimento ocorre de forma iterativa at√©
a retirada da √∫ltima observa√ß√£o como teste.

## Leave-one-out cross-validation

<br>

Observe a anima√ß√£o abaixo que ilustra o procedimento de
**l**eave-**o**ne-**o**ut **c**ross-**v**alidation - LOOCV, em uma
amostra de tamanho $n = 8$. Ao fim, teremos $n$ modelos ajustados, em
que calculamos as suas respectivas performances, i.e., com o risco
observado, estimamos o risco de $R(g)$.

<br>

![](gifs/LOOCV.gif)

## Leave-one-out cross-validation

<br>

Vejo muitas pessoas que usam uma valida√ß√£o cruzada, por exemplo,
leave-one-out cross-validation - LOOCV comparando com o m√©todo Jackknife
e algumas inclusive dizendo ser a mesma coisa. N√£o, n√£o s√£o!

<br>

O algoritmo Jackknife √© um procedimento de estima√ß√£o e que por sua vez
deve estar dentro do conjunto de treinamento. Para haver algum
Jackknife, a estimativa com $n-1$ observa√ß√µes deve estar dentro do
conjunto de treinamento, em que dentro do treinamento teria a remo√ß√£o de
um observa√ß√£o por vez. **Consegue perceber a diferen√ßa sutil?**

<br>

![](gifs/bean_01.gif){width="20%"}

## Leave-one-out cross-validation

<br>

O m√©todo LOOCV foi proposto por Stones (1974), no artigo intitulado
Cross-Validatory Choice and Assessment of Statistical Predictions, no
Royal Statistical Society, S√©rie B. Clique
[aqui](https://www.jstor.org/stable/pdf/2984809.pdf?refreqid=excelsior%3A3071b86b3588905b095d44668025b005&ab_segments=&origin=&initiator=&acceptTC=1)
se tiver curiosidade em ler o artigo.

<br>

Escrevendo o estimador do risco em um procedimento de LOOCV, temos que:

$$\widehat{R}(g) = \frac{1}{n}\sum_{i = 1}^n (Y_i - g_{-i}({\bf X}_i))^2,$$
em que $g_{-i}(\bf{X}_i)$, representa o ajuste do modelo no conjunto de
dados sem a $i$-√©sima observa√ß√£o.

<br>

N√£o √© dif√≠cil perceber que a depender do valor de $n$, o m√©todo LOOCV √©
**computacionalmente intensivo**. O m√©todo requer que ajustemos $n$
modelos. Em algumas situa√ß√µes isso n√£o √© um grande problema, por√©m, em
diversas outras pode ser impeditivo utilizar o LOOCV. ü§Ø

## $k$-fold cross-validation

<br>

Uma alternativa ao LOOCV √© utilizar o m√©todo $k$-fold cross-validation.
Nessa abordagem, dividimos o conjunto de dados em $k$-folds (lotes)
disjuntos e com aproximadamente o mesmo tamanho. Dessa forma, temos
$L_1, \cdots, L_k \subset \{1, \cdots, n\}$ s√£o, cada um, um conjunto de
indices aleat√≥rios associados a cada um dos lotes. A ideia aqui √©
construir $k$ estimadores da fun√ß√£o de regress√£o, denotados por
$\widehat{g}_{-1}, \cdots, \widehat{g}_{-k}$, em que $\widehat{g}_{-j}$
√© criado usando todas as observa√ß√µes do banco de dados, com exce√ß√£o
daquelas do lote $L_j$, utilizado para **valida√ß√£o**. O estimador do
risco √© dado por:

$$\widehat{R}(g) = \frac{1}{n}\sum_{j=1}^k \sum_{i \in L_j}(Y_i - g_{-j}({\bf X}_i))^2.$$
Perceba que, que o LOOCV √© um caso particular do $k$-fold
cross-validation, quando fazemos $k = n$. Em outras palavras,
$L_1, \cdots, L_k \subset \{1, \cdots, n\}$ representam os √≠ndices
aleat√≥rios do conjunto de treinamento nos $k$ lotes.

![](gifs/hum.gif)

## $k$-fold cross-validation

A anima√ß√£o abaixo, ilustra o procedimento de $3$-fold cross-validation
($k = 3$), para uma amostra de tamanho $n = 12$ observa√ß√µes. Note que os
valores que pertencem a cada um dos lotes s√£o aleat√≥rios. Portanto, o
procedimento LOOCV √© deterministico, j√° o procedimento de $k$-fold
cross-validation √© randomizado.

<br>

![](gifs/KfoldCV.gif)

Perceba que teremos agora apenas $3$ modelos. Para cada um desses lotes,
calulamos o EQM com o conjunto de teste (parte [azul]{.trueblue}) e
treinamos o modelo com o conjunto de treinamento (parte
[vermelha]{.truered}).

## $k$-fold cross-validation

<br>

Muitos modelos mais sofisticados apresentam hiperpar√¢metros (par√¢metros
de sintoniza√ß√£o) que n√£o dependem dos dados. √â muito comum os algoritmos
de aprendizagem de m√°quina se utilizarem do procedimento de valida√ß√£o
cruzada, para al√©m da estima√ß√£o do risco $R(g)$.

<br>

Ao estimar $k$ modelos, normalmente faz-se um grid de poss√≠veis valores
para esses hiperpar√¢metros em que ao final, escolhe-se como
hiperpar√¢metro o modelo com menor EQM. Por fim, ajusta-se um modelo
final, com todo o conjunto de treinamento usando o valor do
hiperpar√¢metro que retornou o menor EQM no conjunto de valida√ß√£o.

<br>

![](gifs/ok.gif)

## $k$-fold cross-validation

<br>

::: columns
::: {.column width="50%"}
O termo [valida√ß√£o]{.red} refere-se √† parcela do conjunto de treinamento
incial que dividimos em valida√ß√£o e treinamento, dentro de uma valida√ß√£o
cruzada.

<br>

O conjunto [*Testing*]{.red} na segunda hierarquia da √°rvore ao lado, s√≥
usamos no final para avaliar o desempenho do modelo nesse conjunto.

<br>

Perceba que o conjunto de treinamento ([*Not Testing*]{.red}) √©
particionado em treinamento e valida√ß√£o. Poder√≠amos fazer uma √∫nica
parti√ß√£o, mas o procedimento comumente utilizado √© particionar entre
[*Training*]{.red} e [*Validation*]{.red} uzando algum procedimento de
valida√ß√£o cruzada.
:::

::: {.column width="50%"}
![](imgs/validation-split.svg){fig-aling="center" width="64%"}
:::
:::

## $k$-fold cross-validation

A imagem abaixo ilustra o procedimento $k$-fold cross-validation, em que
uma $5$-fold cross-validation √© realizada dentro do conjunto de
treinamento. Em cada *split*, o conjunto verde de observa√ß√µes (fold
[verde]{.green}) s√£o utilizados para treinar/ajustar o modelo e o
conjunto [azul]{.trueblue}, em cada um dos *splits* √© utilizado para
avaliar o risco preditivo $R(g)$ (atrav√©s, por exemplo do EQM).

::: columns
::: {.column width="40%"}
![](imgs/grid_search_cross_validation.png){width="800"}
![](gifs/hum.gif)
:::

::: {.column width="60%"}
N√£o confunda os folds azuis com o conjunto de teste ([Test
data]{.trueblue}), este √∫ltimo utilizado por fim, depois do modelo
pronto, para avaliar o desempenho do modelo treinado.

Note tamb√©m que a valida√ß√£o cruzada tamb√©m √© utilizada para o ajuste de
hiperpar√¢metros, que s√£o par√¢metros de sintoniza√ß√£o que n√£o dependem dos
dados para serem equalizados. Por exemplo, em uma regress√£o lasso, que
veremos adiante, h√° o hiperpar√¢metro $\lambda$ que precisamos obter,
normalmente por meio de um [grid search]{.red} (sequ√™ncia finita), por
exemplo, $\lambda \in [0.5, 1, 1.5, 2, 2.5]$ de poss√≠veis valores. Cada
*split* pode ser utilizado para avaliar um valor de $\lambda$, dos
poss√≠veis valores dispostos no grid. Aumentar√≠amos a quantidade de
splits para mais valores de $\lambda$ na sequ√™ncia.
:::
:::

## Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o

::: columns
::: {.column width="50%"}
![](imgs/data_split_validation_cross.png)
:::

::: {.column width="50%"}
O simples procedimento de dividir o conjunto de dados em dois, uma parte
para treinar o modelo e a outra parte (conjunto de teste) para estimar o
risco $R(g)$ √© denominado de [*data splitting*]{.red} ou [*Hold-out
Method*]{.red}. √â um procedimento mais simples, por√©m, pode n√£o ser √∫til
em conjunto de dados n√£o muito grandes.

A segunda linha da ilustra√ß√£o, demonstra o procedimento de
cross-validation (valida√ß√£o cruzada), procedimento mais utilizado nos
treinamentos de modelos de aprendizagem de m√°quina.

A terceira linha √© uma abordagem tamb√©m utilizada, por√©m n√£o t√£o
interessante quanto a valida√ß√£o cruzada. Nessa abordagem o banco de
dados √© dividido aleatoriamente em tr√™s partes. Treina-se o modelo com a
parte [verde]{.green}, estima-se o risco com o conjunto de valida√ß√£o
amarelo e testa-se o modelo com o conjunto de teste.
:::
:::

## Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o

<br> A abordagem do conjunto de valida√ß√£o envolve dividir o conjunto de
treinamento em duas partes: uma parte √© usada para treinar o modelo e a
outra parte √© usada para avaliar o desempenho do modelo. O conjunto de
valida√ß√£o √© utilizado para ajustar os hiperpar√¢metros do modelo, como a
taxa de aprendizado, o n√∫mero de camadas ocultas em uma rede neural,
entre outros. Ap√≥s o ajuste dos hiperpar√¢metros, o modelo final √©
treinado com o conjunto de treinamento completo e avaliado em um
conjunto separado chamado conjunto de teste. Essa abordagem √© conhecida
como divis√£o simples de treinamento/valida√ß√£o/teste.

<br>

Por outro lado, a valida√ß√£o cruzada $k$-fold √© uma abordagem que visa
obter uma estimativa mais robusta do desempenho do modelo. Nessa
abordagem, o conjunto de treinamento √© dividido em k subconjuntos
(folds) de tamanho aproximadamente igual. O modelo √© treinado $k$ vezes,
cada vez usando $k-1$ folds como conjunto de treinamento e $1$ fold como
conjunto de valida√ß√£o. O desempenho do modelo √© ent√£o calculado como a
m√©dia dos resultados obtidos em cada itera√ß√£o. Isso permite avaliar o
modelo de forma mais precisa, pois utiliza todos os dados para
treinamento e valida√ß√£o, evitando a depend√™ncia de uma √∫nica divis√£o do
conjunto de treinamento.

## Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o

<br>

A valida√ß√£o cruzada $k$-fold √© particularmente √∫til quando o conjunto de
dados √© limitado, pois aproveita ao m√°ximo os dados dispon√≠veis. Al√©m
disso, ela permite verificar se o modelo √© est√°vel e se seu desempenho
varia significativamente com diferentes divis√µes dos dados. √â importante
ressaltar que a valida√ß√£o cruzada $k$-fold pode ser computacionalmente
mais cara do que a abordagem do conjunto de valida√ß√£o, uma vez que
envolve treinar e avaliar o modelo v√°rias vezes.

<br>

![](gifs/mr-bean-pivot.gif){width="40%"}

## Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o

<br>

Um outro detalhe que muitas vezes n√£o √© falado √© que apesar de temos
duas tarefas de estima√ß√£o, uma envolvendo o conjunto de **treinamento**,
em que treinamos o modelo e outra envolvendo o conjunto de **teste**, em
que queremos estimar o risco $R(g)$, de modo a poder selecionar o melhor
modelo, a segunda tarefa √© bem mais f√°cil √â por isso que o conjunto de
treinamento tende a ser menor que o conjunto de teste.

<br>

![](gifs/hum.gif)

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

A ideia de precis√£o e exatid√£o est√£o ligadas ao vi√©s e vari√¢ncia do
modelo $g$, em que precis√£o est√° ligado a ideia de vari√¢ncia pequena e
exatid√£o est√° ligada a ideia de baixo vi√©s. A ideia √© termos um
estimador pr√≥ximo o que ilustra o item [d]{.red}. Muitas vezes temos um
estimador nas situa√ß√µes [b]{.red} e [c]{.red}. O ideal √© o balan√ßo de
vi√©s e vari√¢ncia, que seria o estimador ilustrado pelo item [d]{.red}.

![](imgs/precisao_exatidao.png){fig-align="center" width="55%"}

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

Um grande apelo para o uso do risco quadr√°tico, i.e., risco que utiliza
a fun√ß√£o de perda $L_2$ √© sua interpretabilidade. Temos que o risco
quadr√°tico $R(g)$ condicional a um novo ${\bf x}$ poder√° ser decomposto
por:

$$\mathbb{E}\left[(Y - \widehat{g}({\bf X}))^2| {\bf X} = {\bf x}\right] = \underbrace{\mathbb{V}[Y | {\bf X = x}]}_{\mathrm{i - Vari√¢ncia\,\, intr√≠nseca}} + \overbrace{(r({\bf x}) - \mathbb{E}[\widehat{g}({\bf x})])^2}^{\mathrm{ii - Vi√©s\, ao\, quadrado\, do\, modelo}} + \underbrace{\mathbb{V}[\widehat{g}({\bf x})]}_{\mathrm{iii - Vari√¢ncia\, do\, modelo}}.$$
**Temos que**:

<br>

i - √â a vari√¢ncia intr√≠nseca da vair√°vel resposta (*label*), que n√£o
depende da fun√ß√£o $\widehat{g}$ escolhida e, assim, n√£o poder√° ser
reduzida. Na verdade, poderemos reduzir $i$, se incluirmos mais
*features* (covari√°veis/vari√°veis explicativas) ao nosso modelo;

ii - √â o vi√©s ao quadrado do estimador $\widehat{g}$ (vi√©s ao quadrado
do modelo);

iii - √â a vari√¢ncia do estimador $\widehat{g}$.

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

Assim, lembre-se que uma escolha adequada de $\widehat{g}$ nos garante
que conseguiremos reduzir o risco preditivo $R(g)$, pois a escolha
apropriada implica em escolhermos um estimador de $\widehat{g}$ com
balan√ßo entre v√≠es e vari√¢ncia.

<br>

Modelos com muitos par√¢metros possuem vi√©s relativamente baixo, por√©m,
tendem a ter vari√¢ncia muito alta, em geral, uma vez que precisamos
estimar muitos par√¢metros. J√° modelos com poucos par√¢metros, normalmente
tendem a ter vari√¢ncia baixa, acompanhados normalmente de um alto vi√©s.

<br>

Geralmente, modelos com muitos par√¢metros nos levam a termos
[*overffiting*]{.red} (super-ajuste), o que n√£o √© bom pois s√£o
acompanhados de alta vari√¢ncia. J√° modelos muito simplistas nos conduzem
√† um ajuste muito ruim ([*underffiting*]{.red} ou sub-ajuste).
Entendeu!?

![](gifs/mais_ou_menos.gif)

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

```{r}
#| code-fold: true
#| code-summary: "Estude o c√≥digo"
#| eval: false
library(ggplot2)
library(tibble)
library(ggplot2)
library(patchwork)

# Fun√ß√£o de regress√£o verdadeira. Na pr√°tica √© desconhecida.
regressao_verdadeira <- function(x)
  45 * tanh(x/1.9 - 7) + 57

observacoes_regressao_real <- function(n, desvio_padrao = 0.2) {
  # Permitindo que o mesmo x possa ter dois pontos de y, como ocorre na 
  # pratica
  seq_x <- sample(seq(0, 17.5, length.out = n), size = n, replace = TRUE)
  
  step <- function(x)
    regressao_verdadeira(x) + rnorm(n = 1L, mean = 0, sd = desvio_padrao)
  
  tibble::tibble(y = purrr::map_vec(.x = seq_x, .f = step), x = seq_x)
}

# Usaremos uma regress√£o polinomial para tentar ajustar √† regress√£o -------
regressao_polinomial <- function(n = 30L, desvio_padrao = 4, grau = 1L) {
  
  dados <- observacoes_regressao_real(n = n, desvio_padrao = desvio_padrao)
    
  iteracoes <- function(tibble_data, grau) {
      x <- tibble_data$x
      iteracoes <- lapply(X = 2L:grau, FUN = function(i) x^i)
      
      result <- cbind(tibble_data, do.call(cbind, iteracoes))
      colnames(result)[(ncol(tibble_data) + 1):ncol(result)] <- paste0("x", 2L:grau)
      
      as_tibble(result)
  }  
  
  if(grau >= 2L)
    dados <- iteracoes(dados, grau = grau)
  
  ajuste <- lm(formula = y ~ ., data = dados)
  dados$y_chapeu <- predict(ajuste, new.data = dados)
  
  dados |> 
    dplyr::relocate(y_chapeu, .before = x)
}

plotando <- function(dados){
  dados |>  
    ggplot(aes(x = x, y = y_chapeu)) +
    geom_point()
}

mc_ajustes <- function(mc = 100L, n = 50L, desvio_padrao = 5, grau = 1L){

  p <- 
    ggplot(data = NULL) +
      coord_cartesian(xlim = c(0, 17.5), ylim = c(0, 110)) +      
      ylab("Valores estimados")
  
  df <- NULL
  for(i in 1L:mc){
    df <- regressao_polinomial(n = n, desvio_padrao = desvio_padrao, grau = grau)
    p <- p + geom_line(data = df, aes(x = x, y = y_chapeu))
  }
  p + 
    stat_function(fun = regressao_verdadeira, col = "red", size= 1.4) +
    labs(
      title = "Regress√£o Polinomial",
      subtitle = paste("Grau: ", grau)
    ) +
    theme(
      plot.title = element_text(face = "bold"),
      axis.title = element_text(face = "bold")
    )
}

# Fixando uma semente
set.seed(0)

p1 <- mc_ajustes(grau = 1, n = 100, desvio_padrao = 10)
p2 <- mc_ajustes(grau = 7, n = 100, desvio_padrao = 10)
p3 <- mc_ajustes(grau = 70, n = 100, desvio_padrao = 10)
p4 <- mc_ajustes(grau = 200, n = 100, desvio_padrao = 10)

p <- ((p1 | p2) / (p3 | p4)) + plot_annotation(tag_levels = "A")

ggsave(p, file = "imgs/vies_variancia.png", device = "png", width = 40, height = 30, units = "cm")
```

![](imgs/vies_variancia.png){fig-align="center" width="60%"}

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

Experimente de forma interativa altera a complefixade do modelo.

<br>

```{=html}
 <iframe id="example1" src="https://pedro-rafael.shinyapps.io/shiny_apps/" style="border: none; width: 100%; height: 90%" frameborder="0"></iframe>
```
## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

No exemplo anterior, note que os par√¢metros dos modelos s√£o os
coeficientes $\beta$'s que indexam a regress√£o polinomial. Por√©m,
perceba que √° um par√¢metro de sintoniza√ß√£o ([*tuning parameter*]{.red})
que √© o valor de $p$, isto √©, qual o grau do polin√¥mio que iremos
utilizar.

<br>

Normalmente a escolha √© feita realizando um [*grid search*]{.red} por
meio de um [*cross-validation*]{.red}.

<br>

No exemplo anterior, fizemos uma simula√ß√£o e observamos que ao
considerar graus nem muito grandes nem muito pequenos, aparentemente
teremos escolhas razo√°veis.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

[Exemplo]{.red}: Consedere os dados de expectativa de vida versus PIB
per Capita, dispon√≠veis
[aqui](https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData).
Selecione o melhor estimador $g$ da classe $\mathbb{G}$, em que

$$\mathbb{G} = \left\{g(x)\,\,:\,\, \beta_0 + \sum_{i = 1}^p \beta_i x^i\,\, \text{para } p \in \{1, 2, \cdots,11\} \right\}.$$
Note que selecionar o melhor polin√¥mio √© uma busca em $p$. Devemos
utilizar o erro quadr√°tico m√©dio - EQM sob o conjunto de valida√ß√£o, uma
vez que sabemos que apenas em um conjunto de valida√ß√£o ou em novas
observa√ß√µes o estimador do risco pelo EQM √© consistente, pela Lei dos
Grandes N√∫meros.

<br>

Vamos utilizar a biblioteca
[rsample](https://rsample.tidymodels.org/index.html) para a tarefa de
valida√ß√£o cruzada. Leia a documenta√ß√£o da biblioteca, em especial, a da
fun√ß√£o `vfold_cv`, respons√°vel por construir a valida√ß√£o cruzada. Na
verdade ela faz a divis√£o da base de dados em $v$ *splits* de tamanho
aproximadamente iguais. Por padr√£o, $v = 10$. Esse √© o procedimento de
$k$-*fold cross-validation* que apresentamos aqui, em que $v = k$.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

Algumas observa√ß√µes gerais a respetio da biblioteca
[rsample](https://rsample.tidymodels.org/index.html), que s√£o √∫teis para
resolver esse problema:

![](imgs/rsample.png){fig-align="center"}

1.  Para realizar uma **primeira divis√£o** do conjunto de dados (*data
    splitting/hold-out*), utiliza-se a fun√ß√£o `initial_split`;
2.  Para acessar o conjunto de **treinamento** dos dados, usamos a
    fun√ß√£o `training`;
3.  Para acessar o conjunto de **teste**, usamos a fun√ß√£o `testing`;
4.  Para constuir todas as divis√µes da valida√ß√£o cruzada, entre
    treinamento e valida√ß√£o, no conjunto de treinamento inicial, usamos
    a fun√ß√£o `vfold_cv` j√° mencionada;
5.  Para acessar o conjunto de **treinamento** de um *split* da
    valida√ß√£o cruzada, usamos a fun√ß√£o `analysis`;
6.  Para acessar o conjunto de **valida√ß√£o**, utilizamos a fun√ß√£o
    `assessment`.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

![](imgs/rsample.png){fig-align="center" width="5%"}

<br> Note que realizar uma valida√ß√£o cruzada √© importante para podemos
selecionar o melhor polin√¥mio, i.e., o melhor valor de $p$. Caso
venhamos negligenciar esse aspecto da an√°lise, iremos cair na fal√°cia de
acreditarmos que quanto maior o grau do polin√¥mio, maior ser√° o poder
preditivo do modelo. Isso n√£o √© verdade e voc√™ dever√° selecionar o
melhor modelo dentro de um esquema de valida√ß√£o cruzada.

<br>

No mundo de aprendizagem de m√°quina, muitos chamam o processo de
encontrar o melhor hiperpar√¢metro de ["tunagem"]{.red}. Em v√°rios
modelos, podemos ter mais de um.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

As Figuras abaixo, mostram a avalia√ß√£o dos polin√¥mios da classe
$\mathbb{G}$, usando o risco estimado $\widehat{R}(g)$ pelo erro
quadr√°tico m√©dio - EQM. Por√©m, a Figura [A]{.red} aprenseta a avalia√ß√£o
dos modelos, usando simplesmente o conjunto de treinamento e a Figura
[B]{.red} aprensenta a avalia√ß√£o do grau do polin√¥mio considerando uma
valida√ß√£o cruzada dentro do conjunto de treinamento.

<br> ![](imgs/avaliacao_risco.png){fig-align="center"}

<br>

A mensagem equivocada passada pela Figura [A]{.red} √© que supostamente
aumentar a complexidade do modelo seria uma uma boa alternativa e nos
conduzir√≠amos √† bons modelos preditivos. Mas sempre se lembre do
equil√≠brio que temos que ter entre vi√©s e vari√¢ncia. A Figura [B]{.red}
mostra que um polin√¥mio com grau pr√≥ximo √† $p = 8$ √© a melhor
alternativa.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

Observe o *dashboard* interativo! Sabemos que para que tenhamos uma boa
estimativa do risco preditivo, devemos utilizar novas observa√ß√µes. No
*dashboard* √© poss√≠vel observar que a forma errada (usando o conjunto de
treinamento para avaliar o risco), sugere que sempre ser√° bom adicionar
mais par√¢metros ao modelo, levando a *overfitting*. Perceba que usando a
forma correta (usando valida√ß√£o cruzada), o EQM (risco estimado) sugere
que n√£o podemos aumentar muito a quantidade de par√¢metros.

<br>

```{=html}
 <iframe id="example1" src="https://pedro-rafael.shinyapps.io/shiny_apps/#section-avalia%C3%A7%C3%A3o-do-risco-preditivo" style="border: none; width: 100%; height: 90%" frameborder="0"></iframe>
```
## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

Abaixo voc√™ poder√° acessar o c√≥digo que soluciona o problema. O
par√¢metro `errado = FALSE` da fun√ß√£o valida√ß√£o no c√≥digo que segue,
conduz a solu√ß√£o correta (usando a valida√ß√£o cruzada), que sempre voc√™
dever√° considerar na pr√°tica.

<br>

```{r}
#| code-fold: true
#| code-summary: "Estude o c√≥digo da solu√ß√£o de exemplo"
#| eval: false

library(rsample)
library(yardstick)
library(tibble)
library(purrr)
library(ggplot2)
library(patchwork)

# Lendo dados
url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"
arquivo_temp <- tempfile()
download.file(url = url, destfile = arquivo_temp)
load(arquivo_temp)

dados <- 
  dados_expectativa_renda |> 
  dplyr::select(-CountryName) |> 
  dplyr::rename(y = LifeExpectancy, x = GDPercapita)
  
iteracoes <- function(tibble_data, grau) {
  x <- tibble_data$x
  iteracoes <- lapply(X = 2L:grau, FUN = function(i) x^i)
  
  result <- cbind(tibble_data, do.call(cbind, iteracoes))
  colnames(result)[(ncol(tibble_data) + 1):ncol(result)] <- paste0("x", 2L:grau)
  
  as_tibble(result)
}  

regressao_polinomial <- function(dados, grau = 1L) {
  if(grau >= 2L)
    dados <- iteracoes(dados, grau = grau)
  
  lm(formula = y ~ ., data = dados)
}

# Divis√£o dos dados
divisao_inicial <- rsample::initial_split(dados)
treinamento <- rsample::training(divisao_inicial)
teste <- rsample::testing(divisao_inicial) # Teste final

# v-folds cross-validation
validacao <- function(dados, grau = 1L, errado = FALSE, ...){
  
  # Todas as divis√µes da validacao cruzada
  cv <- rsample::vfold_cv(dados, ...)
  
  hiper <- function(i){
    treino <- rsample::analysis(cv$splits[[i]]) # Treinamento
    validacao <- rsample::assessment(cv$splits[[i]]) # Validaca√ß√£o
    ajuste <- regressao_polinomial(dados = treino, grau = grau)
    
    if(errado){
      df_treino <- iteracoes(treino, grau = grau)
      df_treino <- df_treino |> dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_treino))
      yardstick::rmse(data = df_treino, truth = y, estimate = y_chapeu)$.estimate
    } else {
      df_validacao <- iteracoes(validacao, grau = grau)
      df_validacao <- df_validacao |> dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_validacao))
      yardstick::rmse(data = df_validacao, truth = y, estimate = y_chapeu)$.estimate
    }
  }
  purrr::map_dbl(.x = seq_along(cv$splits), .f = hiper) |> 
    mean()
}

plot_avaliacao <- function(dados, errado = FALSE){
  # Testando iterativamente, v√°rios valores de p:
  p <- seq(1L:11L)
  risco <- purrr::map_dbl(.x = p, .f = \(p) validacao(dados = dados, grau = p, errado = errado))
  df_risco <- tibble::tibble(p = p, risco = risco)
  
  # Plotando
  df_risco |> 
    ggplot(aes(x = p, y = risco, color = risco)) +
    geom_point(size = 5) +
    scale_x_continuous(breaks = p) +
    scale_y_continuous(breaks = p) +
    labs(
      title = "Valiando o risco estimado para diversos graus do polin√¥mio",
      subtitle = "EQM no conjunto de valida√ß√£o"
    ) +
    theme(
      plot.title = element_text(size = 18, face = "bold"),
      plot.subtitle = element_text(size = 16),
      axis.text = element_text(size = 10), 
      axis.title = element_text(size = 14, face = "bold")
    )
}

# Avaliac√£o errada versus correta
set.seed(0)
grafico <- 
  plot_avaliacao(dados, errado = TRUE) + 
  plot_avaliacao(dados, errado = FALSE) +
  plot_annotation(tag_levels = c("A", "B"))

ggsave(grafico, file = "imgs/avaliacao_risco.png", device = "png", width = 50, height = 20, units = "cm", limitsize = F)

plot_bar <- function(grau){
  ruim <- validacao(dados, errado = TRUE, grau = grau)
  bom <- validacao(dados, errado = FALSE, grau = grau)
  df <- tibble::tibble(x = c("Errado", "Certo"), y = c(log(ruim), log(bom)))
  
  df |> 
    ggplot(aes(x = x, y = y)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = y), vjust = 0)
}
```

![](gifs/mr-bean-pivot.gif)

## üìö Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Explique resumidamente o que √© aprendizagem
supervisionada e n√£o-supervisionada. Cite um problema de aprendizagem
supervisionada e um outro de aprendizagem n√£o-supervisionada.

<br>

[Exerc√≠cio]{.red}: Considere o conjunto de dados de Expectativa de vida
versus PIB per Capita, dispon√≠vel
[aqui](https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData).
Considere a fun√ß√£o $g$, da seguinte forma:

$$g(x) = \beta_0 + \sum_{i = 1}^p \beta_i x^i,$$ com
$p \in \{1, 2, ..., 50\}$. Utilizando o erro quadr√°tico m√©dio observado,
sem fazer nenhuma estrat√©gia de divis√£o dos dados, implemente um c√≥digo
em R para checar qual o melhor modelo.

<br>

[Exerc√≠cio]{.red}: Explique qual o motivo que faz com que o Erro
Quadr√°tico M√©dio - EQM para avaliar o desempenho de um modelo √© ruim
quando n√£o adotamos nenhuma estrat√©gia de divis√£o do conjunto de dados
em treinamento e teste.

## üìö Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Com suas palavras, explique o dilema de balan√ßo entre
v√≠es e vari√¢ncia.

<br>

[Exerc√≠cio]{.red}: Refa√ßa o exerc√≠cio do polin√¥mio, utilizando a
estrat√©gia de [*data splitting*]{.red}, em que divide-se o conjunto de
dados em treinamento e teste. Utilize o conjunto de teste para calcular
a estimativa do risco, usando o EQM.

<br>

[Exerc√≠cio]{.red}: Ainda considerando o exerc√≠cio do polin√¥mio,
implemente uma estrat√©gia de [*leave-one-out cross-validation*]{.red} e
selecione o melhor modelo minimizando a fun√ß√£o de risco.

<br>

[Exerc√≠cio]{.red}: Por fim, considerando o exerc√≠cio do polin√¥mio,
rafa√ßa-o utilizando um procedimento de [$k$-fold
cross-validation]{.red}. Considere $k = 5$. **Dica**: considere utiliza
a biblioteca [rsample](https://rsample.tidymodels.org/).

![](imgs/rsample.png)

## Melhor subconjunto de covari√°veis

<br>

O estimador de m√≠nimos quadrados - EMQ, na presen√ßa de muitas *features*
(covari√°veis), i.e., quando temos $d$ grande, possui um baixo poder
preditivo devido *overfitting* (super-ajuste). Isso, porqu√™ haver√°
muitos par√¢metros a serem estimados, e portanto, a fun√ß√£o de regress√£o
estimada $\widehat{r}({\bf x})$ ter√° baixo poder preditivo.

<br>

Isso se deve ao fato do balan√ßo de vi√©s e vari√¢ncia. Havendo muitos
par√¢metros, como j√° tinhamos visto, a vari√¢ncia do modelo ser√° muito
alta.

<br>

**Portanto, deveremos buscar meios de encontrar o melhor (ao menos um
bom) comjunto de covari√°veis.**

<br>

![](gifs/chapulin-colorado-no.gif){width="20%"}

## Melhor subconjunto de covari√°veis

<br>

A ideia para resolver esse problema √© retirar algumas covari√°veis do
modelo de regress√£o, com o objetivo de diminuir a vari√¢ncia de
$\widehat{g}$.

<br>

Voc√™ poder√° entender que estamos em busca de um estimador $\widehat{g}$
de $g$ um **pouco** mais viesado. Trata-se de uma troca em que desejamos
reduzir substancialmente a variabilidade do estiamdor do modelo e troca
de ganharmos um pouco mais de vi√©s.

<br>

![](gifs/kiko.gif)

## Melhor subconjunto de covari√°veis

<br>

Matematicamente, uma maneira de fazer isso, √© buscar a estimativa para

$$\widehat{\beta}_{L_0} = \argmin_{\beta_0 \in \mathbb{R}, \beta \in \mathbb{R}^d}\sum_{k = 1}^n\left(y_k - \beta_0 - \sum_{i = 1}^d \beta_i x_{x,i}\right)^2 + \lambda \,\,\underbrace{\sum_{i = 1}^d \mathbb{I}(\beta_i \neq 0)}_{\text{Penaliza√ß√£o}}.$$ {#eq-risco-penalizacao}

Note que a penaliza√ß√£o $\sum_{i = 1}^d \mathbb{I}(\beta_i \neq 0)$ nos
conduz na dire√ß√£o de modelos com poucas covari√°veis, quando $\lambda$ √©
um valor alto. Em particualr, quando $\lambda \to \infty$, for√ßamos a
retirada de todas as covari√°veis $\beta_i$'s, i.e., a solu√ß√£o para o
problema seria $\widehat{\beta}_{L_0} \equiv (\overline{y}, {\bf 0})$.
Note que n√£o h√° penaliza√ß√£o para o intercepto $\beta_0$.

<br> No outro extremo, para $\lambda = 0$, temos o estimador de m√≠nimos
quadrados, em que nenhuma penaliza√ß√£o ser√° considerada.

<br> [N√£o h√° uma forma f√°cil de minimizar
$\widehat{\beta}_{L_0}$.]{.red}

## Melhor subconjunto de covari√°veis

<br>

Poder√≠amos, ingenuamente, pensar em ajustar todas as combina√ß√µes
poss√≠veis de par√¢metros e utilizar algum crit√©rio, por exemplo, o EQM em
novas observa√ß√µes para escolher o melhor modelo de todas as combina√ß√µes
poss√≠veis. Isto √©, escolher o melhor modelo entre todas as $2^d$
combina√ß√µes poss√≠veis de modelos em $\mathbb{G}$.

<br>

Se $\widehat{\lambda} = \frac{2}{n}\widehat{\sigma}^2$, estimar
$\widehat{\beta}_{L_0}$ equivale uma busca entre $2^d$ modelos da classe
$\mathbb{G}$:

<br>

```{=tex}
\begin{align*}
\mathbb{G} = \{
&g({\bf x}) = \widehat{\beta}_0, \\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_2x_2,\\
&\cdots\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_dx_d,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_2x_2,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_3x_3,\\
&\cdots\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_dx_d,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_2x_2 + \widehat{\beta}_3x_3,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_2x_2 + \widehat{\beta}_dx_d,\\
&\cdots\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_2x_2 + \widehat{\beta}_3x_3 + \cdots + &\widehat{\beta}_dx_d
\}.
\end{align*}
```
## Melhor subconjunto de covari√°veis

<br>

Utilizar $\lambda = \frac{2}{n}\widehat{\sigma}^2$ √© o mesmo que
utilizar o crit√©rio AIC para determinar o melhor modelo, em que dado

$$\widehat{R}(g) = \frac{1}{m}\sum_{k = 1}^m \underbrace{(\widetilde{Y}_k - g({\bf \widetilde{X}}_k))^2}_{W_k},$$
em que
$(\widetilde{{\bf X}}_1, \widetilde{Y}_1), \cdots, (\widetilde{{\bf X}}_m, \widetilde{Y}_m)$,
representa o conjunto de teste, i.e., calculado com base em $m$
observa√ß√µes em um conjundo de dados n√£o utilizados para treinar o
modelo, independentemente da estrat√©gia de divis√£o utilizada, em que

$$\widehat{\sigma}^2 = \frac{1}{m}\sum_{k = 1}^m (W_k - \overline{W})^2,$$
com $\overline{W} = \frac{1}{m}\sum_{k=1}^m W_k$.

## Melhor subconjunto de covari√°veis

<br>

Temos que $\widehat{R}(g)$, calculado em novas observa√ß√µes (oboserva√ß√µes
n√£o utilizadas no treinamento), pode se valer do Teorema Central do
Limite, uma vez que $\widehat{R}(g)$ √© calculado em uma sequ√™ncia de
vari√°veis aleat√≥rias i.i.d.'s. Ent√£o:

$$\widehat{R}(g) \sim \text{Normal}\left(R(g), \frac{1}{m}\mathbb{V}[W_1]\right).$$

Portanto, um intervalo aleat√≥rio de aproximadamente $95\%$ de confian√ßa
para o erro preditivo $R(g)$ poder√° ser calculado como:

$$\widehat{R}(g) \pm 1,645 \sqrt{\frac{1}{m}\widehat{\sigma}^2}.$$

O c√°lculo de um intervalo de confian√ßa poder√° ser √∫til para entendermos
como est√° variando o risco preditivo do nosso modelo. Gostamos de ter
modelos com intervalo de amplitude pequena. O intervalo poder√° ser
utilizado para fornecer insight de como escolher a divis√£o de
treinamento e teste. Por exemplo, pode-se escolher o menor valor de $m$
de modo que a amplitude seja a menor poss√≠vel.

## Melhor subconjunto de covari√°veis

<br>

Por que essa seria uma escolha ing√™nua? Pense na situa√ß√£o em que temos
$d = 30$, i.e., trinta covari√°veis. Ter√≠amos portanto $2^{30}$ modelos
para ajustar, ou seja, um bilh√£o e setenta e tr√™s milh√µes, setecentos e
quarenta e um mil, oitocentos e vinte e quatro modelos para ajustar. √â
um a quantidade absurda de modelos para serem estimados!

<br>

Se $d = 100$, ter√≠amos que estimar uma quantidade de modelos que a
quantidade estimada de estrelas no universo. Alias, seriam mais modelos
para ajustar que a quantidade de √°tomos no universo.

<br>

![](gifs/side-eyeing-chloe-chloe.gif)

## Regress√£o *Stepwise*

<br> Devido a impossibilidade de experimentar uma grande quantidade de
modelos ($2^d$), existe uma s√©rie de algoritmos (heur√≠sticas), que visam
reduzir a quantidade de modelos avaliados. Um dos mais conhecidos √© o
[forward stepwise]{.red}. Trata-se de um algoritmo sequencial, que em
cada passo, apenas uma vari√°vel √© adicionada:

<br>

1 - Para $j = 1, \cdots, d$, ajuste a regress√£o de $Y$ na $j$-√©sima
vari√°vel $X_j$. Seja $\widehat{R}(g_j)$ o risco estimado desta fun√ß√£o.
Ent√£o,

$$\widehat{j} = \argmin_j \widehat{R}(g_j)\,\,\,\,\,\, \text{e}\,\,\,\,\,\, S = \{\widehat{j}\}.$$
2 - Para cada $j \in S^c$, ajuste a regress√£o
$Y = \beta_jX_j + \sum_{s \in S}\beta_sX_S$, em que $\widehat{R}(g_j)$ √©
o risco estimado desta fun√ß√£o. Defina

$$\widehat{j} = \argmin_{j \in S^c} \widehat{R}(g_j)\,\,\,\,\,\, \text{e atualize}\,\,\,\,\,\, S \leftarrow \{S \cup \widehat{j}\}.$$

3 - Repita os passos anteriores at√© que todas as vari√°veis estejam em
$S$ ou at√© quando n√£o seja mais poss√≠vel ajustar o modelo de regress√£o.

4 - Selecione o modelo com menor risco estimado.

## Regress√£o *Stepwise*

<br>

Utilizar o algoritmo de sele√ß√£o de vari√°veis [*foward stepwise*]{.red},
ao inv√©s de buscarmos o melhor ajuste entre $2^d$ poss√≠veis modelos, que
muitas vezes √© imposs√≠vel, precisaremos investigar apenas
$1 + d(d + 1)/2$ modelos. Reduzimos a complexidade da sele√ß√£o que antes
era um problema exponencial. Melhor, n√£o?!

<br>

![](gifs/bom.gif)

## Penaliza√ß√£o

<br>

Quando temos modelos que envolve $d$ par√¢metros e que temos controle
sobre eles (conhecemos muito bem cada um deles), acrescentar algum tipo
de penaliza√ß√£o √† fun√ß√£o objetivo poder√° ser √∫til. A penaliza√ß√£o √© uma
[medida de complexidade]{.red}, em que √© √∫til para equilibrar o modelo,
de modo a tentar buscar um equilibrio entre vi√©s e vari√¢ncia, discutidos
anteriormente. Assim, sob novas observa√ß√µes, desejamos estimar o risco
$R(g)$, por

<br>

$$R(g) \approx EQM(g) + \mathcal{P}(g).$$

<br>

Desejamos minimiar $R(g)$, mas n√£o a custa de muitos par√¢metros, pois
assim ter√≠amos [overfitting]{.red}. Portanto, para muitos par√¢metros
temos que ter EQM baixo, por√©m, $\mathcal{P}(g)$ deve ser alto. J√° em
modelos viesados, quando temos poucos par√¢metros, o EQM normalmente √©
alto, mas a complexidade $\mathcal{P}(g)$ deve ser baixo, pois temos um
modelo mais simplista.

## AIC e BIC

<br>

Existem diversas penaliza√ß√µes, em que o AIC (**A**kaike **I**nformation
**C**riterion) e BIC (**B**ayesian **I**nformation **C**riterion) s√£o as
mais conhecidas. Com base nesses crit√©rios, temos que

<br>

::: {columns}
::: {.column width="30%"}
1.  [AIC]{.red}: $$EQM + \frac{2}{n\,d\, \widehat{\sigma}^2}.$$
2.  [BIC]{.red}: $$EQM + \frac{\log(n)}{n\, d\, \widehat{\sigma}^2}.$$
:::

::: {.column width="70%"}
$$\widehat{\sigma}^2 = \frac{1}{m}\sum_{k = 1}^m (W_k - \overline{W})^2.$$
:::
:::

<br>

Aqui, $d$ √© a quantidade de par√¢metros no modelo e $\widehat{\sigma}^2$
√© uma estimativa da vari√¢ncia do erro, que para um conjunto de teste
suficientemente grande, poder√° ser considerado o estimador de
$\widehat{\sigma}^2$ conforme descrito anteriormente. Segundo [James,
Gareth, et al. An introduction to statistical learning. Ed. 2, p.
233](https://hastie.su.domains/ISLR2/ISLRv2_corrected_June_2023.pdf),
assume-se o modelo com todos os preditores para o c√°lculo de
$\widehat{\sigma}^2$.

## Lasso

<br>

::: columns
::: {.column width="50%"}
O lasso foi desenvolvido pelo Robert Tibshirani, em um artigo publicado
no artigo [Regression Shrinkage and Selection via the
Lasso](https://www.jstor.org/stable/2346178).

![](imgs/lasso.png)
:::

::: {.column width="50%"}
![](imgs/P55268-Robert-Tibshirani.jpg){width="60%"}
:::
:::

## Lasso

<br>

O lasso tem como objetivo encontrar um estimador de uma regress√£o linear
que possui risco menor que o de m√≠nimos quadrados, possuindo duas
grandes vantagens, em rela√ß√£o ao *stepwise*:

<br>

1.  Sua solu√ß√£o √© mais r√°pida, ainda que *stepwise* seja
    consideravalmente mais r√°pido do que avaliar $2^d$ modelos;
2.  O lasso √© capaz de selecionar automaticamente as vari√°veis mais
    relevantes para o modelo, reduzindo a dimensionalidade dos dados.

<br>

A segunda vantagem ocorre, uma vez que ele realiza uma penaliza√ß√£o que
leva √† estimativas de alguns coeficientes $\beta_i$ igual a zero,
eliminando as vari√°veis menos importantes.

<br>

![](gifs/uau.gif)

## Lasso

<br>

No lasso, ao inv√©s de reduzir a vari√¢ncia do estimador de m√≠nimos
quadrados usando a complexidade
($L_0 = \sum_{i = 1}^d\mathbb{I}(\beta_i) \neq 0$) em
@eq-risco-penalizacao, usa-se a penaliza√ß√£o
$L_1 = \sum_{i = 1}^d|\beta_i|$. No lasso, buscamos:

$$\widehat{\beta}_{L_1,\lambda} = \argmin_{\beta_0 \in \mathbb{R}, \beta \in \mathbb{R}^d}\sum_{k = 1}^n\left(y_k - \beta_0 - \sum_{i = 1}^d \beta_i x_{x,i}\right)^2 + \lambda \,\,\underbrace{\sum_{j = 1}^d|\beta_j|}_{\text{Penaliza√ß√£o}},$$
em que $\lambda$ √© um *tuning parameter*. Perceba que quando
$\lambda = 0$, ca√≠mos no caso do modelo de regress√£o por m√≠nimos
quadrados sem penaliza√ß√£o. J√°, quando $\lambda \rightarrow \infty$,
temos um modelo em que todas as vari√°veis s√£o removidas, uma vez que a
primeira parte do modelo torna-se insignificante.

## Lasso

<br> <br>

Quando $\lambda$ √© grande, temos que

$$\sum_{k = 1}^n \left(y_k - \beta_0 - \sum_{j = 1}^d \beta_j x_{k,j}\right)^2 + \lambda \sum_{j = 1}^d |\beta_j| \approx \lambda \sum_{j = 1}^d |\beta_j|,$$
e portanto, $\widehat{\beta}_1 = 0, \cdots, \widehat{\beta}_d = 0$.

<br>

A escolha de $\lambda$, em geral, √© feita utilizado algum m√©todo de
valida√ß√£o cruzada.

## Lasso

<br>

O lasso √© extremamente r√°pido, e nos √∫ltimos anos, diversos algoritmos
foram constru√≠dos para fazer essa tar√©fa de forma eficiente. O LARS foi
um dos primeiros algoritmos desenvolvidos em 2010. Para detalhes, ler
[Friedman, J. H. (2001). Greedy function approximation: a gradient
boosting machine. Annals of statistics,
1189--1232](https://www.jstor.org/stable/2699986).

<br>

No R, a regress√£o lasso poder√° ser feita usando a biblioteca
[glmnet](https://cran.r-project.org/web/packages/glmnet/index.html),
assim:

<br>

```{r}
#| eval: false
library(glmnet)
ajuste <- cv.glmnet(x, y, alpha = 1)
```

<br>

![](gifs/teclado-anime.gif){width="21%"}

## Ridge

<br>

Uma alternativa que surgiu antes do lasso √© a [regress√£o ridge]{.red}.
Ela foi proposta no artigo [Hoerl, A. E. & Kennard, R. W. (1970). Ridge
regression: Biased estimation for nonorthogonal problems. Technometrics,
12(1), 55--67](https://www.jstor.org/stable/1267351). Aqui, utiliza-se
como medida de complexidade a norma $L_2$, em que, o estimador √© dado
por:

$$\widehat{\beta}_{L_2,\lambda} = \argmin_{\beta_0 \in \mathbb{R}, \beta \in \mathbb{R}^d}\sum_{k = 1}^n\left(y_k - \beta_0 - \sum_{i = 1}^d \beta_i x_{x,i}\right)^2 + \lambda \,\,\underbrace{\sum_{j = 1}^d\beta_j^2}_{\text{Penaliza√ß√£o}}.$$
Diferentemente do lasso, a regress√£o ridge possui solu√ß√£o anal√≠tica,
dada por:

$$\widehat{\beta}_{L_2,\lambda} = ({\bf X}^{T}{\bf X} + \lambda\mathbb{\bf I}_0)^{-1}{\bf X}^{T}Y,$$
em que $\mathbb{\bf I}_0$ √© a matriz identidade $(d + 1) \times (d + 1)$
com $\mathbb{\bf I}_0(1,1) = 0$.

<br>

## Ridge

<br>

A regress√£o ridge poder√° ter uma vari√¢ncia menor que a regress√£o lasso,
por√©m seu vi√©s poder√° ser maior. Outra caracter√≠stica da regress√£o ridge
√© que ela possue uma √∫nica solu√ß√£o, enquanto a regress√£o lasso poder√°
ter multiplas solu√ß√µes. Os autores tamb√©m demonstram que a regress√£o
ridge lida melhor com multicolinearidade.

<br>

No R, tamb√©m poderemos utilizar a biblioteca
[glmnet](https://cran.r-project.org/web/packages/glmnet/index.html):

<br>

```{r}
#| eval: false
library(glmnet)
ajuste <- cv.glmnet(x, y, alpha = 0)
```

<br>

![](gifs/teclado-anime.gif){width="21%"}

## Elastic Net

<br>

Nesse tipo de modelo de gress√£o, combina-se as penaliza√ß√µes da regress√£o
ridge com a utilizada na regress√£o lasso, herdando os benef√≠cios do uso
de cada um dos m√©todos isoladamente, melhorando a estabilidade das
estimativas do lasso, em situa√ß√µes de multicolinearidade entre as
vari√°veis e tamb√©m permitindo a sele√ß√£o autom√°tica de vari√°veis.

$$(1-\alpha)\widehat{\beta}_{L_2,\lambda} + \alpha\widehat{\beta}_{L_1,\lambda},$$
em que $0 \leq \alpha \leq1$. Em R, basta especificar para a fun√ß√£o
`glmnet` um valor de $\alpha$ diferente de 0 e 1.

<br>

![](gifs/teclado-anime.gif){width="21%"}

## Exemplo: EMQ, Ridge, Lasso e Elastic Net

<br>

[Exemplo]{.red}: Considere uma base de dados simulada, com $n = 500$
observa√ß√µes, de tal forma que

$$Y = 3X_{1} - 2X_2 + X_3 + -3X_4 + X_5 + \sum_{i = 6}^{20}0X_i + \varepsilon,$$
em que $\varepsilon \sim \text{Normal}(0, 0.5^2)$ e
$X_i \sim \text{Normal}(0, 1)$, independentes, com $i = 1, \cdots, 20$.
Desejamos ajustar quatro modelos de regress√£o. Para o caso do Estimador
de M√≠nimos Quadrados - EMQ e do modelo Ridge, que n√£o tem sele√ß√£o
autom√°tica de vari√°veis, usaremos **todas** as vari√°veis. Desejamos
avaliar o risco estimado de cada uma das regress√µes.

![](gifs/teclado-anime.gif){width="21%"}

## Exemplo: EMQ, Ridge, Lasso e Elastic Net

<br>

```{r}
#| code-fold: true
#| code-summary: "Solu√ß√£o utilizando o tidymodels"
#| eval: false
library(tidymodels)
library(tibble)
library(purrr)
library(ggplot2)
library(patchwork)

# Removendo poss√≠veis conflitos de pacotes --------------------------------
tidymodels::tidymodels_prefer()

# Fun√ß√£o para gerar os dados ----------------------------------------------
gerando_dados <- function(n = 300L){
  regressao <- function(i){
    x <- rnorm(n = 5L)
    y <- 3*x[1L] - 2*x[2L] + x[3L] - 3*x[4L] + x[5L] + rnorm(1L, 0, 0.5)
    tibble(
      y = y,
      x1 = x[1L],
      x2 = x[2L],
      x3 = x[3L],
      x4 = x[4L],
      x5 = x[5L]
    )
  }
  dados <- purrr::map(.x = 1L:n, .f = regressao) |> 
    purrr::list_rbind()
  
  parte_esparsa <- matrix(0, n, 15)
  
  dados <- cbind(dados, parte_esparsa)
  colnames(dados) <- c("y", paste0("x", 2L:ncol(dados)))
  as_tibble(dados)
}

dados <- gerando_dados(n = 500)

# Divis√£o inicial da base -------------------------------------------------
hod_out <- initial_split(dados, prop = 0.7)
treinamento <- training(hod_out)
teste <- testing(hod_out)

# Setando o modelo (set engine) -------------------------------------------
modelo_eqm <- 
  linear_reg(penalty = 0, mixture = 0) |> 
  set_mode("regression") |> 
  set_engine("glmnet")
  
modelo_ridge <- 
  linear_reg(penalty = tune::tune(), mixture = 0) |> 
  set_mode("regression") |> 
  set_engine("glmnet")

modelo_lasso <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) |> 
  set_mode("regression") |> 
  parsnip::set_engine("glmnet")
  
modelo_elastic <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) |> 
  set_mode("regression") |> 
  parsnip::set_engine("glmnet")

# Criando workflows -------------------------------------------------------
all_wf <- 
  workflow_set(
    preproc = list(y ~ . ),
    models = list(eqm = modelo_eqm, ridge = modelo_ridge, lasso = modelo_lasso, elastic = modelo_elastic), 
    cross = TRUE
  )

# Valida√ß√£o cruzada -------------------------------------------------------
set.seed(0)
cv <- rsample::vfold_cv(treinamento, v = 5L)

# Setando a m√©trica -------------------------------------------------------
metrica <- yardstick::metric_set(rmse)

# Tunagem dos hiperpar√¢metros ---------------------------------------------
# A semente (seed = 0) faz com que dentro da valida√ß√£o cruzada para cada modelo
# a semente seja sempre a mesma.
tunagem <- 
  all_wf |> 
  workflow_map(
    seed = 0, 
    verbose = TRUE,
    resamples = cv,
    grid = 50,
    metrics = metrica
  )

# Rank dos melhores modelos -----------------------------------------------
modelos_rank <- tunagem |> rank_results()

melhor_eqm <- 
  tunagem |> 
  extract_workflow_set_result("formula_eqm") |> 
  select_best("rmse")

melhor_ridge <- 
  tunagem |> 
  extract_workflow_set_result("formula_ridge") |> 
  select_best("rmse")

melhor_lasso <- 
  tunagem |> 
  extract_workflow_set_result("formula_lasso") |> 
  select_best("rmse")

melhor_elastic <- 
  tunagem |> 
  extract_workflow_set_result("formula_elastic") |> 
  select_best("rmse")

finalizando_eqm <- 
  tunagem |> 
  extract_workflow("formula_eqm") |> 
  finalize_workflow(melhor_eqm) |> 
  last_fit(split = hod_out)

finalizando_ridge <- 
  tunagem |> 
  extract_workflow("formula_ridge") |> 
  finalize_workflow(melhor_ridge) |> 
  last_fit(split = hod_out)

finalizando_lasso <- 
  tunagem |> 
  extract_workflow("formula_lasso") |> 
  finalize_workflow(melhor_lasso) |> 
  last_fit(split = hod_out)

finalizando_elastic <- 
  tunagem |> 
  extract_workflow("formula_elastic") |> 
  finalize_workflow(melhor_elastic) |> 
  last_fit(split = hod_out)

# Visualizando as m√©tricas
finalizando_eqm |> collect_metrics()
finalizando_ridge |> collect_metrics()
finalizando_lasso |> collect_metrics()
finalizando_elastic |> collect_metrics()

# Visualizando predi√ß√µes:
finalizando_eqm |> collect_predictions()
finalizando_ridge |> collect_predictions()
finalizando_lasso |> collect_predictions()
finalizando_elastic |> collect_predictions()
```

## üìö Exerc√≠cios

<br> [Exerc√≠cio]{.red}: Utilizando os dados de vinho vermelhoüç∑,
dispon√≠veis
[aqui](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009),
fa√ßa uma pequena an√°lise explorat√≥ria dos dados. No
[link](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)
do Kaggle voc√™ consegue uma explica√ß√£o sobre o que significa cada uma
das vari√°veis.

![](gifs/mr-bean-test.gif){width="211"}

## üìö Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Utilizando os dados de vinho vermelhoüç∑, dispon√≠veis
[aqui](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009),
obtenha o melhor modelo de regress√£o linar para modelar a qualidade do
vinho, considerando:

<br>

1.  $g_1$ - M√©todo dos m√≠nimos quadrados;
2.  $g_2$ - Regress√£o ridge;
3.  $g_3$ - Regressao lasso;
4.  $g_4$ - Elastic Net.

<br>

Voc√™ dever√° selecionar o melhor modelo de cada uma das classes de
modelos de regress√£o e construir uma tabela com o risco estimado
$\widehat{R}(g_i),\,\, i = 1, \cdots, 4$, em que aqui $g_i$ representa o
modelo geral n√£o estimado. Ao fim, construa quatro gr√°ficos mostrando o
ajuste de cada um dos modelos.

<br>

[Exerc√≠cio]{.red}: Se voc√™ utilizou o
[tidymodels](https://www.tidymodels.org/) para resolver o exerc√≠cio
anterior, rafa√ßa usando a biblioteca
[glmnet](https://cran.r-project.org/web/packages/glmnet/index.html).
Caso contr√°rio, resolva-o utilizando o
[tidymodels](https://www.tidymodels.org/).

## üìö Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Considere agora o conjunto de dados de despesas
m√©dicas, dispon√≠vel
[aqui](https://www.kaggle.com/datasets/mirichoi0218/insurance), refa√ßa o
mesmo exerc√≠cio dos dados de vinho vermelho, em que aqui, o objetivo √©
prever a vari√°vel `charges`. Perceba que algumas vari√°veis s√£o
qualitativas, e port√£o, voc√™ dever√° transform√°-las em [*dummy*]{.red}.
Indique os melhores cen√°rios dos quatro modelos e informe qual modelo
voc√™ utilizaria. Explique!

<br>

![](gifs/bean_simple.gif)

## M√©todos n√£o-param√©tricos

<br>

M√©todos param√©tricos podem impor muitas limita√ß√µes na solu√ß√£o de um
problema de regress√£o, i.e., em problemas que desejamos estimar a fun√ß√£o
de regress√£o $r({\bf x})$. Por exemplo, nem sempre o melhor estimador
linear √© um bom estimador para $r({\bf x})$.

<br>

M√©todos param√©tricos s√£o muitas vezes simplistas e restritivos, em que
normalmente abrimos m√£os para se ter um estimador um pouco mais viesado,
em detrimento da diminui√ß√£o da vari√¢ncia do modelo. Por exemplo, nas
regress√µes penalizadas que vimos anteriormente (**ridge**, **lasso** e
**elastic-net**), penalizamos modelos com muitas covari√°veis o que
naturalmente aumentar√° o vi√©s, na maioria das vezes.

<br>

![](gifs/hum.gif)

## M√©todos n√£o-param√©tricos

<br>

Em situa√ß√µes em que temos muitos dados ($n$ grande), os modelos
n√£o-param√©tricos possuem, em geral, boa peformance, uma vez que apesar
de que nessa classe de modelos existir um aumento da vari√¢ncia, por√©m,
seguida de uma redu√ß√£o de vi√©s, a vari√¢ncia do modelo n√£o aumenta muito.

<br>

De um lado, nos modelos de regress√£o que vimos at√© o momento,
introduzimos uma penaliza√ß√£o para diminuir a vari√¢ncia do modelo frente
ao m√©todo dos m√≠nimos quadrados (quando n√£o usamos penaliza√ß√£o) em troca
de um aumento no v√≠es. Aqui, em modelos n√£o param√©tricos, desejamos
fazer a troca oposta, i.e., diminuir o vi√©s, em troca de um ganho na
vari√¢ncia no modelo.

<br>

Qualquer abordagem param√©trica tr√°s consigo a possibilidade de que a
forma funcional $g$ para estimar $f$ seja muito diferente da verdadeira,
claro, se o modelo resultante n√£o se ajustar bem aos dados, isto √©
$\widehat{g}$ n√£o tem boa capacidade preditiva, muito embora, tamb√©m √©
poss√≠vel que tenhamos $\widehat{g}$ com boa capacidade preditiva, por√©m,
n√£o represente a estrutura real de $f$ (sempre desconhecida).

## M√©todos n√£o-param√©tricos

<br> <br>

Isso n√£o √© regra, por√©m ajuda a entender um pouco o dilema entre essas
classes de modelos (param√©tricos e n√£o-param√©tricos).

<br>

![](imgs/vies_variancia_nao_parametrico.png){fig-aling="center"}

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Tamb√©m chamado de [$k$-nearest neighbours - $k$NN]{.red}, o $k$NN √© um
dos m√©todos mais populares na comunidade de aprendizagem de m√°quina. O
m√©todo foi formulado em uma sequ√™ncia de dois artigos:

<br>

1 - Benedetti, J. K. (1977). **On the nonparametric estimation of
regression functions**. Journal of the Royal Statistical Society. Series
B (Methodological), 248--253;

<br>

2 - Stone, C. J. (1977). **Consistent nonparametric regression**. The
Annals of Statistics, 595-- 620.

<br>

A ideia do m√©todo √© estimar a fun√ß√£o de regress√£o $r({\bf x})$, para um
dado ${\bf x}$ com base nas respostas $Y$ dos $k$-vizinhos mais pr√≥ximos
de ${\bf x}$.

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Formalmente, temos que

$$g({\bf x^*}) = \frac{1}{k}\sum_{i \in \mathcal{N}_{\bf x^*}}y_i,$$ em
que $\mathcal{N}_{\bf x}$ √© o conjunto √≠ndices das $k$ observa√ß√µes mais
pr√≥ximas de ${\bf x}$, i.e,

$$\mathcal{N}_{\bf x^*} = \{i \in \{1, \cdots, n\}\, : \, d({\bf x}_i, {\bf x^*}) \leq d_{\bf x^*}^k\},$$
em que $d_{\bf x^*}^k$ √© a dist√¢ncia do $k$-√©simo vizinho mais pr√≥ximo
de $\bf{x^*}$ em $\bf{x}$. Portanto, o valor da regress√£o no ponto
${\bf x^*},$ i.e., o valor de
$r({\bf x^*}) = \mathbb{E}(Y|{\bf X} = {\bf x^*})$ √© estimado pela m√©dia
de $Y_{N_{\bf x^*}}$. Ou seja, estimamos por:

$$\overline{Y}_{N_{\bf x^*}} = \frac{1}{k} \sum_{i \in \mathcal{N}_{\bf x^*}}y_i.$$

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br> <!-- http://leg.ufpr.br/~lucambio/MSM/MSM03.html --> Para
determinar $d_{\bf x^*}^k$, poderemos utilizar alguma m√©trica de
dist√¢ncia e assim mensurarmos a proximidade. Entre elas:

<br>

1.  [Dist√¢ncia Euclidiana]{.red} ou dist√¢ncia $L_2$:
    $d(x^a, x^b) = \sqrt{(x_1^a - x_1^b)^2 + \cdots + (x_d^a - x_d^b)^2}$;

<br>

2.  [Dist√¢ncia de Manhattan]{.red}, City Block ou dist√¢ncia $L_1$:
    $d(x^a, x^b) = \sqrt{|x_1^a - x_1^b| + \cdots + |x_d^a - x_d^b|}$;

<br>

2.  [Dist√¢ncia de Mahalanobis]{.red}:
    $d(x^a, x^b) = \sqrt{(x^a - x^b)^{T}S^{-1}(x^a - x^b)}$, em que $S$
    √© a matriz de covari√¢ncia, em que na diagonal princial temos as
    vari√¢ncias e fora dela as covari√¢ncias entre os pontos. Lembre-se
    que se $x$ e $y$ s√£o vetores de dados quaisquer, a interdepend√™ncia
    linear entre eles poder√° ser estimada como:

<br>

$$\mathrm{cov}(x, y) = \frac{1}{n-1}\sum_{i = 1}^n (x_i - \overline{x})(y_i - \overline{y}).$$

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Voc√™ poder√° utilizar qualquer outra medida de dist√¢ncia al√©m das que
foram citadas acima.

<br>

√â importante perceber que **o m√©todo** $k$NN n√£o faz uma "compress√£o"
dos dados como a regress√£o linear que estudamos. L√°, temos uma equa√ß√£o
que utilizamos para estimar o valor de $Y$, ap√≥s as estima√ß√£o dos
coeficientes do modelo de regress√£o, ou seja, n√£o precisamos mais dos
dados para estimar novas observa√ß√µes. J√° no $k$NN, precisamos sempre nos
recorrer aos dados para fazer novas predi√ß√µes, ou seja, sempre que
desejarmos calcular $r({\bf x}) = \mathbb{E}(Y|{\bf X} = {\bf x})$
deveremos sempre fazer uma nova consulta aos dados para calcular a m√©dia
dos vizinhos mais pr√≥ximos. O $k$NN n√£o possui coeficientes para
interpretar. Diferentemente da regress√£o linear, o $k$NN √© um pouco mais
"*black box*".

<br>

![](gifs/giphy.gif)

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br> O valor da constante $k$ √© um hiperpar√¢metro do $k$NN e dever√° ser
obtido por valida√ß√£o cruzada. Perceba que se $k = n$ temos um modelo
muito viesado, por√©m com vari√¢ncia pequena. Isso, porqu√™ para $k = n$
basicamente iremos tirar uma m√©dia dos dados. Para $k = 1$, teremos um
*overfitting*, uma vez que o estimador ir√° interpolar os dados.

<br> [Exemplo]{.red}: Considere novamente o conjunto de dados de
expectativa de vida versus PIB per Capita dispon√≠veis
[aqui](https://github.com/prdm0/dados/blob/main/dados_expectativa_renda.RData).
Utilizando o [tidymodels](https://www.tidymodels.org/), vamos construir
uma fu√ß√£o que retorne um gr√°fico com as estimativas do $k$NN. A fun√ß√£o
receber√° como argumentos o conjunto de dados e o valor de $k$. Voc√™
tamb√©m poderia utilizar outras bibliotecas, como por exemplo a
[FNN](https://cran.r-project.org/web/packages/FNN/index.html), ou a
[KKNN](https://github.com/KlausVigo/kknn), esta √∫tlima √© a que √©
utilizada internamente na biblioteca
[parsnip](https://parsnip.tidymodels.org/) do
[tidymodels](https://www.tidymodels.org/).

<br>

![](imgs/parsnip.png)

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Abrindo apenas um par√™ntese, o [tidymodels](https://www.tidymodels.org/)
refere-se a um conjunto de pacotes que s√£o √∫teis para o tratamento,
treinamento, tunagem e avalia√ß√£o de modelos de aprendizagem de m√°quina,
em que o [parsnip](https://parsnip.tidymodels.org/) implementa as
*engines* (algoritmos/motores) que iremos utilizar para treinar um
modelo. Na verdade, os algoritmos est√£o implementados em pacotes de
terceiros e n√£o precisamente no
[parsnip](https://parsnip.tidymodels.org/). Por√©m, o
[parsnip](https://parsnip.tidymodels.org/) unifica a sintaxe de diversos
algoritmos implementados em pacotes separados.

<br>

![](gifs/thumbs-up-nod.gif)

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Observe que na imagem abaixo, a Figura [A]{.red}, quando $k=1$,
percebemos initidamente que houve *overfitting*, i.e., h√° uma
interpola√ß√£o dos dados. J√° na Figura [D]{.red} temos um modelo com
vari√¢ncia menor, por√©m, este √© muito simplista, o que sugere um alto
vi√©s.

<br>

![](imgs/knn_plot.png){fig-aling="center"}

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Estude o c√≥digo! Ele fornece a solu√ß√£o para o exemplo.

<br>

```{r}
#| eval: false
#| code-summary: "Solu√ß√£o pelo m√©todo knn do exemplo anterior"
#| code-fold: true

library(tidymodels)
library(glue)
library(dplyr)
library(ggplot2)
library(patchwork)

tidymodels::tidymodels_prefer()

# Lendo dados
url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"
arquivo_temp <- tempfile()
download.file(url = url, destfile = arquivo_temp)
load(arquivo_temp)

dados <- 
  dados_expectativa_renda |> 
  dplyr::select(-CountryName) |> 
  dplyr::rename(y = LifeExpectancy, x = GDPercapita)

knn_exp_pip <- function(dados, k = 1L){
  # Criando receita
  receita <- recipe(y ~ x, data = dados)
  
  # Definindo o modelo
  modelo_knn <- nearest_neighbor(neighbors = k) |> 
    set_mode("regression") |> 
    set_engine("kknn")
  
  # Workflow
  ajuste_final <- 
    workflow() |> 
    add_model(modelo_knn) |> 
    add_recipe(receita) |> 
    fit(data = dados)
  
  # Retornando previsoes
  y_chapeu <- predict(ajuste_final, new_data = dados)
  
  dados <- 
    dados |> 
    mutate(y_chapeu = y_chapeu$.pred)
  
  dados |> 
    ggplot() +
    geom_point(aes(x = x, y = y), size = 3) +
    geom_line(aes(x = x, y = y_chapeu), col = "red", alpha = 0.6, size = 2) +
    labs(title = "k-nearest neighbours", subtitle = glue("k = {k}")) +
    theme(
      title = element_text(face = "bold")
    )
}

p1 <- knn_exp_pip(dados, k = 1L)
p2 <- knn_exp_pip(dados, k = 7L)
p3 <- knn_exp_pip(dados, k = 10L)
p4 <- knn_exp_pip(dados, k = 200L)

p <- p1 + p2 + p3 + p4 + plot_annotation(tag_levels = "A")

ggsave(p, file = "imgs/knn_plot.png", width = 50, height = 30, units = "cm")
```

<br>

![](gifs/chapulin-colorado-no.gif){width="25%"}

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

**Algumas limita√ß√µes do** $k$NN s√£o:

<br>

1.  √â totalmente dependente do conjunto de dados para fazer novas
    predi√ß√µes;

2.  Para novas observa√ß√µes que s√£o fora dos limites dos dados de
    treinamento, as predi√ß√µes do $k$NN tendem a serem imprecisas;

3.  Pode ser custoso para uma grande base de dados;

4.  O c√°lculo de dist√¢ncias pode sofrer com a chamada "maldi√ß√£o da
    dimensionalidade", em que a depender da m√©trica de dist√¢ncia
    utilizada, tudo fica muito distante.

<br>

**Algumas vantagens s√£o**:

<br>

1.  √â um m√©todo simples de ser implementado;

2.  √â muito utilizado para imputa√ß√£o de observa√ß√µes faltantes;

3.  √â comumente utilizado, por conta de sua simplicidade, em explora√ß√µes
    iniciais.

## Nadaraya-Watson

<br>

Uma varia√ß√£o do m√©todo $k$NN que √© bastante difundida na comunidade
estat√≠stica √© o m√©todo de Nadaraya-Watson, propostos nos artigos:

<br>

1.  Nadaraya, E. A. (1964). **On estimating regression**. Theory of
    Probability & Its Applications, 9(1), 141--142;

2.  Watson, G. S. (1964). **Smooth regression analysis**. Sankhya: The
    Indian Journal of Statistics, Series A, 359--372.

<br>

Esse m√©todo tamb√©m √© chamado de estimador $k$-vizinhos ponderados ($k$NN
ponderado), uma vez que a estima√ß√£o da fun√ß√£o de regress√£o em um dado
ponto ${\bf x}$ utiliza de m√©dias ponderadas das observa√ß√µes do conjunto
de treinamento:

$$g({\bf x}) = \sum_{i = 1}^n w_i({\bf x})y_i,$$ em que $w_i({\bf x})$ √©
o peso atribu√≠do √† $i$-√©sima observa√ß√£o, medindo a similaridade de
${\bf x}_i$ √† ${\bf x}$.

## Nadaraya-Watson

<br>

Temos que $w_i({\bf x})$ √© definido por:

$$w_i({\bf x}) = \frac{K({\bf x}, {\bf x}_i)}{\sum_{j = 1}^n K({\bf x}, {\bf x}_j)},$$
em que $K({\bf x}, {\bf x}_j)$ √© um kernel de suaviza√ß√£o usado para
medir a similaridade entre as observa√ß√µes. Escolhas que s√£o populares
para $K({\bf x}, {\bf x}_j)$, s√£o:

<br>

1.  [Kernel uniforme]{.red}:
    $K({\bf x}, {\bf x}_i) = \mathbb{I}(d({\bf x}, {\bf x}_i) \leq h)$;
2.  [Kernel gaussiano]{.red}:
    $K({\bf x}, {\bf x}_i) = (\sqrt{2\pi h^2})^{-1}\exp\left\{ -\frac{d^2({\bf x}, {\bf x}_i)}{2h^2}\right\}$;
3.  [Kernel triangular]{.red}:
    $K({\bf x}, {\bf x}_i) = (1 - d({\bf x}, {\bf x}_i)/h)\mathbb{I}(d({\bf x}, {\bf x}_i) \leq h)$;
4.  [Kernel de Epanechnikov]{.red}:
    $K({\bf x}, {\bf x}_i) = (1 - d^2({\bf x}, {\bf x}_i)/h^2)\mathbb{I}(d({\bf x}, {\bf x}_i) \leq h)$.

## Nadaraya-Watson

<br>

Enquanto no kernel uniforme, os pesos s√£o iguais para as observa√ß√µes a
uma dist√¢ncia menor que $h$ de ${\bf x}$ e atribui peso zero para
observa√ß√µes maiores que $h$, os kernels triangular e de Epanechnikov
atribui pesos maiores para observa√ß√µes mais pr√≥ximas de ${\bf x}$. A
quantidade $h$ √© um [*tuning parameter*]{.red}, e na pr√°tica, deve ser
estimada por um procedimento de valida√ß√£o cruzada.

<br>

**Algumas propriedades de uma fun√ß√£o kernel s√£o**:

<br>

1.  **Simetria**: $K(x,y) = K(y,x)$, permitindo que a fun√ß√£o de
    similaridade seja invariante em rela√ß√£o a ordem dos argumentos;
2.  **Positiva definida**: Para qualquer vetor $c$, em que seja poss√≠vel
    fazer $c^{T}K(x,y)$, temos que $c^{T}K(x,y)c > 0$.

<br>

Voc√™ poder√° encontrar outras fun√ß√µes kernel
[aqui](https://en.wikipedia.org/wiki/Kernel_(statistics)).

## Nadaraya-Watson

<br>

[Exemplo]{.red}: Novamente, considerando o conjunto de dados de
expectativa de vida versus PIB per Capita dispon√≠veis
[aqui](https://github.com/prdm0/dados/blob/main/dados_expectativa_renda.RData).
Utilizando o [tidymodels](https://www.tidymodels.org/), vamos construir
uma fu√ß√£o que retorne um gr√°fico com as estimativas. A fun√ß√£o receber√°
como argumentos o conjunto de dados e o valor de $h$. Observe a
documenta√ß√£o da fun√ß√£o `nearest_neighbor` do pacote
[parsnip](https://parsnip.tidymodels.org/). Perceba que o argumento
`weight_func` permite que possamos escolher entre algumas fun√ß√µes
kernel. Por√©m, como m√©trica de dist√¢ncias, apenas poderemos utilizar a
de Minkowski. Seja $x = (x_1, \cdots, x_n)$ e $y = (y_1, \cdots, y_n)$,
ambos vetores do $\mathbb{R}^n$. Ent√£o, a dist√¢ncia de Minkowski √© dada
por:

$$d(x,y) = \left(\sum_{i = 1}^n |x_i - y_i|^p\right)^{\frac{1}{p}},$$
com $p \geq 1$. Note que se $p = 1$ temos a dist√¢ncia euclidiana
(dist√¢ncia $L_1$) e se $p = 2$ teremos a distancia de Manhattan
(dist√¢ncia $L_2$).

## Nadaraya-Watson

<br>

Portanto, com o argumento `dist_power` da fun√ß√£o `nearest_neighbor`, do
pacote [parsnip](https://parsnip.tidymodels.org/), voc√™ poder√°
especificar o valor de $p$, que inclusive poder√° ser um hiperpar√¢metro,
podendo ser obtido por meio de uma valida√ß√£o cruzada.

<br>

![](gifs/mr-bean-pivot.gif)

<br>

No exemplo n√£o iremos fazer a valida√ß√£o cruzada, pois apenas queremos
implementar uma fun√ß√£o em que seja poss√≠vel experimentar o m√©todo para
diferentes valores de $h$ e diferentes fun√ß√µes de kernel.

## Nadaraya-Watson

<br> A imagem abaixo utiliza o kernel gaussiano:

<br>

![](imgs/nadaraya_watson.png){fig-aling="center"}

## Nadaraya-Watson

<br>

```{r}
#| code-fold: true
#| code-summary: "Solu√ß√£o do exempƒ∫o de Nadaraya-Watson"

library(tidymodels)
library(glue)
library(dplyr)
library(ggplot2)
library(patchwork)

tidymodels::tidymodels_prefer()


# Lendo dados
url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"
arquivo_temp <- tempfile()
download.file(url = url, destfile = arquivo_temp)
load(arquivo_temp)

dados <- 
  dados_expectativa_renda |> 
  dplyr::select(-CountryName) |> 
  dplyr::rename(y = LifeExpectancy, x = GDPercapita)

nadaraya_watson_exp_pip <- function(dados, h = 1, ...){
  # Criando receita
  receita <- 
    recipe(y ~ x, data = dados) |> 
    step_normalize()
  
  # Definindo o modelo
  modelo_knn <- nearest_neighbor(dist_power = h, ...) |> 
    set_mode("regression") |> 
    set_engine("kknn")
  
  # Workflow
  ajuste_final <- 
    workflow() |> 
    add_model(modelo_knn) |> 
    add_recipe(receita) |> 
    fit(data = dados)
  
  # Retornando previsoes
  y_chapeu <- predict(ajuste_final, new_data = dados)
  
  dados <- 
    dados |> 
    mutate(y_chapeu = y_chapeu$.pred)
  
  dados |> 
    ggplot() +
    geom_point(aes(x = x, y = y), size = 3) +
    geom_line(aes(x = x, y = y_chapeu), col = "red", alpha = 0.6, size = 2) +
    labs(title = "Nadaraya-Watson", subtitle = glue("h = {h}")) +
    theme(
      title = element_text(face = "bold")
    )
}

p1 <- nadaraya_watson_exp_pip(dados, h = 1, weight_func = "gaussian")
p2 <- nadaraya_watson_exp_pip(dados, h = 1000, weight_func = "gaussian")

p <- p1 + p2 + plot_annotation(tag_levels = "A")

ggsave(p, file = "imgs/nadaraya_watson.png", width = 30, height = 15, units = "cm")
```

<br>

![](gifs/side-eyeing-chloe-chloe.gif)

## Tidymodels $k$NN e Nadaraya-Watson

<br>

Para que possamos experimentar o
[tidymodels](https://www.tidymodels.org/) seguindo todo o fluxo de
"padr√£o" de aprendizagem de m√°quina, com divis√£o do conjunto de dados,
valida√ß√£o cruzada e busca pelos melhores hiperpar√¢metros ("tunagem").
Iremos reproduir dois exemplos com os dados de expectativa de vida e PIB
per Capita.

<br>

[Exemplo]{.red}: Nesse exemplo estamos realizando o $k$NN, em que
estamos obtendo um candidato para o valor de $k$, por meio de um
procedimento de *cross-validation* (10-*folds cross-validation*). Aqui,
a busca do hiperpar√¢metro $k$ far√° uso de um *grid search*. Perceba, no
c√≥digo que segue o exemplo, que no processo de "tunagem", alterei o grid
de valores usando a fun√ß√£o `grid_max_entropy` do pacote
[dails](https://dials.tidymodels.org/reference/grid_max_entropy.html).
Uma observa√ß√£o √© que voc√™ poderia criar uma tibble com valores do seu
interesse. O argumento `grid` da fun√ß√£o `tune_grid` do pacote
[tune](https://tune.tidymodels.org/reference/tune_grid.html) deve ser um
data frame/tibble ou um n√∫mero inteiro. Esse objeto conter√° todas as
poss√≠veis combina√ß√µes de hiperpar√¢metros que ser√£o testadas na valida√ß√£o
cruzada, no nosso caso, temos apenas um hiperpar√¢metro. Foi utilizado um
*grid* de tamanho 60. Foi utilizado uma divis√£o de $80\%$ para
treinamento e $20\%$ para teste.

## Tidymodels $k$NN e Nadaraya-Watson

<br>

```{r}
#| code-fold: true
#| code-summary: Workflow completo do treimanento de um modelo KNN.
#| eval: false
library(tidymodels)
library(dplyr)
library(ggplot2)
library(patchwork)

# Resolvendo eventuais conflitos entre tidymodels e outros pacotes eventualmente
# carregados:
tidymodels::tidymodels_prefer()

# Lendo a base de dados:
url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"
arquivo_temp <- tempfile()
download.file(url = url, destfile = arquivo_temp)
load(arquivo_temp)

dados_expectativa_renda <-
  dados_expectativa_renda |>
  dplyr::select(-CountryName)

# Setando uma semente
set.seed(0)

# Divis√£o da base de dados ------------------------------------------------
# Divis√£o inicial (treino e teste)
splits <- 
  rsample::initial_split(
    dados_expectativa_renda,
    strata = "LifeExpectancy", 
    prop = 0.8 
  )

# O conjunto de dados de treinamento ser√° utilizado para ajustar/treinar o
# modelo:
treinamento <- rsample::training(splits)

# O conjunto de teste ser√° utilizado apenas no fim, para avaliar o desempenho
# preditivo final do modelo:
teste <- rsample::testing(splits) 

# Criando uma receita para os dados ---------------------------------------

# Poderia ter passado o conjunto treinamento ou posso passar o conjunto "splits".
# O comando recipes j√° entende que dever√° utilizar o conjunto de treinamento.
receita <- 
  recipes::recipe(formula = LifeExpectancy ~ ., data = treinamento) |> 
  step_YeoJohnson(all_predictors()) |> # Ajuda na normaliza√ß√£o dos dados. Pode ser bom!
  step_normalize(all_predictors()) # Normalizando vari√°veis num√©ricas.

# Construindo modelo kNN --------------------------------------------------
modelo_knn <- 
  parsnip::nearest_neighbor(neighbors = tune()) |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("kknn")

# Construindo um workflow (pipeline) --------------------------------------
wf_knn <-
  workflows::workflow() |>
  workflows::add_recipe(receita) |>
  workflows::add_model(modelo_knn)

# Cross-validation --------------------------------------------------------
cv <- 
  treinamento |> 
  rsample::vfold_cv(v = 10L, strata = "LifeExpectancy")

# Busca do hiperpar√¢metro k -----------------------------------------------
metrica <- metric_set(rmse)

# Extraindo e atualizando range do par√¢metro ------------------------------
update_parametros <-
  wf_knn |> 
  extract_parameter_set_dials() |>
  update("neighbors" = neighbors(c(1, 50)))

# Tunagem -----------------------------------------------------------------
meu_grid <- dials::grid_max_entropy(update_parametros, size = 60)

tunagem <-
  tune::tune_grid(
    wf_knn,
    resamples = cv,
    grid = meu_grid,
    metrics = metrica,
    control = control_grid(save_pred = TRUE, verbose = TRUE)
  )

p_hiper <- autoplot(tunagem) +
  labs(title = "KNN - Sele√ß√£o do n√∫mero k (vizinhos)", subtitle = "Sintoniza√ß√£o do hiperpar√¢metro (valor de k)") +
  theme(
    title = element_text(face = "bold")
  )

# Atualizando workflow ----------------------------------------------------
wf_knn <- 
  wf_knn |> 
  finalize_workflow(select_best(tunagem))

# Ajustar o modelo ao conjunto de treinamento e avaliar no teste --------
ajuste_final <- last_fit(wf_knn, splits)

# Ajuste final com toda a base de dados -----------------------------------
modelo_final <- fit(wf_knn, data = dados_expectativa_renda)

# Visualizando as predi√ß√µes na base de treino
p_ajuste <- ajuste_final$.predictions[[1L]] |> 
  ggplot(aes(x = LifeExpectancy, y = .pred)) + 
  geom_point(size = 3, alpha = 0.7, col = "red") +
  labs(
    title = "Predi√ß√µes versus Real", 
    subtitle = "Usando apenas os dados de teste"
  ) +
  xlab("LifeExpectancy") + 
  xlab("LifeExpectancy predito") + 
  theme(
    title = element_text(face = "bold")
  )

# Unindo os dois plots
p <- p_hiper + p_ajuste + plot_annotation(tag_levels = "A")

# Salvando gr√°ficos
ggsave(p, file = "imgs/plot_hiper_ajuste_tidymodels_knn_whatson.png", width = 30,
       height = 15, units = "cm")
```

O pacote
[dials](https://dials.tidymodels.org/reference/grid_max_entropy.html)
fornece tr√™s fun√ß√µes o *grid* de par√¢metros. S√£o apenas fun√ß√µes que
criam *grids* para os hiperpar√¢metros, segundo algumas metodologias, mas
que na pr√°tica n√£o h√° garantias de qual ir√° funcionar melhor. A ideia √©
experimentar e, por meio de uma valida√ß√£o cruzada, decidir por qual
utilizar. Normalmente, a `grid_max_entropy`, utilizada no c√≥digo acima,
funciona bem.

::: columns
::: {.column width="50%"}
1.  [`grid_max_entropy`](https://dials.tidymodels.org/reference/grid_max_entropy.html)
2.  [`grid_latin_hypercube`](https://dials.tidymodels.org/reference/grid_max_entropy.html)
3.  [`grid_regular`](https://dials.tidymodels.org/reference/grid_regular.html)
4.  [`grid_random`](https://dials.tidymodels.org/reference/grid_regular.html)
:::

::: {.column width="50%"}
![](imgs/dails.png)
:::
:::

![](gifs/thumbs-up-nod.gif)

## Tidymodels $k$NN e Nadaraya-Watson

<br>

Para demonstar que podemos realizar transforma√ß√µes (receitas) na base de
dados, entre do processo de treinamento, foi realizado duas
transforma√ß√µes na vari√°vel `GDPercapita`. A primeira foi a Yeo--Johnson
*transformation* e a segunda foi uma simples normaliza√ß√£o dos dados
(subitrair da m√©dia e dividir pelo desvio padr√£o). A [transforma√ß√£o de
Yeo--Johnson](https://en.wikipedia.org/wiki/Power_transform#Yeo%E2%80%93Johnson_transformation)
√© uma transforma√ß√£o semelhante a de
[Box-Cox](https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation).
A transforma√ß√£o de
[Yeo--Johnson](https://en.wikipedia.org/wiki/Power_transform#Yeo%E2%80%93Johnson_transformation)
trata de situa√ß√µes que a transforma√ß√£o de
[Box-Cox](https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation)
n√£o trata. Por exemplo, ela trata de valores negativos e zero.

<br>

A ideia do *steps* utilizados na faze de pr√©-processamento dos dados, em
que utilizamos o pacote recipes do R, √© que para novas observa√ß√µes,
depois do modelo ajustado, essas transforma√ß√µes ser√£o automaticamente
aplicadas aos novos dados.

<br>

![](gifs/hum.gif)

## Tidymodels $k$NN e Nadaraya-Watson

<br>

![](imgs/plot_hiper_ajuste_tidymodels_knn.png){fig-aling="center"
width="50%"}

## Tidymodels $k$NN e Nadaraya-Watson

<br>

[Exemplo]{.red}: Vamos reproduzir todo o fluxo de treinamento que
fizemos com o m√©todo $k$NN no exemplo anterior, agora, utilizando o
modelo Nadaraya-Watson. Note que uma vez que entendemos o
[tidymodels](https://www.tidymodels.org/), fica f√°cil adaptar um c√≥digo
j√° existente para o treinamento de um outro modelo. Na verdade, o m√©todo
de Nadaraya-Watson implementado no tidymodels √© um pouco diferente.
Ainda utilizamos a informa√ß√£o de $k$, em que o valor de $h$ √©
deverminado pela m√©dia dos vizinhos mais pr√≥ximos de ${\bf x}_i$ √†
${\bf x}$. Al√©m de $k$, temos o valor de $p$ para a dist√¢ncia de
Minkowski como hiperpar√¢metro. Portanto, aqui, teremos dois
hiperpar√¢metros (par√¢metros de sintoniza√ß√£o).

<br>

```{r}
#| code-fold: true
#| code-summary: Workflow completo do treimanento de um modelo Nadaraya-Watson.
#| eval: false
library(tidymodels)
library(dplyr)
library(ggplot2)
library(patchwork)
library(doMC)

# Paralelizando o c√≥digo em sistemas Unix
registerDoMC(cores = parallel::detectCores())

# Resolvendo eventuais conflitos entre tidymodels e outros pacotes eventualmente
# carregados:
tidymodels::tidymodels_prefer()

# Lendo a base de dados:
url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"
arquivo_temp <- tempfile()
download.file(url = url, destfile = arquivo_temp)
load(arquivo_temp)

dados_expectativa_renda <-
  dados_expectativa_renda |>
  dplyr::select(-CountryName)

# Setando uma semente
set.seed(0)

# Divis√£o da base de dados ------------------------------------------------
# Divis√£o inicial (treino e teste)
splits <- 
  rsample::initial_split(
    dados_expectativa_renda,
    strata = "LifeExpectancy", 
    prop = 0.8 
  )

# O conjunto de dados de treinamento ser√° utilizado para ajustar/treinar o
# modelo:
treinamento <- rsample::training(splits)

# O conjunto de teste ser√° utilizado apenas no fim, para avaliar o desempenho
# preditivo final do modelo:
teste <- rsample::testing(splits) 

# Criando uma receita para os dados ---------------------------------------

# Poderia ter passado o conjunto treinamento ou posso passar o conjunto "splits".
# O comando recipes j√° entende que dever√° utilizar o conjunto de treinamento.
receita <- 
  recipes::recipe(formula = LifeExpectancy ~ ., data = treinamento) |> 
  step_YeoJohnson(all_predictors()) |> # Ajuda na normaliza√ß√£o dos dados. Pode ser bom!
  step_normalize(all_predictors()) # Normalizando vari√°veis num√©ricas.

# Construindo modelo Nadaraya ---------------------------------------------
modelo_nadaraya <- 
  parsnip::nearest_neighbor(dist_power = tune(), weight_func = "gaussian") |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("kknn")

# Construindo um workflow (pipeline) --------------------------------------
wf_nadaraya <-
  workflows::workflow() |>
  workflows::add_recipe(receita) |>
  workflows::add_model(modelo_nadaraya)

# Cross-validation --------------------------------------------------------
cv <- 
  treinamento |> 
  rsample::vfold_cv(v = 10L, strata = "LifeExpectancy")

# Busca do hiperpar√¢metro k -----------------------------------------------
metrica <- metric_set(rmse)

# Extraindo e atualizando range do par√¢metro ------------------------------
update_parametros <-
  wf_nadaraya |> 
  extract_parameter_set_dials() |>
  update("dist_power" = dist_power(c(2, 50)))

# Tunagem -----------------------------------------------------------------
meu_grid <- dials::grid_max_entropy(update_parametros, size = 100L)

tunagem <-
  tune::tune_grid(
    wf_knn,
    resamples = cv,
    grid = meu_grid,
    metrics = metrica,
    control = control_grid(save_pred = TRUE, verbose = TRUE)
  )

p_hiper <- autoplot(tunagem) +
  labs(title = "Nadaraya-Watson - Sele√ß√£o do par√¢metro p", subtitle = "Sintoniza√ß√£o do hiperpar√¢metro (dist√¢ncia p)") +
  theme(
    title = element_text(face = "bold")
  )

# Atualizando workflow ----------------------------------------------------
wf_nadaraya <- 
  wf_nadaraya |> 
  finalize_workflow(select_best(tunagem))

# Ajustar o modelo ao conjunto de treinamento e avaliar no teste --------
ajuste_final <- last_fit(wf_nadaraya, splits)

# Ajuste final com toda a base de dados -----------------------------------
modelo_final <- fit(wf_nadaraya, data = dados_expectativa_renda)

# Visualizando as predi√ß√µes na base de treino
p_ajuste <- ajuste_final$.predictions[[1L]] |> 
  ggplot(aes(x = LifeExpectancy, y = .pred)) + 
  geom_point(size = 3, alpha = 0.7, col = "red") +
  labs(
    title = "Predi√ß√µes versus Real", 
    subtitle = "Usando apenas os dados de teste"
  ) +
  xlab("LifeExpectancy") + 
  xlab("LifeExpectancy predito") + 
  theme(
    title = element_text(face = "bold")
  )

# Unindo os dois plots
p <- p_hiper + p_ajuste + plot_annotation(tag_levels = "A")

# Salvando gr√°ficos
ggsave(p, file = "imgs/plot_hiper_ajuste_tidymodels_nadaraya.png", width = 30,
       height = 15, units = "cm")
```

## Tidymodels $k$NN e Nadaraya-Watson

<br>

![](imgs/plot_hiper_ajuste_tidymodels_nadaraya.png){fig-aling="center"}
\## Tidymodels $k$NN e Nadaraya-Watson

<br>

Podemos visualizar a melhor combina√ß√£o de hiperpar√¢metros, segundo
$\widehat{R}(g)$ usando fazendo:

```{r}
#| eval: false

# As cinco melhores combina√ß√µes
tunagem |> 
  show_best()
```

![](gifs/bean_simple.gif)

## Comparando dois ou mais modelos

<br>

**Voc√™ poderia perguntar**: "Certo, mais tenho como comparar dois ou
mais modelos de uma √∫nica vez?"

<br>

::: columns
::: {.column width="50%"}
![](gifs/giphy.gif)
:::

::: {.column width="50%"}
<br>

A resposta √© **Sim**!

<br>

![](gifs/yes.gif)
:::
:::

## Comparando dois ou mais modelos

<br>

Na verdade, √© bem mais interessante comparar conjuntamente, visto que
para poder compararmos devemos garantir que as mesmas amostras de
treinamento e teste est√£o sendo utilizadas, i.e., para termos uma
compara√ß√£o mais justa. Claro que d√° para fazer de forma separada,
fixando a semente dos geradores de n√∫meros pseudo-aleat√≥rios, para que a
biblioteca rsample possa reproduzir a mesma divis√£o para ambos os
modelos. Por√©m, a estrat√©gia do exemplo abaixo √© mais consistente.

<br>

[Exemplo]{.red}: Estude o c√≥digo que segue! Ele compara os modelos de
$k$NN com o m√©todo de Nadaraya-Watson.

<br>

```{r}
#| code-fold: true
#| code-summary: Workflow completo do treimanento e compara√ß√£o de dois modelos (KNN e Nadaraya-Whatson).
#| eval: false

library(tidymodels)
library(dplyr)
library(ggplot2)
library(patchwork)

# Resolvendo eventuais conflitos entre tidymodels e outros pacotes eventualmente
# carregados:
tidymodels::tidymodels_prefer()

# Lendo a base de dados:
url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"
arquivo_temp <- tempfile()
download.file(url = url, destfile = arquivo_temp)
load(arquivo_temp)

dados_expectativa_renda <-
  dados_expectativa_renda |>
  dplyr::select(-CountryName)

# Setando uma semente
set.seed(0)

# Divis√£o da base de dados ------------------------------------------------
# Divis√£o inicial (treino e teste)
splits <- 
  rsample::initial_split(
    dados_expectativa_renda,
    strata = "LifeExpectancy", 
    prop = 0.8 
  )

# O conjunto de dados de treinamento ser√° utilizado para ajustar/treinar o
# modelo:
treinamento <- rsample::training(splits)

# O conjunto de teste ser√° utilizado apenas no fim, para avaliar o desempenho
# preditivo final do modelo:
teste <- rsample::testing(splits) 

# Criando uma receita para os dados ---------------------------------------

# Poderia ter passado o conjunto treinamento ou posso passar o conjunto "splits".
# O comando recipes j√° entende que dever√° utilizar o conjunto de treinamento.
receita_knn <- 
  recipes::recipe(formula = LifeExpectancy ~ ., data = treinamento) |> 
  step_YeoJohnson(all_predictors()) |> # Ajuda na normaliza√ß√£o dos dados. Pode ser bom!
  step_normalize(all_predictors()) # Normalizando vari√°veis num√©ricas.

receita_nadaraya <- receita_knn

# Construindo modelo kNN --------------------------------------------------
modelo_knn <- 
  parsnip::nearest_neighbor(neighbors = tune()) |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("kknn")

# Construindo modelo Nadaraya ---------------------------------------------
modelo_nadaraya <- 
  parsnip::nearest_neighbor(dist_power = tune(), neighbors = tune(),
                            weight_func = "gaussian") |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("kknn")

# Valida√ß√£o cruzada -------------------------------------------------------
set.seed(0)
cv <- rsample::vfold_cv(treinamento, v = 5L)

# Criando workflow conjunto -----------------------------------------------
all_wf <- 
  workflow_set(
    preproc = list(receita_knn, receita_nadaraya),
    models = list(modelo_knn = modelo_knn, modelo_nadaraya = modelo_nadaraya)
  )

# Tunando ambos os modelos ------------------------------------------------
tunagem <- 
  all_wf |> 
  workflow_map(
    seed = 0, 
    verbose = TRUE,
    resamples = cv,
    grid = 50,
    metrics = metric_set(rmse)
  )

# Selecionando o melhor de cada um dos modelos ----------------------------
melhor_knn <- 
  tunagem |> 
  extract_workflow_set_result("recipe_1_modelo_knn") |> 
  select_best("rmse")

melhor_nadaraya <- 
  tunagem |> 
  extract_workflow_set_result("recipe_1_modelo_nadaraya") |> 
  select_best("rmse")

# Avaliando o desempenho no conjunto de teste
teste_knn <- 
  tunagem |> 
  extract_workflow("recipe_1_modelo_knn") |> 
  finalize_workflow(melhor_knn) |> 
  last_fit(split = splits)

teste_nadaraya <- 
  tunagem |> 
  extract_workflow("recipe_1_modelo_nadaraya") |> 
  finalize_workflow(melhor_nadaraya) |> 
  last_fit(split = splits)

# Visualizando as m√©tricas de cada um
collect_metrics(teste_knn)
collect_metrics(teste_nadaraya)

# Ajustando o modelo com todos os dados. Aqui escolhemos o Nadaraya-Watson
modelo_final <- 
  teste_nadaraya |> 
  extract_workflow("recipe_1_modelo_nadaraya") |> 
  fit(data = dados_expectativa_renda)

# Fazendo previs√µes com novos dados. Aqui usarei os mesmos dados
predict(modelo_final, new_data = dados_expectativa_renda)

# Salvando o modelo em um arquivo. Aqui estou supondo que salvei em
# "~/Downloads/modelo_final.rds":
# saveRDS(modelo_final, file = "~/Downloads/modelo_final.rds")

# Lendo um modelo salvo para depois fazer predi√ß√µes. Aqui estou supondo que 
# o modelo encontra-se salvo em "~/Downloads/modelo_final.rds":
# readRDS("~/Downloads/modelo_final.rds")
![](gifs/bom.gif)
```

## Suport Vector Regression Machine

<br>

M√©todos de estima√ß√£o da fun√ß√£o de regress√£o $r({\bf x})$ com base em *Reproducing Kernel Hilbert Spaces* - RKHs s√£o fam√≠lias de metodologias bastante gerais. A ideia desses m√©todos envolvem definir uma fun√ß√£o objetivo para a quantifica√ß√£o da qualidade das predi√ß√µes e, porteriormente, busca-se uma fun√ß√£o que melhor se ajuste ao espa√ßo de fun√ß√µes $\mathcal{H}$. Busca-se uma solu√ß√£o para

$$\argmin_{g \in \mathcal{H}} \sum_{k = 1}^n L(g({\bf x}_k, y_k)) + \mathcal{P}(g),$${#eq-objetivo-geral-hilbert}
em que $L$ √© uma fun√ß√£o de perda arbitr√°ria, $\mathcal{P}$ uma medida de complexidade de $g$ e $\mathcal{H}$ um subespa√ßo de fun√ß√µes.

<br>

::: columns

::: {.column width='50%'}
Ocorre que para um espa√ßo de fun√ß√µes arbitr√°rio, a solu√ß√£o para o problema seria bastante dif√≠cil. A ideia √© poder uma grande fam√≠lia de espa√ßos $\mathcal{H}$ (RKHs) de modo que a solu√ß√£o do problema seja relativamente simples de ser implementada.
:::

::: {.column width='50%'}
![](gifs/ok.gif){fig-aling='rigth'}
:::
:::

## Suport Vector Regression Machine

<br>

M√©todos de regress√£o que se baseiam em panaliza√ß√£o em RKHS s√£o uma generaliza√ß√£o da @eq-objetivo-geral-hilbert, em que a fun√ß√£o objetivo nesse caso √© dada por:

$$\argmin_{g \in \mathcal{H}_k} \sum_{k = 1}^n L(g({\bf x}_k, y_k)) + \lambda||g||_{\mathcal{H}_k}^2,$${#eq-funcao-objetivo-geral}
em que $\mathcal{H}_{k}$ √© um RKHS e $L$ √© uma fun√ß√£o adequada para o problema em quest√£o. Calma que vai ser relativamente simples definir $\mathcal{H}_{k}$, uma vez que isso √© feito utilizando fun√ß√µes kernel, em particular, o [kernel de Mercer](https://en.wikipedia.org/wiki/Mercer%27s_theorem).

![](gifs/bean_simple.gif)

## Suport Vector Regression Machine

<br>

O termo $||g||_{\mathcal{H}_k}^2$ na @eq-funcao-objetivo-geral reflete a suavidade das fun√ß√µes em $\mathcal{H}_k$ e cada espa√ßo poder√° conter uma no√ß√£o de suavidade diferente, a depender da fun√ß√£o de kernel escolhida. Sim, a fun√ß√£o ed kernel e fun√ß√£o de perda $L$ s√£o escolhidas pelo usu√°rio da metodologia.

<br>

√â claro que para diferen√ßas kernel (kernel de Mercer), poderemos ter diferentes resultados que pode ser avaliado em um procedimento de valida√ß√£o-cruzada (*cross-validation*). O par√¢metro $\lambda$ √© um hiperpar√¢metro que podemos obter dentro de uma valida√ß√£o-cruzada, testando, por exemplo, um *grid* de par√¢metros, para selecionarmos um $\lambda$ que forne√ßa o melhor risco estimado $\widehat{R}(g)$.

<br>

A parcela $||g||_{\mathcal{H}_k}^2$ mensura a suavidade das fun√ß√µes em $\mathcal{H}_k$. Assim como $g$, $||g||_{\mathcal{H}_k}^2$ ser√° definidas em termos da fun√ß√£o de kernel, e essa √© a grande sacada!

<br>

![](gifs/uau.gif)

## Suport Vector Regression Machine

<br>

**Defini√ß√£o** ([Kernel de Mercer]{.red}): Seja $K({\bf x}_a, {\bf x}_b)$ uma fun√ß√£o
com dom√≠nio em $\mathcal{X} \times \mathcal{X}$ (dom√≠nio das *features*/covari√°veis/espa√ßo de caracter√≠sticas) que 
poder√° ser mais geral que $\mathbb{R}^d$. Diremos que uma fun√ß√£o $K$, tal que $K:{\mathcal{X}\times\mathcal{X}}\longrightarrow \mathbb{R}$ √© um **Kernel de Mercer**
se ele satisfaz √†s condi√ß√µes que seguem:

<br>

1. [Simetria]{.red}: $K({\bf x}_a, {\bf x}_b) = K({\bf x}_b, {\bf x}_a)$, para todo
${\bf x}_a,{\bf x}_b \in \mathcal{X}$;

2. [Positivo semi-definido]{.red}: a matriz $\big[K({\bf x}_a,{\bf x}_b)\big]_{i,j = 1}^n$ √© 
positiva semi-definida para todo $n \in \mathbb{N}$ e para todo ${\bf x}_1,\cdots, {\bf x}_n \in \mathcal{X}$.

<br>

Ser positiva semi-definida, significa que para qualquer sequ√™ncia $c_r \in \mathbb{R}\,, \forall r = 1, \cdots, n$, temos que

$$\sum_{i = 1}^n\sum_{k = 1}^n c_i c_k K({\bf x}_i,{\bf x}_k)\geq 0,\, \forall n \geq 2.$$

## Suport Vector Regression Machine

<br>

Alguns kernels de Mercer comuns s√£o:

<br>

1. **Kernel Linear**: $K({\bf x}_i, {\bf x}_l) = {\bf x}_i^T{\bf x}_l$;
2. **Kernel Polinomial de grau** $p$: $K({\bf x}_i, {\bf x}_l) = (1 + \langle{\bf x}_i, {\bf x}_l\rangle)^p, \gamma > 0, \theta \geq 0, p \in \mathbb{N}$;
3. **Kernel Gaussiano**: $K({\bf x}_i, {\bf x}_l) = \exp\left\{-\frac{d^2({\bf x}_i, {\bf x}_l)}{2h^2}\right\},\, h > 0$;
4. **Kernel Laplaciano**: $K({\bf x}_i, {\bf x}_l) = \mathrm{e}^{-\gamma d({\bf x}_i, {\bf x}_l)}\,, \gamma > 0$;
5. **Kernel Sigm√≥ide**: $K({\bf x}_i, {\bf x}_l) = \tanh(\gamma {\bf x}_i^T{\bf x}_l + \theta), \, \gamma>0, \theta>0$.

<br>

em que $\gamma, h, \theta$ e $p$, s√£o par√¢metros do kernel.


## Suport Vector Regression Machine

<br>

A ideia principal por tr√°s dos m√©todos que fazem uso de kernel √© fazer o uso de um mapeamento n√£o-linear
arbitr√°rio $\phi$ do espa√ßo original dos padr√µes de entrada para um espa√ßo de mais alta dimens√£o, $\mathcal{X} \times \mathcal{X}$ chamado de espa√ßo de caracter√≠sticas.

<br>

Um conjunto de padr√µes que entrada, em um problema de classifica√ß√£o, por exemplo, que n√£o √© linearmente separ√°vel
poder√° se tornar linearmente separ√°vel atrav√©s desse mapeamento n√£o linear.

<br>

Em um espa√ßo vetorial, o **produto interno**, $\langle{\bf x}_i,{\bf x}_j\rangle = {\bf x}_i^{T}{\bf x}_j$, normalmente √© utilizado como medida de similaridade entre vetores. Por√©m, como n√£o conhecemos $\phi(\cdot)$, n√£o √© poss√≠vel realizar $\phi({\bf x}_i)^T\phi({\bf x}_j)$ em $\mathcal{X}\times\mathcal{X}.$ Aparentemente √© bem complicado calcular $\langle\phi({\bf x}_i),\phi({\bf x}_j)\rangle$, sem conhecer $\phi(\cdot)$, n√£o √© verdade?!

![](gifs/ok.gif)

## Suport Vector Regression Machine

<br>

A ess√™ncia dos m√©todos m√©todos baseado em kernel, √© que n√£o precisamos conhecer $\phi(\cdot)$. Os produtos internos no espa√ßo de caracter√≠sticas poder√° ser calculado utilizando um kernel de Mercer. 

<br>

[Teorema de Mercer]{.red}: Todo kernel de Mercer $K$ pode ser decomposto como 

$$K({\bf x}_a,{\bf x}_b) = \sum_{i \geq 0} \gamma_i \phi_i({\bf x}_a)\phi_i({\bf x}_b),$$ {#eq-mercer-decomposicao}
em que $\sum_{i \geq 0} \gamma_i^2 < \infty$ e $\phi_0, \phi_1, \cdots$ √© uma sequ√™ncia de fun√ß√µes. Essa propriedade dos em que o kernel de Mercer poder√° ser decomposto na forma acima e que n√£o precisamos conhecer $\phi(\cdot)$ para o c√°lculo de produtos internos no espa√ßo de caracter√≠sticas √© comumente denominada de [*kernel trick*]{.red}/[truque kernel]{.red}.  Ver detalhes em [aqui](https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.1909.0016).


## Suport Vector Regression Machine

<br>

[Defini√ß√£o]{.red}: Seja $K$ um kernel de Mercer, e sejam $\phi_i$ e $\gamma_i,\, i \geq 0$, da forma do teorema acima. Ent√£o,

<br>

$$\mathcal{H}_K = \left\{g \in L^2(\mathcal{X}):\,\, existem\,\, (c_i)_{i\geq0}\,\, com\,\,\sum_{i\geq1}\frac{c_i^2}{\gamma_i} < \infty\,\,,\, tais\,\, que\,\, g({\bf x}) = \sum_{i\geq1} c_i\phi_i({\bf x}) \right\}.$$

<br>

Diremos que $\mathcal{H}_k$ √© o *Reproducing Kernel Hilbert Space* - RKHS associado ao kernel $K$, em que a norma de uma fun√ß√£o $g({\bf x}) = \sum_{i\geq0}c_i\phi({\bf x})$ √© definda por

$$||g||_{\mathcal{H}_k}^2 := \sum_{i \geq 0} c_i^2/\gamma_i.$$

<br>

Al√©m disso, tem-se que $\mathcal{H}_K$ √© **√∫nica** para um dado $K$, muito embora a decomposi√ß√£o dada pela @eq-mercer-decomposicao n√£o seja √∫nica.

## Suport Vector Regression Machine

<br>
O Teorema que segue, frequentemente atribu√≠do a ao artigo Kimeldorf, G. S. & Wahba, G. (1970). **A correspondence between Bayesian estimation on stochastic processes and smoothing by splines**. The Annals of Mathematical
Statistics, 495‚Äì502, simplifica o problema de otimizar a fun√ß√£o objetivo dada na @eq-funcao-objetivo-geral.

<br>

[Teorema da Representa√ß√£o]{.red}: Seja $K$ um kernel de Mercer correspondente ap RKHS $\mathcal{H}_K$. Considere o conjunto de treinamento $({\bf x}_1, y_1), \cdots, ({\bf x}_n, y_n)$ e uma fun√ß√£o de perda arbitr√°ria $L$. Ent√£o, a solu√ß√£o de 

<br>

$$\argmin_{g \in \mathcal{H}_K} \sum_{k = 1}^n L(g({\bf x}_k), y_k) + \lambda||g||_{\mathcal{H}_K^2},$$ {#eq-teorema-representacao}
existe, e √© √∫nica, em que

<br>

$$g({\bf x}) = \sum_{k=1}^n \alpha_k K({\bf x}_k, {\bf x}),$$
em que $\alpha_1, \cdots, \alpha_n$ √© uma sequ√™ncia de valores reais.

## Suport Vector Regression Machine

<br>

√â poss√≠vel desmontrar que a otimiza√ß√£o da @eq-teorema-representacao poder√° se dar pela otimiza√ß√£o de

<br>

$$\argmin_{\alpha_1, \cdots, \alpha_n}\sum_{k = 1}^n L\left(\overbrace{\sum_{i=1}^n\alpha_iK({\bf x}_i, {\bf x})}^{g({\bf x})}, y_k \right) + \lambda\underbrace{\sum_{1 \leq j,k \leq n}\alpha_i\alpha_k K({\bf x}_j, {\bf x}_k)}_{||g||_{\mathcal{H}_K}^2}.$$

<br>

Portanto, o problema de otimizar a fun√ß√£o objetivo dada na @eq-funcao-objetivo-geral se reduz a encontrar os valores de $\alpha_1, \cdots, \alpha_n$ que minimiza a @eq-teorema-representacao. Portanto, ir√° especificar o kernel $K$ e a fun√ß√£o de perda $L$, em que $\lambda$ √© um par√¢metro de sintoniza√ß√£o (hiperpar√¢metro) que poder√° ser obtido por uma valida√ß√£o cruzada.

## Suport Vector Regression Machine

<br>

Em se tratando de estimadores de regress√£o, *Support Vector Regression Machines*, utiliza-se uma fun√ß√£o de perda diferente da quadr√°tica, como definido em Drucker, H., Burges, C. J., Kaufman, L., Smola, A. J. & Vapnik, V. (1997). **Support vector regression machines** em Advances in neural information processing systems.

<br>

Eles definem a seguinte fun√ß√£o de perda $L(g({\bf x}_k, y_k)) = (|y_k - g({\bf x}_k)| - \varepsilon)_{+}$, que assume o valor 0 se $|y_k - g({\bf x}_k)| < \varepsilon$ e assumir√° $|y_k - g({\bf x}_k)| - \varepsilon$, caso contr√°rio.

<br>

![](gifs/hum.gif)

## Suport Vector Regression Machine

[Exemplo]{.red}: Vamos consirar a base de dados de vinho vermelhoüç∑,
dispon√≠veis
[aqui](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009),
fa√ßa uma pequena an√°lise explorat√≥ria dos dados. No
[link](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)
do Kaggle voc√™ consegue uma explica√ß√£o sobre o que significa cada uma
das vari√°veis.

```{=html}
 <iframe id="example1" src="reports_code/tufte_svm_regressao.html" style="border: none; width: 100%; height: 90%" frameborder="0"></iframe>
```

## üå≥ √Årvores de regress√£o

<br>

Em aprendizagem de m√°quina, uma arvore de regress√£o consiste em uma
metodologia n√£o-param√©trica que nos leva a resultados que s√£o facilmente
interpret√°veis. A √°rvore √© construirda por meio de particionamentos
recursivos no espa√ßo das covari√°veis. Cada parti√ß√£o recebe o nome de
[n√≥]{.red} e o resultado final (valor da regress√£o) √© denominado de
[folha]{.red} üçÉ.

<br>

[Exemplo]{.red}: Construindo uma √°rvore de regress√£o, usando a
biblioteca
[rpart](https://cran.r-project.org/web/packages/rpart/index.html) para
constru√ß√£o da √°rvore e a biblioteca
[rpart.plot](https://cran.r-project.org/web/packages/rpart.plot/index.html)
para a plotagem da √°rvore estimada.

```{r}
library(rpart)
library(rpart.plot)

dados <- readr::read_csv(file = "dados/winequality-red.csv", show_col_types = FALSE)
arvore <-  rpart::rpart(formula = quality ~ ., data = dados)
rpart.plot(arvore, type = 4, extra = 1)
```

Perceba que h√° um particionamento bin√°rio em cada n√≥ da √°rvore üå≥ e que
poderemos sequir para a aresta da esquerda quando a condi√ß√£o no n√≥ for
verdadeira e para direita caso contr√°rio. Dada uma nova observa√ß√£o
${\bf x}_i$, poderemos seguir as condi√ß√µes da √°rvore at√© chegar a uma
folha üçÉ dessa √°rvore. Nesse caso, a folha üçÉ cont√©m uma estimativa da
qualidade do vinho.

<br>

Por exemplo, na √°rvore acima podemos perceber que vinhos com teor
alco√≥lico inferior √† 11 nos conduzem a vinhos üç∑ de qualidade inferior.
Temos que vinhos com teor alco√≥lico maior que 11 e com sulfato maior que
0.65 nos levam √† √≥timos vinhos, segundo o conjunto de dados utilizado.

<br>

Perceba que dado ${\bf x}_i$, poderemos percorrer a √°rvore a m√£o.

## üå≥ √Årvores de regress√£o

<br>

Formalmente, temos que a metodologia de estima√ß√£o de uma √°rvore de
regress√£o cria uma parti√ß√£o no espa√ßo das covari√°veis em regi√µes
distintas e disjuntas, que denotaremos de $R_1, R_2, \cdots, R_j$, com
$R_a \cap R_b$, $\forall a,b \in 1, \cdots, j$. A predi√ß√£o √© dada por:

$$g({\bf x}) = \frac{1}{|\{i:{\bf x}_i \in R_k\}|}\sum_{i:{\bf x}_i \in R_k} y_i.$$

<br>

**A constru√ß√£o de uma √°rvore de regress√£o envolve dois passos
principais**:

<br>

1.  A cria√ß√£o de uma √°rvore complexa que nos leve a parti√ß√µes "puras",
    i.e., a parti√ß√µes nas observa√ß√µes do conjunto de coveri√°veis que nos
    leve a valores de $Y$, no conjunto de treinamento em cada uma das
    folhas sejam homog√™neas;

2.  Podar a √°rvore, com a finalidade de evitarmos super-ajuste
    (*overffiting*), e portanto, termos uma alta vari√¢ncia do modelo.

## üå≥ √Årvores de regress√£o

<br>

No passo 1, para avaliarmos o qu√£o razo√°vel √© uma √°rvore $T$, utilizamos
o Erro Quadr√°tico M√©dio - EQM, em que

$$\mathcal{P}(T) = \sum_{R}\sum_{i:{\bf x}_i \in R} \frac{(y_i - \widehat{y}_R)^2}{n},$$
em que $\widehat{y}_R$ √© o valor predito de $y$ para a resposta de uma
observa√ß√£o pertencente √† regi√£o $R$.

<br>

Encontrar uma √°rvore $T$ que minimize $\mathcal{P}(T)$ √© uma tarefa
computacionalmente cara. Por isso, que os algoritmos de estima√ß√£o de $T$
normalmente utilizam parti√ß√µes bin√°rias, como no exemplo anterior.

<br>

Existem diversos algoritmos utilizados para estima√ß√£o de $T$, em que o
[*C*]{.red}*lassification [A]{.red}nd [R]{.red}egression [T]{.red}ree* -
[CART]{.red} √© o mais conhecido. O algoritmo foi estabelecido no livro Breiman
L., Friedman J. H., Olshen R. A., and Stone, C. J. (1984)
**Classification and Regression Trees**. Wadsworth.

## üå≥ √Årvores de regress√£o

<br>

O algoritmo particiona o espa√ßo de covari√°veis em duas regi√µes
disjuntas. Para a escolha dessa parti√ß√£o, busca-se, dentre todas as
covari√°veis $x_i$ e cortes $t_1$, a combina√ß√£o que conduz a uma parti√ß√£o
$(R_1, R_2)$ com menor predi√ß√µes de erro quadr√°tico, i.e., dado um n√≥, a
parti√ß√£o √© constru√≠da de modo a minimizar:

$$SSE = \sum_{i:{\bf x}_i \in R_1}^n (y_i - \widehat{y}_{R_1})^2 + \sum_{i:{\bf x}_i \in R_2}^n (y_i - \widehat{y}_{R_2})^2,$${#eq-sse-tree}
em que $\widehat{y}_{R_k}$ √© a predi√ß√£o de $y$ fornecida pela regi√£o
$R_k$ e SSE √© denominado *[S]{.red}um of [S]{.red}quares of [E]{.red}rrors* - SSE.

<br>

Assim, tem-se que o algoritmo ir√° fornecer:

<br>

$$R_1 = \{{\bf x} : {\bf x}_i < t_1\}\, \mathrm{e}\, R_2 = \{{\bf x} : {\bf x}_i \geq t_1\},$$
em que $x_i$ √© a vari√°vel escolhida e $t_1$ √© o corte definido.

## üå≥ √Årvores de regress√£o

<br>

Uma vez que estabelecemos um n√≥ raiz, este √© fixado. No passo seguinte, o algoritmo ir√° particionar as regi√µes $R_1$ e $R_2$ em regi√µes menores, seguindo o mesmo crit√©rio,tanto para $R_1$ quanto para $R_2$. O algoritmo continua de forma recursiva at√© que tenhamos uma √°rvore com poucas observa√ß√µes em uma das folhas üçÉ. 

<br>

Por exemplo, podemos decidir em parar de tornar a √°rvore profunda quando em cada folha tivermos menos de 5 observa√ß√µes. Por√©m, essa √°rvore criada ir√° produzir boas predi√ß√µes para o conjunto de treinamento, por√©m, n√£o ir√° performar bem em novas observa√ß√µes. Isso, por conta, do *trade off* entre vi√©s e vari√¢ncia. Em outras palavas, haver√° *overfitting*.

<br>
Na etapa do processo de poda, cada n√≥ √© retirado, um por vmez, e observa-se como o erro de predi√ß√£o varia no conjunto de valida√ß√£o. Com base nisso, decide-se quais n√≥s permanecem na √°rvore. O processo de poda reduz o *overffiting* do modelo.

## üå≥ √Årvores de regress√£o

<br>

Para limitar a profundidade da arvore $T$ a ser estimada, um par√¢metro de penaliza√ß√£o/complexidade poder√° ser introduzido na @eq-sse-tree. Assim, o problema consistem em obter regi√µes e pontos de cortes que minimize:

$$SSE + \alpha|T|,$$
em que $\alpha > 0$ √© o hiperpar√¢metro de complexidade do modelo e $|T|$ √© um valor inteiro que define a profundidade m√°xima da √°rvore. Por exemplo, $|T|$ na biblioteca [rpart](https://cran.r-project.org/web/packages/rpart/index.html) √© definido pelo par√¢metro `tree_depth` em 30. Normalmente nos concentramos em em tunar o par√¢metro `cost_complexity` que √© o $\alpha$. 

![](gifs/hum.gif)

## üå≥ √Årvores de regress√£o

<br>

[Exemplo]{.red}: Poderemos podar a √°rvore usando a fun√ß√£o `prune` do pacote [rpart](https://cran.r-project.org/web/packages/rpart/index.html). Considerando o exemplo anterior, tornando a √°rvore menos comple√ßa, poder√≠amos decidir em podar alterando o seu par√¢metro de complexidade.

```{r}
library(rpart)
library(rpart.plot)

dados <- readr::read_csv(file = "dados/winequality-red.csv")

arvore <- dados |> 
  rpart::rpart(formula = quality ~ ., data = _) 

# O melhor par√¢metro de custo
melhor_grau <- arvore$cptable[nrow(arvore$cptable),][1L]

# Aumentando o par√¢metro de custo de 0.01 para 0.04
arvore_podada <- rpart::prune(tree = arvore, cp = 0.04)

# Plotando a √°rvore podada
rpart.plot::rpart.plot(arvore_podada)
```

## üå≥ √Årvores de regress√£o

<br>
O par√¢metro de complexidade/custo √© um hiperpar√¢metro, e dever√° ser estimado dentro de um procedimento de valida√ß√£o cruzada.


<br>

![](gifs/bom.gif)

## üå≥ √Årvores de regress√£o

<br>
**Algumas observa√ß√µes sobre a √°rvore üå≥ de regress√£o**:

<br>

1. √â um m√©todo n√£o-param√©trico;
2. Pode ser representado graficamente;
3. √â √∫til na an√°lise explorat√≥ria dos dados do problema em quest√£o;
4. Pode ser utilizada para selecionar vari√°veis. Aparentemente, as vari√°veis que pertence √† √°rvore tem uma maior import√¢ncia para o problema em quest√£o;
5. Poder√° trabalhar com vari√°veis num√©ricas, mas tamb√©m poder√° trabalhar com vari√°veis categ√≥ricas. Veremos o uso de √°rvore de classifica√ß√£o mais a frente.

<br>

![](gifs/chapulin-colorado-no.gif)

## üå≥ √Årvores de regress√£o

<br>

O n√≠vel de complexidade √© obtido via *cross-validation* de modo a encontrar a menor sub√°rvore que generaliza melhor o problema para dados n√£o visto. 

<br>

Assim como nos modelos de regress√£o com penalidade que vimos anteriormente, aqui, para valores menores de $\alpha$ tende a produzir modelos mais complexos. Consequentemente, √† medida que uma √°rvore cresce, a redu√ß√£o no $SSE$ deve ser maior do que a penalidade de complexidade de custo.

<br>

![](gifs/chaves-isso.gif)

## üå≥ √Årvores de regress√£o

<br>

Experimente alterar o par√¢metro de complexidade e perceba como ele influencia nas regi√ß√µes da √°rvore de regress√£o. Quando maior o valor, maior a penalidade, e portanto, mais simples ser√° a √°rvore de regress√£o que ir√° estimar os valores de $Y_i$ com base em $X_i$.

<br>

```{=html}
 <iframe id="example1" src="https://pedro-rafael.shinyapps.io/shiny_apps/#section-%C3%A1rvore-de-regress%C3%A3o" style="border: none; width: 100%; height: 90%" frameborder="0"></iframe>
```

![](gifs/giphy.gif)

## üìö Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Considere a vari√°vel aleat√≥ria $Y_i \sim \mathcal{N}(\sin(X_i), \sigma^2)$, com $X_i \in \mathcal{U}(0, 10)\,, \forall i.$ Utilizando a biblioteca **rpart**, implemente a fun√ß√£o `arvore(n = 250L, complexidade, sigma = 0.1)` que devolve o gr√°fico *scatterplot* com os pontos $X_i$ e $Y_i$ e por cima deles o gr√°fico de linha com os valores preditos. A fun√ß√£o dever√° ter tr√™s argumentos, `n`, `complexidade` e `sigma`, que s√£o o tamanho da amostra, o grau de complexidade do modelo, e o desvio padr√£o, respectivamente. Aqui n√£o se preocupe com divis√£o entre treino e teste nem valida√ß√£o cruzada. A solu√ß√£o desse exerc√≠cio n√£o tem como objetivo encontrar o melhor hiperpar√¢metro, i.e., n√£o √© necess√°rio "tunar" o par√¢metro `complexidade`. A fun√ß√£o dever√° retornar algo como:

```{r}
#| echo: false
library(ggplot2)
library(tibble)
library(rpart)

random_y <- function(n = 250L, sigma = 0.1){
  x <- runif(n = n, min = 0, max = 10)
  tibble(x = x, y = rnorm(n = n, mean = sin(x), sd = sigma))
}

set.seed(0)

arvore <- function(dados, complexidade = 0.5, graph = TRUE, ...){
  
  dados <- random_y(...)
  
  arvore <- rpart::rpart(formula = y ~ ., data = dados)
  arvore <- rpart::prune(arvore, cp = complexidade) # Realizando poda
  
  dados$y_chapeu <- predict(arvore, newdata = dados)
  
  # Plotando x versus y -----------------------------------------------------
  dados |> 
    ggplot(aes(x, y)) + 
    geom_point() + 
    geom_line(aes(x, y_chapeu), linewidth = 1.5, col = "red") +
    labs(
      title = "√Årvore de regress√£o",
      subtitle = glue::glue("Par√¢metro de coplexidade = {complexidade}")
    )
}

arvore(complexidade = 0.2)
```

## üìö Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Ainda com base no exerc√≠cio anterior, construa uma fun√ß√£o que retorne v√°rias estimativas obtidas por √°rvores de regress√£o, com base em v√°rias amostra de $X_i$ e $Y_i$. O gr√°fico dever√° mostrar as estimativas das diversas √°rvores de regress√£o, sem mostrar os pontos. Perceba a flutua√ß√£o das estimativas em diferentes valores de `complexidade`, dado `n` e `sigma` fixos. 

<br>

[Exerc√≠cio]{.red}: Sem utilizar a biblioteca **tidymodels**, apenas as bibliotecas **rsample** e **rpart**, treine um modelo com 10 mil observa√ß√µes geradas. No procedimento $k$-folds cross-validation, para $k = 20$, encontre um bom valor para o grau de complexidade considerando um *grid* de poss√≠veis valores. *Dica*: experimente testar um par√¢metro dentro do conjunto de treino no procedimento de *cross-validation*. Por exemplo, experimente criar um *grid* com valores entre $0.001$ e $0.4$. Aprensente o gr√°fico com a estimativa do melhor modelo. N√£o esque√ßa de fixar um valor de semente, para que os resultados possam ser reproduzidos.

<br>

[Exerc√≠cio]{.red}: Refa√ßa o exerc√≠cio anterior utilizando a biblioteca **tidymodels**. Fique livre para tunar o hiperpar√¢metro que achar necess√°rio, da *engine* que utilizar com a biblioteca **parsnip**. Compare o risco preditivo do exerc√≠cio anterior com o que voc√™ obteve utilizando o **tidymodels**.
