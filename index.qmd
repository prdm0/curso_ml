---
title: "Machine Learning / Aprendizagem de M√°quina"
author: "Prof. Dr. Pedro Rafael D. Marinho<br>Departamento de Estat√≠stica - UFPB<br>"
date: '`r Sys.Date()`'
format: 
  revealjs:
    theme: [default, style.scss]
    width: 1920
    height: 1080
    logo: "https://www.ufpb.br/de/contents/imagens/logode.png"
    footer: '<a href="https://www.ufpb.br/de">Departamento de Estat√≠stica da UFPB</a>'
    transition: slide
    background-transition: fade
    preview-links: true
    slide-number: true
    chalkboard: true
    scrollable: true
    controls: true
    incremental: true  
    code-tools: true
    auto-stretch: true
    code-link: true
    html-math-method: katex
    auto-animate: false
  pdf: 
    include-in-header:  
      - text: |
            \usepackage{amsfonts}
            \usepackage{amsmath}
revealjs-plugins:
  - pointer
  - attribution
  - roughnotation
filters:
   - roughnotation
execute:
  refresh: true
  warning: false
  error: false
  eval: true
  echo: true
editor: 
  markdown: 
    wrap: 72
lang: pt
---

<!-- ```{r} -->

<!-- #| echo: false -->

<!-- #| warning: false -->

<!-- #| eval: true -->

<!-- if(fs::dir_exists("index_files/")) -->

<!--   fs::dir_delete("index_files/") -->

<!-- ``` -->

::: r-fit-text
Aprendizagem de M√°quina

[Bacharelado em Estat√≠stica]{.flow}

UFPB
:::

#  {.title}

::: r-fit-text
[Apresenta√ß√£o]{.flow}
:::

##  {background-image="https://raw.githubusercontent.com/prdm0/imagens/main/eu.jpg" background-size="contain" background-position="left"}

::: columns
::: {.column width="40%"}
:::

::: {.column width="60%"}
## Sobre mim {.r-fit-text}

<br> <br>

-   Me chamo [Prof. Dr. Pedro Rafael D.
    Marinho](https://prdm.netlify.app/about_pt_br.html){preview-link="true"}.
    Meu curr√≠culo Lattes poder√° ser acessado clicando
    [aqui](http://lattes.cnpq.br/7185368598935272){preview-link="true"}.

-   Sou docente do Departamento de Estat√≠stica da UFPB. üë®‚Äçüè´

-   Toda minha forma√ß√£o acad√™mica √© na √°rea de estat√≠stica (bacharelado
    ao doutorado).

-   Tenho entusiasmo por programa√ß√£o, ci√™ncia de dados e aprendizagem de
    m√°quina üíªüìà.

-   `r fontawesome::fa("github", "black")` Me acompanhe no GitHub:
    <https://github.com/prdm0>.

-   `r fontawesome::fa("linkedin", "black")` Me acompanhe no Linkedin:
    <https://www.linkedin.com/in/prdm0/>.
:::
:::

# O Departamento {.title}

## Meu segundo lar {.r-fit-text background-color="black" background-image="https://raw.githubusercontent.com/prdm0/imagens/main/foto_aerea_ufpb.jpeg" background-size="1600px" background-repeat="repeat" background-opacity="0.35"}

```{r width = 100, height = 100, echo = FALSE, fig.cap="Departamento de Estat√≠stica da UFPB."}
library(leaflet)
leaflet() |>
  addMarkers(-34.846199, -7.140400) |>
  leaflet::addTiles() |>
  setView(
  -34.846199, -7.140400, zoom = 37,
  options = popupOptions(
    minWidth = 1600,
    maxWidth = 1500
  ))
```

## `r fontawesome::fa("laptop-code", "black")` Que linguagem de programa√ß√£o utilizar?

<br>

Nesse curso, ser√° abordado a linguagem de programa√ß√£o
[R](https://www.r-project.org/), mas lembre-se que voc√™ poder√° utilizar
qualquer linguagem de programa√ß√£o para fazer ci√™ncia de dados. Por√©m, R
e Python s√£o as minhas sugest√µes, haja vista que, atualmente, elas s√£o
as linguagens com maior quantidade de ferramentas e usu√°rios trabalhando
na √°rea de [ci√™ncia de
dados](https://en.wikipedia.org/wiki/Data_science).

<br>

[Outros motivos que me leva a lecionar a disciplina utilizando a
linguagem R s√£o:]{.black}

1.  Possui ferramentas muito bem pensadas para manipula√ß√£o e tratamento
    de dados;
2.  Normalmente, os frameworks de machine learning de R s√£o menos
    verbosos que os de Python;
3.  Matrizes e data frames s√£o estruturas de dados que j√° encontra-se
    definidas dentro da linguagem, n√£o precisando assim de importar
    bibliotecas.

Isso √© meu gosto pessoal. √â um gosto que, talvez, faz mais sentido, em
se tratando de algu√©m que vem da estat√≠stica. No mercado de trabalho e
em seus estudos, ap√≥s cursar as disciplinas de R e Python, fornecidas
pelo [Bacharelado em Estat√≠stica da UFPB](https://www.ufpb.br/de), voc√™
ter√° a capacidade de estudar os frameworks de machine learning, aos seus
pr√≥prios passos e escolher o que melhor te agrada. A linguagem
[Julia](https://julialang.org/) tamb√©m poder√° ser uma √≥tima op√ß√£o.

#  {.title}

::: r-fit-text
[Aprendizagem de M√°quina: O que √©?]{.flow}
:::

## `r fontawesome::fa("robot", "black")` Aprendizagem de m√°quina

<br>

![](gifs/am.gif){.fragment width="800" height="600"}

## `r fontawesome::fa("robot", "black")` Aprendizagem de m√°quina

<br> <br>

**Alguns pontos**:

<br>

1.  A **A**prendizagem de **M**√°quina (AM), tamb√©m chamada de
    **M**achine **L**earning (ML), no ingl√™s, nasceu na d√©cada de 60
    como um campo da intelig√™nica artificial.

2.  Em sua origem, as aplica√ß√µes de AM tinha como objetivo aprender
    padr√µes com base nos dados.

3.  Originalmente, as aplica√ß√µes de AM eram de cunho estritamente
    computacional. Todavia, desde o in√≠cio dos anos 90, a √°rea de
    aprendizagem de m√°quina expandiu seus horizontes e come√ßou a se
    estabelecer como um campo por sim mesma.

4.  Em particular, a √°rea de aprendizagem de m√°quina come√ßou a
    estabelecer muitas intersec√ß√µes com a estat√≠stica. Muitos de seus
    algoritmos s√£o constru√≠dos com base em metodologias que surgiram na
    estat√≠stica.

5.  Atualmente, a comunidade de AM √© bastante interdisciplinar e
    utiliza-se de ideias desenvolvidas em diversas √°reas, sendo a
    estat√≠stica uma delas.

## `r fontawesome::fa("robot", "black")` Tipos de Aprendizado

<br>

[Aprendizado supervisionado]{.black}

<br>

Nesse curso, inicialmente estudaremos problemas de [aprendizado
supervisionado]{.red}, que consiste em aprender a fazer predi√ß√µes a
partir de conjunto de dados em que r√≥tulos (valores da vari√°vel resposta
$Y$) s√£o observados. Trataremos tanto de problemas de regress√£o (estimar
um valor n√∫m√©rico) quanto problemas de classifica√ß√£o (classificar um
cliente como aprovado ou reprovado, em um problema de concess√£o de
cr√©dito). Por exemplo, os [modelos de regress√£o]{.red} s√£o exemplos de
aprendizado supervisionado.

<br>

[Aprendizado n√£o supervisionado]{.black}

<br>

Na segunda parte do curso, aprenderemos alguns m√©todos de aprendizado
[n√£o supervisionado]{.red}, ou seja, algoritmos que n√£o utilizam-se de
r√≥tulos, em que busca-se aprender mais sobre a estrutura dos dados. Por
exemplo, os [m√©todos de agrupamento]{.red} (cluster), s√£o exempƒ∫os de
m√©todos de aprendizado n√£o supervisionado.

## `r fontawesome::fa("robot", "black")` Tipos de Aprendizado

<br>

Muito embora no nosso curso focaremos nas abordagens de aprendizagem
**supervisionada** e **n√£o-supervisionada**, os tipos de aprendizagem,
em geral, podem ser mais amplos, em que temos:

<br>

1.  Aprendizagem supervisionada;
2.  Aprendizagem n√£o-supervisionada;
3.  Aprendizagem semi-supervisionada;
4.  Aprendizagem por refor√ßo.

## O que √© aprender?

<br>

Antes de detalharmos os tipos de aprendizagem de m√°quina, uma d√∫vida que
poder√° surgir √©: ["O que √© aprender?"]{.red}. ["Como a m√°quina
aprende?"]{.red}.

<br>

![](gifs/am.gif){.fragment width="900" height="600"}

## O que √© aprender?

<br>

De forma simples, aprender √© ganhar conhecimento atrav√©s de estudo,
experi√™ncias, por meio de ensinamentos.

<br>

T√°, mais como √© que a [m√°quina]{.red} aprende?

<br>

1.  [Aprendizagem]{.red} √© o processo em que se adquire conhecimento,
    isto √©, √© o processo em que utilizamos de algoritmos e fornecemos
    dados a esses algoritmos para que possamos extrair conhecimento.
    Nesse processo de aprendisagem, os algoritmos fazem uso de dados
    para a extress√£o de conhecimento, atrav√©s de procedimentos
    **supervisionado**, **n√£o-supervisionado**, **semi-supervisionado**
    ou **por refor√ßo**, a depender do algoritmo que voc√™ deseja
    utilizar.

<br>

2.  [Aprendizado]{.red} √© o modelo ajustado, isto √©, √© o conhecimento
    adquirido ap√≥s o treinamamento obtido no processo de aprendizagem.
    Voc√™ poder√° entender como sendo o modelo ajustado e que utilizamores
    para a tomada de decis√µes.

## O que √© aprender?

<br>

Portanto, voc√™ poder√° entender, basiciamente, existe quatro tipos de
aprendizagem, sendo os dois primeiros o que mais focaremos nesse curso e
que de loge s√£o os mais utilizados:

<br>

1.  Aprendizagem supervisionada;
2.  Aprendizagem n√£o-supervisionada;
3.  Aprendizagem semi-supervisionada;
4.  Aprendizagem por refor√ßo.

## Aprendizagem supervisionada

<br>

Nesse tipo de aprendizagem, o algoritmo ir√° receber um conjunto de dados
em que conhecemos r√≥tulos para a vari√°vel de interesse. √â como se voc√™
soubesse onde um bom modelo deve chegar, para assim ser reconhecido como
um bom modelo. Por exemplo,

<br>

1.  [Classifica√ß√£o]{.red}: precisamos determinar a classe de uma
    inst√¢ncia de dados, o seu atributo, i.e.,
    $\widehat{y} = \mathrm{argmax}_y\,P(Y = y\,|\, X = \bf{x})$, em que
    y √© um atributo que desejamos prever (cahorro, gato, sapo), e
    $\bf{x}$ √© um vetor de caracter√≠sticas (peso, altura, comprimento,
    se tem rabo, etc).

2.  [Regress√£o]{.red}: precisamos estimar uma quantidade num√©rica, i.e.,
    o valor da vari√°vel alvo por meio de uma inst√¢ncia de dados, ou
    seja, precisamos estimar $Y = \mathbb{E}(Y\,|\,X = \bf{x})$, i.e.,
    devemos encontrar meios de obter $\widehat{Y}$.

<br>

::: aside
**Algumas observa√ß√µes de nomenclaturas**:

1.  √â comum chamar cada exemplo de dados, i.e., o vetor $\bf{x}$ que
    ser√° passado ao modelo de [atributos]{.red} ou [features]{.red};
2.  Tamb√©m √© comum chamarmos de [r√≥tulo]{.red} ou [label]{.red} a classe
    ou valor alvo, ou seja, estas s√£o as formas de nomearmos $Y$, sendo
    $Y$ uma quantidade num√©rica (modelos de regress√£o) ou n√£o (modelos
    de classifica√ß√£o).
:::

## Aprendizagem supervisionada

<br>

Em se tratando de m√©todos de classifica√ß√£o, podemos ter os m√©todos:

<br>

1.  [Generativos]{.red}: s√£o os m√©todos que dada as vari√°veis $X$ e $Y$,
    o objetivo √© encontrar a distribui√ß√£o de probabilidade conjunta
    $P(X, Y)$, para ent√£o poder determinar $P(Y\, | \, X = \bf{x})$.
    Alguns m√©todos s√£o:

    -   Naive Bayes;
    -   Descriminante linear.

<br>

2.  [Descriminativos]{.red}: s√£o os m√©todos que estimam diretamente a
    probabilidade condicional $P(Y \, | \, X = \bf{x})$ ou que mesmo nem
    assumem modelos probabil√≠sticos. Podemos citar:
    -   Regress√£o logistica;
    -   Perceptron;
    -   Support Vector Machine - SVM.

## Aprendizagem supervisionada

<br>

::: columns
::: {.column width="60%"}
![](gifs/classificacao.webp)
:::

::: {.column width="40%"}
<br> Poder√≠amos estar interessados em classificar o tamanho de morangos:

<br>

1.  S (**S**low): pequeno;

2.  M (**M**edium): m√©dio;

3.  L (**L**arge): grande.
:::
:::

## Aprendizagem supervisionada

<br> <br>

![Mais dois problemas de classifica√ß√£o (linear x
n√£o-linear).](gifs/Classification-Examples.gif){fig-align="center"
width="45%"}

## Aprendizagem supervisionada

<br> <br>

![](gifs/regression.gif){fig-align="center" width="1200"}

Um exemplo de de um problema de regress√£o. Aqui, a ideia √© utilizar a
equa√ß√£o da reta estimada, a reta que minimiza a soma dos quadrados entre
a reta e os ponto seria a melhor, de modo a ter uma estimativa num√©rica
atrav√©s de novos atributos passado ao modelo, i.e., por meio da equa√ß√£o
da reta e de um novo valor de $x$.

## Aprendizagem supervisionada

<br>

Um outro exemplo seria a classifica√ß√£o de imagem/v√≠deo, utilizando um
algoritmo de rede neural, por exemplo, usando uma **C**onvolutional
**N**eural **N**etwork -
[CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network). Foram
utilizados diversas imagens de pessoas "com" e "sem" m√°scara. Em que
"com" representa detec√ß√£o da m√°scara na face da pessoa e "sem" a n√£o
detec√ß√£o.

<br>

{{< video https://www.youtube.com/watch?v=Zt_Fr7YbU1c width="50%" height="50%" >}}

## Aprendizagem n√£o-supervisionada

<br>

Nesse tipo de aprendizagem, os algoritmos trabalham sobre dados n√£o
rotulados, por exemplo, em uma trarefa de agrupamento.

<br>

Os algoritmos verificam se as inst√¢ncias observadas poder√£o ser
arranjadas de alguma maneira, por exemplo, usando alguma m√©trica de
dist√¢ncia, formando grupos (*clusters*).

<br>

A ideia √© maximizar a dist√¢ncia entre os clusters e minimizar a
dist√¢ncia entre os elementos no interrior do grupo. Em outras palavras,
o que se quer √© tornar os grupos mais diferentes poss√≠veis e tornar os
elementos dos grupos o mais parecido poss√≠vel.

<br>

Aqui, por n√£o haver r√≥tulos, um problema comum √© determinar a quantidade
de grupos ideal que muitas vezes s√£o obtidos de forma subjetiva ou por
heur√≠sticas. A quantidade de grupos √© um dilema!

## Aprendizagem n√£o-supervisionada

<br>

![](gifs/kmeans.gif){fig-align="center" width="900"}

Ap√≥s a detec√ß√£o dos grupos, √© preciso analisar o resultado de modo a
tentar extrair informa√ß√µes coerentes de modo a saber o que cada grupo
representa no problema em quest√£o.

## Aprendizagem semi-supervisionada

<br>

A aprendizagem semi-supervisionada √© uma abordagem na √°rea de
aprendizagem de m√°quina onde um algoritmo utiliza tanto dados rotulados
quanto n√£o rotulados para treinamento. Por exemplo, algoritmos que
propagam r√≥tulos, como o *Label Propagation*, em que r√≥tulos conhecidos
s√£o propagados para dados n√£o rotulados com base em sua sua proximidade
no espa√ßo de caracter√≠sticas.

<br>

Uma outra abordagem seria misturar modelos (*Model Blending*), em que
diferentes modelos s√£o treinados em diferentes partes do conjunto de
dados, por exemplo, um modelo para a parte roturada e um para a parte
n√£o rotulada.

<br>

![](gifs/hum.gif){.fragment width="50%"}

## Aprendizagem por refor√ßo

<br>

Nesse tipo de aprendizagem, n√£o h√° uma fonte externa de exemplos. O
agente (modelo) aprende aprende com sua pr√≥pria experi√™ncia, por
tentativas e erros, em que voc√™ dever√° definir uma medida de sucesso, e
eventualmente recompensar os acertos. No v√≠deo abaixo, veja um joguinho
que criei em R, onde o carrinho aprendeu a desviar de obst√°culos
aleat√≥rios que aparecem em sua frente. Utilizou-se uma rede neural cuja
a sa√≠da poderia ser ("parado", "para cima" ou "para baixo"). Veja o
c√≥digo clicando
[**aqui**](https://github.com/prdm0/desviando_obstaculos).

<br>

{{< video https://www.youtube.com/watch?v=9NXUtwGkkDw&t=2s width="50%" height="50%" >}}

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamentom

<br>

Um dos passos mais importante no fluxo de trabalho (*workflow*) de um
modelo de aprendizagem de m√°quina, consiste na prepara√ß√£o dos dados,
onde realizamos transforma√ß√µes, inputa√ß√µes de valores ausentes,
identifica√ß√£o de outliers, remo√ß√£o de vari√°veis altamente
correlacionadas, entre outros.

<br>

Fazer uma an√°lise explorat√≥ria dos dados √© um passo importante para que
se possa entender e detecatar poss√≠veis inconsist√™ncias na base de
dados. N√£o adianta fazer uso de modelos muito sofisticados quando se tem
uma base de dados cheia de problemas.

<br>

Normalmente trabalhamos com juntos de dados (tabelas) relacionais, em
que cada linha √© uma observa√ß√£o e cada coluna representa um atributo do
objeto/observa√ß√£o. A linha de uma base de dados relacional, sem sua a
vari√°vel de interesse, lembre-se que denominamos $Y$ de [r√≥tulo]{.red}
ou [label]{.red}, fornece o vetor de caracter√≠sticas $\bf{x}$ que
descreve uma dada observa√ß√£o.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

No artigo [Tidy Data](https://www.jstatsoft.org/article/view/v059i10),
2014, publicado no Journal of Statistical Sofware, o Hadley Wickham
discute que o princ√≠pio de dados organizados est√£o intimamente
relacionados com banco de dados relacional e mais pr√≥ximo do recioc√≠nio
que empregamos na √°lgebra. Nesse artigo, ele define o que √© [Tidy
Dados]{.red}, sendo essa uma maneira de mapear um conjunto de dados.

<br>

Segundo o artigo, um conjunto de dados √© [bagun√ßado]{.red} ou
[arrumado]{.red}/[tidy]{.red}, dependendo de como as linhas, colunas e
tabelas s√£o combinadas com as observa√ß√µes, vari√°veis e tipos. Em dados
arrumados (dados tidy), temos que:

<br>

1.  Cada vari√°vel forma uma coluna;
2.  Cada observa√ß√£o forma uma linha;
3.  Cada valor deve ter sua pr√≥pria c√©lula.

<br>

Embora existam situa√ß√µes em que j√° podemos come√ßar a analisar uma base
de dados real, essa √© a exce√ß√£o e n√£o a regra. Normalmente, nos
deparamos com bases de dados que violam uma ou mais dessas regras.
Sempre, que poss√≠vel, procure utilizar dados no formato [Tidy]{.red}.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

![Representa√ß√£o de uma base de dados no formato tidy.](imgs/tidy-1.png)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

> "As fam√≠lias felizes s√£o todas iguais; toda fam√≠lia infeliz √© infeliz
> √† sua maneira." -- [Leo
> Tolstoy](https://en.wikipedia.org/wiki/Leo_Tolstoy)

> "Conjuntos de dados organizados s√£o todos iguais, mas todo conjunto de
> dados confuso √© confuso √† sua maneira." -- [Hadley
> Wickham](https://hadley.nz/)

<br>

![Trabalhar com a Tabela do lado esquerdo √© melhor que a Tabela do lado
direito. Prefira, sempre que poss√≠vel, o formato tidy. N√£o permita-se
ficar estressado t√£o facilmente.](imgs/tidy-2.png){width="50%"}

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

A linguagem de programa√ß√£o R possue diversas ferramentas que permite
manipular e explorar bases de dados. Enumero algumas:

1.  [dplyr](https://dplyr.tidyverse.org/): biblioteca que implementa √©
    uma gram√°tica de manipula√ß√£o de dados, fornecendo um conjunto
    consistente de verbos que ajudam a resolver os desafios mais comuns
    de manipula√ß√£o de dados;
2.  [tidyr](https://tidyr.tidyverse.org/): ferramentas para ajudar a
    criar dados organizados, onde cada coluna √© uma vari√°vel, cada linha
    √© uma observa√ß√£o e cada c√©lula cont√©m um √∫nico valor;
3.  [ggplot2](https://ggplot2-book.org/): um sistema para criar gr√°ficos
    'declarativamente', baseado no livro [The Grammar of
    Graphics](https://www.amazon.com.br/Grammar-Graphics-Leland-Wilkinson/dp/0387245448),
    de [Leland
    Wilkinson](https://en.wikipedia.org/wiki/Leland_Wilkinson);
4.  [visdat](https://docs.ropensci.org/visdat/): uma biblioteca √∫til
    para um visualiza√ß√£o explorat√≥ria preliminar de dados;
5.  [explore](https://github.com/rolkra/explore): biblioteca que
    apresenta algumas rotinas de an√°lise para realizar uma an√°lise
    explorat√≥ria nos dados.

Todas essas bibliotecas est√£o muito bem documentadas. √â importante que
voc√™s explorem as documentas dessas bibliotecas, pois eventualmente irei
utizar alguma delas.

![](gifs/ok.gif)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

No [Cap√≠tulo 12](https://r4ds.had.co.nz/tidy-data.html), do livro [R for
Data Science](https://r4ds.had.co.nz/index.html), o autor aborda mais
sobre o formato Tidy e como trabalhar com a biblioteca
[tidyr](https://tidyr.tidyverse.org/).
[Aqui](https://r4ds.had.co.nz/transform.html?q=dplyr#dplyr-basics) o
autor aborda de forma b√°sica o pacote
[dplyr](https://dplyr.tidyverse.org/).

<br>

Durante o curso, na medida da necessidade de utiliza√ß√£o dessas
ferramentas, durante a exposi√ß√£o de exemplos, abordaremos alguns
conceitos. Ok?

<br>

![](gifs/ok.gif)

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Muitas vezes, no processo de tratamento dos dados, tamb√©m estamos
preocupados em remover atributos que n√£o s√£o significativo para a
modelagem, em que nesse momento a experi√™ncia dos especialistas s√£o
fundamentais.

<br>

√â comum enriquercermos a base de dados com informa√ß√µes de outras bases
de dados, em um sistema de gerenciamento de banco de dados relacional,
em que as bases de dados est√£o relacionadas por uma chave. Nesse caso,
buscamos por novos atributos para um mesmo objeto (para uma mesma linha
da base), em que atributos cruzados devem ter um √∫nico valor, para cada
objeto, respeitando a regra tr√™s de conjuntos de dados tidy.

<br>

As vezes transformamos vari√°veis. Por exemplo, √© comum tomar o logaritmo
de uma vari√°vel num√©rica que √© assim√©trica, se $x >= 1$, em que $x$ √© um
atributo num√©rico qualquer.

<br>

Em diveras situa√ß√µes, tamb√©m √© comum a base de dados apresentar
informa√ß√µes faltantes. Nos data frames de R, a falta de informa√ß√£o na
base, normlamente ser√£o representadas por `NA`.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Poder√° ser que um dado atributo apresente informa√ß√£o faltante, e
normalmente n√£o optaremos em remover a observa√ß√£o e precisaremos imputar
a informa√ß√£o, por exemplo:

<br>

1.  Tomando alguma medida de tend√™ncia central como m√©dia/moda/mediana
    dos valores que s√£o conhecidos para aquele atributo;
2.  Criar um novo valor que √© indica√ß√£o de valor faltante;
3.  Usar algoritmos como $k$-nearest neighbors - KNN ($k$ vizinhos mais
    pr√≥ximos) para imputar valores coerentes;
4.  Interpolar os dados.

<br>

Esses s√£o alguns exemplos de como podemos imputar observa√ß√µes faltantes.
Muitas vezes n√£o podemos nos dar o luxo de percer observa√ß√µes de nossa
base de dados.

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

√â comum ser necess√°rio transformar os dados:

1.  Pode ser necess√°rio transformar os tipos ou os valores dos atributos
    para tentar obter um melhor ajuste do modelo;

2.  Pode-se discretizar valores cont√≠nuos ou transform√°-los em
    intervalos;

3.  √â comum transformar atributos categ√≥ricos com $p$ categorias, em $p$
    novos atributos bin√°rios.

    -   [One-hot encoding](https://en.wikipedia.org/wiki/One-hot)
    -   [Vari√°veis
        dummy](https://en.wikipedia.org/wiki/Dummy_variable_(statistics))

4.  Outra transforma√ß√£o muito comum √© a normaliza√ß√£o dos dados.
    Normalizar os dados √© muito √∫til quando os atributos num√©ricos
    possuem escalas muito diferentes.

::: columns
::: {.column width="50%"}
$$X_{novo} = \frac{X - X_{min}}{X_{max} - X_{min}},$$ em que
$X_{novo} \in [0, 1].$
:::

::: {.column width="50%"}
$$X_{novo} = Z = \frac{X - \mu}{\sigma^2},$$ em que
$\mathbb{E}(X) = \mu$ √© a m√©dia dos dados e
$\mathrm{Var}(X) = \sigma^2$. Na pr√°tica, em um contexto de v.a., iids,
usamos $\overline{x}$ como estimador de $\mu$ e $S^2$ (vari√¢ncia
amostral) como estimador de $\sigma^2$.
:::
:::

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Lembre-se, como citado anteriormente, tomar o logaritmo natural, ou
mesmo na base 10 de vari√°veis num√©ricas muito assim√©tricas, poder√°
ajudar um pouco, desde que seja possivel tomar o $\log(\cdot)$.

<br>

::: columns
::: {.column width="50%"}
```{r}
set.seed(0)
rgamma(1000, 2, 2) |> 
  hist()
```
:::

::: {.column width="50%"}
```{r}
set.seed(0)
rgamma(1000, 2, 2) |> 
  log() |> hist()
```
:::
:::

## `r fontawesome::fa("database", "black")` Dados: explora√ß√£o e tratamento

<br>

Anteriormente eu citei algumas bibliotecas √∫teis de R para explorar os
dados, na fase de tratamento das observa√ß√µes. Por√©m, n√£o estranhe n√£o
ter cidado bibliotecas do framework
[tidymodels](https://www.tidymodels.org/packages/), em especial o
[recipes](https://recipes.tidymodels.org/) que √© muito utilizado no
workflow de aprendizagem de m√°quina na fase de pr√©-processamento dos
dados. Muitas dessas transforma√ß√µes s√£o aplicadas como receitas de
pr√©-processamento com o pacote
[recipes](https://recipes.tidymodels.org/).

<br>

O tidymodels ser√° muito √∫til para n√≥s, mas, aos poucos, seu uso e
explica√ß√µes mais detalhadas ser√£o apresentadas, apesar que em algumas
situa√ß√µes mais simples, poderei n√£o utiliz√°-lo, expor detalhes que
eventualmente n√£o ser√° poss√≠vel ou estariam camuflados na utiliza√ß√£o do
tidymodels.

<br>

![](gifs/ok-2.gif){width="20%"}

## As duas culturas

<br>

Em [Breiman, L. (2001a). Statistical modeling: The two cultures.
Statistical Science, 16(3),
199--231](https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2Fss%2F1009213726),
o Leo Breiman argumenta que existe duas culturas no uso de modelos
estat√≠sticos, em especialmente na √°rea de modelos de regress√£o. Segundo
eles, as culturas s√£o:

<br>

1.  [Data modeling culture]{.red}: nela, em geral, se assume que o
    modelo de regress√£o utilizado $r(x)$, por exemplo,
    $r(x) = \beta_0 + \sum_{i = 1}^d \beta_ix_i$ √© correto. O principal
    objetivo dessa abordagem √© a interpreta√ß√£o dos par√¢metros que
    indexam o modelo $r(x)$. Nesse tipo de cultura, a ideia tamb√©m √©
    construir intervalos aleat√≥rios e testar hip√≥teses para os
    $\beta_i's$. Sob essa √≥tica, muitas suposi√ß√µes sob o modelo s√£o
    realizadas, em que formas para checar essas suposi√ß√µes s√£o
    desenvolvidas, uma vez que elas s√£o fundamentais para esse tipo de
    modelagem.

<br>

2.  [Algorithmic modeling culture]{.red}: essa √© a cultura que domina a
    comunidade de aprendizagem de m√°quina. Nessa abordagem, o principal
    objetivo s√£o as predi√ß√µes por meio de novas observa√ß√µes. N√£o se
    assume que o modelo utilizado √© o modelo correto. Nesse tipo de
    modelagem, muitas vezes os algoritmos n√£o envolve nenhuma estrutura
    probabil√≠stica. Muitas vezes, modelos n√£o bem especificado conduzem
    a boas predi√ß√µes.

## As duas culturas

<br>

::: columns
::: {.column width="50%"}
![Breiman, L. (2001a). Statistical modeling: The two cultures.
Statistical Science, 16(3), 199--231.](imgs/paper_breiman){width="70%"}
:::

::: {.column width="50%"}
![Leo como um probabilista jovem na Universidade da
Calif√≥rina.](imgs/leo_breiman){width="60%"}
:::
:::

## As duas culturas

<br>

H√° diversos artigos interessantes que s√£o respostas ao artigo do Leo
Breiman, como por exemplo, o artigo [Statistical Modeling: The Two
Cultures: Comment](https://www.jstor.org/stable/2676682) do David Cox e
com coment√°rios do Brad Efron.

![[Sir David
Cox.](https://en.wikipedia.org/wiki/David_Cox_(statistician))](imgs/david_cox.png){width="20%"}

## As duas culturas

<br>

Muito embora exista essa divis√£o entre as culturas, Breiman foi um
estat√≠stico que desempenhou um grande trabalho para unir a √°rea de
estat√≠stica com aprendizado de m√°quina. Por conta dessa grande
import√¢ncia, um pr√™mio concedido em sua homenagem foi criado pela
[American Statistical
Association](https://community.amstat.org/slds/awards/breiman-award).

![[Leo Breiman trabalhando em sua resid√™ncia, em
1985.](https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2Fss%2F1009213290)](imgs/breiman_residencia.png){width="30%"}

#  {.title background-image="imgs/rawpixel/freight.jpg"}

::: r-fit-text
[Regress√£o / Parte I]{.flow}
:::

## Regress√£o

<br>

M√©todos de regress√£o surgiram h√° mais de dois s√©culos com Legendre
(1805) e Gauss (1809), que exploraram o m√©todo dos m√≠nimos quadrados com
o objetivo de prever √≥rbitas ao redor do Sol. Hoje em dia, o problema de
estima√ß√£o de uma fun√ß√£o de regress√£o possui papel central em
estat√≠stica.

<br>

> Apesar de as primeiras t√©cnicas para solucionar esse problema datarem
> de ao menos 200 anos, os avan√ßos computacionais recentes permitiram
> que novas metodologias fossem exploradas. Em particular, com a
> capacidade cada vez maior de armazenamento de dados, m√©todos com menos
> suposi√ß√µes sobre o verdadeiro estado da natureza ganham cada vez mais
> espa√ßo. Com isso, v√°rios desafios surgiram: por exemplo, m√©todos
> tradicionais n√£o s√£o capazes de lidar de forma satisfat√≥ria com bancos
> de dados em que h√° mais covari√°veis que observa√ß√µes, uma situa√ß√£o
> muito comum nos dias de hoje. Similarmente, s√£o frequentes as
> aplica√ß√µes em que cada observa√ß√£o consiste em uma imagem ou um
> documento de texto, objetos complexos que levam a an√°lises que
> requerem metodologias mais elaboradas. -- Izbick et al.

## Regress√£o

<br>

De forma geral, temos que o objetivo de um modelo de regress√£o √©
determinar a rela√ß√£o entre uma vari√°vel aleat√≥ria (label)
$Y \in \mathbb{R}$ e um vetor de covari√°veis (features)
$\mathbf{x} = (x_1, \cdots, x_d) \in \mathbb{R}^d$. Mais
especificamente, busaca-se estimar

$$r(\bf{x}) := \mathbb{E}(Y\,|\,\bf{X} = \bf{x}),$$

sendo esta chamada de [fun√ß√£o de regress√£o]{.red}. Temos que:

<br>

1.  Se $Y$ √© uma vari√°vel quantitativa, ent√£o estamos sob um problema de
    [regress√£o]{.red};
2.  Se $Y$ √© uma vari√°vel qualitativa, ent√£o teremos um problema de
    [classifica√ß√£o]{.red}.

Em aprendizagem de m√°quina, assumimos que n√£o temos meios de calcular
$r({\bf{x}})$, i.e., n√£o conhecemos a distribui√ß√£o condicional de
${\bf{Y}\,|\,X}$. Portanto, n√£o temos meios de calcular

$$\mathbb{E}({\bf X}|Y = y) = \int x\,\mathrm{d}F_{\bf X}({\bf x} | Y = y).$$

## Nota√ß√µes

<br>

A vari√°vel $Y$ recebe frequentemente o nome de vari√°vel resposta,
vari√°vel dependente, r√≥tulo ou *label*. J√° as observa√ß√µes contidas no
vetor $\bf{x} = (x_1, \cdots, x_d)$, s√£o, em geral, denominadas de
vari√°veis explicativas, vari√°veis independentes, caracter√≠sticas,
atributos, preditores, covari√°veis ou *features*.

<br>

A ideia, nessa primeira parte do curso, √© descrever algumas t√©cnicas
para estimar (**treinar**, como √© dito em aprendizagem de m√°quina)
$r(\bf{x})$.

<br>

A menos quando dito o contr√°rio, assumiremos que nossa amostra s√£o
i.i.d. (independentes e identicamente distribu√≠das), ou seja,
$(\bf{X}_1, Y_1), \cdots, (\bf{X}_n, Y_n)$ s√£o i.i.d.

<br>

Denota-se por $x_{i,j}$ o valor da $j$-√©sima covari√°vel na $i$-√©sima
amostra, com $j = 1, \cdots, d$ e $i = 1, \cdots, n$.

## Nota√ß√µes

<br>

| Label    | Features                                     |
|----------|----------------------------------------------|
| $Y_1$    | $X_{1,1},\cdots, X_{1,d}\,\,\, (= \bf{X}_1)$ |
| $\vdots$ | $\,\,\,\vdots\,\,\,\,\, \ddots\,\,\ \vdots$  |
| $Y_n$    | $X_{n,1},\cdots, X_{n,d}\,\,\, (= \bf{X}_n)$ |

: Nota√ß√£o utilizada nesse material para as vari√°veis envolvidas em um
problema de regress√£o. {tbl-colwidths="\[25,25\]"}

## Regress√£o

Nossa ideia √© construir uma boa estimativa $g$ da fun√ß√£o de regress√£o
$r(\bf{x}) := \mathbb{E}(Y\,|\,\bf{X} = \bf{x})$, para novas
observa√ß√µes, i.e., queremos obter uma fun√ß√£o $g$, tal que:

$$g: \mathbb{R}^d \rightarrow \mathbb{R},$$

de tal forma que $g$ possua um bom poder preditivo. Em aprendizagem de
m√°quina, s√≥ estaremos interessados em obter uma fun√ß√£o $g$ que estime
bem um n√∫mero real (em problemas de regress√£o), ou que classifique bem
(em um problema de classifica√ß√£o), utilizando as $d$ covari√°veis. Ou
seja, para $m$ novas observa√ß√µes, desejamos obter $g$, que

$$g({\bf{x}}_{n + 1}) \approx y_{n + 1}, \cdots, g({\bf{x}}_{n + m}) \approx y_{n + m}.$$

## Fun√ß√£o de risco

<br>

Para que possamos construir boas fun√ß√µes de predi√ß√£o, √© preciso que
tenhamos um crit√©rio para medir o desempenho de uma dada fun√ß√£o
$g:\mathbb{R}^d \rightarrow \mathbb{R}$. Em contexto de regress√£o,
usaremos o risco quadr√°tico, muito embora esta n√£o √© a √∫nica op√ß√£o.
Denotaremos a fun√ß√£o de risco quadr√°tico por:

$$R_{pred}(g) = \mathbb{E}\left[({\bf Y} - g({\bf X}))^2\right],$$ em
que $(\bf X, Y)$ s√£o observa√ß√µes novas que n√£o foram utilizadas para
treinar/estimar $g$. L√™-se $R_{pred}(g)$ como "risco preditivo de $g$".
Note que, como $\bf X$ s√£o observa√ß√µes conhecidas e $g(\cdot)$ √© um
modelo preditivo, portanto, $g$ √© conhecido, ent√£o,
$\widehat{\bf Y} = g(\bf X)$ √© um estimador dos labels, i.e., de
$\bf Y$.

<br>

Diremos que $L(g({\bf X}); {\bf Y}) = ({\bf Y} - g({\bf X}))^2$ √© a
[fun√ß√£o de perda quadr√°tica]{.red}, as vezes chamado de perda $L_2$.
Outra fun√ß√µes como a [fun√ß√£o de perda absoluta]{.red} denotada por
$L(g({\bf X}); {\bf Y}) = |{\bf Y} - g({\bf X})|$, as vezes chamada de
perda $L_1$ poderiam ser consideradas.

## Fun√ß√£o de risco

<br>

Em linhas gerais, seja $L(\cdot)$ uma fun√ß√£o qualquer, tal que
$\forall \, 0 < u < v$, de modo que:

<br>

i)  $0 = L(0) \leq L(u) \leq L(v)$;
ii) $0 = L(0) \leq L(-u) \leq L(-v)$.

<br>

Qualquer fun√ß√£o $L(\cdot)$ que satisfaz as propriedades acima √© chamada
de [fun√ß√£o de perda](https://en.wikipedia.org/wiki/Loss_function). Em
especial, temos que:

<br>

-   Fun√ß√£o de perda quadr√°tica: $L(u) = u^2$;
-   Fun√ß√£o de perda absoluta: $L(u) = |u|$;
-   Fun√ß√£o de perda degradu: $L(0) = 0$, se $|u| < \delta$ e $1$ caso
    contr√°rio, para algum $\delta > 0$;

## Fun√ß√£o de risco

<br>

Normalmente considera-se a perda $L_2$, uma vez que em modelos de
regress√£o, minimizar $R_{pred}(g)$, em $g$, equivale a encontrar
$r({\bf x}) = \mathbb{E}({\bf X}|{\bf Y})$, i.e., equivale a estimar a
fun√ß√£o de regress√£o.

<br>

[Teorema]{.red}: Suponha que definimos o risco de uma fun√ß√£o de predi√ß√£o
$g: \mathbb{R}^d \rightarrow \mathbb{R}$ via fun√ß√£o perda quadr√°tica,
i.e, $R_{pred}(g) = \mathbb{E}\left[({\bf Y} - g({\bf X}))^2\right]$, em
que $\bf (X, Y)$ s√£o novas observa√ß√µes que n√£o foram utilizadas para
estimar $g$. Suponha tamb√©m que estimaos o risco de um estimador de
regress√£o $r({\bf X})$ via fun√ß√£o perda quadr√°tica
$R_{reg}(g) = \mathbb{E}\left[(r({\bf X}) - g({\bf X}))^2\right]$.
Ent√£o,

$$R_{pred}(g) = R_{reg}(g) + \mathbb{E}\left[\mathbb{V}[{\bf Y} | {\bf X}]\right],$$

em que $\mathbb{E}\left[\mathbb{V}[{\bf Y} | {\bf X}]\right]$ √© a
vari√¢ncia m√©dia do modelo que n√£o depende de $g$. Portanto, estimar bem
$r({\bf x})$ √© de fundamental import√¢ncia para criar uma boa fun√ß√£o de
predi√ß√£o. Em especial, sob a √≥tica do risco quadr√°tico, a melhor fun√ß√£o
de predi√ß√£o para $\bf Y$ √© a fun√ß√£o de regress√£o $r({\bf x})$, de tal
modo que:

$$\argmin_g R_{pred}(g) = \argmin_g R_{reg}(g) = r({\bf x}).$$

## Fun√ß√£o de risco

<br>

**Lembre-se**: $r({\bf x}) = \mathbb{E}(Y | \bf{X} = \bf{x})$ √© a nossa
[fun√ß√£o de regress√£o]{.red}.

<br>

A defini√ß√£o de risco preditivo $R_{pred}$, que tamb√©m denotaremos
simplesmente por $R$, tem um apelo frequentista. Dessa forma, para um
novo conjunto com $m$ novas observa√ß√µs,
$({\bf X}_{n+1}, Y_{n+1}), \cdots, ({\bf X}_{n+m}, Y_{n+m})$, temos que
que essa nova amostra √© i.i.d √† amostra observada (utilizada no
treinamento do modelo/na estima√ß√£o). Ent√£o, pela Lei dos Grandes
N√∫meros, temos que um bom estimador para a fun√ß√£o para o risco preditivo
√© dado por:

$$\frac{1}{m}\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \approx R(g) := \mathbb{E}\left[(Y - g({\bf X}))^2\right].$$ {#eq-risco-correto}

Chamaremos a quantidade acima de [Erro Quadr√°tico M√©dio -
EQM](https://pt.wikipedia.org/wiki/Erro_quadr%C3%A1tico_m%C3%A9dio). Em
aprendizagem de m√°quina, normalmente estaremos no contexto em que temos
muitas observa√ß√µes, e que portanto, poderemos fazer esse apelo
frequentista.

<br>

Desejamos encontrar $g$ (encontrar m√©todos) que minimize de forma
satisfat√≥ria $R$, i.e., m√©todos que nos conduzam √† um risco baixo.

## Fun√ß√£o de risco

<br>

Sendo assim, se $R(g)$ possui um valor baixo, ent√£o, temos que

$$g({\bf x}_{n+1}) \approx y_{n+1}, \cdots, g({\bf x}_{n+m}) \approx y_{n+m}.$$
<br> ![](gifs/hum.gif){width="25%"}

## Regress√£o linear

<br>

Nesse momento, vamos pensar um pouco em regress√£o linear. No caso mais
simples, queremos prever o comportamento de uma vari√°vel de interesse
$Y$ condicional a uma vari√°vel explicativa $X$ (regress√£o linear
simples, i.e., $d = 1$). O melhor preditor de $Y$ condicional em $X$ √©
aquele que minimiza a fun√ß√£o de perda esperada, ou seja, √© aquele que
resolve:

$$\argmin_g \mathbb{E}(L(Y - g)\,|\,X).$$

Para o caso da fun√ß√£o perda quadr√°tica (fun√ß√£o $L_2$), o melhor preditor
de $Y$ condicional √† $X$ √© a m√©dia condicional de $Y$ dado $X$, i.e.,
$r(X) = \mathbb{E}(Y\,|\,X)$. J√°, na situa√ß√£o em que considera-se a
perda absoluta (fun√ß√£o $L_1$), o melhor estimador √© a mediana
condicional.

<br>

**Os modelos de regress√£o, em geral, fazem uso da fun√ß√£o de perda
quadr√°tica.**

## Regress√£o linear simples

<br>

No caso da regress√£o linear simples ($d = 1$), temos que o modelo √© dado
por:

$$g(x) = \beta_0 + \beta_1 x_{i,1} + \varepsilon_i, \,\, i = 1, \cdots, n.$$

Assumindo que a regress√£o linear simples √© o modelo $g$ que iremos
utilizar, ent√£o, desejamos minimizar:

$$\argmin_{\beta} R(g_\beta) = \argmin_{\beta} \sum_{i = 1}^n(y_i - \beta_0 - \beta_1x_{i,1})^2.$$
Derivando em rela√ß√£o √† $\beta$ e igualando a zero, ap√≥s algumas
manipula√ß√µes alg√©bricas, temos que:

$$\widehat{\beta} = \frac{\sum_{i = 1}^n (x_i - \overline{x})(y_i - \overline{y})}{\sum_{i=1}^n(x_i - \overline{x})^2} = r_{xy}\frac{s_y}{s_x},$$
em que $s_x$ e $s_y$ s√£o os desvio-padr√£o de $x$ e $y$, respectivamente,
e $r_{xy}$ √© o coeficiente de correla√ß√£o da amostra.

## Regress√£o linear simples

<br>

$$r_{xy} = \frac{\overline{xy} - \overline{x}\,\overline{y}}{\sqrt{(\overline{x^2} - \overline{x}^2)(\overline{y^2} - \overline{y}^2)}}.$$
O coeficiente de determina√ß√£o $R^2$ do modelo √© dado por $r_{xy}^2$,
quando o modelo √© linear e possue uma √∫nica vari√°vel independente
(feature).

<br>

Portanto, temos que:

$$\widehat{\beta_0} = \overline{y} - \widehat{\beta}\overline{x},$$

Na [*data modeling culture*]{.red} (na estat√≠stica), normalmente
assumimos que o $\varepsilon_i$ tem distribui√ß√£o normal e vari√¢ncia
constante, $\forall\, i = 1, \cdots, n$. Assume-se tamb√©m que
$\mathbb{E}(\varepsilon_i) = 0, \, \forall i$.

## Regress√£o linear simples

<br>

Aqui n√£o iremos nos preocupar com essas suposi√ß√µes, uma vez que em
[*algorithmic modeling culture*]{.red}, n√£o estamos preocupados com
suposi√ß√µes nem interpreta√ß√µes, ok!?

<br>

![](gifs/ok-2.gif)

## Regress√£o linear multipla

<br>

A fun√ß√£o de perda quadr√°tica (fun√ß√£o $L_2$) tem algumas vantagens em
rela√ß√£o a fun√ß√£o de perda absoluta. Listo algumas:

1.  A fun√ß√£o de perda quadr√°tica penaliza mais os erros maiores, devido
    ao vato dos erros serem levado ao quadrado;

2.  A fun√ß√£o de perda quadr√°tica √© mais sens√≠vel a presen√ßa de
    [outlier](https://en.wikipedia.org/wiki/Outlier), que em compensa√ß√£o
    s√£o menos penalizados ao se considerar a fun√ß√£o de perda absoluta
    (fun√ß√£o $L_1$);

3.  Em situa√ß√µes em que o erro tem distribui√ß√£o normal, a estimativa de
    m√≠nimos quadrados √© a solu√ß√£o de m√°xima verossimilhan√ßa e √© a
    estimativa linear n√£o viesada e com menor vari√¢ncia. Portanto,
    gozamos de um estimador com √≥timas propriedades, muito embora ele
    tamb√©m √© um bom estimador mesmo quando a suposi√ß√£o de normalidade
    n√£o √© verificada;

4.  A fun√ß√£o de perda quadr√°tica √© deferenci√°vel, j√° a fun√ß√£o de perda
    absoluta n√£o √©.

Para o caso de regerss√£o linear m√∫ltipla, i.e., quando $d > 1$,
poderemos utilizar uma nota√ß√£o matricial para representar o modelo
linear m√∫ltiplo de regress√£o.

## Regress√£o linear multipla

<br>

Considerando o modelo de regress√£o linear m√∫ltiplo, temos que:

$$Y = g({\bf X}) = \beta^{T}{\bf X} + \varepsilon,$$

em que $Y$ √© um vetor $n \times 1$, ${\bf X}$ √© uma matriz fixa e
conhecida com os atributos de dimens√£o $n \times d$, em que a primeira
coluna √© preenchida de 1, $\beta = (\beta_0, \cdots, \beta_d)$. Na
cultura de machine learning, iremos desconsiderar $\varepsilon$, n√£o
feremos suposi√ß√µes sobre $\varepsilon$. Portanto, considere

$$g({\bf x}) = \beta^{T}{\bf X} = \beta_{0}x_0 + \beta_1x_{i,1} + \cdots + \beta_dx_{i,d},$$
em que $x_0 \equiv 1$.

## Regress√£o linear multipla

<br>

O m√©todo dos m√≠nimos quadrados, para o caso de regress√£o linear m√∫ltipla
($d > 1$) √© dado por aquele que minimiza $R(\beta^{T}{\bf X})$, i.e.,
minimiza:

$$\argmin_\beta \sum_{i = 1}^n (Y_i - \beta_0 - \beta_1x_{i,1} - \cdots - \beta_dx_{i,d})^2.$$
Temos que

$$\widehat{\beta} = ({\bf X}^{T}{\bf X})^{-1}{\bf X}^{T}Y.$$

Portanto, a fun√ß√£o de regress√£o estimada √© dada por:

$$g({\bf x}) = \widehat{\beta}^{T}{\bf x}.$$

## Regress√£o linear multipla

<br>

Grande parte da literatura estat√≠stica √© voltada para justificar que o
m√©todo de m√≠nimos quadrados sob um ponto de vista de um estimador de
m√°xima verossimilhan√ßa, assim como tamb√©m para constru√ß√£o de testes de
ader√™ncia, m√©todos para constru√ß√£o de intervalos de confian√ßa e teste de
hip√≥tese para $\beta_i$ (par√¢metros que indexam o modelo), an√°lise de
res√≠duos, entre outros.

<br>

Assumir que a verdadeira regress√£o
$r({\bf x}) = \mathbb{E}({\bf X}\,|\,Y)$ √© uma suposi√ß√£o muito forte.
Contudo, existe, na literatura, justificativas para o uso de m√©todos de
m√≠nimos quadrados para estimar os coeficientes, mesmo quando a regress√£o
real $r({\bf x})$ n√£o satisfaz a suposi√ß√£o de linearidade.

## Regress√£o linear multipla

<br>

O estimador de m√≠nimos quadrados
$\widehat{\beta} = ({\bf X}^{T}{\bf X})^{-1}{\bf X}^{T}Y$ √© bom, por
alguns motivos:

<br>

1.  √â igual ao estimador de m√°xima verossimilhan√ßa sob normalidade,
    linearidade e homoscedasticidade, portanto, consistente sob essas
    condi√ß√µes

2.  √â [*best linear unbiased prediction* - BLUE]{.red} sob linearidade e
    homoscedasticidade;

3.  O m√©todo de m√≠nimos quadrados tem alguma garantia, mesmo sem assumir
    muitas suposi√ß√µes.

<br>

![](gifs/hum.gif)

## M√≠nimos quadrados sem suposi√ß√£o de linearidade

<br>

Quando a suposi√ß√£o de linearidade falha, ou seja, quando a regress√£o
verdadeira que desconhecemos $r({\bf x})$ n√£o √© linear, frequentemente
existe um vetor $\beta_{*}$, tal que
$g_{\beta_{*}}({\bf x}) = \beta_{*}^{T}{\bf x}$ tem um bom poder
preditivo. Nesses casos, o m√©trodo dos m√≠nimos quadrados
$\widehat{\beta}$ tende a produzir estimadores com baixo risco. Isso se
deve ao fato que $\widehat{\beta}$ converge para o melhor preditor
linear (para o or√°culo $\beta_{*}$) que √© dado por:

$$\beta_{*} = \argmin_\beta R(g_\beta) =  \argmin_\beta \mathbb{E}\left[(Y - \beta^{T}X)^2\right],$$
mesmo que a verdadeira regress√£o $r({\bf x})$ n√£o seja linear, em que
$({\bf X}, Y)$ √© uma nova observa√ß√£o.

<br>

[Teorema]{.red}: Seja $\beta_{*}$ o melhor estimador linear e
$\widehat{\beta}$ o estimador de m√≠nimos quadrados. Ent√£o,

$$\widehat{\beta}\overset{p}{\longrightarrow}  \beta_{*}\,\, \mathrm{e}\,\, R(g_{\widehat{\beta}})\overset{p}{\longrightarrow} R(g_{\beta_{*}}), $$
quando $n \longrightarrow \infty$. Para uma demonstra√ß√£o, veja
<http://www.rizbicki.ufscar.br/AME.pdf>, p√°gina. 29.

## M√≠nimos quadrados sem suposi√ß√£o de linearidade

<br>

Em palavras, o que o Teorema anterior diz √© que mesmo quando a regress√£o
verdadeira n√£o √© linear, o estimador de m√≠nimos quadrados √© consistente
para nos conduzir a um bom estimador **linear**, ou seja, ao menos
conseguiremos o melhor estimador linear como uma aproxima√ß√£o √†
$r({\bf x})$ que n√£o √© linear.

<br>

Isso n√£o quer dizer que voc√™ ter√° boas estimativas em todas as
situa√ß√µes, muito embora o or√°culo $\beta_{*}$, em muitas situa√ß√µes, ter√°
bom poder preditivo. Em outras palavras, em situa√ß√µes que um problema,
em sua natureza, n√£o linear, poderemos alcan√ßar boas estimativas por uma
aproxima√ß√£o linear pelo m√©todo dos m√≠nimos quadrados.

<br>

![](gifs/uau.gif)

## Predi√ß√£o versus Infer√™ncia

<br>

**Infer√™ncia**: assume que o modelo linear √© correto. O principal
objetivo consiste em interpretar os par√¢metros:

<br>

-   Quais s√£o os par√¢metros significantes?
-   Qual o efeito do aumento da dose de um rem√©dio no paciente?

<br>

**Predi√ß√£o**: queremos criar $g({\bf x})$ com bom poder preditivo, mesmo
que a especifica√ß√£o do modelo n√£o esteja correta. N√£o assume que a
verdadeira regress√£o √© de fato linear! A interpreta√ß√£o aqui n√£o √© o
foco. Tudo bem?

<br>

![](gifs/ok.gif){width="15%"}

## Ajustando uma regress√£o linear no R

<br>

Caso voc√™ n√£o queira implementar o estimador de m√≠nimos quadrados
$\widehat{\beta} = ({\bf X}^{T}{\bf X})^{-1}{\bf X}^{T}Y$, voc√™ poder√°
utilizar a famosa fun√ß√£o `lm`. Na verdade √© melhor que n√£o implemente o
estimador $\widehat{\beta}$, uma vez que a fun√ß√£o `lm`, assim como a
fun√ß√£o `glmnet` do pacote
[glmnet](https://glmnet.stanford.edu/articles/glmnet.html), utilizam-se
de truques num√©ricos para um c√°lculo mais eficiente.

<br>

Falaremos do pacote
[glmnet](https://glmnet.stanford.edu/articles/glmnet.html), um pouco
mais a frente, quando abordarmos regress√£o penalizada. Certo!?

<br>

![](gifs/bom.gif)

## Ajustando uma regress√£o linear no R

<br>

Considere o conjunto de dados de expectativa de vida versus PIB per
Capita dispon√≠veis
[aqui](https://github.com/prdm0/dados/blob/main/dados_expectativa_renda.RData).
O comportamente entre as vari√°veis `LifeExpectancy` e `GDPercapita`, se
fizermos um gr√°fico, n√£o √© linear.

<br>

Todavia, isso n√£o impede que possamos ajustar um modelo de regerss√£o
linear, muito embora o seu poder preditivo ser√° baixo.

<br>

Por√©m, como j√° sabemos, ao menos conseguiremos o melhor or√°culo,
denotado por $\beta_{*}$, i.e., o melhor estimador dentre os poss√≠veis
estimadores lineares, como mostrado em teoremas anteriores.

<br>

E est√° tudo bem. Aqui n√£o estou querendo defender que voc√™ use uma
aproxima√ß√£o linear para esse caso. Em breve, com um pequeno truque,
poderemos ajustar uma regress√£o polinomial √† esses dados, e
incorporaremos um pouco da tend√™ncia n√£o linar presente nos dados.

## Ajustando uma regress√£o linear no R

<br>

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Veja o c√≥digo do gr√°fico"
#| fig-align: center
#| out-width: "1200px"
#| out-height: "700px"

library(ggplot2)

url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"

# Criando um arquivo tempor√°rio
arquivo_temp <- tempfile()

# Baixando um arquivo tempor√°rio
download.file(url = url, destfile = arquivo_temp)

# Carregando os dados
load(arquivo_temp)

dados_expectativa_renda |> 
  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +
  geom_point() +
  labs(
    title = "PIB per Capita versus Expectativa de Vida",
    x = "PIB per Capita",
    y = "Expectativa de Vida"
  ) +
  geom_smooth(method = "lm", se = FALSE) +
  theme(
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold")
  )
```

## Ajustando uma regress√£o linear no R

<br>

Claramente, a reta de regress√£o (linha azul) do gr√°fico anterior n√£o tem
um bom poder preditivo. O ajuste foi feito diretamente usando o pacote
[ggplot2](https://ggplot2.tidyverse.org/), utilizando a fun√ß√£o
`geom_smooth`, em que foi escolhido o m√©todo `"lm"`.

<br>

Poder√≠amos ter utilizado a fun√ß√£o `lm`:

<br>

```{r}
#| code-fold: true
#| code-summary: "Veja o c√≥digo do gr√°fico"
#| fig-align: center
#| out-width: "1200px"
#| out-height: "700px"
#| results: markup

library(ggplot2)

url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"

# Criando um arquivo tempor√°rio
arquivo_temp <- tempfile()

# Baixando um arquivo tempor√°rio
download.file(url = url, destfile = arquivo_temp)

# Carregando os dados
load(arquivo_temp)

# Ajustando o modelo usando a fun√ß√£o lm
ajuste <- lm(LifeExpectancy ~ GDPercapita, data = dados_expectativa_renda)

modelo <- function(x){
  novos_dados <- tibble::tibble(GDPercapita = x)
  predict(ajuste, newdata = novos_dados)
}

dados_expectativa_renda |> 
  ggplot(aes(x = GDPercapita, y = LifeExpectancy)) +
  geom_point() +
  labs(
    title = "PIB per Capita versus Expectativa de Vida",
    x = "PIB per Capita",
    y = "Expectativa de Vida"
  ) +
  stat_function(fun = modelo, color = "red", size = 1.2) +
  theme(
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold")
  )
```

## Matriz esparsa

<br>

Para grandes bases de dados, em um problema real que voc√™ venha
trabalhar, e se o custo computacional voc√™ considera elevado, poder√°
utilizar o pacote
[biglm](https://cran.r-project.org/web/packages/biglm/index.html).

<br>

Em situa√ß√µes em que h√° muitos zeros na sua matriz, poder√° utilizar
representa√ß√£o [esparsa](https://en.wikipedia.org/wiki/Sparse_matrix).

<br>

[Matrizes esparsas]{.red} s√£o matrizes com muitas entradas iguais √† $0$.
Elas ocorrem naturalmente em diversas aplica√ß√µes, como por exemplo uma
matriz de termos presentes em um documento, em que se o termo estiver no
documento resebe 1, e zero, caso contr√°rio. Abaixo, ${\bf X}$ √© um
exemplo de matriz esparsa.

<br>

$$
{\bf X} = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 2 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 3 & 0 & 0 \\
0 & 0 & 0 & 4 & 0 \\
\end{bmatrix}
$$

## Matriz esparsa

<br>

Considere os textos:

1.  [Texto 1]{.red}: "Eu amo essa disciplina."
2.  [Texto 2]{.red}: "Eu adoro meu professor."
3.  [Texto 3]{.red}: "Eu serei muito bom em aprendizagem de m√°quina."
4.  [Texto 4]{.red}: "Adoro o departamento de estat√≠stica da UFPB."

<br>

| Textos          | disciplina | amo | aprendizagem | m√°quina | estatistica | adoro | UFPB |
|-----------------|------------|-----|--------------|---------|-------------|-------|------|
| [Texto 1]{.red} | 1          | 1   | 0            | 0       | 0           | 0     | 0    |
| [Texto 2]{.red} | 0          | 0   | 0            | 0       | 0           | 1     | 0    |
| [Texto 3]{.red} | 0          | 0   | 1            | 1       | 0           | 0     | 0    |
| [Texto 4]{.red} | 0          | 0   | 0            | 0       | 1           | 1     | 1    |

## Matriz esparsa

<br>

A matriz com a ocorr√™ncia de determinados termos nos textos √© dada por:

$$
{\bf X} = 
\begin{bmatrix}
1 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 1 & 1 \\
\end{bmatrix}
$$

A representa√ß√£o esparsa de ${\bf X}$, aqui denotada por ${\bf X_*}$ √©:

$$
{\bf X_*} = 
\begin{bmatrix}
1 & 1 & 1 \\
2 & 6 & 1 \\
3 & 3 & 1 \\
3 & 4 & 1 \\
4 & 5 & 1 \\
4 & 6 & 1 \\
4 & 7 & 1 \\
\end{bmatrix},
$$ em que as duas primeiras colunas, s√£o as linhas e colunas de
${\bf X}$ com valor diferente de 0. A √∫ltima coluna representa o valor.

## Regress√£o linear com matriz esparsa

<br>

**Exemplo**: Ajuste de um modelo de regerss√£o linear m√∫ltiplo, em que
${\bf X}$ poder√° ter uma representa√ß√£o esparsa. Aqui n√£o estamos
interessados em verificar qualidade de predi√ß√µes. Trata-se apenas de um
exemplo de como utilizar uma representa√ß√£o esparsa para ajustar um
modelo de regess√£o linear com algumas covari√°veis, em R.

<br>

```{r}
#| code-fold: true
#| code-summary: "Estude o c√≥digo"
library(glmnet)
library(Matrix)

# Dados de exemplo
x1 <- c(1, 0, 2, 0, 0)
x2 <- c(0, 3, 0, 4, 0)
x3 <- c(5, 0, 6, 0, 7)
y <- c(1, 2, 3, 4, 5)

# Criar data frame com as vari√°veis explicativas
dados <- data.frame(x1, x2, x3)

# Converter o data frame para matriz esparsa
X <- sparse.model.matrix(~ ., data = dados)

# Ajustar a regress√£o linear utilizando glmnet
modelo <- glmnet(x = X, y = y, alpha = 0, lambda = 0)

# Realizar previs√µes
predicoes <- predict(modelo, newx = X)
```

## Erro quadr√°tico m√©dio

<br>

Como exposto anteriormente, para avaliar o poder preditivo de uma
modelo, i.e., a aprendizagem de um modelo, devemos avaliar a fun√ß√£o de
risco, i.e., devemos avaliar
$R(g) := \mathbb{E}\left[L(g({\bf X}); Y)\right]$. Em particular,
considere $L = L_2$ (fun√ß√£o perda quadr√°tica). Ent√£o, poder√≠amos ser
levados a acreditar que o melhor estimador de $R(g)$, utilizando a Lei
dos Grandes N√∫meros seria:

$$\frac{1}{n}\sum_{i = 1}^n(Y_{i} - g({\bf X_{i}}))^2 \approx R(g) := \mathbb{E}\left[L_2(g({\bf X}); Y)\right].$$

<br>

Essa quantidade √© chamada, de **E**rro **Q**uadr√°tico **M**√©dio -
**EQM**. Desejamos escolher o melhor mode, entre os modelos testados,
que minimiza o EQM.

<br>

O apelo frequentista em utilizar a Lei dos Grandes N√∫meros na forma
acima n√£o √© correto, uma vez que usamos as $n$ observa√ß√µes para
treinar/ajustar o modelo $g$.

## Erro quadr√°tico m√©dio

<br>

Por exemplo, no problema de PIB per Capita versus expectativa de vida,
em que consideramos uma aproxima√ß√£o linear, n√£o poder√≠amos utilizar o
EQM da forma acima, com as $n$ observa√ß√µes utilizadas para treinar o
modelo. √â um detalhe sutil, mas que muitas pessoas cometem esse erro.

<br>

N√£o podemos utilizar as $n$ observa√ß√µes para estimar o risco $R(g)$
atrav√©s do EQM, uma vez que estamos utilizando o mesmo conjunto de dados
para ajustar e avaliar $g$.

<br>

**Qual o problema?**

<br>

1.  N√£o vale a Lei dos Grandes N√∫meros;
2.  Usamos os mesmos valores de ${\bf x}$ e $y$ para treinar e avaliar o
    modelo.

## Erro quadr√°tico m√©dio

<br>

O que diz a Lei dos Grandes N√∫meros, em particular, a Lei Forte de
Kolmogorov?

<br>

[Teorema]{.red} (**Lei Forte de Kolmogorov**): Sejam $X_1, \cdots, X_n$
uma sequ√™ncia de veri√°veis aleat√≥rias - v.a. i.i.d. e integr√°veis, i.e.,
com valor esperado limitado, tal que
$\mathbb{E}(X) = \mu\,\, \forall i$. Ent√£o,

$$\frac{X_1 + X_2 + \cdots + X_n}{n} \rightarrow \mu,$$

quase certamente, i.e., com probabilidade 1.

<br>

Note que se desejamos comparar diversos modelos,
$g_1({\bf x}), g_2({\bf x}), \cdots,$ e se utilizarmos as mesmas $n$
oberva√ß√µes para calularmos $R(g_1({\bf x})), R(g_2({\bf x})), \cdots$,
os termos de cada uma das somas **n√£o s√£o independentes**. Lembre-se que
desejamos obter $\argmin_g R_{pred}(g)$.

## Erro quadr√°tico m√©dio

<br>

Portanto, nunca utilize as mesmas observa√ß√µes utilizadas para treinar o
modelo, como aquelas que ser√£o utilizadas para se estimar $R(g)$. Nunca!
Isso √© um pecado mortal! Ok?!

<br>

![](gifs/thumbs-up-nod.gif){width="20%"}

## Data Splitting

<br>

Corrigir o problema de depend√™ncia que h√° ao estimarmos o risco usando o
EQM √© f√°cil. Uma abordagem muito utilizada √© utilizar [*data
splitting*]{.red}, tamb√©m chamado de m√©todo [hold-out]{.red}. Algo como
a segunda linha da imagem abaixo:

<br>

![](imgs/train-and-test-1-min-1.webp){width="35%"}

## Data Splitting

<br>

Essa divis√£o √© feita de forma aleat√≥ria, algumas vezes estratificada de
acordo com algumas vari√°v√°veis. A ideia de aleatorizar √© se livrar de
problemas de conjunto de dados ordenados. Queremos que tanto no conjunto
de treinamento [*Training*]{.red} quanto no conjunto de teste
[*Testing*]{.red}, na imagem, contenham a mesma diversidade de
observa√ß√µes.

<br>

Por exemplo, ainda no exemplo de PIB per Capita versus Expectaitiva de
Vida, n√£o quero correr o risco de ter no conjunto de treinamento apenas
o pa√≠ses com maiores valores de PIB per Capita, caso o conjunto de dados
tenha sido ordenado pela vari√°vel `GDPercapita`. Por isso aleatorizar o
conjunto de treinamento e teste √© simple uma √≥tima ideia. Certo!?

<br>

![](gifs/ok-2.gif){width="20%"}

## Data Splitting

<br>

O percentual de divis√£o dos dados normalmente √© emp√≠rico. Usa-se
normalmente a propor√ß√£o de $70\%$ para treinamento e $30\%$ para teste
$(70\%, 30\%)$. Outros esquemas de divis√µes s√£o bastante utilizados, por
exemplo, $(80\%, 20\%)$, $(99\%, 1\%)$, a depender da quantidade de
observa√ß√µes (tamanho do conjunto de dados).

<br>

Portanto, utilizar o EQM sob o conjunto de dados de teste para avaliar
$g_1({\bf x}), g_2({\bf x}), \cdots,$, √© uma boa estrat√©gia, uma vez que
agora n√£o teremos mais uma depend√™ncia no numerador do c√°lculo do EQM.
Em nota√ß√£o matem√°tica, poder√≠amos escrever como j√° apresentado
anteriormente, em @eq-risco-correto, i.e,

$$\frac{1}{m}\sum_{i = 1}^m (Y_{n + i} - g(X_{n + i}))^2 \approx R(g) := \mathbb{E}\left[(Y - g({\bf X}))^2\right].$$

<br>

Esse resultado valeria para qualquer outra fun√ß√£o de perda.

## Data Splitting

Reescrevendo, suponha que o conjunto de dados total possua $n$
observa√ß√µes e que separamos aleatoriamente $s < n$ observa√ß√µes para o
conjunto de treinamento. Assim, temos, algo como:

<br>

$$\overbrace{(X_1, Y_1), (X_2, Y_2), \cdots, (X_s, Y_s)}^{70\%}, \,\,\, \overbrace{(X_{s + 1}, Y_{s + 1}), (X_{s + 2}, Y_{s + 2}), \cdots, (X_n, Y_n)}^{30\%}.$$

<br>

Ent√£o, temos que uma boa estimativa de $R(g)$ √© dada pelo EQM calculado
sobre o conjunto de dados de teste, que nesse caso considerei o conjunto
com $30\%$, mas esse percentual poderia ser outro. Ent√£o, temos que um
bom estimador √©:

$$\frac{1}{n - s}\sum_{i = s + 1}^n (Y_{i} - g(X_{i}))^2 \approx R(g) := \mathbb{E}\left[(Y - g({\bf X}))^2\right].$$

## Data Splitting

<br>

**Agora voc√™ entende por que dividimos os dados em treinamento e
teste?**

<br>

![](gifs/yes.gif){width="25%"}

<br>

Dividimos para obermos um bom estimador do risco utilizando o
[EQM](https://en.wikipedia.org/wiki/Mean_squared_error). üéä

## Data Splitting

<br>

Podemos argumentar que o procedimento de *data splitting*, em que
dividimos o nosso conjunto de dados em treinamento e teste far√° com que
venhamos perder muitas observa√ß√µes que poderiam ter sido utilizadas para
treinar o modelo. E de certa forma isso √© verdade, principalmente quando
termos um conjunto n√£o muito grande de observa√ß√µes.

<br>

Portanto, uma melhor abordagem, sendo esta uma varia√ß√£o do m√©todo de
*data splitting* √© o procedimento de [*cross-validation - cv (valida√ß√£o
cruzada)*](https://en.wikipedia.org/wiki/Cross-validation_(statistics)).
Uma vers√£o mais geral de uma valida√ß√£o cruzada √© o [*leave-one-out
cross-validation*]{.red}.

<br>

Em palavras, o procedimento consiste em tirar de fora uma √∫nica
observa√ß√£o das $n$ observa√ß√µes da base de dados para ser o nosso
conjunto de teste e treinar o modelo com as observa√ß√µes que
permaneceram. Da√≠, calcula-se o **risco observado** (EQM, sob o conjunto
de teste). Na segunda itera√ß√£o, a observa√ß√£o que antes era de teste
volta para perterncer ao conjunto de treinamento e uma nova observa√ß√£o √©
removida para ser teste. Esse procedimento ocorre de forma iterativa at√©
a retirada da √∫ltima observa√ß√£o como teste.

## Leave-one-out cross-validation

<br>

Observe a anima√ß√£o abaixo que ilustra o procedimento de
**l**eave-**o**ne-**o**ut **c**ross-**v**alidation - LOOCV, em uma
amostra de tamanho $n = 8$. Ao fim, teremos $n$ modelos ajustados, em
que calculamos as suas respectivas performances, i.e., com o risco
observado, estimamos o risco de $R(g)$.

<br>

![](gifs/LOOCV.gif)

## Leave-one-out cross-validation

<br>

Vejo muitas pessoas que usam uma valida√ß√£o cruzada, por exemplo,
leave-one-out cross-validation - LOOCV comparando com o m√©todo Jackknife
e algumas inclusive dizendo ser a mesma coisa. N√£o, n√£o s√£o!

<br>

O algoritmo Jackknife √© um procedimento de estima√ß√£o e que por sua vez
deve estar dentro do conjunto de treinamento. Para haver algum
Jackknife, a estimativa com $n-1$ observa√ß√µes deve estar dentro do
conjunto de treinamento, em que dentro do treinamento teria a remo√ß√£o de
um observa√ß√£o por vez. **Consegue perceber a diferen√ßa sutil?**

<br>

![](gifs/bean_01.gif){width="20%"}

## Leave-one-out cross-validation

<br>

O m√©todo LOOCV foi proposto por Stones (1974), no artigo intitulado
Cross-Validatory Choice and Assessment of Statistical Predictions, no
Royal Statistical Society, S√©rie B. Clique
[aqui](https://www.jstor.org/stable/pdf/2984809.pdf?refreqid=excelsior%3A3071b86b3588905b095d44668025b005&ab_segments=&origin=&initiator=&acceptTC=1)
se tiver curiosidade em ler o artigo.

<br>

Escrevendo o estimador do risco em um procedimento de LOOCV, temos que:

$$\widehat{R}(g) = \frac{1}{n}\sum_{i = 1}^n (Y_i - g_{-i}({\bf X}_i))^2,$$
em que $g_{-i}(\bf{X}_i)$, representa o ajuste do modelo no conjunto de
dados sem a $i$-√©sima observa√ß√£o.

<br>

N√£o √© dif√≠cil perceber que a depender do valor de $n$, o m√©todo LOOCV √©
computacionalmente intensivo. O m√©todo requer que ajustemos $n$ modelos.
Em algumas situa√ß√µes isso n√£o √© um grande problema, por√©m, em diversas
outras pode ser impeditivo utilizar o LOOCV. ü§Ø

## $k$-fold cross-validation

<br>

Uma alternativa ao LOOCV √© utilizar o m√©todo $k$-fold cross-validation.
Nessa abordagem, dividimos o conjunto de dados em $k$-folds (lotes)
disjuntos e com aproximadamente o mesmo tamanho. Dessa forma, temos
$L_1, \cdots, L_k \subset \{1, \cdots, n\}$ s√£o, cada um, um conjunto de
indices aleat√≥rios associados a cada um dos lotes. A ideia aqui √©
construir $k$ estimadores da fun√ß√£o de regress√£o, denotados por
$\widehat{g}_{-1}, \cdots, \widehat{g}_{-k}$, em que $\widehat{g}_{-j}$
√© criado usando todas as observa√ß√µes do banco de dados, com exce√ß√£o
daquelas do lote $L_j$, utilizado para **valida√ß√£o**. O estimador do
risco √© dado por:

$$\widehat{R}(g) = \frac{1}{n}\sum_{j=1}^k \sum_{i \in L_j}(Y_i - g_{-j}({\bf X}_i))^2.$$
Perceba que, que o LOOCV √© um caso particular do $k$-fold
cross-validation, quando fazemos $k = n$. Em outras palavras,
$L_1, \cdots, L_k \subset \{1, \cdots, n\}$ representam os √≠ndices
aleat√≥rios do conjunto de treinamento nos $k$ lotes.

![](gifs/hum.gif)

## $k$-fold cross-validation

A anima√ß√£o abaixo, ilustra o procedimento de $3$-fold cross-validation
($k = 3$), para uma amostra de tamanho $n = 12$ observa√ß√µes. Note que os
valores que pertencem a cada um dos lotes s√£o aleat√≥rios. Portanto, o
procedimento LOOCV √© deterministico, j√° o procedimento de $k$-fold
cross-validation √© randomizado.

<br>

![](gifs/KfoldCV.gif)

Perceba que teremos agora apenas $3$ modelos. Para cada um desses lotes,
calulamos o EQM com o conjunto de teste (parte [azul]{.trueblue}) e
treinamos o modelo com o conjunto de treinamento (parte
[vermelha]{.truered}).

## $k$-fold cross-validation

<br>

Muitos modelos mais sofisticados apresentam hiperpar√¢metros (par√¢metros
de sintoniza√ß√£o) que n√£o dependem dos dados. √â muito comum os algoritmos
de aprendizagem de m√°quina se utilizarem do procedimento de valida√ß√£o
cruzada, para al√©m da estima√ß√£o do risco $R(g)$.

<br>

Ao estimar $k$ modelos, normalmente faz-se um grid de poss√≠veis valores
para esses hiperpar√¢metros em que ao final, escolhe-se como
hiperpar√¢metro o modelo com menor EQM. Por fim, ajusta-se um modelo
final, com todo o conjunto de treinamento usando o valor do
hiperpar√¢metro que retornou o menor EQM no conjunto de valida√ß√£o.

<br>

![](gifs/ok.gif)

## $k$-fold cross-validation

<br>

::: columns
::: {.column width="50%"}
O termo [valida√ß√£o]{.red} refere-se √† parcela do conjunto de treinamento
incial que dividimos em valida√ß√£o e treinamento, dentro de uma valida√ß√£o
cruzada.

<br>

O conjunto [*Testing*]{.red} na segunda hierarquia da √°rvore ao lado, s√≥
usamos no final para avaliar o desempenho do modelo nesse conjunto.

<br>

Perceba que o conjunto de treinamento ([*Not Testing*]{.red}) √©
particionado em treinamento e valida√ß√£o. Poder√≠amos fazer uma √∫nica
parti√ß√£o, mas o procedimento comumente utilizado √© particionar entre
[*Training*]{.red} e [*Validation*]{.red} uzando algum procedimento de
valida√ß√£o cruzada.
:::

::: {.column width="50%"}
![](imgs/validation-split.svg){fig-aling="center" width="64%"}
:::
:::

## $k$-fold cross-validation

A imagem abaixo ilustra o procedimento $k$-fold cross-validation, em que
uma $5$-fold cross-validation √© realizada dentro do conjunto de
treinamento. Em cada *split*, o conjunto verde de observa√ß√µes (fold
[verde]{.green}) s√£o utilizados para treinar/ajustar o modelo e o
conjunto [azul]{.trueblue}, em cada um dos *splits* √© utilizado para
avaliar o risco preditivo $R(g)$ (atrav√©s, por exemplo do EQM).

::: columns
::: {.column width="40%"}
![](imgs/grid_search_cross_validation.png){width="800"}
![](gifs/hum.gif)
:::

::: {.column width="60%"}
N√£o confunda os folds azuis com o conjunto de teste ([Test
data]{.trueblue}), este √∫ltimo utilizado por fim, depois do modelo
pronto, para avaliar o desempenho do modelo treinado.

Note tamb√©m que a valida√ß√£o cruzada tamb√©m √© utilizada para o ajuste de
hiperpar√¢metros, que s√£o par√¢metros de sintoniza√ß√£o que n√£o dependem dos
dados para serem equalizados. Por exemplo, em uma regress√£o lasso, que
veremos adiante, h√° o hiperpar√¢metro $\lambda$ que precisamos obter,
normalmente por meio de um [grid search]{.red} (sequ√™ncia finita), por
exemplo, $\lambda \in [0.5, 1, 1.5, 2, 2.5]$ de poss√≠veis valores. Cada
*split* pode ser utilizado para avaliar um valor de $\lambda$, dos
poss√≠veis valores dispostos no grid. Aumentar√≠amos a quantidade de
splits para mais valores de $\lambda$ na sequ√™ncia.
:::
:::

## Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o

::: columns
::: {.column width="50%"}
![](imgs/data_split_validation_cross.png)
:::

::: {.column width="50%"}
O simples procedimento de dividir o conjunto de dados em dois, uma parte
para treinar o modelo e a outra parte (conjunto de teste) para estimar o
risco $R(g)$ √© denominado de [data splitting]{.red} ou [Hold-out
Method]{.red}. √â um procedimento mais simples, por√©m, pode n√£o ser √∫til
em conjunto de dados n√£o muito grandes.

A segunda linha da ilustra√ß√£o, demonstra o procedimento de
cross-validation (valida√ß√£o cruzada), procedimento mais utilizado nos
treinamentos de modelos de aprendizagem de m√°quina.

A terceira linha √© uma abordagem tamb√©m utilizada, por√©m n√£o t√£o
interessante quanto a valida√ß√£o cruzada. Nessa abordagem o banco de
dados √© dividido aleatoriamente em tr√™s partes. Traina-se o modelo com a
parte [verde]{.green}, estima-se o risco com o conjunto de valida√ß√£o
amarelo e testa-se o modelo com o conjunto de teste.
:::
:::

## Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o

<br> A abordagem do conjunto de valida√ß√£o envolve dividir o conjunto de
treinamento em duas partes: uma parte √© usada para treinar o modelo e a
outra parte √© usada para avaliar o desempenho do modelo. O conjunto de
valida√ß√£o √© utilizado para ajustar os hiperpar√¢metros do modelo, como a
taxa de aprendizado, o n√∫mero de camadas ocultas em uma rede neural,
entre outros. Ap√≥s o ajuste dos hiperpar√¢metros, o modelo final √©
treinado com o conjunto de treinamento completo e avaliado em um
conjunto separado chamado conjunto de teste. Essa abordagem √© conhecida
como divis√£o simples de treinamento/valida√ß√£o/teste.

<br>

Por outro lado, a valida√ß√£o cruzada $k$-fold √© uma abordagem que visa
obter uma estimativa mais robusta do desempenho do modelo. Nessa
abordagem, o conjunto de treinamento √© dividido em k subconjuntos
(folds) de tamanho aproximadamente igual. O modelo √© treinado $k$ vezes,
cada vez usando $k-1$ folds como conjunto de treinamento e $1$ fold como
conjunto de valida√ß√£o. O desempenho do modelo √© ent√£o calculado como a
m√©dia dos resultados obtidos em cada itera√ß√£o. Isso permite avaliar o
modelo de forma mais precisa, pois utiliza todos os dados para
treinamento e valida√ß√£o, evitando a depend√™ncia de uma √∫nica divis√£o do
conjunto de treinamento.

## Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o

<br>

A valida√ß√£o cruzada $k$-fold √© particularmente √∫til quando o conjunto de
dados √© limitado, pois aproveita ao m√°ximo os dados dispon√≠veis. Al√©m
disso, ela permite verificar se o modelo √© est√°vel e se seu desempenho
varia significativamente com diferentes divis√µes dos dados. √â importante
ressaltar que a valida√ß√£o cruzada $k$-fold pode ser computacionalmente
mais cara do que a abordagem do conjunto de valida√ß√£o, uma vez que
envolve treinar e avaliar o modelo v√°rias vezes.

<br>

![](gifs/mr-bean-pivot.gif){width="40%"}

## Resumindo: data splitting, valida√ß√£o cruzada e conjunto de valida√ß√£o

<br>

Um outro detalhe que muitas vezes n√£o √© falado √© que apesar de temos
duas tarefas de estima√ß√£o, uma envolvendo o conjunto de **treinamento**,
em que treinamos o modelo e outra envolvendo o conjunto de **teste**, em
que queremos estimar o risco $R(g)$, de modo a poder selecionar o melhor
modelo, a segunda tarefa √© bem mais f√°cil √â por isso que o conjunto de
treinamento tende a ser menor que o conjunto de teste.

<br>

![](gifs/hum.gif)

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

A ideia de precis√£o e exatid√£o est√£o ligadas ao vi√©s e vari√¢ncia do
modelo $g$, em que precis√£o est√° ligado a ideia de vari√¢ncia pequena e
exatid√£o est√° ligada a ideia de baixo vi√©s. A ideia √© termos um
estimador pr√≥ximo o que ilustra o item [d]{.red}. Muitas vezes temos um
estimador nas situa√ß√µes [b]{.red} e [c]{.red}. O ideal √© o balan√ßo de
vi√©s e vari√¢ncia, que seria o estimador ilustrado pelo item [d]{.red}.

![](imgs/precisao_exatidao.png){fig-align="center" width="55%"}

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

Um grande apelo para o uso do risco quadr√°tico, i.e., risco que utiliza
a fun√ß√£o de perda $L_2$ √© sua interpretabilidade. Temos que o risco
quadr√°tico $R(g)$ condicional a um novo ${\bf x}$ poder√° ser decomposto
por:

$$\mathbb{E}\left[(Y - \widehat{g}({\bf X}))^2| {\bf X} = {\bf x}\right] = \underbrace{\mathbb{V}[Y | {\bf X = x}]}_{\mathrm{i - Vari√¢ncia\,\, intr√≠nseca}} + \overbrace{(r({\bf x}) - \mathbb{E}[\widehat{g}({\bf x})])^2}^{\mathrm{ii - Vi√©s\, ao\, quadrado\, do\, modelo}} + \underbrace{\mathbb{V}[\widehat{g}({\bf x})]}_{\mathrm{iii - Vari√¢ncia\, do\, modelo}}.$$
**Temos que**:

<br>

i - √â a vari√¢ncia intr√≠nseca da vair√°vel resposta (*label*), que n√£o
depende da fun√ß√£o $\widehat{g}$ escolhida e, assim, n√£o poder√° ser
reduzida. Na verdade, poderemos reduzir $i$, se incluirmos mais
*features* (covari√°veis/vari√°veis explicativas) ao nosso modelo;

ii - √â o vi√©s ao quadrado do estimador $\widehat{g}$ (vi√©s ao quadrado
do modelo);

iii - √â a vari√¢ncia do estimador $\widehat{g}$.

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

Assim, lembre-se que uma escolha adequada de $\widehat{g}$ nos grarante
que conseguiremos reduzir o risco preditivo $R(g)$, pois a escolha
aproriada implica em escolhermos um estimador de $\widehat{g}$ com
balan√ßo entre v√≠es e vari√¢ncia.

<br>

Modelos com muitos par√¢metros possuem vi√©s relativamente baixo, por√©m,
tendem a ter vari√¢ncia muito alta, em geral, uma vez que precisamos
estimar muitos par√¢metros. J√° modelos com poucos par√¢metros, normalmente
tendem a ter vari√¢ncia baixa, acompanhados, normalmente de um alto vi√©s.

<br>

Normalmente, modelos com muitos par√¢metros nos levam a termos
[*overffiting*]{.red} (super-ajuste), o que n√£o √© bom pois s√£o
acompanhados de alta vari√¢ncia. J√° modelos muito simplistas nos conduzem
a um ajuste muito ruim ([*underffiting*]{.red} ou sub-ajuste).
Entendeu!?

![](gifs/mais_ou_menos.gif)

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

```{r}
#| code-fold: true
#| code-summary: "Estude o c√≥digo"
#| eval: false
library(ggplot2)
library(tibble)
library(ggplot2)
library(patchwork)

# Fun√ß√£o de regress√£o verdadeira. Na pr√°tica √© desconhecida.
regressao_verdadeira <- function(x)
  45 * tanh(x/1.9 - 7) + 57

observacoes_regressao_real <- function(n, desvio_padrao = 0.2) {
  # Permitindo que o mesmo x possa ter dois pontos de y, como ocorre na 
  # pratica
  seq_x <- sample(seq(0, 17.5, length.out = n), size = n, replace = TRUE)
  
  step <- function(x)
    regressao_verdadeira(x) + rnorm(n = 1L, mean = 0, sd = desvio_padrao)
  
  tibble::tibble(y = purrr::map_vec(.x = seq_x, .f = step), x = seq_x)
}

# Usaremos uma regress√£o polinomial para tentar ajustar √† regress√£o -------
regressao_polinomial <- function(n = 30L, desvio_padrao = 4, grau = 1L) {
  
  dados <- observacoes_regressao_real(n = n, desvio_padrao = desvio_padrao)
    
  iteracoes <- function(tibble_data, grau) {
      x <- tibble_data$x
      iteracoes <- lapply(X = 2L:grau, FUN = function(i) x^i)
      
      result <- cbind(tibble_data, do.call(cbind, iteracoes))
      colnames(result)[(ncol(tibble_data) + 1):ncol(result)] <- paste0("x", 2L:grau)
      
      as_tibble(result)
  }  
  
  if(grau >= 2L)
    dados <- iteracoes(dados, grau = grau)
  
  ajuste <- lm(formula = y ~ ., data = dados)
  dados$y_chapeu <- predict(ajuste, new.data = dados)
  
  dados |> 
    dplyr::relocate(y_chapeu, .before = x)
}

plotando <- function(dados){
  dados |>  
    ggplot(aes(x = x, y = y_chapeu)) +
    geom_point()
}

mc_ajustes <- function(mc = 100L, n = 50L, desvio_padrao = 5, grau = 1L){

  p <- 
    ggplot(data = NULL) +
      coord_cartesian(xlim = c(0, 17.5), ylim = c(0, 110)) +      
      ylab("Valores estimados")
  
  df <- NULL
  for(i in 1L:mc){
    df <- regressao_polinomial(n = n, desvio_padrao = desvio_padrao, grau = grau)
    p <- p + geom_line(data = df, aes(x = x, y = y_chapeu))
  }
  p + 
    stat_function(fun = regressao_verdadeira, col = "red", size= 1.4) +
    labs(
      title = "Regress√£o Polinomial",
      subtitle = paste("Grau: ", grau)
    ) +
    theme(
      plot.title = element_text(face = "bold"),
      axis.title = element_text(face = "bold")
    )
}

# Fixando uma semente
set.seed(0)

p1 <- mc_ajustes(grau = 1, n = 100, desvio_padrao = 10)
p2 <- mc_ajustes(grau = 7, n = 100, desvio_padrao = 10)
p3 <- mc_ajustes(grau = 70, n = 100, desvio_padrao = 10)
p4 <- mc_ajustes(grau = 200, n = 100, desvio_padrao = 10)

p <- ((p1 | p2) / (p3 | p4)) + plot_annotation(tag_levels = "A")

ggsave(p, file = "imgs/vies_variancia.png", device = "png", width = 40, height = 30, units = "cm")
```

![](imgs/vies_variancia.png){fig-align="center" width="60%"}

## `r fontawesome::fa("scale-balanced", "black")` Balan√ßo vi√©s e vari√¢ncia

<br>

Experimente de forma interativa altera a complefixade do modelo.

<br>

```{=html}
 <iframe id="example1" src="https://pedro-rafael.shinyapps.io/shiny_apps/" style="border: none; width: 100%; height: 90%" frameborder="0"></iframe>
```
## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

No exemplo anterior, note que os par√¢metros dos modelos s√£o os
coeficientes $\beta$'s que indexam a regress√£o polinomial. Por√©m,
perceba que √° um par√¢metro de sintoniza√ß√£o ([*tuning parameter*]{.red})
que √© o valor de $p$, isto √©, qual o grau do polin√¥mio que iremos
utilizar.

<br>

Normalmente a escolha √© feita realizando um [*grid search*]{.red} por
meio de um [*cross-validation*]{.red}.

<br>

No exemplo anterior, fizemos uma simula√ß√£o e observamos que ao
considerar graus nem muito grandes nem muito pequenos, aparentemente
teremos escolhas razo√°veis.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

[Exemplo]{.red}: Consedere os dados de expectativa de vida versus PIB
per Capita, dispon√≠veis
[aqui](https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData).
Selecione o melhor estimador $g$ da classe $\mathbb{G}$, em que

$$\mathbb{G} = \left\{g(x)\,\,:\,\, \beta_0 + \sum_{i = 1}^p \beta_i x^i\,\, \text{para } p \in \{1, 2, \cdots,11\} \right\}.$$
Note que selecionar o melhor polin√¥mio √© uma busca em $p$. Devemos
utilizar o erro quadr√°tico m√©dio - EQM sob o conjunto de valida√ß√£o, uma
vez que sabemos que apenas em um conjunto de valida√ß√£o ou em novas
observa√ß√µes o estimador do risco pelo EQM √© consistente, pela Lei dos
Grandes N√∫meros.

<br>

Vamos utilizar a biblioteca
[rsample](https://rsample.tidymodels.org/index.html) para a tarefa de
valida√ß√£o cruzada. Leia a documenta√ß√£o da biblioteca, em especial, a da
fun√ß√£o `vfold_cv`, respons√°vel por construir a valida√ß√£o cruzada. Na
verdade ela faz a divis√£o da base de dados em $v$ *splits* de tamanho
aproximadamente iguais. Por padr√£o, $v = 10$. Esse √© o procedimento de
$k$-fold cross-validation que apresentamos aqui, em que $v = k$.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

Algumas observa√ß√µes gerais a respetioda biblioteca
[rsample](https://rsample.tidymodels.org/index.html), que s√£o √∫teis para
resolver esse problema:

![](imgs/rsample.png){fig-align="center"}

1.  Para realizar uma primeira divis√£o do conjunto de dados (data
    splitting/hold-out), utiliza-se a fun√ß√£o `initial_split`;
2.  Para acessar o conjunto de treinamento dos dados, usamos a fun√ß√£o
    `training`;
3.  Para acessar o conjunto de teste, usamos a fun√ß√£o `testing`;
4.  Para constuir todas as divis√µes da valida√ß√£o cruzada, entre
    treinamento e valida√ß√£o, no conjunto de treinamento inicial, usamos
    a fun√ß√£o `vfold_cv` j√° mencionada;
5.  Para acessar o conjunto de treinamento de um split da valida√ß√£o
    cruzada, usamos a fun√ß√£o `analysis`;
6.  Para acessar o conjunto de valida√ß√£o, utilizamos a fun√ß√£o
    `assessment`.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

![](imgs/rsample.png){fig-align="center" width="10%"}

<br> Note que realizar uma valida√ß√£o cruzada √© importante para podemos
selecionar o melhor polin√¥mio, i.e., o melhor valor de $p$. Caso
venhamos negligenciar esse aspecto da an√°lise, iremos cair na fal√°cia de
acreditarmos que quanto maior o grau do polin√¥mio, maior ser√° o poder
preditivo do modelo. Isso n√£o √© verdade e voc√™ dever√° selecionar o
melhor modelo dentro de um esquema de valida√ß√£o cruzada.

<br>

No mundo de aprendizagem de m√°quina, muitos chamam o processo de
encontrar o melhor hiperpar√¢metro de ["tunagem"]{.red}.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

As Figuras abaixo, mostra a avalia√ß√£o dos polin√¥mios da classe
$\mathbb{G}$, usando o risco estimado $\widehat{R}(g)$ pelo erro
quadr√°tico m√©dio - EQM. Por√©m, a Figura [A]{.red} aprenseta a avalia√ß√£o
dos modelos, usando simplesmente o conjunto de treinamento e a Figura
[B]{.red} aprensenta a avalia√ß√£o do grau do polin√¥mio considerando uma
valida√ß√£o cruzada dentro do conjunto de treinamento.

<br> ![](imgs/avaliacao_risco.png){fig-align="center"}

<br>

A mensagem equivocada passada pela Figura [A]{.red} √© que supostamente
aumentar a complexidade do modelo seria uma uma boa alternativa e nos
conduzir√≠amos √† bons modelos preditivos. Mas sempre se lembre do
equil√≠brio que temos que ter entre vi√©s e vari√¢ncia. A Figura [B]{.red}
mostra que um polin√¥mio com grau pr√≥ximo √† $p = 8$ √© a melhor
alternativa.

## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

Observe o dashboard interativo. Sabemos que para que tenhamos uma boa
estimativa do risco preditivo, devemos utilizar novas observa√ß√µes. No
dashboard √© poss√≠vel observar que a forma errada (usando o conjunto de
treinamento para avaliar o risco), sugere que sempre ser√° bom adicionar
mais par√¢metros ao modelo, levando a *overfitting*. Perceba que usando a
forma correta (usando valida√ß√£o cruzada), o EQM (risco estimado) sugere
que n√£o podemos aumentar muito a quantidade de par√¢metros.

<br>

```{=html}
 <iframe id="example1" src="https://pedro-rafael.shinyapps.io/shiny_apps/#section-avalia%C3%A7%C3%A3o-do-risco-preditivo" style="border: none; width: 100%; height: 90%" frameborder="0"></iframe>
```
## `r fontawesome::fa("scale-balanced", "black")` Tuning Parameters

<br>

Abaixo voc√™ poder√° acessar o c√≥digo que soluciona o problema. O
par√¢metro `errado = FALSE` da fun√ß√£o valida√ß√£o no c√≥digo que segue,
conduz a solu√ß√£o correta (usando a valida√ß√£o cruzada), que sempre voc√™
dever√° considerar na pr√°tica.

<br>

```{r}
#| code-fold: true
#| code-summary: "Estude o c√≥digo da solu√ß√£o de exemplo"
#| eval: false

library(rsample)
library(yardstick)
library(tibble)
library(purrr)
library(ggplot2)
library(patchwork)

# Lendo dados
url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"
arquivo_temp <- tempfile()
download.file(url = url, destfile = arquivo_temp)
load(arquivo_temp)

dados <- 
  dados_expectativa_renda |> 
  dplyr::select(-CountryName) |> 
  dplyr::rename(y = LifeExpectancy, x = GDPercapita)
  
iteracoes <- function(tibble_data, grau) {
  x <- tibble_data$x
  iteracoes <- lapply(X = 2L:grau, FUN = function(i) x^i)
  
  result <- cbind(tibble_data, do.call(cbind, iteracoes))
  colnames(result)[(ncol(tibble_data) + 1):ncol(result)] <- paste0("x", 2L:grau)
  
  as_tibble(result)
}  

regressao_polinomial <- function(dados, grau = 1L) {
  if(grau >= 2L)
    dados <- iteracoes(dados, grau = grau)
  
  lm(formula = y ~ ., data = dados)
}

# Divis√£o dos dados
divisao_inicial <- rsample::initial_split(dados)
treinamento <- rsample::training(divisao_inicial)
teste <- rsample::testing(divisao_inicial) # Teste final

# v-folds cross-validation
validacao <- function(dados, grau = 1L, errado = FALSE, ...){
  
  # Todas as divis√µes da validacao cruzada
  cv <- rsample::vfold_cv(dados, ...)
  
  hiper <- function(i){
    treino <- rsample::analysis(cv$splits[[i]]) # Treinamento
    validacao <- rsample::assessment(cv$splits[[i]]) # Validaca√ß√£o
    ajuste <- regressao_polinomial(dados = treino, grau = grau)
    
    if(errado){
      df_treino <- iteracoes(treino, grau = grau)
      df_treino <- df_treino |> dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_treino))
      yardstick::rmse(data = df_treino, truth = y, estimate = y_chapeu)$.estimate
    } else {
      df_validacao <- iteracoes(validacao, grau = grau)
      df_validacao <- df_validacao |> dplyr::mutate(y_chapeu = predict(ajuste, newdata = df_validacao))
      yardstick::rmse(data = df_validacao, truth = y, estimate = y_chapeu)$.estimate
    }
  }
  purrr::map_dbl(.x = seq_along(cv$splits), .f = hiper) |> 
    mean()
}

plot_avaliacao <- function(dados, errado = FALSE){
  # Testando iterativamente, v√°rios valores de p:
  p <- seq(1L:11L)
  risco <- purrr::map_dbl(.x = p, .f = \(p) validacao(dados = dados, grau = p, errado = errado))
  df_risco <- tibble::tibble(p = p, risco = risco)
  
  # Plotando
  df_risco |> 
    ggplot(aes(x = p, y = risco, color = risco)) +
    geom_point(size = 5) +
    scale_x_continuous(breaks = p) +
    scale_y_continuous(breaks = p) +
    labs(
      title = "Valiando o risco estimado para diversos graus do polin√¥mio",
      subtitle = "EQM no conjunto de valida√ß√£o"
    ) +
    theme(
      plot.title = element_text(size = 18, face = "bold"),
      plot.subtitle = element_text(size = 16),
      axis.text = element_text(size = 10), 
      axis.title = element_text(size = 14, face = "bold")
    )
}

# Avaliac√£o errada versus correta
set.seed(0)
grafico <- 
  plot_avaliacao(dados, errado = TRUE) + 
  plot_avaliacao(dados, errado = FALSE) +
  plot_annotation(tag_levels = c("A", "B"))

ggsave(grafico, file = "imgs/avaliacao_risco.png", device = "png", width = 50, height = 20, units = "cm", limitsize = F)

plot_bar <- function(grau){
  ruim <- validacao(dados, errado = TRUE, grau = grau)
  bom <- validacao(dados, errado = FALSE, grau = grau)
  df <- tibble::tibble(x = c("Errado", "Certo"), y = c(log(ruim), log(bom)))
  
  df |> 
    ggplot(aes(x = x, y = y)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = y), vjust = 0)
}
```

![](gifs/mr-bean-pivot.gif)

## `r fontawesome::fa("book", "black")` Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Explique resumidamente o que √© aprendizagem
supervisionada e n√£o-supervisionada. Cite um problema de aprendizagem
supervisionada e um outro de aprendizagem n√£o-supervisionada.

<br>

[Exerc√≠cio]{.red}: Considere o conjunto de dados de Expectativa de vida
versus PIB per Capita, dispon√≠vel
[aqui](https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData).
Considere a fun√ß√£o $g$, da seguinte forma:

$$g(x) = \beta_0 + \sum_{i = 1}^p \beta_i x^i,$$ com
$p \in \{1, 2, ..., 50\}$. Utilizando o erro quadr√°tico m√©dio observado,
sem fazer nenhuma estrat√©gia de divis√£o dos dados, implemente um c√≥digo
em R para checar qual o melhor modelo.

<br>

[Exerc√≠cio]{.red}: Explique qual o motivo que faz com que o Erro
Quadr√°tico M√©dio - EQM para avaliar o desempenho de um modelo √© ruim
quando n√£o adotamos nenhuma estrat√©gia de divis√£o do conjunto de dados
em treinamento e teste.

## `r fontawesome::fa("book", "black")` Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Com suas palavras, explique o dilema de balan√ßo entre
v√≠es e vari√¢ncia.

<br>

[Exerc√≠cio]{.red}: Refa√ßa o exerc√≠cio do polin√¥mio, utilizando a
estrat√©gia de [*data splitting*]{.red}, em que divide-se o conjunto de
dados em treinamento e teste. Utilize o conjunto de teste para calcular
a estimativa do risco, usando o EQM.

<br>

[Exerc√≠cio]{.red}: Ainda considerando o exerc√≠cio do polin√¥mio,
implemente uma estrat√©gia de [*leave-one-out cross-validation*]{.red} e
selecione o melhor modelo minimizando a fun√ß√£o de risco.

<br>

[Exerc√≠cio]{.red}: Por fim, considerando o exerc√≠cio do polin√¥mio,
rafa√ßa-o utilizando um procedimento de [$k$-fold
cross-validation]{.red}. Considere $k = 5$. **Dica**: considere utiliza
a biblioteca [rsample](https://rsample.tidymodels.org/).

![](imgs/rsample.png)

## Melhor subconjunto de covari√°veis

<br>

O estimador de m√≠nimos quadrados - EMQ, na presen√ßa de muitas *features*
(covari√°veis), i.e., quando temos $d$ grande, possui um baixo poder
preditivo devido *overfitting* (super-ajuste). Isso, porqu√™ haver√°
muitos par√¢metros a serem estimados, e portanto, a fun√ß√£o de regress√£o
estimada $\widehat{r}({\bf x})$ ter√° baixo poder preditivo.

<br>

Isso se deve ao fato do balan√ßo de vi√©s e vari√¢ncia. Havendo muitos
par√¢metros, como j√° tinhamos visto, a vari√¢ncia do modelo ser√° muito
alta.

<br>

**Portanto, deveremos buscar meios de encontrar o melhor (ao menos um
bom) comjunto de covari√°veis.**

<br>

![](gifs/chapulin-colorado-no.gif){width="20%"}

## Melhor subconjunto de covari√°veis

<br>

A ideia para resolver esse problema √© retirar algumas covari√°veis do
modelo de regress√£o, com o objetivo de diminuir a vari√¢ncia de
$\widehat{g}$.

<br>

Voc√™ poder√° entender que estamos em busca de um estimador $\widehat{g}$
de $g$ um **pouco** mais viesado. Trata-se de uma troca em que desejamos
reduzir substancialmente a variabilidade do estiamdor do modelo e troca
de ganharmos um pouco mais de vi√©s.

<br>

![](gifs/kiko.gif)

## Melhor subconjunto de covari√°veis

<br>

Matematicamente, uma maneira de fazer isso, √© buscar a estimativa para

$$\widehat{\beta}_{L_0} = \argmin_{\beta_0 \in \mathbb{R}, \beta \in \mathbb{R}^d}\sum_{k = 1}^n\left(y_k - \beta_0 - \sum_{i = 1}^d \beta_i x_{x,i}\right)^2 + \lambda \,\,\underbrace{\sum_{i = 1}^d \mathbb{I}(\beta_i \neq 0)}_{\text{Penaliza√ß√£o}}.$$ {#eq-risco-penalizacao}

Note que a penaliza√ß√£o $\sum_{i = 1}^d \mathbb{I}(\beta_i \neq 0)$ nos
conduz na dire√ß√£o de modelos com poucas covari√°veis, quando $\lambda$ √©
um valor alto. Em particualr, quando $\lambda \to \infty$, for√ßamos a
retirada de todas as covari√°veis $\beta_i$'s, i.e., a solu√ß√£o para o
problema seria $\widehat{\beta}_{L_0} \equiv (\overline{y}, {\bf 0})$.
Note que n√£o h√° penaliza√ß√£o para o intercepto $\beta_0$.

<br> No outro extremo, para $\lambda = 0$, temos o estimador de m√≠nimos
quadrados, em que nenhuma penaliza√ß√£o ser√° considerada.

<br> [N√£o h√° uma forma f√°cil de minimizar
$\widehat{\beta}_{L_0}$.]{.red}

## Melhor subconjunto de covari√°veis

<br>

Poder√≠amos, ingenuamente, pensar em ajustar todas as combina√ß√µes
poss√≠veis de par√¢metros e utilizar algum crit√©rio, por exemplo, o EQM em
novas observa√ß√µes para escolher o melhor modelo de todas as combina√ß√µes
poss√≠veis. Isto √©, escolher o melhor modelo entre todas as $2^d$
combina√ß√µes poss√≠veis de modelos em $\mathbb{G}$.

<br>

Se $\widehat{\lambda} = \frac{2}{n}\widehat{\sigma}^2$, estimar
$\widehat{\beta}_{L_0}$ equivale uma busca entre $2^d$ modelos da classe
$\mathbb{G}$:

<br>

```{=tex}
\begin{align*}
\mathbb{G} = \{
&g({\bf x}) = \widehat{\beta}_0, \\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_2x_2,\\
&\cdots\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_dx_d,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_2x_2,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_3x_3,\\
&\cdots\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_dx_d,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_2x_2 + \widehat{\beta}_3x_3,\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_2x_2 + \widehat{\beta}_dx_d,\\
&\cdots\\
&g({\bf x}) = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_2x_2 + \widehat{\beta}_3x_3 + \cdots + &\widehat{\beta}_dx_d
\}.
\end{align*}
```
## Melhor subconjunto de covari√°veis

<br>

Utilizar $\lambda = \frac{2}{n}\widehat{\sigma}^2$ √© o mesmo que
utilizar o crit√©rio AIC para determinar o melhor modelo, em que dado

$$\widehat{R}(g) = \frac{1}{m}\sum_{k = 1}^m \underbrace{(\widetilde{Y}_k - g({\bf \widetilde{X}}_k))^2}_{W_k},$$
em que
$(\widetilde{{\bf X}}_1, \widetilde{Y}_1), \cdots, (\widetilde{{\bf X}}_m, \widetilde{Y}_m)$,
representa o conjunto de teste, i.e., calculado com base em $m$
observa√ß√µes em um conjundo de dados n√£o utilizados para treinar o
modelo, independentemente da estrat√©gia de divis√£o utilizada, em que

$$\widehat{\sigma}^2 = \frac{1}{m}\sum_{k = 1}^m (W_k - \overline{W})^2,$$
com $\overline{W} = \frac{1}{m}\sum_{k=1}^m W_k$.

## Melhor subconjunto de covari√°veis

<br>

Temos que $\widehat{R}(g)$, calculado em novas observa√ß√µes (oboserva√ß√µes
n√£o utilizadas no treinamento), pode se valer do Teorema Central do
Limite, uma vez que $\widehat{R}(g)$ √© calculado em uma sequ√™ncia de
vari√°veis aleat√≥rias i.i.d.'s. Ent√£o:

$$\widehat{R}(g) \sim \text{Normal}\left(R(g), \frac{1}{m}\mathbb{V}[W_1]\right).$$

Portanto, um intervalo aleat√≥rio de aproximadamente $95\%$ de confian√ßa
para o erro preditivo $R(g)$ poder√° ser calculado como:

$$\widehat{R}(g) \pm 1,645 \sqrt{\frac{1}{m}\widehat{\sigma}^2}.$$

O c√°lculo de um intervalo de confian√ßa poder√° ser √∫til para entendermos
como est√° variando o risco preditivo do nosso modelo. Gostamos de ter
modelos com intervalo de amplitude pequena. O intervalo poder√° ser
utilizado para fornecer insight de como escolher a divis√£o de
treinamento e teste. Por exemplo, pode-se escolher o menor valor de $m$
de modo que a amplitude seja a menor poss√≠vel.

## Melhor subconjunto de covari√°veis

<br>

Por que essa seria uma escolha ing√™nua? Pense na situa√ß√£o em que temos
$d = 30$, i.e., trinta covari√°veis. Ter√≠amos portanto $2^{30}$ modelos
para ajustar, ou seja, um bilh√£o e setenta e tr√™s milh√µes, setecentos e
quarenta e um mil, oitocentos e vinte e quatro modelos para ajustar. √â
um a quantidade absurda de modelos para serem estimados!

<br>

Se $d = 100$, ter√≠amos que estimar uma quantidade de modelos que a
quantidade estimada de estrelas no universo. Alias, seriam mais modelos
para ajustar que a quantidade de √°tomos no universo.

<br>

![](gifs/side-eyeing-chloe-chloe.gif)

## Regress√£o *Stepwise*

<br> Devido a impossibilidade de experimentar uma grande quantidade de
modelos ($2^d$), existe uma s√©rie de algoritmos (heur√≠sticas), que visam
reduzir a quantidade de modelos avaliados. Um dos mais conhecidos √© o
[forward stepwise]{.red}. Trata-se de um algoritmo sequencial, que em
cada passo, apenas uma vari√°vel √© adicionada:

<br>

1 - Para $j = 1, \cdots, d$, ajuste a regress√£o de $Y$ na $j$-√©sima
vari√°vel $X_j$. Seja $\widehat{R}(g_j)$ o risco estimado desta fun√ß√£o.
Ent√£o,

$$\widehat{j} = \argmin_j \widehat{R}(g_j)\,\,\,\,\,\, \text{e}\,\,\,\,\,\, S = \{\widehat{j}\}.$$
2 - Para cada $j \in S^c$, ajuste a regress√£o
$Y = \beta_jX_j + \sum_{s \in S}\beta_sX_S$, em que $\widehat{R}(g_j)$ √©
o risco estimado desta fun√ß√£o. Defina

$$\widehat{j} = \argmin_{j \in S^c} \widehat{R}(g_j)\,\,\,\,\,\, \text{e atualize}\,\,\,\,\,\, S \leftarrow \{S \cup \widehat{j}\}.$$

3 - Repita os passos anteriores at√© que todas as vari√°veis estejam em
$S$ ou at√© quando n√£o seja mais poss√≠vel ajustar o modelo de regress√£o.

4 - Selecione o modelo com menor risco estimado.

## Regress√£o *Stepwise*

<br>

Utilizar o algoritmo de sele√ß√£o de vari√°veis [*foward stepwise*]{.red},
ao inv√©s de buscarmos o melhor ajuste entre $2^d$ poss√≠veis modelos, que
muitas vezes √© imposs√≠vel, precisaremos investigar apenas
$1 + d(d + 1)/2$ modelos. Reduzimos a complexidade da sele√ß√£o que antes
era um problema exponencial. Melhor, n√£o?!

<br>

![](gifs/bom.gif)

## Penaliza√ß√£o

<br>

Quando temos modelos que envolve $d$ par√¢metros e que temos controle
sobre eles (conhecemos muito bem cada um deles), acrescentar algum tipo
de penaliza√ß√£o √† fun√ß√£o objetivo poder√° ser √∫til. A penaliza√ß√£o √© uma
[medida de complexidade]{.red}, em que √© √∫til para equilibrar o modelo,
de modo a tentar buscar um equilibrio entre vi√©s e vari√¢ncia, discutidos
anteriormente. Assim, sob novas observa√ß√µes, desejamos estimar o risco
$R(g)$, por

<br>

$$R(g) \approx EQM(g) + \mathcal{P}(g).$$

<br>

Desejamos minimiar $R(g)$, mas n√£o a custa de muitos par√¢metros, pois
assim ter√≠amos [overfitting]{.red}. Portanto, para muitos par√¢metros
temos que ter EQM baixo, por√©m, $\mathcal{P}(g)$ deve ser alto. J√° em
modelos viesados, quando temos poucos par√¢metros, o EQM normalmente √©
alto, mas a complexidade $\mathcal{P}(g)$ deve ser baixo, pois temos um
modelo mais simplista.

## AIC e BIC

<br>

Existem diversas penaliza√ß√µes, em que o AIC (**A**kaike **I**nformation
**C**riterion) e BIC (**B**ayesian **I**nformation **C**riterion) s√£o as
mais conhecidas. Com base nesses crit√©rios, temos que

<br>

::: {columns}
::: {.column width="30%"}
1.  [AIC]{.red}: $$EQM + \frac{2}{n\,d\, \widehat{\sigma}^2}.$$
2.  [BIC]{.red}: $$EQM + \frac{\log(n)}{n\, d\, \widehat{\sigma}^2}.$$
:::

::: {.column width="70%"}
$$\widehat{\sigma}^2 = \frac{1}{m}\sum_{k = 1}^m (W_k - \overline{W})^2.$$
:::
:::

<br>

Aqui, $d$ √© a quantidade de par√¢metros no modelo e $\widehat{\sigma}^2$
√© uma estimativa da vari√¢ncia do erro, que para um conjunto de teste
suficientemente grande, poder√° ser considerado o estimador de
$\widehat{\sigma}^2$ conforme descrito anteriormente. Segundo [James,
Gareth, et al. An introduction to statistical learning. Ed. 2, p.
233](https://hastie.su.domains/ISLR2/ISLRv2_corrected_June_2023.pdf),
assume-se o modelo com todos os preditores para o c√°lculo de
$\widehat{\sigma}^2$.

## Lasso

<br>

::: columns
::: {.column width="50%"}
O lasso foi desenvolvido pelo Robert Tibshirani, em um artigo publicado
no artigo [Regression Shrinkage and Selection via the
Lasso](https://www.jstor.org/stable/2346178).

![](imgs/lasso.png)
:::

::: {.column width="50%"}
![](imgs/P55268-Robert-Tibshirani.jpg){width="60%"}
:::
:::

## Lasso

<br>

O lasso tem como objetivo encontrar um estimador de uma regress√£o linear
que possui risco menor que o de m√≠nimos quadrados, possuindo duas
grandes vantagens, em rela√ß√£o ao *stepwise*:

<br>

1.  Sua solu√ß√£o √© mais r√°pida, ainda que *stepwise* seja
    consideravalmente mais r√°pido do que avaliar $2^d$ modelos;
2.  O lasso √© capaz de selecionar automaticamente as vari√°veis mais
    relevantes para o modelo, reduzindo a dimensionalidade dos dados.

<br>

A segunda vantagem ocorre, uma vez que ele realiza uma penaliza√ß√£o que
leva √† estimativas de alguns coeficientes $\beta_i$ igual a zero,
eliminando as vari√°veis menos importantes.

<br>

![](gifs/uau.gif)

## Lasso

<br>

No lasso, ao inv√©s de reduzir a vari√¢ncia do estimador de m√≠nimos
quadrados usando a complexidade
($L_0 = \sum_{i = 1}^d\mathbb{I}(\beta_i) \neq 0$) em
@eq-risco-penalizacao, usa-se a penaliza√ß√£o
$L_1 = \sum_{i = 1}^d|\beta_i|$. No lasso, buscamos:

$$\widehat{\beta}_{L_1,\lambda} = \argmin_{\beta_0 \in \mathbb{R}, \beta \in \mathbb{R}^d}\sum_{k = 1}^n\left(y_k - \beta_0 - \sum_{i = 1}^d \beta_i x_{x,i}\right)^2 + \lambda \,\,\underbrace{\sum_{j = 1}^d|\beta_j|}_{\text{Penaliza√ß√£o}},$$
em que $\lambda$ √© um *tuning parameter*. Perceba que quando
$\lambda = 0$, ca√≠mos no caso do modelo de regress√£o por m√≠nimos
quadrados sem penaliza√ß√£o. J√°, quando $\lambda \rightarrow \infty$,
temos um modelo em que todas as vari√°veis s√£o removidas, uma vez que a
primeira parte do modelo torna-se insignificante.

## Lasso

<br> <br>

Quando $\lambda$ √© grande, temos que

$$\sum_{k = 1}^n \left(y_k - \beta_0 - \sum_{j = 1}^d \beta_j x_{k,j}\right)^2 + \lambda \sum_{j = 1}^d |\beta_j| \approx \lambda \sum_{j = 1}^d |\beta_j|,$$
e portanto, $\widehat{\beta}_1 = 0, \cdots, \widehat{\beta}_d = 0$.

<br>

A escolha de $\lambda$, em geral, √© feita utilizado algum m√©todo de
valida√ß√£o cruzada.

## Lasso

<br>

O lasso √© extremamente r√°pido, e nos √∫ltimos anos, diversos algoritmos
foram constru√≠dos para fazer essa tar√©fa de forma eficiente. O LARS foi
um dos primeiros algoritmos desenvolvidos em 2010. Para detalhes, ler
[Friedman, J. H. (2001). Greedy function approximation: a gradient
boosting machine. Annals of statistics,
1189--1232](https://www.jstor.org/stable/2699986).

<br>

No R, a regress√£o lasso poder√° ser feita usando a biblioteca
[glmnet](https://cran.r-project.org/web/packages/glmnet/index.html),
assim:

<br>

```{r}
#| eval: false
library(glmnet)
ajuste <- cv.glmnet(x, y, alpha = 1)
```

<br>

![](gifs/teclado-anime.gif){width="21%"}

## Ridge

<br>

Uma alternativa que surgiu antes do lasso √© a [regress√£o ridge]{.red}.
Ela foi proposta no artigo [Hoerl, A. E. & Kennard, R. W. (1970). Ridge
regression: Biased estimation for nonorthogonal problems. Technometrics,
12(1), 55--67](https://www.jstor.org/stable/1267351). Aqui, utiliza-se
como medida de complexidade a norma $L_2$, em que, o estimador √© dado
por:

$$\widehat{\beta}_{L_2,\lambda} = \argmin_{\beta_0 \in \mathbb{R}, \beta \in \mathbb{R}^d}\sum_{k = 1}^n\left(y_k - \beta_0 - \sum_{i = 1}^d \beta_i x_{x,i}\right)^2 + \lambda \,\,\underbrace{\sum_{j = 1}^d\beta_j^2}_{\text{Penaliza√ß√£o}}.$$
Diferentemente do lasso, a regress√£o ridge possui solu√ß√£o anal√≠tica,
dada por:

$$\widehat{\beta}_{L_2,\lambda} = ({\bf X}^{T}{\bf X} + \lambda\mathbb{\bf I}_0)^{-1}{\bf X}^{T}Y,$$
em que $\mathbb{\bf I}_0$ √© a matriz identidade $(d + 1) \times (d + 1)$
com $\mathbb{\bf I}_0(1,1) = 0$.

<br>

## Ridge

<br>

A regress√£o ridge poder√° ter uma vari√¢ncia menor que a regress√£o lasso,
por√©m seu vi√©s poder√° ser maior. Outra caracter√≠stica da regress√£o ridge
√© que ela possue uma √∫nica solu√ß√£o, enquanto a regress√£o lasso poder√°
ter multiplas solu√ß√µes. Os autores tamb√©m demonstram que a regress√£o
ridge lida melhor com multicolinearidade.

<br>

No R, tamb√©m poderemos utilizar a biblioteca
[glmnet](https://cran.r-project.org/web/packages/glmnet/index.html):

<br>

```{r}
#| eval: false
library(glmnet)
ajuste <- cv.glmnet(x, y, alpha = 0)
```

<br>

![](gifs/teclado-anime.gif){width="21%"}

## Elastic Net

<br>

Nesse tipo de modelo de gress√£o, combina-se as penaliza√ß√µes da regress√£o
ridge com a utilizada na regress√£o lasso, herdando os benef√≠cios do uso
de cada um dos m√©todos isoladamente, melhorando a estabilidade das
estimativas do lasso, em situa√ß√µes de multicolinearidade entre as
vari√°veis e tamb√©m permitindo a sele√ß√£o autom√°tica de vari√°veis.

$$(1-\alpha)\widehat{\beta}_{L_2,\lambda} + \alpha\widehat{\beta}_{L_1,\lambda},$$
em que $0 \leq \alpha \leq1$. Em R, basta especificar para a fun√ß√£o
`glmnet` um valor de $\alpha$ diferente de 0 e 1.

<br>

![](gifs/teclado-anime.gif){width="21%"}

## Exemplo: EMQ, Ridge, Lasso e Elastic Net

<br>

[Exemplo]{.red}: Considere uma base de dados simulada, com $n = 500$
observa√ß√µes, de tal forma que

$$Y = 3X_{1} - 2X_2 + X_3 + -3X_4 + X_5 + \sum_{i = 6}^{20}0X_i + \varepsilon,$$
em que $\varepsilon \sim \text{Normal}(0, 0.5^2)$ e
$X_i \sim \text{Normal}(0, 1)$, independentes, com $i = 1, \cdots, 20$.
Desejamos ajustar quatro modelos de regress√£o. Para o caso do Estimador
de M√≠nimos Quadrados - EMQ e do modelo Ridge, que n√£o tem sele√ß√£o
autom√°tica de vari√°veis, usaremos **todas** as vari√°veis. Desejamos
avaliar o risco estimado de cada uma das regress√µes.

![](gifs/teclado-anime.gif){width="21%"}

## Exemplo: EMQ, Ridge, Lasso e Elastic Net

<br>

```{r}
#| code-fold: true
#| code-summary: "Solu√ß√£o utilizando o tidymodels"
#| eval: false
library(tidymodels)
library(tibble)
library(purrr)
library(ggplot2)
library(patchwork)

# Removendo poss√≠veis conflitos de pacotes --------------------------------
tidymodels::tidymodels_prefer()

# Fun√ß√£o para gerar os dados ----------------------------------------------
gerando_dados <- function(n = 300L){
  regressao <- function(i){
    x <- rnorm(n = 5L)
    y <- 3*x[1L] - 2*x[2L] + x[3L] - 3*x[4L] + x[5L] + rnorm(1L, 0, 0.5)
    tibble(
      y = y,
      x1 = x[1L],
      x2 = x[2L],
      x3 = x[3L],
      x4 = x[4L],
      x5 = x[5L]
    )
  }
  dados <- purrr::map(.x = 1L:n, .f = regressao) |> 
    purrr::list_rbind()
  
  parte_esparsa <- matrix(0, n, 15)
  
  dados <- cbind(dados, parte_esparsa)
  colnames(dados) <- c("y", paste0("x", 2L:ncol(dados)))
  as_tibble(dados)
}

dados <- gerando_dados(n = 500)

# Divis√£o inicial da base -------------------------------------------------
hod_out <- initial_split(dados, prop = 0.7)
treinamento <- training(hod_out)
teste <- testing(hod_out)

# Setando o modelo (set engine) -------------------------------------------
modelo_eqm <- 
  linear_reg(penalty = 0, mixture = 0) |> 
  set_mode("regression") |> 
  set_engine("glmnet")
  
modelo_ridge <- 
  linear_reg(penalty = tune::tune(), mixture = 0) |> 
  set_mode("regression") |> 
  set_engine("glmnet")

modelo_lasso <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) |> 
  set_mode("regression") |> 
  parsnip::set_engine("glmnet")
  
modelo_elastic <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) |> 
  set_mode("regression") |> 
  parsnip::set_engine("glmnet")

# Criando workflows -------------------------------------------------------
all_wf <- 
  workflow_set(
    preproc = list(y ~ . ),
    models = list(eqm = modelo_eqm, ridge = modelo_ridge, lasso = modelo_lasso, elastic = modelo_elastic), 
    cross = TRUE
  )

# Valida√ß√£o cruzada -------------------------------------------------------
set.seed(0)
cv <- rsample::vfold_cv(treinamento, v = 5L)

# Setando a m√©trica -------------------------------------------------------
metrica <- yardstick::metric_set(rmse)

# Tunagem dos hiperpar√¢metros ---------------------------------------------
# A semente (seed = 0) faz com que dentro da valida√ß√£o cruzada para cada modelo
# a semente seja sempre a mesma.
tunagem <- 
  all_wf |> 
  workflow_map(
    seed = 0, 
    verbose = TRUE,
    resamples = cv,
    grid = 50,
    metrics = metrica
  )

# Rank dos melhores modelos -----------------------------------------------
modelos_rank <- tunagem |> rank_results()

melhor_eqm <- 
  tunagem |> 
  extract_workflow_set_result("formula_eqm") |> 
  select_best("rmse")

melhor_ridge <- 
  tunagem |> 
  extract_workflow_set_result("formula_ridge") |> 
  select_best("rmse")

melhor_lasso <- 
  tunagem |> 
  extract_workflow_set_result("formula_lasso") |> 
  select_best("rmse")

melhor_elastic <- 
  tunagem |> 
  extract_workflow_set_result("formula_elastic") |> 
  select_best("rmse")

finalizando_eqm <- 
  tunagem |> 
  extract_workflow("formula_eqm") |> 
  finalize_workflow(melhor_eqm) |> 
  last_fit(split = hod_out)

finalizando_ridge <- 
  tunagem |> 
  extract_workflow("formula_ridge") |> 
  finalize_workflow(melhor_ridge) |> 
  last_fit(split = hod_out)

finalizando_lasso <- 
  tunagem |> 
  extract_workflow("formula_lasso") |> 
  finalize_workflow(melhor_lasso) |> 
  last_fit(split = hod_out)

finalizando_elastic <- 
  tunagem |> 
  extract_workflow("formula_elastic") |> 
  finalize_workflow(melhor_elastic) |> 
  last_fit(split = hod_out)

# Visualizando as m√©tricas
finalizando_eqm |> collect_metrics()
finalizando_ridge |> collect_metrics()
finalizando_lasso |> collect_metrics()
finalizando_elastic |> collect_metrics()

# Visualizando predi√ß√µes:
finalizando_eqm |> collect_predictions()
finalizando_ridge |> collect_predictions()
finalizando_lasso |> collect_predictions()
finalizando_elastic |> collect_predictions()
```

## `r fontawesome::fa("book", "black")` Exerc√≠cios

<br> [Exerc√≠cio]{.red}: Utilizando os dados de vinho vermelhoüç∑,
dispon√≠veis
[aqui](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009),
fa√ßa uma pequena an√°lise explorat√≥ria dos dados. No
[link](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)
do Kaggle voc√™ consegue uma explica√ß√£o sobre o que significa cada uma
das vari√°veis.

![](gifs/mr-bean-test.gif){width="211"}

## `r fontawesome::fa("book", "black")` Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Utilizando os dados de vinho vermelhoüç∑, dispon√≠veis
[aqui](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009),
obtenha o melhor modelo de regress√£o linar para modelar a qualidade do
vinho, considerando:

<br>

1.  $g_1$ - M√©todo dos m√≠nimos quadrados;
2.  $g_2$ - Regress√£o ridge;
3.  $g_3$ - Regressao lasso;
4.  $g_4$ - Elastic Net.

<br>

Voc√™ dever√° selecionar o melhor modelo de cada uma das classes de
modelos de regress√£o e construir uma tabela com o risco estimado
$\widehat{R}(g_i),\,\, i = 1, \cdots, 4$, em que aqui $g_i$ representa o
modelo geral n√£o estimado. Ao fim, construa quatro gr√°ficos mostrando o
ajuste de cada um dos modelos.

<br>

[Exerc√≠cio]{.red}: Se voc√™ utilizou o
[tidymodels](https://www.tidymodels.org/) para resolver o exerc√≠cio
anterior, rafa√ßa usando a biblioteca
[glmnet](https://cran.r-project.org/web/packages/glmnet/index.html).
Caso contr√°rio, resolva-o utilizando o
[tidymodels](https://www.tidymodels.org/).

## `r fontawesome::fa("book", "black")` Exerc√≠cios

<br>

[Exerc√≠cio]{.red}: Considere agora o conjunto de dados de despesas
m√©dicas, dispon√≠vel
[aqui](https://www.kaggle.com/datasets/mirichoi0218/insurance), refa√ßa o
mesmo exerc√≠cio dos dados de vinho vermelho, em que aqui, o objetivo √©
prever a vari√°vel `charges`. Perceba que algumas vari√°veis s√£o
qualitativas, e port√£o, voc√™ dever√° transform√°-las em [*dummy*]{.red}.
Indique os melhores cen√°rios dos quatro modelos e informe qual modelo
voc√™ utilizaria. Explique!

<br>

![](gifs/bean_simple.gif)

## M√©todos n√£o-param√©tricos

<br>

M√©todos param√©tricos podem impor muitas limita√ß√µes na solu√ß√£o de um problema de regress√£o, i.e., em problemas que desejamos estimar a fun√ß√£o de regress√£o $r({\bf x})$. Por exemplo, nem sempre o melhor estimador linear √© um bom estimador para $r({\bf x})$.

<br>

M√©todos param√©tricos s√£o muitas vezes simplistas e restritivos, em que normalmente abrimos m√£os para se ter um estimador um pouco mais viesado, em detrimento da diminui√ß√£o da vari√¢ncia do modelo. Por exemplo, nas regress√µes penalizadas que vimos anteriormente (**ridge**, **lasso** e **elastic-net**), penalizamos modelos com muitas covari√°veis o que naturalmente aumentar√° o vi√©s, na maioria das vezes.

<br>

![](gifs/hum.gif)

## M√©todos n√£o-param√©tricos

<br>

Em situa√ß√µes em que temos muitos dados ($n$ grande), os modelos n√£o-param√©tricos possuem, em geral, boa peformance, uma vez que apesar de que nessa classe de modelos existir um aumento da vari√¢ncia, por√©m, seguida de uma redu√ß√£o de vi√©s, a vari√¢ncia do modelo n√£o aumenta muito.

<br>

De um lado, nos modelos de regress√£o que vimos at√© o momento, introduzimos uma penaliza√ß√£o para diminuir a vari√¢ncia do modelo frente ao m√©todo dos m√≠nimos quadrados (quando n√£o usamos penaliza√ß√£o) em troca de um aumento no v√≠es. Aqui, em modelos n√£o param√©tricos, desejamos fazer a troca oposta, i.e., diminuir o vi√©s, em troca de um ganho na vari√¢ncia no modelo.

<br>

Qualquer abordagem param√©trica tr√°s consigo a possibilidade de que a forma funcional $g$ para estimar $f$ seja muito diferente da verdadeira, claro, se o modelo resultante n√£o se ajustar bem aos dados, isto √© $\widehat{g}$ n√£o tem boa capacidade preditiva, muito embora, tamb√©m √© poss√≠vel que tenhamos $\widehat{g}$ com boa capacidade preditiva, por√©m, n√£o represente a estrutura real de $f$ (sempre desconhecida). 

## M√©todos n√£o-param√©tricos

<br>
<br>

Isso n√£o √© regra, por√©m ajuda a entender um pouco o dilema entre essas classes de modelos (param√©tricos e n√£o-param√©tricos).

<br>

![](imgs/vies_variancia_nao_parametrico.png){fig-aling='center'}

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Tamb√©m chamado de [*$k$-nearest neighbours* - KNN]{.red}, o KNN √© um dos m√©todos mais populares na comunidade de aprendizagem de m√°quina. O m√©todo foi formulado em uma sequ√™ncia de dois artigos:

<br>

1 - Benedetti, J. K. (1977). **On the nonparametric estimation of regression functions**. Journal of the Royal Statistical Society. Series B (Methodological), 248‚Äì253;

<br>

2 - Stone, C. J. (1977). **Consistent nonparametric regression**. The Annals of Statistics, 595‚Äì
620.

<br>

A ideia do m√©todo √© estimar a fun√ß√£o de regress√£o $r({\bf x})$, para um dado ${\bf x}$ com base nas respostas $Y$ dos $k$-vizinhos mais pr√≥ximos de ${\bf x}$. 


## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Formalmente, temos que

$$g({\bf x^*}) = \frac{1}{k}\sum_{i \in \mathcal{N}_{\bf x^*}}y_i,$$
em que $\mathcal{N}_{\bf x}$ √© o conjunto √≠ndices das $k$ observa√ß√µes mais pr√≥ximas de ${\bf x}$, i.e,

$$\mathcal{N}_{\bf x^*} = \{i \in \{1, \cdots, n\}\, : \, d({\bf x}_i, {\bf x^*}) \leq d_{\bf x^*}^k\},$$
em que $d_{\bf x^*}^k$ √© a dist√¢ncia do $k$-√©simo vizinho mais pr√≥ximo de $\bf{x^*}$ em $\bf{x}$. Portanto, o valor da regress√£o no ponto ${\bf x^*},$ i.e., o valor de $r({\bf x^*}) = \mathbb{E}(Y|{\bf X} = {\bf x^*})$ √© estimado pela m√©dia de $Y_{N_{\bf x^*}}$. Ou seja, estimamos por:

$$\overline{Y}_{N_{\bf x^*}} = \frac{1}{k} \sum_{i \in \mathcal{N}_{\bf x^*}}y_i.$$

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>
<!-- http://leg.ufpr.br/~lucambio/MSM/MSM03.html -->
Para determinar $d_{\bf x^*}^k$, poderemos utilizar alguma m√©trica de dist√¢ncia e assim mensurarmos a proximidade. Entre elas:

<br>

1. [Dist√¢ncia Euclidiana]{.red} ou dist√¢ncia $L_2$: $d(x^a, x^b) = \sqrt{(x_1^a - x_1^b)^2 + \cdots + (x_d^a - x_d^b)^2}$;

<br>

2. [Dist√¢ncia de Manhattan]{.red}, City Block ou dist√¢ncia $L_1$: $d(x^a, x^b) = \sqrt{|x_1^a - x_1^b| + \cdots + |x_d^a - x_d^b|}$;

<br>

2. [Dist√¢ncia de Mahalanobis]{.red}: $d(x^a, x^b) = \sqrt{(x^a - x^b)^{T}S^{-1}(x^a - x^b)}$, em que $S$ √© a matriz de covari√¢ncia, em que na diagonal princial temos as vari√¢ncias e fora dela as covari√¢ncias entre os pontos. Lembre-se que se $x$ e $y$ s√£o vetores de dados quaisquer, a interdepend√™ncia linear entre eles poder√° ser estimada como:

<br>

$$\mathrm{cov}(x, y) = \frac{1}{n-1}\sum_{i = 1}^n (x_i - \overline{x})(y_i - \overline{y}).$$

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Voc√™ poder√° utilizar qualquer outra medida de dist√¢ncia al√©m das que foram citadas acima.

<br>

√â importante perceber que **o m√©todo KNN n√£o faz uma "compress√£o" dos dados** como a regress√£o linear que estudamos. L√°, temos uma equa√ß√£o que utilizamos para estimar o valor de $Y$, ap√≥s as estima√ß√£o dos coeficientes do modelo de regress√£o, ou seja, n√£o precisamos mais dos dados para estimar novas observa√ß√µes. J√° no KNN, precisamos sempre nos recorrer aos dados para fazer novas predi√ß√µes, ou seja, sempre que desejarmos calcular $r({\bf x}) = \mathbb{E}(Y|{\bf X} = {\bf x})$ deveremos sempre fazer uma nova consulta aos dados para calcular a m√©dia dos vizinhos mais pr√≥ximos.

<br>

![](gifs/giphy.gif)

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>
O valor da constante $k$ √© um hiperpar√¢metro do KNN e dever√° ser obtido por valida√ß√£o cruzada. Perceba que se $k = n$ temos um modelo muito viesado, por√©m com vari√¢ncia pequena. Isso, porqu√™ para $k = n$ basicamente iremos tirar uma m√©dia dos dados. Para $k = 1$, teremos um *overfitting*, uma vez que o estimador ir√° interpolar os dados.

<br>
[Exemplo]{.red}: Considere novamente o conjunto de dados de expectativa de vida versus PIB per
Capita dispon√≠veis
[aqui](https://github.com/prdm0/dados/blob/main/dados_expectativa_renda.RData). Utilizando o [tidymodels](https://www.tidymodels.org/), vamos construir uma fu√ß√£o que retorne um gr√°fico com as estimativas do KNN. A fun√ß√£o receber√° como argumentos o conjunto de dados e o valor de $k$. Voc√™ tamb√©m poderia utilizar outras bibliotecas, como por exemplo a [FNN](https://cran.r-project.org/web/packages/FNN/index.html), ou a [KKNN](https://github.com/KlausVigo/kknn), esta √∫tlima √© a que √© utilizada internamente na biblioteca [parsnip](https://parsnip.tidymodels.org/) do [tidymodels](https://www.tidymodels.org/).

<br>

![](imgs/parsnip.png)

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Abrindo apenas um par√™ntese, o [tidymodels](https://www.tidymodels.org/) refere-se a um conjunto de pacotes que s√£o √∫teis para o tratamento, treinamento, tunagem e avalia√ß√£o de modelos de aprendizagem de m√°quina, em que o [parsnip](https://parsnip.tidymodels.org/) implementa as *engines* (algoritmos/motores) que iremos utilizar para treinar um modelo. Na verdade, os algoritmos est√£o implementados em pacotes de terceiros e n√£o precisamente no [parsnip](https://parsnip.tidymodels.org/). Por√©m, o [parsnip](https://parsnip.tidymodels.org/) unifica a sintaxe de diversos algoritmos implementados em pacotes separados.

<br>

![](gifs/thumbs-up-nod.gif)

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Observe que na imagem abaixo, a Figura [A]{.red}, quando $k=1$, percebemos initidamente que houve *overfitting*, i.e., h√° uma interpola√ß√£o dos dados. J√° na Figura [D]{.red} temos um modelo com vari√¢ncia menor, por√©m, este √© muito simplista, o que sugere um alto vi√©s.

<br>

![](imgs/knn_plot.png){fig-aling='center'}

## $k$-vizinhos mais pr√≥ximo pr√≥ximos

<br>

Estude o c√≥digo! Ele fornece a solu√ß√£o para o exemplo.

<br>

```{r}
#| eval: false
#| code-summary: "Solu√ß√£o pelo m√©todo knn do exemplo anterior"
#| code-fold: true

library(tidymodels)
library(glue)
library(dplyr)
library(ggplot2)
library(patchwork)

tidymodels::tidymodels_prefer()

# Lendo dados
url <- "https://github.com/prdm0/dados/raw/main/dados_expectativa_renda.RData"
arquivo_temp <- tempfile()
download.file(url = url, destfile = arquivo_temp)
load(arquivo_temp)

dados <- 
  dados_expectativa_renda |> 
  dplyr::select(-CountryName) |> 
  dplyr::rename(y = LifeExpectancy, x = GDPercapita)

knn_exp_pip <- function(dados, k = 1L){
  # Criando receita
  receita <- recipe(y ~ x, data = dados)
  
  # Definindo o modelo
  modelo_knn <- nearest_neighbor(neighbors = k) |> 
    set_mode("regression") |> 
    set_engine("kknn")
  
  # Workflow
  ajuste_final <- 
    workflow() |> 
    add_model(modelo_knn) |> 
    add_recipe(receita) |> 
    fit(data = dados)
  
  # Retornando previsoes
  y_chapeu <- predict(ajuste_final, new_data = dados)
  
  dados <- 
    dados |> 
    mutate(y_chapeu = y_chapeu$.pred)
  
  dados |> 
    ggplot() +
    geom_point(aes(x = x, y = y), size = 3) +
    geom_line(aes(x = x, y = y_chapeu), col = "red", alpha = 0.6, size = 2) +
    labs(title = "k-nearest neighbours", subtitle = glue("k = {k}")) +
    theme(
      title = element_text(face = "bold")
    )
}

p1 <- knn_exp_pip(dados, k = 1L)
p2 <- knn_exp_pip(dados, k = 7L)
p3 <- knn_exp_pip(dados, k = 10L)
p4 <- knn_exp_pip(dados, k = 200L)

p <- p1 + p2 + p3 + p4 + plot_annotation(tag_levels = "A")

ggsave(p, file = "imgs/knn_plot.png", width = 50, height = 30, units = "cm")
```
<br>

![](gifs/chapulin-colorado-no.gif){width='25%'}
