---
title: "Suport Vector Regression Machine - SVRM"
subtitle: "Comparando com outros modelos"
date: "`r Sys.Date()`"
lang: pt
author: "Prof. Dr. Pedro Rafael D. Marinho"
format:
  html:
    grid:
      margin-width: 350px
  pdf: default
reference-location: margin
citation-location: margin
---

## Carregando bibliotecas necess√°rias

```{r}
library(tidymodels)
library(tidyverse)
library(GGally)
library(skimr)

# Resolvendo poss√≠veis conflitos entre o tidymodels e outras bibliotecas
tidymodels::tidymodels_prefer()
```

## Importando a base de dados

Utilizando os dados de vinho vermelhoüç∑,
dispon√≠veis
[aqui](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009),
fa√ßa uma pequena an√°lise explorat√≥ria dos dados. No
[link](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)
do Kaggle voc√™ consegue uma explica√ß√£o sobre o que significa cada uma
das vari√°veis.

Os dados, no meu caso, est√£o no diret√≥rio `"../dados/winequality-red.csv"`. Voc√™
dever√° alterar o *path* para o diret√≥rio encontra-se a base que dever√° ser obtida
no link acima.

```{r}
dados <- readr::read_csv(file = "../dados/winequality-red.csv")
```
## Uma explora√ß√£o r√°pida dos dados

√â sempre importante olhar os dados antes de tentar modelar. Uma an√°lise explorat√≥ria
sempre ser√° √∫til para identificarmos poss√≠veis inconsist√™ncias.

```{r}
visdat::vis_dat(dados)
```

O gr√°fico acima mostra que temos uma base de dados sem informa√ß√µes faltantes e todas as *features*
presentes na base s√£o num√©ricas. √â uma situa√ß√£o confort√°vel, haja vista que, aqui, n√£o precisaremos
nos preocupar com imputa√ß√£o de dados faltantes.

Um resumo dos dados poder√° ser obtido utilizando a fun√ß√£o `glimpse` do pacote **dplyr** que √© carregado
com a biblioteca **tidyverse** de R.

```{r}
dados |> 
  dplyr::glimpse()
```

√â poss√≠vel todas as correla√ß√µes entre todas as vari√°veis da base, com a fun√ß√£o `data_vis_cor`. Um gr√°fico √∫til com as correla√ß√µes poder√° ser obtido usando a fun√ß√£o `vis_cor`, conforme abaixo:

```{r}
visdat::data_vis_cor(dados)
visdat::vis_cor(dados)
```

As bibliotecas **GGally** e **skimr** tamb√©m possuem fun√ß√µes √∫teis que podem nos 
auxiliar no processo de explora√ß√£o dos dados.

```{r}
dados |> 
  GGally::ggpairs()

dados |> 
  skimr::skim()
```

## Construindo os workflows dos modelos

Iremos comparar os modelos de regress√£o linar utilizando *elastic net*, com o m√©todo $k$NN e *suport vector regression machine* - SVRM. Buscaremos pelo melhor modelo de cada uma das metodologias consideradas. Posteriormente iremos escolher o melhor modelo entre os melhores de cada uma das classes. A ideia √© escolher o melhor modelo que consiga prever melhor a qualidade do vinho, i.e., prever a vari√°vel `quality`.

### Parti√ß√£o dos dados

Como sabemos, precisamos dividir nossa base de dados em conjunto de treinamento, em que nesse conjunto iremos ser√° realizado o procedimento de valida√ß√£o cruzada e uma base de dados de teste para a avalia√ß√£o final dos nossos modelos. Deixaremos $80\%$ para o treniamento do modelo e $20\%$ para teste. Iremos estratificar nossa amostra usando a vari√°vel `quality`, vari√°vel que queremos estimar (*label*/r√≥tulo).

```{r}
divisao <- rsample::initial_split(dados, prop = 0.8, strata = "quality")
treinamento <- rsample::training(divisao)
teste <- rsample::testing(divisao)
```

### Definindo os modelos

O c√≥digo que segue faz a configura√ß√£o realiza a configura√ß√£o dos modelos que ser√£o
comparados. O c√≥digo `tune::tune()` especifica que o respectivo par√¢metro de sintoniza√ß√£o
ser√° obtido no processo de valida√ß√£o cruzada, particularmente, um *grid search*.

```{r}
modelo_elastic <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("glmnet")

modelo_knn <-
  parsnip::nearest_neighbor(
    neighbors = tune::tune(),
    dist_power = tune::tune(), 
    weight_func = "gaussian" 
  ) |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("kknn")

modelo_svm <- 
  parsnip::svm_rbf(
    cost = tune::tune(),
    rbf_sigma = tune::tune(),
    margin = tune::tune()
  ) |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("kernlab")
```

