---
title: "Suport Vector Regression Machine - SVRM"
subtitle: "Comparando com outros modelos"
date: "`r Sys.Date()`"
lang: pt
author: "Prof. Dr. Pedro Rafael D. Marinho"
format:
  html:
    grid:
      margin-width: 350px
  pdf: default
reference-location: margin
citation-location: margin
editor: 
  markdown: 
    wrap: 72
---

## Carregando bibliotecas necess√°rias

```{r cache=TRUE}
library(tidymodels)
library(tidyverse)
library(GGally)
library(skimr)

# Resolvendo poss√≠veis conflitos entre o tidymodels e outras bibliotecas
tidymodels::tidymodels_prefer()
```

## Importando a base de dados

Utilizando os dados de vinho vermelhoüç∑, dispon√≠veis
[aqui](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009),
fa√ßa uma pequena an√°lise explorat√≥ria dos dados. No
[link](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)
do Kaggle voc√™ consegue uma explica√ß√£o sobre o que significa cada uma
das vari√°veis.

Os dados, no meu caso, est√£o no diret√≥rio
`"../dados/winequality-red.csv"`. Voc√™ dever√° alterar o *path* para o
diret√≥rio encontra-se a base que dever√° ser obtida no link acima.

```{r}
dados <- readr::read_csv(file = "../dados/winequality-red.csv")
```

## Uma explora√ß√£o r√°pida dos dados

√â sempre importante olhar os dados antes de tentar modelar. Uma an√°lise
explorat√≥ria sempre ser√° √∫til para identificarmos poss√≠veis
inconsist√™ncias.

```{r}
visdat::vis_dat(dados)
```

O gr√°fico acima mostra que temos uma base de dados sem informa√ß√µes
faltantes e todas as *features* presentes na base s√£o num√©ricas. √â uma
situa√ß√£o confort√°vel, haja vista que, aqui, n√£o precisaremos nos
preocupar com imputa√ß√£o de dados faltantes.

Um resumo dos dados poder√° ser obtido utilizando a fun√ß√£o `glimpse` do
pacote **dplyr** que √© carregado com a biblioteca **tidyverse** de R.

```{r}
dados |> 
  dplyr::glimpse()
```

√â poss√≠vel todas as correla√ß√µes entre todas as vari√°veis da base, com a
fun√ß√£o `data_vis_cor`. Um gr√°fico √∫til com as correla√ß√µes poder√° ser
obtido usando a fun√ß√£o `vis_cor`, conforme abaixo:

```{r}
visdat::data_vis_cor(dados)
visdat::vis_cor(dados)
```

Um gr√°fico de scatterplot para as vari√°veis num√©ricas poder√° ser √∫til.
Voc√™ poder√° fazer isso, usando a fun√ß√£o `ggcatmat` do pacote
[GGally](https://ggobi.github.io/ggally/index.html).

```{r}
dados |> 
  GGally::ggscatmat()
```

As bibliotecas **GGally** e **skimr** tamb√©m possuem fun√ß√µes √∫teis que
podem nos auxiliar no processo de explora√ß√£o dos dados.

```{r}
dados |> 
  GGally::ggpairs()

dados |> 
  skimr::skim()
```

## Construindo os workflows dos modelos

Iremos comparar os modelos de regress√£o linar utilizando *elastic net*,
com o m√©todo $k$NN e *suport vector regression machine* - SVRM.
Buscaremos pelo melhor modelo de cada uma das metodologias consideradas.
Posteriormente iremos escolher o melhor modelo entre os melhores de cada
uma das classes. A ideia √© escolher o melhor modelo que consiga prever
melhor a qualidade do vinho, i.e., prever a vari√°vel `quality`.

### Tratamento dos dados

Apesar de n√£o haver muito o que fazer nos dados que estamos utilizando
nesse exemplo, em que nosso objetivo aqui √© ter uma an√°lise explicativa
de como comparar modelos usando o
[tidymodels](https://www.tidymodels.org/), iremos utilizar a biblioteca
[recipes](https://recipes.tidymodels.org/). Os dados cont√©m apenas
vari√°veis num√©ricas com todas informa√ß√µes presentes, tornando o problema
um pouco mais simples.

**Na receita, iremos colocar as seguintes etapas**:

1.  Tomaremos o logar√≠tmo de todas as vari√°veis peditoras (*features*);
2.  Remover vari√°veis preditoras (*features*) que eventualmente est√£o
    altamente correlacionadas (usando a fun√ß√£o `step_corr`);
3.  Remover vari√°veis que possam ter vari√¢ncia pr√≥xima √† zero, i.e., que
    sejam aproximadamente constantes (usando `step_zv`);
4.  Normalizar os dados utilizando a fun√ß√£o `step_normalize`.

Para que iremos remover vari√°veis altamente correlacionadas apenas nas
vari√°veis preditoras, utilizamos a fun√ß√£o `all_predictors` como
argumentod a fun√ß√£o `step_corr`. J√° no passo de normaliza√ß√£o dos dados,
quando consideramos todas as vari√°veis num√©ricas, passamos para a fun√ß√£o
`step_normalize` a fun√ß√£o `all_numeric` que especifica que dever√° ser
normalizado todas as vari√°veis num√©ricas. Na verdade, a normaliza√ß√£o se
d√° em todas as vari√°veis num√©ricas, e portanto, esse argumento poderia
ser omitido. Al√©m disso, toda nossa base √© formada por vari√°veis
num√©ricas, o que torna redundante o uso, mas irei deixar expl√≠cito que
todas as vari√°veis num√©ricas est√£o sendo normalizadas.

```{r}
receita <- 
  dados |> 
  recipe(formula = quality ~ .)
```


**Como fazemos para observar se nosso pr√©-processamento funcionou?**

![](/gifs/hum.gif)

### Parti√ß√£o dos dados

Como sabemos, precisamos dividir nossa base de dados em conjunto de
treinamento, em que nesse conjunto iremos ser√° realizado o procedimento
de valida√ß√£o cruzada e uma base de dados de teste para a avalia√ß√£o final
dos nossos modelos. Deixaremos $80\%$ para o treniamento do modelo e
$20\%$ para teste. Iremos estratificar nossa amostra usando a vari√°vel
`quality`, vari√°vel que queremos estimar (*label*/r√≥tulo).

```{r}
divisao <- rsample::initial_split(dados, prop = 0.8, strata = "quality")
treinamento <- rsample::training(divisao)
teste <- rsample::testing(divisao)
```

### Definindo os modelos

O c√≥digo que segue faz a configura√ß√£o realiza a configura√ß√£o dos modelos
que ser√£o comparados. O c√≥digo `tune::tune()` especifica que o
respectivo par√¢metro de sintoniza√ß√£o ser√° obtido no processo de
valida√ß√£o cruzada, particularmente, um *grid search*.

```{r}
modelo_elastic <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("glmnet")

modelo_knn <-
  parsnip::nearest_neighbor(
    neighbors = tune::tune(),
    dist_power = tune::tune(), 
    weight_func = "gaussian" 
  ) |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("kknn")

modelo_svm <- 
  parsnip::svm_rbf(
    cost = tune::tune(),
    rbf_sigma = tune::tune(),
    margin = tune::tune()
  ) |> 
  parsnip::set_mode("regression") |> 
  parsnip::set_engine("kernlab")
```
